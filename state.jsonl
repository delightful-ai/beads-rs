{"id":"bd-0863","created_at":[1768680748707,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright foundation: production harness + drift guard","description":"**Problem**\nStateright models are isolated in `beads_stateright_models` with toy types and custom logic. There is no compile-time guarantee that models stay in sync with production, and no shared harness to reuse production code paths.\n\n**Context**\n- Prod logic to reuse: `src/core/event.rs`, `src/core/watermark.rs`, `src/core/apply.rs`, `src/daemon/repl/gap_buffer.rs`, `src/daemon/repl/peer_acks.rs`, `src/daemon/durability_coordinator.rs`, `src/daemon/wal/*`, `src/test_harness/mod.rs`\n- Stateright actor system + network semantics: `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor.rs`, `src/actor/model.rs`, `src/actor/network.rs`\n\n**Goal**\nCreate a minimal production-backed modeling harness and a drift guard so any prod change breaks model compilation.","design":"**Design**\n1) Add a feature-gated modeling harness in the main crate (e.g. `feature = \"model-testing\"`).\n   - New module `src/model/` that exposes only *pure* adapters used by Stateright models.\n   - APIs should wrap production functions, not re-implement logic.\n   - Example helpers:\n     - `model::event_factory` → build canonical `EventBody` + `EventFrameV1` using `encode_event_body_canonical`.\n     - `model::repl_ingest` → thin wrappers around `verify_event_frame`, `GapBufferByNsOrigin`, `Watermark` helpers.\n     - `model::durability` → wrapper around `PeerAckTable` + `DurabilityCoordinator::poll_replicated`.\n     - `model::state_digest` → hash/summary of `CanonicalState` (if needed for model state hashability).\n2) Update `beads_stateright_models/Cargo.toml` to depend on the main crate via a path dep with `default-features = false` + `features = [\"model-testing\"]`.\n3) Add a compile-time drift guard in `beads_stateright_models` (a small module that imports all production types/functions referenced by models). If any signature changes, models should fail to compile.\n4) Add a CI/slow-tests command to compile the models crate (e.g. `cargo check -p beads_stateright_models`).\n5) Document the no-drift rule in `beads_stateright_models/README.md`.\n\n**Notes**\nKeep the harness tiny and feature-gated so normal builds don’t pull daemon deps.","acceptance_criteria":"**Acceptance**\n- [ ] `beads-rs` exposes a `model-testing` (or similar) feature with a `src/model/*` harness of production-backed adapters.\n- [ ] `beads_stateright_models` depends on the main crate via path dep and compiles with `feature = model-testing`.\n- [ ] A drift-guard module in the models crate imports all production APIs used by models and fails compilation on signature changes.\n- [ ] Documented command to compile models in CI/slow-tests.","priority":0,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768687393115,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768687393115,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768687393115,0]}
{"id":"bd-08th","created_at":[1769483948438,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode core namespace presence in StoreState type","description":"**Problem**\n`StoreState` can exist without the core namespace present. The map is just `BTreeMap<NamespaceId, CanonicalState>` with `get` returning `Option`. That means any caller that assumes core exists is relying on convention rather than the type system. The compiler cannot enforce “core namespace is always present”.\n\nKey refs:\n- `crates/beads-core/src/namespaced_state.rs:7` — `StoreState` is a plain map; core can be missing.\n\n**Impact**\nStructural invariant not encoded; subtle bugs when code assumes core exists (especially in daemon, repl, or query paths). This is the canonical namespace of the system; its absence is invalid.","design":"**Design (opinionated)**\nMake core namespace presence structural.\n\n1) Split core from non‑core:\n- `struct StoreState { core: CanonicalState, other: BTreeMap<NamespaceId, CanonicalState> }`.\n- `StoreState::new()` initializes `core` explicitly.\n\n2) Prevent `NamespaceId::core()` from entering the `other` map:\n- Introduce `NonCoreNamespaceId` wrapper returned by `NamespaceId::try_non_core()`.\n- `StoreState::set_namespace_state` should accept `NonCoreNamespaceId` for `other` namespaces and a dedicated `set_core_state` for core.\n\n3) Provide explicit core accessors:\n- `fn core(&self) -> &CanonicalState`\n- `fn core_mut(&mut self) -> &mut CanonicalState`\n\nThis makes “missing core” unrepresentable and pushes mistakes to compile time.","acceptance_criteria":"**Acceptance**\n- [ ] `StoreState` cannot be constructed without a core namespace (compile‑time enforced).\n- [ ] The `other` map cannot contain `NamespaceId::core()`.\n- [ ] All call sites that need core use explicit `core()` accessors, not `get()`.\n- [ ] Tests verify that non‑core namespace insertion rejects core.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769506489422,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769506489422,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769506489422,0]}
{"id":"bd-0ap","created_at":[1765744962426,0],"created_by":"darin@darinsmcstudio2.lan","title":"Observability: replace eprintln with tracing everywhere","description":"**Problem**\nMixed use of `tracing` and `eprintln!`. For a \"daemon for swarms\", logs matter.\n\n**Design**\n- Use `tracing` everywhere (esp sync start/stop, retries, backoff, durations, remote id)\n- Add structured fields for key events\n- Consider counters (sync failures, queue depth, refresh latency) - even structured logs help before full prometheus\n\n**Acceptance**\n- [ ] No `eprintln!` in non-test code\n- [ ] Sync events have structured tracing spans\n- [ ] Key metrics visible in logs (durations, retry counts)\n\n**Files:** grep for eprintln, likely src/daemon/*.rs, src/git/*.rs","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767998814474,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767998814474,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767998814474,0]}
{"id":"bd-0it","created_at":[1768503231152,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL append fsync policy should follow realtime plan","description":"**Problem**\n`SegmentWriter::append` currently uses `sync_all`, which fsyncs file metadata and directory on every append. The realtime plan specifies syncing file data per record and only syncing the directory when a new segment file is created/rotated. The current behavior is significantly slower and diverges from the intended design.\n\n**Files**\n- src/daemon/wal/segment.rs\n- src/daemon/wal/event_wal.rs\n- src/daemon/store_runtime.rs (if metrics/limits need adjustments)","design":"Implement the plan’s fsync policy:\n- Use `File::sync_data()` (or equivalent) for normal record appends.\n- Only `sync_all()` when creating a new segment file or sealing/rotating a segment.\n- Fsync the namespace directory when a new segment file path is created.\nUpdate metrics to distinguish data fsync vs full fsync if needed.","acceptance_criteria":"- [ ] Append path uses sync_data instead of sync_all.\n- [ ] Directory fsync happens only on new segment creation/rotation.\n- [ ] WAL tests updated to account for new sync behavior.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768513032904,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768513032904,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768513032904,0]}
{"id":"bd-0jl3","created_at":[1768508732893,0],"created_by":"darin@darinsmcstudio2.lan","title":"Split IPC into types/codec/client modules","description":"**Problem**\n- `src/daemon/ipc.rs` is ~3k LOC and mixes protocol schema, codecs, socket path logic, and daemon auto-start client logic.\n- This blurs boundaries and makes changes risky.\n\n**Files:**\n- src/daemon/ipc.rs\n- src/daemon/mod.rs\n- src/cli/mod.rs (imports)\n- src/api/mod.rs (only if types move)","design":"- Convert `ipc.rs` into `src/daemon/ipc/` with `mod.rs`.\n- Move request/response types into `ipc/types.rs`.\n- Move encode/decode and error mapping into `ipc/codec.rs`.\n- Move socket path + autostart + send_request/subscribe into `ipc/client.rs`.\n- Re-export the same symbols from `ipc/mod.rs` to keep the public API stable.","acceptance_criteria":"- [ ] `src/daemon/ipc/` contains separate `types`, `codec`, and `client` modules.\n- [ ] Existing imports continue to compile via re-exports.\n- [ ] No behavior change; `cargo test` passes.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768531457476,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768531457476,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-0l1","created_at":[1766116456065,0],"created_by":"darin@darinsmcstudio2.lan","title":"Detect and surface remote force-push/divergence","description":"**Problem**\nIf the remote history is rewritten (force-push), sync currently treats it like a normal remote update and proceeds. There's no explicit detection or warning to the user.\n\n**Design**\nDetect non-ancestor relationships between local/remote refs and surface a structured warning/error (e.g., status payload includes `diverged=true`). Consider requiring manual `bd sync --force` for history rewrites.\n\n**Acceptance**\n- [ ] Divergence detection is explicit\n- [ ] User-visible warning surfaced (status/IPC)\n- [ ] Tests cover force-push/divergence scenario\n\n**Files:** src/git/sync.rs, src/daemon/core.rs, src/api/mod.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766124427291,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766124427291,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766124427291,0]}
{"id":"bd-0y9","created_at":[1765690393596,0],"created_by":"darin@darinsmcstudio2.lan","title":"Installer hardening: checksum verification + rate-limit robustness","description":"## What's Wrong\nInstall script fetches `releases/latest` unauthenticated and downloads a tarball without any integrity verification (checksum/signature). It may also fail due to GitHub API rate limits.\n\n## Where\n- scripts/install.sh: uses https://api.github.com/.../releases/latest and grep/sed parsing\n- scripts/install.sh: downloads release asset and untars with no checksum\n\n## Why It Matters\n- Security: users execute a network script piping to bash; we should verify what we download.\n- Reliability: rate limiting or JSON format changes can break installs.\n\n## Suggested Fix\n- Publish checksums (e.g., SHA256SUMS) as release assets and verify before install.\n- Prefer GitHub release page redirect for latest tag, or allow `BD_VERSION` override.\n- Use `jq` when available; fallback to robust parsing.\n\n## Acceptance\n- Installer verifies integrity of downloaded binary.\n- Installer supports explicit version pinning.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768492349651,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768492349651,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768492349651,0]}
{"id":"bd-0ya","created_at":[1768373551255,0],"created_by":"darin@darinsmcstudio2.lan","title":"Checkpoint snapshot builder rejects non-core namespaces","description":"build_snapshot currently errors on non-core namespaces because StoreRuntime only has CanonicalState. Extend snapshot capture once StoreState is plumbed so checkpoint groups can include multiple namespaces.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768483765241,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768483765241,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768483765241,0]}
{"id":"bd-0yk","created_at":[1765690393395,0],"created_by":"darin@darinsmcstudio2.lan","title":"Release scripts: make version bump portable across macOS/Linux","description":"## What's Wrong\n`just release-patch` / `just release-minor` use `sed -i` in a way that's GNU-sed specific; BSD sed (macOS outside nix) requires an extension argument.\n\n## Where\n- justfile:67-68, 87-88\n\n## Why It Matters\nContributors running release scripts on macOS without nix will hit a broken release flow.\n\n## Suggested Fix\n- Use a portable approach: `perl -pi -e`, or detect BSD vs GNU sed.\n- Consider moving release logic to `scripts/release.sh` with explicit checks.\n\n## Acceptance\n- Release scripts work on macOS + Linux without requiring GNU sed.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767997715862,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767997715862,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767997715862,0]}
{"id":"bd-11jc","created_at":[1768824018695,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace repl transport next-frame bools with enum","description":"tests/integration/fixtures/repl_transport.rs uses drop_next/reorder_next bool flags. Replace with a typed enum that captures next-frame action (drop/reorder/normal) and keep delay as explicit state, so intent is encoded in types.","acceptance_criteria":"- drop_next/reorder_next bool fields removed\\n- next-frame action represented by enum\\n- tests in repl_transport updated\\n- cargo check, cargo clippy -D warnings, cargo test pass","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768824162808,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768824162808,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768824162808,0]}
{"id":"bd-123u","created_at":[1769501207924,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode WAL RecordHeader invariants in types","description":"**Problem**\n`RecordHeader` allows invalid combinations of flags/fields that are only rejected at encode/decode time. The compiler cannot prevent constructing headers where `request_sha256` is present without `client_request_id`, or other invalid flag/field pairings.\n\nKey refs:\n- `crates/beads-rs/src/daemon/wal/record.rs:65` (RecordHeader)\n- `crates/beads-rs/src/daemon/wal/record.rs:103` (encode-time validation)\n\n**Impact**\nWAL integrity depends on runtime checks. Any new constructor or refactor can accidentally build an invalid header that compiles and fails later.","design":"**Design (opinionated)**\nEncode header invariants in the type system with an enum or structured subtype.\n\nOption A (enum):\n```rust\nenum RecordHeader {\n  NoClientRequest { /* fields */ },\n  WithClientRequest { client_request_id: ClientRequestId, request_sha256: Option<[u8;32]>, /* fields */ }\n}\n```\n- Encode/decode produce one of these variants.\n- There is no state where `request_sha256` exists without `client_request_id`.\n\nOption B (struct with nested request):\n```rust\nstruct RecordHeader { common: CommonFields, request: Option<RequestMeta> }\nstruct RequestMeta { id: ClientRequestId, request_sha256: Option<[u8;32]> }\n```\n- Constructors enforce that `request_sha256` cannot exist without `RequestMeta`.\n\nMake invalid combinations unrepresentable, not just validated at runtime.","acceptance_criteria":"**Acceptance**\n- [ ] It is impossible to construct a header with `request_sha256` but no `client_request_id` (compile‑time enforced).\n- [ ] Encode/decode APIs operate on the typed representation only.\n- [ ] All call sites updated; no ad‑hoc header struct literals remain.\n- [ ] Tests cover encode/decode round‑trip and reject invalid bytes at the boundary.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769543599576,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769543599576,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769543599576,0]}
{"id":"bd-124","created_at":[1768183064475,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fix clippy warnings blocking phase 1","description":"Clippy fails with too-many-arguments in store_meta::new and daemon/git helpers, plus redundant closure and needless borrow. Clean up to keep cargo clippy -D warnings green before Phase 1 continues.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768183224591,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768183224591,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768183224591,0]}
{"id":"bd-12qf","created_at":[1768636574419,0],"created_by":"darin@darinsmcstudio2.lan","title":"Store discovery e2e without BD_STORE_ID","description":"**Problem**\nMulti-daemon tests force `BD_STORE_ID`, so we never validate real store discovery via remote URL canonicalization. That is the default deployment path.","design":"**Design**\n- Add a ReplRig option to disable `BD_STORE_ID` env override.\n- Build nodes by cloning the same remote and verify all daemons discover the same store_id from remotes.\n- Add a slow e2e that creates issues on each node and asserts convergence + matching store_id.","acceptance_criteria":"- [ ] ReplRig can run without `BD_STORE_ID`.\n- [ ] Slow e2e validates store discovery and replication convergence.\n- [ ] No writes outside ./tmp.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768637013947,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768637013947,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768637013947,0]}
{"id":"bd-14fs","created_at":[1769398681857,0],"created_by":"darin@darinsmcstudio2.lan","title":"Crate boundary refactor: split beads-rs into workspace DAG","description":"**Problem**\nThe current single-crate architecture (`crates/beads-rs`) couples the public boundary (IPC protocol, schemas, client) with daemon internals. External consumers cannot use the IPC client without pulling in git/WAL/store implementation details.\n\n**Goal**\nSplit into a dependency DAG:\n- `beads-macros`: shared macro crate (enum_str!), no deps\n- `beads-core`: pure domain + CRDT + error-code/payload types + Effect/Transience\n- `beads-api`: canonical JSON schemas for IPC/--json\n- `beads-surface`: IPC protocol + codec + client + request/patch/query schemas\n- `beads-rs`: daemon + CLI + operational logic (re-exports for compatibility)\n\n```\nbeads-macros\n   ↑\nbeads-core\n   ↑\nbeads-api\n   ↑\nbeads-surface\n   ↑\nbeads-rs\n```\n\n**Phases**\n- Phase 0: Workspace scaffolding + versioning (bd-14fs.1)\n- Phase 1A: Extract enum_str! macro (bd-14fs.11) ← NEW\n- Phase 1: Extract core into beads-core (bd-14fs.2)\n- Phase 2: Extract api into beads-api (bd-14fs.3)\n- Phase 3A: Create beads-surface layout (bd-14fs.4)\n- Phase 3B-D: Move IPC types, ops, query schemas (bd-14fs.5-7) ← PARALLEL\n- Phase 3E: Refactor IPC codec (bd-14fs.8)\n- Phase 3F: Move IPC client (bd-14fs.9)\n- Phase 4: Re-wire beads-rs with re-export shims (bd-14fs.10)\n- Cleanup: Add AGENTS.md documentation (bd-14fs.12)\n\n**Key Gotchas** (from codebase analysis)\n1. enum_str! used in 9 places (4 outside core) - beads-rs needs direct beads-macros dep\n2. Core tests cannot depend on git/daemon\n3. Query type duplication must be removed, not papered over\n4. 2 From impls break orphan rules (OpError, IpcError → ErrorPayload)\n5. 161 Response::err() call sites need explicit .to_error_payload()\n6. Runtime + autostart overrides must move into surface","acceptance_criteria":"- [ ] All five crates compile independently\n- [ ] beads-surface consumable without daemon internals\n- [ ] Existing beads_rs::* paths still work via re-exports\n- [ ] cargo test passes\n- [ ] cargo clippy clean","priority":1,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769512015209,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769512015209,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769512015209,0]}
{"id":"bd-14fs.1","created_at":[1769398685959,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 0: Workspace scaffolding and versioning","description":"**Problem**\nNeed workspace structure before extracting any crates.\n\n**Changes**\n1. Update `/Cargo.toml` to add workspace members:\n   - crates/beads-macros\n   - crates/beads-core\n   - crates/beads-api\n   - crates/beads-surface\n\n2. Add workspace versioning at `0.2.0-alpha`:\n   ```toml\n   [workspace.package]\n   version = \"0.2.0-alpha\"\n   ```\n\n3. Create stub crates with minimal Cargo.toml and empty lib.rs:\n   - `crates/beads-macros/Cargo.toml` + `src/lib.rs`\n   - `crates/beads-core/Cargo.toml` + `src/lib.rs`\n   - `crates/beads-api/Cargo.toml` + `src/lib.rs`\n   - `crates/beads-surface/Cargo.toml` + `src/lib.rs`\n\n4. Set `version.workspace = true` in ALL crates (including beads-rs)\n\n**Files**\n- /Cargo.toml (workspace)\n- crates/beads-macros/Cargo.toml + src/lib.rs (new)\n- crates/beads-core/Cargo.toml + src/lib.rs (new)\n- crates/beads-api/Cargo.toml + src/lib.rs (new)\n- crates/beads-surface/Cargo.toml + src/lib.rs (new)\n- crates/beads-rs/Cargo.toml (update version)","acceptance_criteria":"- [ ] `cargo check` passes on workspace\n- [ ] All 5 new crates listed in workspace.members\n- [ ] workspace.package.version = \"0.2.0-alpha\"\n- [ ] All crates use version.workspace = true\n- [ ] env!(\"CARGO_PKG_VERSION\") returns same value in all crates","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1769401181588,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769401181588,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-14fs.10","created_at":[1769398697526,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 4: Re-wire beads-rs daemon with re-export shims","description":"**Problem**\nAfter moving code to surface crate, need to update beads-rs module wiring and re-exports so:\n- CLI keeps compiling without broad edits\n- Existing `beads_rs::*` paths still work\n- Daemon uses surface types correctly\n\n**Changes**\n\n1. **Update Cargo.toml** (`crates/beads-rs/Cargo.toml`):\n   ```toml\n   [dependencies]\n   beads-core = { path = \"../beads-core\" }\n   beads-api = { path = \"../beads-api\" }\n   beads-surface = { path = \"../beads-surface\" }\n   beads-macros = { path = \"../beads-macros\" }\n   ```\n\n2. **Update daemon/ipc/mod.rs** to be a compatibility shim:\n   ```rust\n   // Re-export everything from surface\n   pub use beads_surface::ipc::*;\n\n   // Keep error types accessible\n   pub use beads_core::{ErrorCode, ErrorPayload};\n\n   // Daemon-only additions\n   mod error_mapping;\n   pub use error_mapping::*;\n   ```\n\n3. **Update daemon/mod.rs** re-exports to preserve old paths:\n   ```rust\n   // Surface-owned types\n   pub use beads_surface::ops::{BeadPatch, OpResult, Patch};\n   pub use beads_surface::query::{Filters, SortField};\n   pub use beads_surface::ipc::{Request, Response, ResponsePayload, IpcClient};\n\n   // API types\n   pub use beads_api::QueryResult;\n\n   // Daemon-owned types\n   pub use ops::OpError;\n   ```\n\n4. **Update lib.rs** with crate aliases:\n   ```rust\n   // Crate re-exports for backwards compatibility\n   pub use beads_core as core;\n   pub use beads_api as api;\n   pub use beads_macros::enum_str;\n\n   // Optional: direct surface access\n   pub use beads_surface as surface;\n   ```\n\n5. **Verify all existing paths still work**:\n   - `beads_rs::core::BeadId` ✓\n   - `beads_rs::api::QueryResult` ✓\n   - `beads_rs::daemon::ipc::Request` ✓\n   - `beads_rs::daemon::BeadPatch` ✓\n   - `beads_rs::daemon::Filters` ✓\n\n**Files**\n- crates/beads-rs/Cargo.toml (dependencies)\n- crates/beads-rs/src/lib.rs (crate aliases)\n- crates/beads-rs/src/daemon/mod.rs (re-exports)\n- crates/beads-rs/src/daemon/ipc/mod.rs (shim)","acceptance_criteria":"- [ ] All dependencies added to Cargo.toml\n- [ ] `beads_rs::core::*` paths work via re-export\n- [ ] `beads_rs::api::*` paths work via re-export\n- [ ] `beads_rs::daemon::ipc::*` paths work via shim\n- [ ] `beads_rs::daemon::{BeadPatch, Filters, ...}` work\n- [ ] CLI compiles without changes to command handlers\n- [ ] `cargo check` passes for entire workspace\n- [ ] `cargo test` passes\n- [ ] `cargo clippy -- -D warnings` clean","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769409227924,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769409227924,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769409227924,0]}
{"id":"bd-14fs.11","created_at":[1769400113215,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 1A: Extract enum_str! macro to beads-macros","description":"**Problem**\nbd-14fs.2 is too large - macro extraction should be a separate atomic step.\n\n**Context from codebase analysis**\n`enum_str!` is used in 9 places:\n- `src/core/error.rs` (2 uses)\n- `src/core/domain.rs` (2 uses)\n- `src/core/wire_bead.rs` (1 use)\n- `src/error.rs` (1 use) ← OUTSIDE core\n- `src/cli/commands/store.rs` (1 use) ← OUTSIDE core\n- `src/daemon/store/discovery.rs` (1 use) ← OUTSIDE core\n- `src/daemon/repl/proto.rs` (1 use) ← OUTSIDE core\n\n**Implication**: beads-rs needs direct dependency on beads-macros, not just via beads-core.\n\n**Changes**\n\n1. **Create macro in beads-macros**:\n   ```rust\n   // crates/beads-macros/src/lib.rs\n   #[macro_export]\n   macro_rules! enum_str { ... }\n   ```\n\n2. **Update beads-rs to use it**:\n   - Add `beads-macros` dependency to Cargo.toml\n   - Replace `#[macro_use] mod enum_str;` with `pub use beads_macros::enum_str;`\n   - Delete `crates/beads-rs/src/enum_str.rs`\n\n3. **All existing `crate::enum_str!` calls keep working** because the macro is re-exported at crate root.\n\n**Files**\n- crates/beads-macros/src/lib.rs (populate with macro)\n- crates/beads-rs/Cargo.toml (add beads-macros dep)\n- crates/beads-rs/src/lib.rs (re-export macro)\n- crates/beads-rs/src/enum_str.rs (delete)\n","acceptance_criteria":"- [ ] `cargo check -p beads-macros` passes\n- [ ] `cargo check -p beads-rs` passes\n- [ ] All 9 enum_str! call sites still work\n- [ ] enum_str.rs deleted from beads-rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1769401519801,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769401519801,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-14fs.12","created_at":[1769400202294,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add AGENTS.md files for new crates","description":"**Problem**\nNew crates (beads-macros, beads-core, beads-api, beads-surface) need AGENTS.md files documenting their boundaries, following the pattern established in existing crate directories.\n\n**Files to create**\n- `crates/beads-macros/AGENTS.md`\n- `crates/beads-core/src/AGENTS.md` (can be moved from beads-rs/src/core/AGENTS.md)\n- `crates/beads-api/src/AGENTS.md` (can be moved from beads-rs/src/api/AGENTS.md)\n- `crates/beads-surface/src/AGENTS.md` (new)\n\n**Content pattern** (from existing AGENTS.md files):\n- Boundary: what this directory defines\n- Depends on: upstream dependencies\n- Depended on by: downstream consumers\n- NEVER: anti-patterns to avoid\n- How to work here: guidelines\n- Verification: commands to run\n- Dont copy this: things to avoid\n\n**Surface crate AGENTS.md should include**:\n- Boundary: IPC protocol types, schemas, client (public surface boundary)\n- Depends on: beads-core, beads-api\n- Depended on by: beads-rs daemon, external clients\n- NEVER: include daemon operational logic, git/WAL/store internals\n- Verification: cargo test, cargo check\n","acceptance_criteria":"- [ ] beads-macros has AGENTS.md\n- [ ] beads-core has AGENTS.md\n- [ ] beads-api has AGENTS.md\n- [ ] beads-surface has AGENTS.md\n- [ ] Each documents boundary, deps, and verification","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769409391951,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769409391951,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769409391951,0]}
{"id":"bd-14fs.2","created_at":[1769398695771,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 1: Extract core into beads-core","description":"**Problem**\n`crates/beads-rs/src/core/**` needs to become standalone `beads-core` crate. Currently core has dependencies on:\n- `crate::error::{Effect, Transience}` (must move into core)\n- Tests in `core/state.rs` call `crate::git::wire::serialize_*` (must move tests out)\n\nNote: enum_str! macro extraction is handled separately in bd-14fs.11.\n\n**Changes**\n\n1. **Move Effect + Transience into beads-core**:\n   - Define `beads_core::Effect` and `beads_core::Transience` (in `core/effect.rs` or `core/error.rs`)\n   - Update `core/error.rs` to use local types instead of `crate::error::{Effect, Transience}`\n   - In beads-rs: `pub use beads_core::{Effect, Transience};`\n   - Update `crates/beads-rs/src/error.rs` to use `beads_core::{Effect, Transience}`\n\n2. **Move directory**: `crates/beads-rs/src/core/**` → `crates/beads-core/src/**`\n   - `crates/beads-core/src/lib.rs` mirrors old `core/mod.rs` structure\n   - Keep `#![forbid(unsafe_code)]`\n\n3. **Update beads-rs to re-export**:\n   - Replace `pub mod core;` with `pub use beads_core as core;`\n   - This preserves `beads_rs::core::BeadId` etc.\n\n4. **Move git-dependent tests out of core**:\n   - `core/state.rs` tests that call `crate::git::wire::serialize_*` → move to `crates/beads-rs/tests/core_state_fingerprint.rs`\n   - Rule: **no beads-core tests depend on daemon/git/IPC modules**\n\n5. **Update Cargo.toml files**:\n   - `beads-core/Cargo.toml`: add `beads-macros` dependency, copy relevant deps from beads-rs\n   - `beads-rs/Cargo.toml`: add `beads-core` dependency\n\n**Files**\n- crates/beads-core/src/** (moved from beads-rs/src/core/**)\n- crates/beads-rs/src/lib.rs (re-export as core)\n- crates/beads-rs/src/error.rs (use beads_core types)\n- crates/beads-rs/tests/core_state_fingerprint.rs (new - moved tests)\n- crates/beads-core/Cargo.toml\n- crates/beads-rs/Cargo.toml","acceptance_criteria":"- [ ] `cargo check -p beads-core` passes (core builds in isolation)\n- [ ] `cargo check -p beads-rs` passes\n- [ ] beads-core has ZERO dependencies on beads-rs modules\n- [ ] `beads_rs::core::BeadId` still resolves\n- [ ] All tests pass","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1769402699106,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769402699106,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-14fs.3","created_at":[1769398696082,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 2: Extract api into beads-api","description":"**Problem**\n`crates/beads-rs/src/api/**` needs to become standalone `beads-api` crate. Currently there's type duplication:\n- `api/` has schema types (Issue, IssueSummary, QueryResult, etc.)\n- `daemon/query_model.rs` has duplicate internal types\n- `api/convert.rs` converts between them\n\n**Decision**: Daemon should use beads-api types directly. Delete duplicates and conversion layer.\n\n**Changes**\n\n1. **Move directory**: `crates/beads-rs/src/api/**` → `crates/beads-api/src/**`\n\n2. **Update imports in moved files**:\n   - `use crate::core::...` → `use beads_core::...`\n\n3. **Delete conversion layer**:\n   - Remove `crates/beads-api/src/convert.rs` (was `api/convert.rs`)\n   - Delete `crates/beads-rs/src/daemon/query_model.rs`\n\n4. **Update beads-rs to re-export**:\n   - Replace `pub mod api;` with `pub use beads_api as api;`\n   - This preserves `beads_rs::api::QueryResult`\n\n5. **Update daemon to use beads-api directly**:\n   - `daemon/query_executor.rs`: change imports from `daemon::query_model::*` to `beads_api::*`\n   - `daemon/admin.rs`: return `beads_api::QueryResult` variants directly\n   - `daemon/core.rs`: use `beads_api::*` types\n   - Use existing constructors like `Issue::from_view(...)`, `IssueSummary::from_view(...)`\n\n6. **Update Cargo.toml**:\n   - `beads-api/Cargo.toml`: depends on `beads-core` and serde\n   - `beads-rs/Cargo.toml`: add `beads-api` dependency\n\n**Key insight**: Keep beads-api as schemas + conversions from core types only (e.g., `impl From<&core::Note> for api::Note`). This avoids orphan rules.\n\n**Files**\n- crates/beads-api/src/** (moved from beads-rs/src/api/**)\n- crates/beads-api/src/convert.rs (delete)\n- crates/beads-rs/src/lib.rs (re-export as api)\n- crates/beads-rs/src/daemon/query_model.rs (delete)\n- crates/beads-rs/src/daemon/query_executor.rs (update imports)\n- crates/beads-rs/src/daemon/admin.rs (update imports)\n- crates/beads-rs/src/daemon/core.rs (update imports)\n- crates/beads-api/Cargo.toml\n- crates/beads-rs/Cargo.toml","acceptance_criteria":"- [ ] `cargo check -p beads-api` passes (api builds in isolation)\n- [ ] `cargo check -p beads-rs` passes\n- [ ] No query_model.rs exists in daemon\n- [ ] No convert.rs exists in api\n- [ ] `beads_rs::api::QueryResult` still resolves\n- [ ] Daemon constructs beads_api types directly\n- [ ] All tests pass","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769404316046,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769404316046,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769404316046,0]}
{"id":"bd-14fs.4","created_at":[1769398696286,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3A: Create beads-surface crate layout","description":"**Problem**\nNeed the beads-surface crate structure before moving IPC/ops/query types.\n\n**Changes**\nCreate the crate layout:\n\n```\ncrates/beads-surface/\n├── Cargo.toml\n└── src/\n    ├── lib.rs\n    ├── ipc/\n    │   ├── mod.rs\n    │   ├── types.rs    (Request, Response, ResponsePayload, etc.)\n    │   ├── codec.rs    (NDJSON framing, encode/decode)\n    │   └── client.rs   (IpcClient)\n    ├── ops.rs          (Patch, BeadPatch, OpResult)\n    └── query.rs        (Filters, SortField)\n```\n\n**Cargo.toml dependencies**:\n- beads-core\n- beads-api\n- serde, serde_json, thiserror\n- nix (signals/user)\n- tracing\n- optionally tempfile for tests\n\n**lib.rs public API**:\n```rust\npub mod ipc;\npub mod ops;\npub mod query;\n\npub use ipc::{Request, Response, ResponsePayload, IpcClient, IpcError, ...};\npub use ops::{Patch, BeadPatch, OpResult};\npub use query::{Filters, SortField};\n```\n\n**Files**\n- crates/beads-surface/Cargo.toml (new)\n- crates/beads-surface/src/lib.rs (new)\n- crates/beads-surface/src/ipc/mod.rs (new, empty stubs)\n- crates/beads-surface/src/ipc/types.rs (new, empty)\n- crates/beads-surface/src/ipc/codec.rs (new, empty)\n- crates/beads-surface/src/ipc/client.rs (new, empty)\n- crates/beads-surface/src/ops.rs (new, empty)\n- crates/beads-surface/src/query.rs (new, empty)","acceptance_criteria":"- [ ] `cargo check -p beads-surface` passes (empty stubs OK)\n- [ ] Module structure matches plan\n- [ ] Dependencies declared in Cargo.toml\n- [ ] Workspace builds cleanly","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769404832405,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769404832405,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769404832405,0]}
{"id":"bd-14fs.5","created_at":[1769398696496,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3B: Move IPC protocol types to beads-surface","description":"**Problem**\nIPC protocol types live in `daemon/ipc/types.rs` but are part of the public boundary.\n\n**Complete type inventory from codebase**:\n- `IPC_PROTOCOL_VERSION` (const)\n- `MutationMeta`, `ReadConsistency`\n- `Request` (enum), `Response` (enum), `ResponsePayload` (enum)\n- `OpResponse`\n- `SyncedPayload`, `RefreshedPayload`, `InitializedPayload`, `ShuttingDownPayload`\n- `SubscribedPayload`, `StreamEventPayload`\n\n**Changes**\n\n1. **Move file**: `crates/beads-rs/src/daemon/ipc/types.rs` → `crates/beads-surface/src/ipc/types.rs`\n\n2. **Update imports in moved file**:\n   ```rust\n   // Old\n   use crate::api::QueryResult;\n   use crate::core::ErrorPayload;\n   use crate::core::{Applied, BeadType, DepKind, DurabilityReceipt, Priority, Watermarks};\n   use crate::daemon::ops::{BeadPatch, OpResult};\n   use crate::daemon::query::Filters;\n\n   // New\n   use beads_api::QueryResult;\n   use beads_core::ErrorPayload;\n   use beads_core::{Applied, BeadType, DepKind, DurabilityReceipt, Priority, Watermarks};\n   use crate::ops::{BeadPatch, OpResult};  // surface-local\n   use crate::query::Filters;              // surface-local\n   ```\n\n3. **Change convenience constructors** to avoid cross-crate `Into` issues:\n\n   Current problematic signatures:\n   - `pub fn err(error: impl Into<ErrorPayload>)` in types.rs:464\n   - `fn box_error(err: impl Into<ErrorPayload>)` in subscription.rs:90\n\n   Change to accept concrete types:\n   ```rust\n   impl Response {\n       pub fn err(err: beads_core::ErrorPayload) -> Self { ... }\n   }\n   impl ResponsePayload {\n       pub fn query(result: beads_api::QueryResult) -> Self { ... }\n   }\n   ```\n\n4. **Update beads-surface/src/ipc/mod.rs**:\n   ```rust\n   pub mod types;\n   pub use types::*;\n   ```\n\n**Files**\n- crates/beads-surface/src/ipc/types.rs (moved + updated)\n- crates/beads-surface/src/ipc/mod.rs (re-export)","acceptance_criteria":"- [ ] All 12 IPC protocol types defined in beads-surface\n- [ ] No `impl Into<...>` on cross-crate boundaries\n- [ ] `cargo check -p beads-surface` passes\n- [ ] Types use beads_core:: and beads_api:: imports","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769406208824,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769406208824,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769406208824,0]}
{"id":"bd-14fs.6","created_at":[1769398696700,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3C: Extract patch/op-result schemas to beads-surface","description":"**Problem**\n`daemon/ops.rs` contains both schema types (part of public boundary) and daemon-only operational logic.\n\n**What's in daemon/ops.rs today**:\n- `Patch<T>` - generic patch type (schema)\n- `BeadPatch` - bead mutation schema (schema)\n- `OpResult` - operation result (schema)\n- `OpError` - daemon-only error type (daemon)\n- `validate()`, `apply_to_fields()` - operational logic (daemon)\n\n**Changes**\n\n1. **Create beads-surface/src/ops.rs** with schema types only:\n   ```rust\n   use serde::{Deserialize, Serialize};\n\n   #[derive(Debug, Clone, Serialize, Deserialize)]\n   pub struct Patch<T> { ... }\n\n   impl<T> Patch<T> {\n       pub fn apply(self, current: Option<T>) -> Option<T> { ... }\n   }\n\n   #[derive(Debug, Clone, Serialize, Deserialize)]\n   pub struct BeadPatch { ... }\n\n   impl BeadPatch {\n       pub fn is_empty(&self) -> bool { ... }\n   }\n\n   #[derive(Debug, Clone, Serialize, Deserialize)]\n   pub struct OpResult { ... }\n   ```\n\n2. **Keep daemon-only code in beads-rs/src/daemon/ops.rs**:\n   - `OpError` (daemon error type)\n   - Import schema types: `use beads_surface::ops::{BeadPatch, Patch, OpResult};`\n   - Add extension trait for daemon operations:\n   ```rust\n   pub trait BeadPatchDaemonExt {\n       fn validate_for_daemon(&self) -> Result<(), OpError>;\n       fn apply_to_fields(&self, fields: &mut beads_core::BeadFields, stamp: &beads_core::Stamp)\n           -> Result<(), OpError>;\n   }\n\n   impl BeadPatchDaemonExt for beads_surface::ops::BeadPatch { ... }\n   ```\n\n3. **Update imports** throughout daemon to use:\n   - `beads_surface::ops::{Patch, BeadPatch, OpResult}` for types\n   - Local `ops::OpError` and extension trait for operations\n\n**Files**\n- crates/beads-surface/src/ops.rs (new - schema types)\n- crates/beads-rs/src/daemon/ops.rs (refactored - daemon-only)","acceptance_criteria":"- [ ] Patch<T>, BeadPatch, OpResult defined in beads-surface\n- [ ] OpError stays in beads-rs daemon\n- [ ] Extension trait pattern used for daemon operations\n- [ ] `cargo check -p beads-surface` passes\n- [ ] `cargo check -p beads-rs` passes","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769406581033,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769406581033,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769406581033,0]}
{"id":"bd-14fs.7","created_at":[1769398696907,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3D: Extract query filter schemas to beads-surface","description":"**Problem**\n`Filters` and `SortField` are embedded in IPC `Request::List` and other requests - they're part of the public protocol boundary.\n\n**What's in daemon/query.rs today**:\n- `Filters` - query filter struct (boundary)\n- `SortField` - sort specification (boundary)\n- `Filters::matches(&BeadView)` - filter semantics (boundary - part of protocol contract)\n- Internal query execution logic (daemon-only)\n\n**Decision**: Keep `Filters::matches` in surface because filter semantics are part of the public protocol contract.\n\n**Changes**\n\n1. **Create beads-surface/src/query.rs** with filter schemas:\n   ```rust\n   use serde::{Deserialize, Serialize};\n   use beads_core::BeadView;\n\n   #[derive(Debug, Clone, Default, Serialize, Deserialize)]\n   pub struct Filters { ... }\n\n   impl Filters {\n       /// Returns true if the bead matches all specified filters.\n       /// This is part of the protocol contract - filter semantics must be consistent.\n       pub fn matches(&self, bead: &BeadView) -> bool { ... }\n   }\n\n   #[derive(Debug, Clone, Serialize, Deserialize)]\n   pub enum SortField { ... }\n   ```\n\n2. **Keep daemon-only query execution** in beads-rs:\n   - Import: `use beads_surface::query::{Filters, SortField};`\n   - Keep internal execution logic that iterates over state\n\n3. **Remove duplicates from daemon/query.rs**:\n   - Delete `Filters` and `SortField` definitions\n   - Import from beads-surface instead\n\n**Files**\n- crates/beads-surface/src/query.rs (new - filter types + matches())\n- crates/beads-rs/src/daemon/query.rs (refactored - execution only)","acceptance_criteria":"- [ ] Filters and SortField defined in beads-surface\n- [ ] Filters::matches() implemented in beads-surface\n- [ ] Filter semantics testable at boundary level\n- [ ] `cargo check -p beads-surface` passes\n- [ ] daemon/query.rs imports from beads-surface","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769406787388,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769406787388,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769406787388,0]}
{"id":"bd-14fs.8","created_at":[1769398697115,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3E: Refactor IPC codec into surface + daemon error mapping","description":"**Problem**\n`daemon/ipc/codec.rs` does two things:\n1. NDJSON framing + JSON encode/decode (belongs in surface)\n2. Mapping daemon errors to ErrorPayload (belongs in daemon)\n\n**Orphan rule issue**:\nCurrently `impl From<OpError> for ErrorPayload` exists. After extraction, ErrorPayload is in beads-core (foreign), OpError is in beads-rs, so this `From` impl becomes illegal.\n\n**Affected impls** (daemon/ipc/codec.rs):\n- Line 23: `impl From<OpError> for ErrorPayload`\n- Line 879: `impl From<IpcError> for ErrorPayload`\n\n**Call sites**: 161 uses of `Response::err(e)` where `e: OpError` relies on implicit conversion.\n\n**Recommended fix** (minimal changes):\n1. Add `IntoErrorPayload` trait in beads-rs:\n   ```rust\n   pub trait IntoErrorPayload {\n       fn into_error_payload(self) -> ErrorPayload;\n   }\n   impl IntoErrorPayload for OpError { ... }\n   ```\n2. Add extension method on Response in beads-rs:\n   ```rust\n   pub trait ResponseExt {\n       fn err_from<E: IntoErrorPayload>(e: E) -> Response;\n   }\n   ```\n3. Find-replace: `Response::err(` → `Response::err_from(` in daemon code\n\nThis keeps surface clean (no `impl Into` bounds) and changes are mechanical.\n\n**Changes**\n\n1. **Move framing code to beads-surface/src/ipc/codec.rs**:\n   - `IpcError` (parse/io/frame-too-large/version mismatch)\n   - `encode_response`, `send_response`, `decode_request_with_limits`, `read_requests`\n\n2. **Create daemon error mapping** `crates/beads-rs/src/daemon/ipc/error_mapping.rs`:\n   - `IntoErrorPayload` trait\n   - `impl IntoErrorPayload for OpError`\n   - `impl IntoErrorPayload for IpcError`\n   - `ResponseExt` trait for `Response::err_from()`\n\n3. **Mechanical find-replace** in daemon code:\n   `Response::err(` → `Response::err_from(`\n\n**Files**\n- crates/beads-surface/src/ipc/codec.rs (framing only)\n- crates/beads-rs/src/daemon/ipc/error_mapping.rs (new)\n- crates/beads-rs/src/daemon/ipc/mod.rs\n- Daemon files (mechanical find-replace)","acceptance_criteria":"- [ ] IpcError defined in beads-surface\n- [ ] encode/decode/framing functions in beads-surface\n- [ ] No impl From<DaemonError> for ErrorPayload (orphan rule)\n- [ ] All 161 error conversions use explicit .to_error_payload()\n- [ ] `cargo check -p beads-surface` passes\n- [ ] `cargo check -p beads-rs` passes","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769408229397,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769408229397,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769408229397,0]}
{"id":"bd-14fs.9","created_at":[1769398697324,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3F: Move IPC client with runtime/autostart overrides","description":"**Problem**\n`daemon/ipc/client.rs` contains the IPC client but depends on:\n- `crate::paths::config_runtime_dir_override()` - can't access after extraction\n- Autostart spawns `bd daemon run` - needs to be overridable for tests/embedded use\n- Version check uses `env!(\"CARGO_PKG_VERSION\")` - works with workspace versioning\n\n**Changes**\n\n1. **Move file**: `crates/beads-rs/src/daemon/ipc/client.rs` → `crates/beads-surface/src/ipc/client.rs`\n\n2. **Add runtime dir override hook in surface**:\n   ```rust\n   // In beads-surface/src/ipc/client.rs (or separate config.rs)\n   use std::sync::OnceLock;\n   use std::path::PathBuf;\n\n   static RUNTIME_DIR_OVERRIDE: OnceLock<PathBuf> = OnceLock::new();\n\n   pub fn set_runtime_dir_override(dir: PathBuf) {\n       let _ = RUNTIME_DIR_OVERRIDE.set(dir);\n   }\n\n   fn runtime_dir_override() -> Option<&'static PathBuf> {\n       RUNTIME_DIR_OVERRIDE.get()\n   }\n   ```\n   Then `socket_dir_candidates()` checks this override first.\n\n3. **Wire up override from beads-rs**:\n   In `paths::init_from_config` or `main.rs`:\n   ```rust\n   if let Some(dir) = config_runtime_dir() {\n       beads_surface::ipc::set_runtime_dir_override(dir);\n   }\n   ```\n\n4. **Add autostart command override** for tests/embedded usage:\n   ```rust\n   impl IpcClient {\n       /// Override the program/args used for autostart.\n       /// Default spawns `bd daemon run`.\n       pub fn with_autostart_program(mut self, program: PathBuf, args: Vec<OsString>) -> Self {\n           self.autostart_program = Some(program);\n           self.autostart_args = args;\n           self\n       }\n\n       /// Disable autostart entirely.\n       pub fn with_autostart(mut self, enabled: bool) -> Self {\n           self.autostart = enabled;\n           self\n       }\n   }\n   ```\n\n5. **Optional: Add version check override**:\n   ```rust\n   impl IpcClient {\n       /// Allow callers to relax or pin the version check.\n       /// Default uses env!(\"CARGO_PKG_VERSION\").\n       pub fn with_expected_daemon_version(mut self, version: Option<String>) -> Self {\n           self.expected_version = version;\n           self\n       }\n   }\n   ```\n\n6. **Update beads-surface/src/ipc/mod.rs**:\n   ```rust\n   pub mod client;\n   pub mod codec;\n   pub mod types;\n\n   pub use client::*;\n   pub use codec::*;\n   pub use types::*;\n   ```\n\n**Files**\n- crates/beads-surface/src/ipc/client.rs (moved + refactored)\n- crates/beads-surface/src/ipc/mod.rs (re-export)\n- crates/beads-rs/src/paths.rs or main.rs (wire up override)","acceptance_criteria":"- [ ] IpcClient defined in beads-surface\n- [ ] Runtime dir override works (test with temp dir)\n- [ ] Autostart override works\n- [ ] Version check still works with workspace versioning\n- [ ] `cargo check -p beads-surface` passes\n- [ ] `cargo check -p beads-rs` passes\n- [ ] CLI still auto-starts daemon correctly","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769408930384,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769408930384,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769408930384,0]}
{"id":"bd-16g","created_at":[1768480671080,0],"created_by":"darin@darinsmcstudio2.lan","title":"src/core/event.rs: nested map decoders allow duplicate keys; spec 3.1 requires rejecting duplicates","description":"","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768481051485,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768481051485,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768481051485,0]}
{"id":"bd-1bs5","created_at":[1768680777560,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright repl: network semantics + history hooks","description":"**Problem**\nEven with ActorModel, we’re not yet leveraging Stateright’s network semantics selection, message history capture, or ordered-reliable-link adapter to control assumptions and reduce state.\n\n**Goal**\nExtend the repl ActorModel to fully use Stateright’s network model and history hooks.","design":"**Design**\n1) Add CLI/config switches in the model example to choose:\n   - `Network::UnorderedDuplicating`\n   - `Network::UnorderedNonDuplicating`\n   - `Network::Ordered`\n   - `LossyNetwork::Yes/No`\n2) Implement `record_msg_in` / `record_msg_out` to collect:\n   - last delivered sequence per (ns, origin)\n   - in-flight want ranges\n   - ack histories\n3) Add an ordered-link mode using `actor::ordered_reliable_link::ActorWrapper` to model a reliable channel between replicas when desired.\n4) Add properties that use history (not just actor state) to assert:\n   - ACK monotonicity even under loss/dup\n   - WANTs do not skip gaps\n   - equivalence between delivered history and applied watermark\n\n**References**\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor/network.rs`\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor/ordered_reliable_link.rs`\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/examples/timers.rs`","acceptance_criteria":"**Acceptance**\n- [ ] Repl model supports multiple network semantics via CLI flags.\n- [ ] History hooks are used for at least one property involving message-level invariants.\n- [ ] Ordered reliable link mode exists and can be toggled in the example.","priority":0,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768706961727,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768706961727,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768706961727,0]}
{"id":"bd-1h02","created_at":[1768508732473,0],"created_by":"darin@darinsmcstudio2.lan","title":"Decouple StoreState from RepoState (rename RepoState)","description":"**Problem**\n- `RepoState` owns canonical `StoreState` plus git lane metadata, mixing concerns.\n- `StoreRuntime` holds `repo_state`, so store state is indirectly coupled to git operations.\n- `RepoState` name conflicts with `src/repo.rs` and is easy to open by mistake.\n\n**Files:**\n- src/daemon/repo.rs\n- src/daemon/store_runtime.rs\n- src/daemon/core.rs\n- src/git/sync.rs (only if types are referenced)","design":"- Move `StoreState` ownership into `StoreRuntime` (`state: StoreState`).\n- Rename `RepoState` to `GitLaneState` (or `CheckpointLaneState`) and keep only git/checkpoint metadata there.\n- Update `Daemon` maps to store `GitLaneState` separately from store runtime.\n- Remove unused fields like `wal_sequence` if they are now owned by WAL.\n- Update all references/imports.","acceptance_criteria":"- [ ] Canonical store state lives in `StoreRuntime`, not `RepoState`.\n- [ ] Git lane metadata lives in `GitLaneState` (renamed file/module).\n- [ ] No name collision with `src/repo.rs`.\n- [ ] Tests pass.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768538827687,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768538827687,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768538827687,0]}
{"id":"bd-1lfb","created_at":[1768610564067,0],"created_by":"darin@darinsmcstudio2.lan","title":"Multi-process replication e2e harness","description":"Add slow-tests multi-process replication harness that spawns real bd daemons, configures peers via beads.toml, applies ops, and asserts convergence.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768727730862,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768727730862,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768727730862,0]}
{"id":"bd-1lp","created_at":[1765775712611,0],"created_by":"darin@darinsmcstudio2.lan","title":"IPC: unit ResponsePayload variants serialize as null (ambiguous)","description":"**Problem**\n`ResponsePayload` is `#[serde(untagged)]` and includes multiple unit variants (`Synced`, `Initialized`, `Pong`, `ShuttingDown`). These serialize to JSON `null`, so clients can deserialize ambiguously.\n\nExample symptom: `bd init` prints `synced` instead of `initialized`.\n\n**Design**\nSwitch `ResponsePayload` to an explicit tagged representation (e.g. `#[serde(tag=\"type\", content=\"data\", rename_all=\"snake_case\")]`), or ensure unit variants serialize as distinct strings/objects. Keep backward compatibility via versioning or dual-decode.\n\n**Acceptance**\n- [ ] `bd init` prints `initialized` on success\n- [ ] Unit ok payloads are not serialized as `null`\n- [ ] JSON decoding is deterministic\n- [ ] Tests pass\n\n**Files:** `src/daemon/ipc.rs`, `src/cli/render.rs`","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765780921740,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765780921740,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765780921740,0]}
{"id":"bd-1lzt","created_at":[1768798571480,0],"created_by":"darin@darinsmcstudio2.lan","title":"Clippy collapsible_if in export_worker.rs:63","description":"cargo clippy -D warnings fails due to nested if in src/daemon/export_worker.rs:63. Collapse the if per clippy suggestion or add allow with rationale.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768798821337,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768798821337,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768798821337,0]}
{"id":"bd-1mi","created_at":[1768184592437,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fix phase 1 test harness compile errors","description":"Enable uuid v5 support for store-id test derivation and wrap BD_DATA_DIR env var mutations in unsafe blocks to satisfy Rust 2024 safety checks.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768184607087,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768184607087,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768184607087,0]}
{"id":"bd-1nxv","created_at":[1768689822716,0],"created_by":"darin@darinsmcstudio2.lan","title":"Ordered-link repl model can't inspect wrapped state","description":"In repl_core_machine ordered-link mode, ActorWrapper uses StateWrapper with private wrapped_state, so we can't apply node-level invariants. Consider adding a local adapter or upstream accessor to expose the inner state (or expand history-based checks) so ordered-link runs the full property suite.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769553104744,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769553104744,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769553104744,0]}
{"id":"bd-1p0","created_at":[1766116455164,0],"created_by":"darin@darinsmcstudio2.lan","title":"complete_sync must not drop local mutations on join failure","description":"**Problem**\nIn `Daemon::complete_sync`, if mutations happened during sync and `CanonicalState::join` fails, the code discards local state and keeps `synced_state`. That can drop mutations made during the sync window.\n\n**Design**\nWhen join fails, detect/resolution collisions (reuse `git::collision` logic) and retry the merge. If merge still fails, keep local state, mark dirty, and surface/log the failure so operators can intervene.\n\n**Acceptance**\n- [ ] Local mutations are never dropped on join failure\n- [ ] Collision resolution is applied for dirty-after-sync merges\n- [ ] Tests cover the join-failure path\n- [ ] Tests pass\n\n**Files:** src/daemon/core.rs, src/git/collision.rs","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766124452435,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766124452435,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766124452435,0]}
{"id":"bd-1qp","created_at":[1768273182411,0],"created_by":"darin@darinsmcstudio2.lan","title":"IPC per-request Ping adds ~60ms overhead to each CLI request","description":"**Problem**\nEvery IPC request does a Ping (version check) round-trip before the actual request.\n\n- Direct socket: ~60ms for one request\n- CLI: ~120ms+ for one request (Ping + actual)\n- `bd show` (human mode): 8 requests × 60ms ping = ~480ms overhead\n\n**Evidence**\n```\nbd list -n 1: 64ms    (1 actual request + 1 ping)\nbd --json show: 26ms  (2 actual + 2 pings? or cached?)\nbd show simple: 480ms (8 requests, each with ping)\n```\n\n**Design Options**\n1. Connection reuse: Keep single connection per CLI invocation, verify once\n2. Session tokens: First Ping returns token, skip verification for subsequent\n3. Request batching: Combine Show+Deps+Notes into ShowWithContext\n\n**Acceptance**\n- [ ] `bd show simple-bead` < 200ms\n- [ ] No version mismatch regressions","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Skip version ping when daemon.meta.json matches; added meta-based version checks and unit tests for match/mismatch.","assignee":"darin@book","_at":[1768432343423,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768432343423,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768432343423,0]}
{"id":"bd-1qt","created_at":[1768495449924,0],"created_by":"darin@darinsmcstudio2.lan","title":"Show namespace in CLI issue outputs","description":"**Problem**\nHuman CLI output (show/list/ready/blocked/stale) does not display namespace, which is critical when multiple namespaces are in play.\n\n**Design**\nExtend render helpers in src/cli/render.rs to show `namespace` for issue detail and list rows. Keep formatting concise and deterministic.\n\n**Files**\n- src/cli/render.rs","acceptance_criteria":"- [ ] Issue detail output includes namespace line\n- [ ] Issue lists include namespace indicator\n- [ ] Formatting is deterministic and covered by tests","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768497048898,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768497048898,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768497048898,0]}
{"id":"bd-1u2","created_at":[1765835909920,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add kill -9 crash recovery integration test for WAL","description":"Add integration test that:\n1. Starts daemon\n2. Creates beads\n3. SIGKILL daemon (before sync completes)\n4. Restarts daemon\n5. Verifies beads recovered from WAL\n\nRequires subprocess spawning and signal handling in test harness. See tests/critical_path.rs for existing integration test patterns.","priority":3,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1766129876918,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766129876918,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-1v5w","created_at":[1769580707061,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove legacy label/note stores; migrate to lineage-only","description":"**Problem**\nLabels and notes are stored in two parallel representations: lineage-aware stores and legacy per-bead stores.\n- `LabelStore` has `by_bead` + `legacy_by_bead` in `crates/beads-core/src/state.rs`\n- `NoteStore` has `by_bead` + `legacy_by_bead` in `crates/beads-core/src/state.rs`\n- Call sites merge these in multiple places (`CanonicalState::labels_for`, `bead_view`, `git/wire.rs` serialization, checkpoint import, WAL legacy snapshot)\n\nThis is a root scatter source: the same data lives in two places, invariants are enforced by convention, and every read path must remember to merge legacy + lineage.\n\n**Files:**\n- `crates/beads-core/src/state.rs`\n- `crates/beads-rs/src/git/wire.rs`\n- `crates/beads-rs/src/git/checkpoint/import.rs`\n- `crates/beads-rs/src/daemon/wal_legacy_snapshot.rs`\n- `crates/beads-rs/src/daemon/core.rs`","design":"**Design**\nMake lineage-based storage the only representation for labels and notes, and migrate legacy data on load.\n\nConcrete plan:\n1) Remove `legacy_by_bead` from `LabelStore` and `NoteStore` and all callers that merge legacy state.\n2) Introduce a migration step when loading legacy data (git store, WAL snapshot, checkpoint import) that:\n   - Derives lineage stamps (e.g., from bead core created stamp)\n   - Moves legacy labels/notes into the lineage map\n3) Update serialization to emit only lineage-aware structures.\n4) Keep a single explicit compatibility adapter for legacy on-disk formats (isolated in the import layer), and delete legacy logic elsewhere.\n\n**Design Notes**\n- Ensure collision tombstone behavior remains correct after migration.\n- If any legacy data lacks lineage, use a deterministic fallback stamp with explicit documentation.","acceptance_criteria":"**Acceptance**\n- [ ] `LabelStore` and `NoteStore` no longer contain legacy maps; all state is lineage-based.\n- [ ] Legacy on-disk formats are migrated at the import boundary (git store / WAL / checkpoint).\n- [ ] All read paths (`labels_for`, `bead_view`, serialization) use a single source of truth without legacy merges.\n- [ ] Tests cover migration of legacy labels/notes and correctness of lineage-based reads.","priority":2,"type":"chore","labels":{"entries":{"consistency":[{"replica":"afe27b0e-ec99-eb74-5157-dda998ba4c0b","counter":12841434701901136451}],"scatter":[{"replica":"814fc6b6-edb3-5133-fd32-98a218feea95","counter":14068472835475420936}],"tech-debt":[{"replica":"62f0a584-ff0c-48cc-bc5d-35652e537594","counter":12235574247874123841}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769765456312,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769765456312,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769765456312,0]}
{"id":"bd-1vk","created_at":[1768503238667,0],"created_by":"darin@darinsmcstudio2.lan","title":"Checkpoint dirty shards should be typed (no raw String paths)","description":"**Problem**\n`StoreRuntime` tracks checkpoint dirty shards as `BTreeSet<String>` of shard paths (`checkpoint_dirty_shards` / `checkpoint_dirty_inflight`). This mixes path construction with storage and makes it easy to emit inconsistent shard paths or forget to update a path format. It also spreads stringly-typed shard logic across the runtime.\n\n**Files**\n- src/daemon/store_runtime.rs\n- src/daemon/checkpoint_snapshot.rs (or snapshot builder)\n- src/daemon/checkpoint.rs helpers (shard_path)","design":"Introduce a typed `CheckpointShardPath` (or `CheckpointShardKey` + `to_path()`), containing namespace, shard kind, and shard id. Store these in the dirty shard sets instead of raw strings, and only render to path strings when serializing snapshots. Update helpers like `shard_path` to construct the typed value.","acceptance_criteria":"- [ ] Dirty shard tracking uses a typed shard/path type, not `String`.\n- [ ] Snapshot serialization still emits the same on-disk shard paths.\n- [ ] Dirty shard tests updated to use the typed value.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768530397553,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768530397553,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768530397553,0]}
{"id":"bd-1vt","created_at":[1769398652632,0],"created_by":"darin@book","title":"Crate boundary refactor: split beads-rs into workspace DAG","description":"","priority":1,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1769398652632,0],"_by":"darin@book"}
{"id":"bd-1vt.1","created_at":[1771011162463,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase II: daemon internal modularization + trait seams","description":"**Problem**\\nDaemon internal organization is still broad ( remains a large coordination surface) and boundary seams for future library extraction are not encoded with traits/facades.\\n\\n**Design**\\nComplete the phase-II internal pass by tightening daemon module boundaries, adding trait seams for runtime-facing services, and preserving wire/API behavior. Keep changes internal (no crate moves), with compatibility re-exports where needed.\\n\\n**Acceptance**\\n- [ ] Daemon internal modules are organized by boundary with clear ownership\\n- [ ] New traits/facades added where orchestration currently reaches into concrete subsystems\\n- [ ] External behavior + IPC/API compatibility preserved\\n- [ ] , \nrunning 1 test\ntest crate_dag_matches_policy ... ok\n\ntest result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.03s, , \nrunning 3 tests\ntest issues::tests::issue_updated_at_tracks_note_change ... ok\ntest issues::tests::issue_summary_updated_at_tracks_label_change ... ok\ntest issues::tests::issue_serializes_status_and_type_as_strings ... ok\n\ntest result: ok. 3 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 34 tests\n✗ Aider integration not installed\n  Run: bd setup aider\n✗ No hooks installed\n  Run: bd setup claude\n✗ Cursor integration not installed\n  Run: bd setup cursor\ntest commands::onboard::tests::agents_content_has_key_elements ... ok\ntest commands::prime::tests::context_is_not_empty ... ok\ntest commands::prime::tests::write_context_if_is_silent_outside_beads_repo ... ok\ntest commands::label::tests::split_label_batch_requires_label ... ok\ntest commands::daemon::tests::render_daemon_info_matches_human_format ... ok\ntest commands::setup::tests::aider_instructions_contains_beads ... ok\ntest commands::prime::tests::write_context_if_outputs_context_in_beads_repo ... ok\ntest commands::list::tests::render_issue_list_includes_namespace ... ok\ntest commands::ready::tests::render_ready_includes_namespace ... ok\ntest commands::label::tests::split_label_batch_parses_ids_and_label ... ok\ntest commands::setup::tests::cursor_rules_contains_beads ... ok\ntest commands::setup::tests::check_claude_returns_error_when_not_installed ... ok\ntest commands::show::tests::render_show_includes_namespace ... ok\ntest commands::setup::tests::check_aider_returns_error_when_not_installed ... ok\ntest commands::setup::tests::check_cursor_returns_error_when_not_installed ... ok\ntest commands::admin::tests::render_admin_status_includes_watermarks ... ok\ntest commands::subscribe::tests::handle_response_returns_error_on_non_retryable_error ... ok\ntest commands::store::tests::render_fsck_human_golden ... ok\ntest commands::subscribe::tests::handle_response_stops_stream_on_retryable_error ... ok\ntest commands::tests::render_ok_human_renders_basic_status_payloads ... ok\ntest commands::tests::render_ok_human_renders_op_and_query_variants ... ok\ntest commands::tests::render_ok_human_renders_validation_query ... ok\ntest paths::tests::resolve_data_dir_prefers_env_override ... ok\ntest paths::tests::resolve_log_dir_prefers_env_override ... ok\ntest paths::tests::store_paths_are_derived_from_data_dir ... ok\ntest runtime::tests::mutation_meta_includes_actor_override ... ok\ntest runtime::tests::daemon_response_error_display_includes_code_message_and_details ... ok\ntest runtime::tests::resolve_description_rejects_mismatched_alias_values ... ok\ntest runtime::tests::read_consistency_includes_read_gating ... ok\ntest runtime::tests::response_payload_returns_daemon_error_payload ... ok\ntest runtime::tests::response_payload_returns_ok_payload ... ok\ntest upgrade::release::tests::version_compare ... ok\ntest migrate::go_export::tests::multiple_comments_same_issue_are_unique ... ok\ntest migrate::go_export::tests::comment_ids_are_globally_unique_across_issues ... ok\n\ntest result: ok. 34 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 224 tests\ntest bead::tests::projection_claim_and_closed_info ... ok\ntest bead::tests::content_hash_depends_on_all_fields ... ok\ntest apply::tests::bead_creation_collision_is_deterministic ... ok\ntest apply::tests::note_append_before_bead_exists_is_stored ... ok\ntest apply::tests::outcome_tracks_notes_and_beads ... ok\ntest bead::tests::projection_includes_labels_and_timestamps ... ok\ntest apply::tests::apply_claim_patch_set_with_clear_expiry_is_total ... ok\ntest apply::tests::collision_tombstone_is_order_independent ... ok\ntest apply::tests::apply_event_is_idempotent ... ok\ntest apply::tests::bead_delete_ignores_older_than_live ... ok\ntest apply::tests::note_collision_is_deterministic ... ok\ntest apply::tests::label_ops_on_missing_bead_are_total ... ok\ntest apply::tests::label_add_same_value_different_dot_tracks_change ... ok\ntest apply::tests::dep_delete_before_create_converges ... ok\ntest apply::tests::dep_add_accepts_acyclic_dag_edge ... ok\ntest bead::tests::same_lineage_join_merges_fields ... ok\ntest apply::tests::dep_add_rejects_cycle_from_apply_event ... ok\ntest bead::tests::same_lineage_join_rejects_mixed_wrapper_pairs ... ok\ntest bead::tests::same_lineage_rejects_mismatched_creation ... ok\ntest collections::tests::label_parse_valid ... ok\ntest collections::tests::label_rejects_empty ... ok\ntest collections::tests::label_rejects_newlines ... ok\ntest collections::tests::label_trims_whitespace ... ok\ntest collections::tests::labels_remove_reports_change ... ok\ntest dep::tests::accessors_work ... ok\ntest dep::tests::dep_spec_parse_list_handles_kinds_and_commas ... ok\ntest dep::tests::dep_spec_rejects_parent_kind ... ok\ntest collections::tests::labels_serde_roundtrip ... ok\ntest dep::tests::dep_spec_set_sorts_and_dedups ... ok\ntest dep::tests::dep_spec_set_json_roundtrip ... ok\ntest dep::tests::dep_spec_to_spec_string_omits_default_kind ... ok\ntest dep::tests::parent_edge_rejects_self_parent ... ok\ntest dep::tests::self_dependency_rejected ... ok\ntest dep::tests::serde_rejects_self_dep ... ok\ntest dep::tests::serde_roundtrip ... ok\ntest dep_tombstone_store::tests::tombstone_store_upsert_merges ... ok\ntest domain::tests::dep_kind_ordering_is_lexical ... ok\ntest domain::tests::dep_kind_parse_accepts_aliases ... ok\ntest domain::tests::dep_kind_parse_rejects_unknown ... ok\ntest domain::tests::priority_serde_roundtrip ... ok\ntest domain::tests::priority_serde_validates_on_deserialize ... ok\ntest durability::tests::durability_outcome_serde_roundtrip ... ok\ntest durability::tests::durability_parse_accepts_variants ... ok\ntest durability::tests::durability_parse_rejects_invalid ... ok\ntest durability::tests::durability_receipt_merge_upgrades ... ok\ntest durability::tests::durability_receipt_rejects_achieved_without_quorum ... ok\ntest durability::tests::durability_receipt_rejects_missing_replicated_proof ... ok\ntest durability::tests::durability_proof_serde_roundtrip ... ok\ntest error::tests::error_code_parse_distinguishes_protocol_and_cli ... ok\ntest error::tests::error_code_serializes_to_string_values ... ok\ntest durability::tests::durability_receipt_serde_roundtrip ... ok\ntest error::tests::error_payload_roundtrip_preserves_retryable_and_receipt ... ok\ntest error::tests::unknown_error_code_decodes ... ok\ntest event::tests::canonical_encode_is_stable ... ok\ntest event::tests::decode_rejects_array_entry_bounds ... ok\ntest event::tests::decode_event_hlc_max_extracts ... ok\ntest event::tests::decode_event_hlc_max_rejects_physical_mismatch ... ok\ntest event::tests::decode_accepts_unknown_event_body_fields ... ok\ntest event::tests::cbor_roundtrip_dep_ops ... ok\ntest event::tests::cbor_roundtrip_label_ops_preserves_dots ... ok\ntest event::tests::decode_rejects_depth_bounds ... ok\ntest event::tests::decode_rejects_duplicate_bead_patch_keys ... ok\ntest event::tests::decode_rejects_duplicate_note_keys ... ok\ntest event::tests::decode_rejects_duplicate_event_body_keys ... ok\ntest event::tests::decode_rejects_duplicate_hlc_max_keys ... ok\ntest event::tests::decode_rejects_duplicate_txn_delta_keys ... ok\ntest event::tests::decode_rejects_indefinite_length ... ok\ntest event::tests::decode_rejects_hlc_physical_mismatch ... ok\ntest event::tests::decode_rejects_invalid_branch_name ... ok\ntest event::tests::decode_rejects_legacy_labels_patch ... ok\ntest event::tests::decode_rejects_map_entry_bounds ... ok\ntest event::tests::decode_rejects_invalid_workflow_patch ... ok\ntest event::tests::decode_rejects_overlong_u32 ... ok\ntest event::tests::decode_rejects_partial_tombstone_lineage ... ok\ntest event::tests::decode_rejects_missing_hlc_max_for_txn ... ok\ntest event::tests::decode_rejects_overlong_u64 ... ok\ntest event::tests::decode_rejects_record_size_bounds ... ok\ntest event::tests::decode_rejects_tagged_integer ... ok\ntest event::tests::decode_rejects_text_bounds ... ok\ntest event::tests::encode_tombstone_without_lineage_uses_base_len ... ok\ntest event::tests::decode_roundtrip_event_body ... ok\ntest event::tests::event_validation_rejects_too_many_ops ... ok\ntest event::tests::event_frame_rejects_prev_seq_mismatch ... ok\ntest event::tests::validate_accepts_claim_clear ... ok\ntest event::tests::tombstone_roundtrip_with_lineage ... ok\ntest event::tests::validate_accepts_claim_set_with_clear_expiry ... ok\ntest event::tests::validate_rejects_clear_claim_with_expires_set ... ok\ntest event::tests::decode_roundtrip_event_body_with_ops ... ok\ntest event::tests::validate_rejects_keep_claim_patch_fields ... ok\ntest event::tests::validate_rejects_keep_workflow_patch_fields ... ok\ntest event::tests::validate_rejects_partial_creation_stamp_at_only ... ok\ntest event::tests::validate_rejects_partial_creation_stamp_by_only ... ok\ntest event::tests::validate_rejects_partial_tombstone_lineage ... ok\ntest event::tests::validated_mutation_command_builds_event_body ... ok\ntest event::tests::validated_mutation_command_rejects_invalid_workflow_patch ... ok\ntest event::tests::verified_event_frame_accepts_canonical_frame ... ok\ntest event::tests::verified_event_frame_rejects_hash_mismatch ... ok\ntest event::tests::verified_event_frame_rejects_non_canonical_bytes ... ok\ntest event::tests::verified_event_frame_rejects_prev_seq_mismatch ... ok\ntest event::tests::verify_event_frame_accepts_contiguous_prev ... ok\ntest identity::tests::actor_id_rejects_whitespace_only ... ok\ntest event::tests::verify_event_frame_defers_prev_when_head_unknown ... ok\ntest event::tests::verify_event_frame_rejects_non_canonical_bytes ... ok\ntest identity::tests::actor_id_serde_rejects_whitespace_only ... ok\ntest event::tests::verify_event_frame_returns_canonical_bytes ... ok\ntest identity::tests::actor_id_serde_validates_on_deserialize ... ok\ntest identity::tests::bead_id_parse_with_custom_slug ... ok\ntest identity::tests::bead_id_serde_validates_on_deserialize ... ok\ntest identity::tests::bead_id_slug_is_canonicalized ... ok\ntest identity::tests::bead_id_with_slug_rewrites_prefix ... ok\ntest identity::tests::bead_slug_parse_normalizes ... ok\ntest identity::tests::bead_slug_rejects_invalid ... ok\ntest identity::tests::branch_name_parse_valid ... ok\ntest identity::tests::branch_name_rejects_empty ... ok\ntest identity::tests::branch_name_rejects_invalid ... ok\ntest identity::tests::branch_name_trims ... ok\ntest identity::tests::checkpoint_content_digest_is_stable ... ok\ntest identity::tests::client_request_id_serde_roundtrip ... ok\ntest identity::tests::identity_types_serde_roundtrip ... ok\ntest identity::tests::canonical_state_digest_matches_canon_bytes ... ok\ntest identity::tests::note_id_serde_validates_on_deserialize ... ok\ntest identity::tests::replica_id_serde_roundtrip ... ok\ntest identity::tests::segment_id_serde_roundtrip ... ok\ntest identity::tests::state_canonical_json_digest_is_stable ... ok\ntest identity::tests::state_jsonl_digest_is_stable ... ok\ntest identity::tests::store_epoch_serde_roundtrip ... ok\ntest identity::tests::store_id_serde_roundtrip ... ok\ntest identity::tests::store_identity_serde_roundtrip ... ok\ntest identity::tests::trace_id_serde_roundtrip ... ok\ntest identity::tests::txn_id_serde_roundtrip ... ok\ntest json_canon::tests::canon_json_rejects_non_finite_numbers ... ok\ntest json_canon::tests::canon_json_is_deterministic_for_hashmap ... ok\ntest limits::tests::limits_defaults_match_plan ... ok\ntest meta::tests::current_version_is_1 ... ok\ntest json_canon::tests::canon_json_sorts_keys_recursively ... ok\ntest meta::tests::meta_serde_roundtrip ... ok\ntest meta::tests::meta_serde_roundtrip_with_root_slug ... ok\ntest meta::tests::version_compatibility ... ok\ntest namespace::tests::namespace_id_serde_roundtrip ... ok\ntest namespace::tests::namespace_id_validates ... ok\ntest namespace::tests::namespace_policy_defaults_match_plan ... ok\ntest namespace::tests::namespace_set_json_roundtrip ... ok\ntest namespace::tests::namespace_set_sorts_and_dedups ... ok\ntest namespaced_state::tests::core_namespace_is_always_present ... ok\ntest namespaced_state::tests::core_namespace_rejects_non_core_wrapper ... ok\ntest namespaced_state::tests::non_core_namespace_behaves_like_core ... ok\ntest orset::tests::dvv_join_is_monotonic_for_dominance ... ok\ntest orset::tests::dvv_dominates_and_join ... ok\ntest orset::tests::orset_add_ignores_dominated_dot ... ok\ntest orset::tests::orset_add_remove_basic ... ok\ntest orset::tests::orset_add_wins_over_remove_ctx ... ok\ntest orset::tests::orset_collision_picks_higher_value ... ok\ntest orset::tests::orset_join_commutative_and_idempotent ... ok\ntest orset::tests::orset_join_drops_dominated_dots ... ok\ntest orset::tests::orset_join_preserves_concurrent_add ... ok\ntest orset::tests::orset_join_preserves_unrelated_value_from_remove_ctx ... ok\ntest orset::tests::orset_normalize_for_import_resolves_dot_collisions ... ok\ntest orset::tests::orset_remove_does_not_remove_unrelated_value ... ok\ntest orset::tests::orset_remove_with_ctx_drops_all_dots ... ok\ntest orset::tests::orset_try_from_parts_allows_duplicates_already_dominated_by_cc ... ok\ntest orset::tests::orset_try_from_parts_drops_empty_entries ... ok\ntest orset::tests::orset_try_from_parts_prunes_dominated_dots ... ok\ntest orset::tests::orset_try_from_parts_rejects_duplicate_dots ... ok\ntest replica_roster::tests::rejects_observer_with_durability_eligibility ... ok\ntest replica_roster::tests::parses_observer_without_durability_eligibility ... ok\ntest replica_roster::tests::rejects_duplicate_replica_id ... ok\ntest replica_roster::tests::rejects_duplicate_replica_name ... ok\ntest replica_roster::tests::parses_roster_with_defaults ... ok\ntest state::tests::deletion_wins_when_newer ... ok\ntest state::tests::dep_index_insert_active_edge ... ok\ntest state::tests::dep_index_deps_from_uses_index ... ok\ntest state::tests::dep_index_deps_to_uses_index ... ok\ntest state::tests::dep_index_insert_deleted_edge ... ok\ntest state::tests::collision_hides_other_lineage_labels_and_notes ... ok\ntest state::tests::dep_index_multiple_kinds ... ok\ntest state::tests::dep_index_join_rebuilds_indexes ... ok\ntest state::tests::dep_index_rebuild_from_deps ... ok\ntest state::tests::dep_index_transition_active_to_deleted ... ok\ntest state::tests::dep_index_transition_deleted_to_active ... ok\ntest state::tests::dep_stamp_is_monotonic_for_out_of_order_ops ... ok\ntest state::tests::dep_stamp_updates_on_new_dot_without_membership_change ... ok\ntest state::tests::dependency_cycles_empty_for_acyclic_graph ... ok\ntest state::tests::dependency_cycles_detects_simple_cycle ... ok\ntest state::tests::invariant_delete_removes_live ... ok\ntest state::tests::invariant_insert_removes_tombstone ... ok\ntest state::tests::label_stamp_is_monotonic_for_out_of_order_ops ... ok\ntest state::tests::label_stamp_updates_on_new_dot_without_membership_change ... ok\ntest state::tests::note_store_join_resolves_collisions_deterministically ... ok\ntest state::tests::parent_edges_to_keeps_children_visible_when_parent_tombstoned ... ok\ntest state::tests::require_live_mut_returns_mutable_bead ... ok\ntest state::tests::require_live_returns_bead_when_exists ... ok\ntest state::tests::require_live_returns_deleted_for_tombstoned_id ... ok\ntest state::tests::require_live_returns_not_found_for_unknown_id ... ok\ntest state::tests::resurrection_newer_bead_wins ... ok\ntest state::tests::updated_stamp_includes_labels_and_notes ... ok\ntest store_meta::tests::store_meta_versions_current_is_consistent ... ok\ntest watermark::tests::advance_contiguous_rejects_gaps ... ok\ntest store_meta::tests::store_meta_serde_roundtrip ... ok\ntest watermark::tests::advance_contiguous_sets_seq0_to_seq1 ... ok\ntest watermark::tests::merge_at_least_head_mismatch_is_order_independent ... ok\ntest watermark::tests::observe_at_least_rejects_head_mismatch_same_seq ... ok\ntest watermark::tests::observe_at_least_validates_head_on_equal_seq ... ok\ntest watermark::tests::seq_helpers_work ... ok\ntest watermark::tests::watermark_rejects_genesis_for_nonzero_seq ... ok\ntest watermark::tests::watermark_rejects_head_at_genesis ... ok\ntest watermark::tests::watermark_rejects_unknown_on_deserialize ... ok\ntest wire_bead::tests::txn_delta_rejects_duplicate_keys ... ok\ntest wire_bead::tests::snapshot_codec_rejects_out_of_order_beads ... ok\ntest wire_bead::tests::snapshot_codec_absorbs_legacy_note_lineage_into_live_lineage ... ok\ntest wire_bead::tests::wire_claim_snapshot_rejects_expires_without_assignee ... ok\ntest wire_bead::tests::wire_claim_snapshot_unclaimed_when_fields_absent ... ok\ntest wire_bead::tests::wire_claim_snapshot_rejects_invalid_assignee_instead_of_falling_back ... ok\ntest wire_bead::tests::txn_delta_orders_ops_canonically ... ok\ntest wire_bead::tests::wire_dep_add_rejects_self_dependency ... ok\ntest wire_bead::tests::wire_note_conversion_roundtrip ... ok\ntest wire_bead::tests::wire_bead_patch_roundtrip ... ok\ntest wire_bead::tests::wire_note_roundtrip ... ok\ntest wire_bead::tests::wire_bead_full_preserves_stamps ... ok\ntest wire_bead::tests::txn_delta_roundtrip ... ok\ntest wire_bead::tests::wire_bead_full_json_roundtrip_preserves_sparse_v ... ok\ntest wire_bead::tests::wire_bead_full_normalizes_legacy_timestamps ... ok\ntest wire_bead::tests::snapshot_codec_roundtrip ... ok\ntest state::tests::lineage_tombstone_only_kills_matching_lineage ... ok\ntest state::tests::join_resurrection_rule_prefers_newer_bead ... ok\n\ntest result: ok. 224 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.01s\n\n\nrunning 36 tests\ntest broadcast::tests::hot_cache_evicts_by_bytes ... ok\ntest broadcast::tests::hot_cache_evicts_by_event_count ... ok\ntest clock::tests::backward_jump_keeps_monotonicity ... ok\ntest broadcast::tests::delivers_events_in_order ... ok\ntest broadcast::tests::subscriber_drops_on_full_queue ... ok\ntest broadcast::tests::subscriber_drops_on_byte_limit ... ok\ntest admission::tests::repl_limits_report_queue_metrics ... ok\ntest admission::tests::repl_sheds_before_ipc_mutations ... ok\ntest clock::tests::forward_jump_advances_wall_time ... ok\ntest admission::tests::ipc_limit_enforced_and_released ... ok\ntest clock::tests::forward_jump_clamps_within_session ... ok\ntest clock::tests::receive_with_older_stamp_is_noop ... ok\ntest clock::tests::restart_recovers_without_regression ... ok\ntest clock::tests::tick_is_monotonic ... ok\ntest clock::tests::receive_advances_clock ... ok\ntest git_lane::tests::backoff_exponential ... ok\ntest git_lane::tests::mark_dirty ... ok\ntest git_lane::tests::new_state_not_dirty ... ok\ntest io_budget::tests::rate_zero_disables_throttle ... ok\ntest io_budget::tests::reserve_returns_wait_for_deficit ... ok\ntest metrics::tests::emits_counters_and_histograms ... ok\ntest remote::tests::normalize_file_url_localhost_matches_path ... ok\ntest metrics::tests::snapshot_collects_metrics ... ok\ntest remote::tests::normalize_file_url_with_host_preserves_host ... ok\ntest remote::tests::normalize_file_urls_are_stable ... ok\ntest remote::tests::normalize_https_and_ssh ... ok\ntest remote::tests::normalize_https_userinfo_matches_host_only ... ok\ntest remote::tests::normalize_local_paths_trim_git_suffix ... ok\ntest remote::tests::normalize_trims_slashes ... ok\ntest remote::tests::normalize_with_port_and_case ... ok\ntest remote::tests::normalize_user_and_scheme_variants_match ... ok\ntest scheduler::tests::backoff_never_shortens_deadline ... ok\ntest scheduler::tests::cancel ... ok\ntest scheduler::tests::reschedule_debounces_later ... ok\ntest scheduler::tests::schedule_and_drain_due ... ok\ntest scheduler::tests::stress_reschedules_do_not_accumulate_due_fires ... ok\n\ntest result: ok. 36 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.01s\n\n\nrunning 44 tests\ntest repl::contiguous_batch::tests::contiguous_batch_rejects_gap ... ok\ntest repl::frame::tests::frame_reader_rejects_oversize_frame ... ok\ntest repl::frame::tests::frame_reader_enforces_negotiated_limit ... ok\ntest repl::contiguous_batch::tests::contiguous_batch_rejects_duplicate ... ok\ntest repl::contiguous_batch::tests::contiguous_batch_accepts_valid_sequence ... ok\ntest repl::contiguous_batch::tests::contiguous_batch_rejects_mixed_origin ... ok\ntest repl::frame::tests::frame_roundtrip_validates_crc ... ok\ntest durability::tests::unavailable_when_not_enough_eligible ... ok\ntest durability::tests::replicated_fsync_succeeds_after_k_acks ... ok\ntest repl::frame::tests::frame_too_large_maps_to_error_payload ... ok\ntest repl::gap_buffer::tests::duplicate_events_are_noops ... ok\ntest repl::gap_buffer::tests::gap_bytes_overflow_rejects ... ok\ntest repl::gap_buffer::tests::deferred_event_blocks_drain ... ok\ntest repl::gap_buffer::tests::gap_overflow_rejects ... ok\ntest repl::gap_buffer::tests::gap_timeout_rejects ... ok\ntest repl::gap_buffer::tests::multiple_gaps_drain_in_order ... ok\ntest repl::gap_buffer::tests::single_gap_buffers_then_drains ... ok\ntest repl::peer_acks::tests::divergent_heads_are_excluded_from_quorum ... ok\ntest repl::peer_acks::tests::updates_require_monotonic_seq ... ok\ntest repl::peer_acks::tests::satisfied_k_distinguishes_failure_modes ... ok\ntest repl::proto::tests::decode_ack_rejects_missing_head_for_nonzero_seq ... ok\ntest repl::proto::tests::decode_hello_rejects_missing_head_for_nonzero_seq ... ok\ntest repl::proto::tests::decode_ack_rejects_head_at_genesis ... ok\ntest repl::proto::tests::decode_namespace_list_accepts_empty ... ok\ntest repl::proto::tests::decode_namespace_list_canonicalizes_order_and_dedups ... ok\ntest repl::proto::tests::decode_hello_rejects_head_at_genesis ... ok\ntest repl::proto::tests::decode_namespace_list_rejects_invalid_namespace ... ok\ntest repl::proto::tests::decode_welcome_rejects_head_at_genesis ... ok\ntest durability::tests::timeout_returns_pending_receipt ... ok\ntest repl::proto::tests::decode_welcome_rejects_missing_head_for_nonzero_seq ... ok\ntest repl::proto::tests::repl_envelope_key_order_is_stable ... ok\ntest repl::proto::tests::repl_batch_too_large_maps_to_error_payload ... ok\ntest repl::proto::tests::repl_message_roundtrip_ack ... ok\ntest repl::proto::tests::repl_message_rejects_version_mismatch_for_events_ack_want ... ok\ntest repl::proto::tests::repl_message_roundtrip_error_payload ... ok\ntest repl::proto::tests::repl_message_body_key_order_is_stable ... ok\ntest repl::proto::tests::repl_message_roundtrip_hello ... ok\ntest repl::proto::tests::repl_message_roundtrip_ping ... ok\ntest repl::proto::tests::repl_message_roundtrip_pong ... ok\ntest repl::proto::tests::repl_message_roundtrip_want ... ok\ntest repl::proto::tests::repl_message_roundtrip_welcome ... ok\ntest wal::memory_index::tests::memory_index_records_event_and_watermarks ... ok\ntest repl::proto::tests::repl_message_roundtrip_events ... ok\ntest wal::memory_index::tests::memory_index_rejects_client_request_id_mismatch ... ok\n\ntest result: ok. 44 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 375 tests\ntest cli::tests::normalize_optional_client_request_id_accepts_uuid ... ok\ntest cli::tests::normalize_optional_client_request_id_rejects_empty ... ok\ntest cli::tests::normalize_optional_namespace_accepts_core ... ok\ntest cli::tests::normalize_optional_namespace_rejects_empty ... ok\ntest cli::tests::normalize_optional_namespace_rejects_invalid_chars ... ok\ntest cli::tests::normalize_bead_id_rejects_empty ... ok\ntest cli::tests::normalize_bead_slug_rejects_invalid ... ok\ntest cli::tests::normalize_bead_id_canonicalizes ... ok\ntest cli::tests::resolve_actor_override_accepts_actor ... ok\ntest cli::tests::mutation_meta_includes_actor_override ... ok\ntest cli::tests::validate_actor_id_rejects_blank ... ok\ntest cli::tests::parse_require_min_seen_rejects_invalid_json ... ok\ntest compat::export::tests::test_hash_remote_different_urls ... ok\ntest compat::export::tests::test_hash_remote_deterministic ... ok\ntest compat::export::tests::test_export_context_path ... ok\ntest cli::tests::read_consistency_includes_read_gating ... ok\ntest cli::tests::resolve_defaults_cli_overrides_config ... ok\ntest cli::tests::parse_require_min_seen_accepts_json ... ok\ntest cli::tests::resolve_defaults_use_config_when_no_flags ... ok\ntest compat::go_schema::tests::test_derive_status ... ok\ntest compat::go_schema::tests::test_dep_kind_mapping ... ok\ntest compat::go_schema::tests::test_write_stamp_to_rfc3339 ... ok\ntest config::merge::tests::env_log_filter_overrides_config ... ok\ntest config::load::tests::config_defaults_match_plan ... ok\ntest config::merge::tests::env_path_overrides_apply ... ok\ntest config::merge::tests::merge_layers_respects_precedence ... ok\ntest config::merge::tests::env_overrides_apply ... ok\ntest config::merge::tests::env_test_fast_overrides_clamp_timers ... ok\ntest daemon::admin::tests::wal_guardrails_warn_on_limits ... ok\ntest daemon::checkpoint_scheduler::tests::debounce_reschedules_later ... ok\ntest daemon::checkpoint_scheduler::tests::dirty_during_in_flight_schedules_follow_up ... ok\ntest daemon::checkpoint_scheduler::tests::max_events_triggers_immediate ... ok\ntest daemon::checkpoint_scheduler::tests::max_interval_caps_deadline ... ok\ntest daemon::checkpoint_scheduler::tests::queue_limit_coalesces_by_group ... ok\ntest compat::export::tests::test_nonexistent_clone_path_skipped ... ok\ntest daemon::admin::tests::offline_lock_info_returns_none_when_missing ... ok\ntest compat::export::tests::test_export_with_beads ... ok\ntest compat::export::tests::test_symlink_replaced_when_wrong_target ... ok\ntest compat::export::tests::test_regular_file_backed_up_and_replaced ... ok\ntest compat::export::tests::test_symlink_skipped_when_correct ... ok\ntest daemon::core::tests::checkpoint_roster_hash_mismatch_warns ... ok\ntest compat::export::tests::test_export_empty_state ... ok\ntest daemon::core::tests::detect_clock_skew_flags_large_delta ... ok\ntest config::load::tests::config_roundtrip ... ok\ntest daemon::core::tests::detect_clock_skew_ignores_small_delta ... ok\ntest compat::export::tests::test_tombstones_not_exported ... ok\ntest compat::export::tests::test_symlink_created_when_none_exists ... ok\ntest daemon::admin::tests::offline_unlock_removes_stale_lock_file ... ok\ntest compat::export::tests::test_export_sorted_by_id ... ok\ntest compat::export::tests::test_multiple_clones_same_canonical ... ok\ntest daemon::admin::tests::offline_unlock_requires_force_for_live_daemon ... ok\ntest daemon::core::tests::complete_refresh_unknown_remote_is_noop ... ok\ntest daemon::core::tests::ensure_repo_loaded_rejects_non_git_repo ... ok\ntest daemon::core::tests::complete_refresh_applies_state_when_clean ... ok\ntest daemon::core::tests::complete_refresh_clears_flag_on_error ... ok\ntest daemon::core::tests::admin_flush_returns_output ... ok\ntest daemon::core::tests::replica_roster_enforces_permissions ... ok\ntest daemon::core::tests::replica_roster_rejects_symlink ... ok\ntest daemon::core::tests::complete_sync_preserves_local_state_on_collision ... ok\ntest daemon::durability_coordinator::tests::replicated_fsync_succeeds_after_k_acks ... ok\ntest daemon::durability_coordinator::tests::replicated_fsync_unavailable_with_insufficient_eligible ... ok\ntest daemon::durability_coordinator::tests::timeout_returns_pending_receipt ... ok\ntest daemon::executor::tests::attach_issue_includes_created_issue ... ok\ntest daemon::core::tests::complete_refresh_clears_in_progress_flag ... ok\ntest daemon::core::tests::complete_refresh_skips_state_when_dirty ... ok\ntest daemon::executor::tests::op_result_add_note_uses_note_id ... ok\ntest daemon::executor::tests::op_result_claim_reads_expiry ... ok\ntest daemon::executor::tests::op_result_claim_requires_expiry ... ok\ntest daemon::executor::tests::op_result_create_uses_delta_id ... ok\ntest daemon::core::tests::complete_refresh_schedules_sync_when_needs_sync ... ok\ntest daemon::ipc::error_mapping::tests::decode_request_accepts_valid_bead_id ... ok\ntest daemon::ipc::error_mapping::tests::decode_request_invalid_json_is_malformed_payload ... ok\ntest daemon::ipc::error_mapping::tests::decode_request_rejects_invalid_bead_id ... ok\ntest daemon::ipc::error_mapping::tests::decode_request_rejects_invalid_durability ... ok\ntest daemon::ipc::error_mapping::tests::decode_request_rejects_invalid_namespace ... ok\ntest daemon::ipc::error_mapping::tests::decode_request_rejects_invalid_status_value ... ok\ntest daemon::ipc::error_mapping::tests::decode_request_rejects_oversize_frames ... ok\ntest daemon::ipc::error_mapping::tests::decode_request_semantic_error_is_invalid_request ... ok\ntest daemon::ipc::error_mapping::tests::durability_timeout_includes_receipt ... ok\ntest daemon::ipc::error_mapping::tests::invalid_json_would_cause_parse_error ... ok\ntest daemon::ipc::error_mapping::tests::lock_permission_denied_includes_details ... ok\ntest daemon::ipc::error_mapping::tests::namespace_policy_violation_includes_details ... ok\ntest daemon::ipc::error_mapping::tests::version_mismatch_error_includes_parse_error ... ok\ntest daemon::ipc::error_mapping::tests::version_mismatch_is_retryable ... ok\ntest daemon::ipc::error_mapping::tests::wal_index_equivocation_includes_details ... ok\ntest daemon::ipc::error_mapping::tests::wal_index_store_epoch_mismatch_includes_details ... ok\ntest daemon::ipc::error_mapping::tests::wal_replay_format_unsupported_includes_details ... ok\ntest daemon::ipc::error_mapping::tests::wal_replay_hash_mismatch_includes_details ... ok\ntest daemon::ipc::error_mapping::tests::wal_replay_header_decode_is_corrupt ... ok\ntest daemon::ipc::error_mapping::tests::wal_replay_prev_sha_mismatch_includes_details ... ok\ntest daemon::mutation_engine::tests::add_dep_allows_related_cycle ... ok\ntest daemon::mutation_engine::tests::add_dep_rejects_blocks_cycle ... ok\ntest daemon::mutation_engine::tests::add_dep_rejects_parent_kind ... ok\ntest daemon::mutation_engine::tests::create_with_assignee_sets_in_progress ... ok\ntest daemon::mutation_engine::tests::extend_claim_sets_in_progress ... ok\ntest daemon::mutation_engine::tests::invalid_workflow_patch_rejected_in_planning ... ok\ntest daemon::mutation_engine::tests::parsed_request_rejects_invalid_label ... ok\ntest daemon::mutation_engine::tests::planning_does_not_mutate_state ... ok\ntest daemon::mutation_engine::tests::rejects_note_over_limit ... ok\ntest daemon::mutation_engine::tests::rejects_ops_over_limit ... ok\ntest daemon::mutation_engine::tests::request_hash_is_stable_with_label_ordering ... ok\ntest daemon::mutation_engine::tests::set_parent_rejects_cycle ... ok\ntest daemon::mutation_engine::tests::set_parent_replaces_existing_parent_with_parent_ops ... ok\ntest daemon::mutation_engine::tests::stamped_context_rejects_mismatched_actor ... ok\ntest daemon::mutation_engine::tests::txn_id_includes_actor_identity ... ok\ntest daemon::mutation_engine::tests::update_rejects_clearing_required_fields ... ok\ntest daemon::mutation_engine::tests::update_rejects_empty_required_fields ... ok\ntest daemon::mutation_engine::tests::update_trims_required_fields ... ok\ntest daemon::ops::tests::bead_patch_validation ... ok\ntest daemon::query::tests::filters_default_matches_all ... ok\ntest daemon::query::tests::query_repo ... ok\ntest daemon::query_executor::tests::dep_cycles_from_state_reports_cycle ... ok\ntest daemon::query_executor::tests::issue_summary_uses_read_namespace ... ok\ntest daemon::query_executor::tests::issue_view_uses_read_namespace ... ok\ntest daemon::query_executor::tests::ready_sort_orders_by_priority_then_created_at ... ok\ntest daemon::repl::contiguous_batch::tests::contiguous_batch_accepts_valid_sequence ... ok\ntest daemon::repl::contiguous_batch::tests::contiguous_batch_rejects_duplicate ... ok\ntest daemon::repl::contiguous_batch::tests::contiguous_batch_rejects_gap ... ok\ntest daemon::repl::contiguous_batch::tests::contiguous_batch_rejects_mixed_origin ... ok\ntest daemon::repl::error::tests::to_payload_carries_details ... ok\ntest daemon::repl::error::tests::to_payload_preserves_basic_fields ... ok\ntest daemon::repl::gap_buffer::tests::deferred_event_blocks_drain ... ok\ntest daemon::repl::gap_buffer::tests::duplicate_events_are_noops ... ok\ntest daemon::repl::gap_buffer::tests::gap_bytes_overflow_rejects ... ok\ntest daemon::repl::gap_buffer::tests::gap_overflow_rejects ... ok\ntest daemon::repl::gap_buffer::tests::gap_timeout_rejects ... ok\ntest daemon::repl::gap_buffer::tests::multiple_gaps_drain_in_order ... ok\ntest daemon::repl::gap_buffer::tests::single_gap_buffers_then_drains ... ok\ntest daemon::repl::keepalive::tests::keepalive_deadline_trumps_ping ... ok\ntest daemon::repl::keepalive::tests::keepalive_emits_ping_after_idle ... ok\ntest daemon::repl::keepalive::tests::keepalive_recv_resets_deadline ... ok\ntest daemon::repl::manager::tests::backoff_exponentially_grows ... ok\ntest daemon::core::tests::read_scope_rejects_unknown_namespace ... ok\ntest daemon::repl::manager::tests::manager_fans_out_events_and_respects_policy ... ok\ntest daemon::export_worker::tests::export_worker_writes_jsonl_and_symlink ... ok\ntest daemon::repl::manager::tests::manager_connects_and_sends_hello ... ok\ntest daemon::repl::manager::tests::manager_filters_to_accepted_namespaces ... ok\ntest daemon::repl::manager::tests::send_events_respects_negotiated_max_frame_bytes ... ok\ntest daemon::repl::pending::tests::pending_events_drops_new_event_too_large ... ok\ntest daemon::repl::pending::tests::pending_events_drops_oldest_on_byte_limit ... ok\ntest daemon::repl::pending::tests::pending_events_drops_oldest_on_event_limit ... ok\ntest daemon::repl::runtime::tests::wal_range_corrupt_maps_to_wal_corrupt_details ... ok\ntest daemon::repl::runtime::tests::wal_range_index_maps_to_index_corrupt_details ... ok\ntest daemon::core::tests::ingest_accepts_orphan_note_after_append ... ok\ntest daemon::core::tests::read_gate_requires_min_seen ... ok\ntest daemon::repl::server::tests::server_listens_and_spawns_session ... ok\ntest daemon::repl::session::tests::ack_allowed_namespace_forwards_validated_ack ... ok\ntest daemon::repl::session::tests::ack_rejects_disallowed_namespace ... ok\ntest daemon::repl::session::tests::ack_rejects_mixed_namespaces ... ok\ntest daemon::repl::session::tests::decode_error_frame_too_large_maps_to_frame_too_large ... ok\ntest daemon::repl::session::tests::decode_error_indefinite_length_maps_to_non_canonical ... ok\ntest daemon::repl::session::tests::decode_error_invalid_field_maps_to_invalid_request ... ok\ntest daemon::repl::session::tests::events_apply_and_ack ... ok\ntest daemon::repl::session::tests::events_buffer_gap_sends_want ... ok\ntest daemon::repl::session::tests::events_gap_drains_when_missing_event_arrives ... ok\ntest daemon::core::tests::repl_ingest_accepts_non_core_namespace ... ok\ntest daemon::repl::session::tests::events_rejects_unaccepted_namespace ... ok\ntest daemon::repl::manager::tests::reconnects_after_disconnect ... ok\ntest daemon::repl::session::tests::events_wrong_store_errors ... ok\ntest daemon::repl::session::tests::handshake_negotiates_snapshot_only_when_peer_disables_live_stream ... ok\ntest daemon::repl::session::tests::handshake_negotiates_version_and_namespaces ... ok\ntest daemon::core::tests::read_scope_defaults_namespace_and_timeout ... ok\ntest daemon::repl::session::tests::handshake_rejects_version_incompatible ... ok\ntest daemon::repl::session::tests::hash_mismatch_maps_to_hash_mismatch_details ... ok\ntest daemon::repl::session::tests::hello_replay_accepts_reordered_namespaces ... ok\ntest daemon::repl::session::tests::protocol_range_exact_negotiates ... ok\ntest daemon::repl::session::tests::protocol_range_rejects_inverted ... ok\ntest daemon::repl::session::tests::prev_mismatch_maps_to_prev_sha_mismatch_details ... ok\ntest daemon::repl::session::tests::repl_lagged_payload_includes_reason ... ok\ntest daemon::repl::session::tests::typestate_outbound_reaches_snapshot_streaming ... ok\ntest daemon::repl::session::tests::typestate_outbound_reaches_streaming ... ok\ntest daemon::repl::session::tests::welcome_rejects_stale_nonce_after_hello_resend ... ok\ntest daemon::repl::session::tests::welcome_rejects_nonce_mismatch ... ok\ntest daemon::repl::session::tests::welcome_sends_initial_want_when_peer_ahead ... ok\ntest daemon::core::tests::non_core_mutation_and_query_use_namespace_state ... ok\ntest daemon::repl::want::tests::want_frames_stop_at_gap ... ok\ntest daemon::repl::want::tests::want_frames_round_robin_interleaves_keys ... ok\ntest daemon::server::tests::durability_waiter_releases_on_quorum ... ok\ntest daemon::server::tests::durability_waiter_times_out ... ok\ntest daemon::server::tests::request_context_extracts_create_fields ... ok\ntest daemon::server::tests::request_context_extracts_show_fields ... ok\ntest daemon::server::tests::stream_event_decode_failure_is_wal_corrupt ... ok\ntest daemon::server::tests::request_span_includes_schema_fields ... ok\ntest daemon::repl::server::tests::connection_limit_enforced ... ok\ntest daemon::store::discovery::tests::resolve_store_id_uses_cached_verified_without_opening_repo ... ok\ntest daemon::core::tests::ingest_uses_canonical_sha_for_index_and_watermarks ... ok\ntest daemon::core::tests::wal_checkpoint_deadline_tracks_interval ... ok\ntest daemon::repl::server::tests::unknown_replica_rejected_when_roster_present ... ok\ntest daemon::core::tests::ingest_rotation_seals_previous_segment ... ok\ntest daemon::core::tests::store_lock_heartbeat_updates_metadata ... ok\ntest daemon::store::runtime::tests::namespace_policies_fall_back_to_defaults_when_missing ... ok\ntest daemon::executor::tests::idempotent_retry_reuses_wal_mapping ... ok\ntest daemon::store::lock::tests::acquire_keeps_live_lock_when_pid_alive ... ok\ntest daemon::store::runtime::tests::namespace_policies_enforce_permissions ... ok\ntest daemon::store::lock::tests::acquire_reclaims_stale_lock_when_pid_missing ... ok\ntest daemon::store::runtime::tests::namespace_policies_reject_symlink ... ok\ntest daemon::repl::manager::tests::manager_skips_live_stream_when_disabled ... ok\ntest daemon::executor::tests::mutation_span_includes_realtime_context ... ok\ntest daemon::subscription::tests::backfill_corrupt_range_is_corruption ... ok\ntest daemon::subscription::tests::backfill_missing_range_is_bootstrap_required ... ok\ntest daemon::subscription::tests::backfill_plan_reads_ranges_and_tracks_last_seq ... ok\ntest daemon::store::runtime::tests::store_runtime_rejects_version_mismatch ... ok\ntest daemon::wal::event_wal::tests::event_wal_reuses_active_segment ... ok\ntest daemon::wal::frame::tests::frame_crc_mismatch_fails ... ok\ntest daemon::wal::frame::tests::frame_roundtrip_validates_crc ... ok\ntest daemon::core::tests::restores_hlc_state_for_non_daemon_actor ... ok\ntest daemon::wal::index::tests::client_request_event_ids_rejects_empty ... ok\ntest daemon::wal::index::tests::client_request_event_ids_rejects_mixed_namespace ... ok\ntest daemon::wal::index::tests::client_request_event_ids_rejects_mixed_origin ... ok\ntest daemon::wal::index::tests::client_request_event_ids_rejects_out_of_order ... ok\ntest daemon::wal::index::tests::replica_durability_role_rejects_observer_eligible ... ok\ntest daemon::wal::index::tests::client_request_event_ids_round_trip_encode ... ok\ntest daemon::wal::index::tests::replica_durability_role_reports_role_and_eligibility ... ok\ntest daemon::store::discovery::tests::remote_fallback_is_unverified_and_not_persisted ... ok\ntest daemon::store::runtime::tests::checkpoint_snapshot_includes_roster_hash ... ok\ntest daemon::wal::event_wal::tests::event_wal_rotates_on_size ... ok\ntest daemon::server::tests::read_gate_waiter_times_out ... ok\ntest daemon::server::tests::read_gate_waiter_releases_on_apply ... ok\ntest daemon::wal::index::tests::sqlite_index_hlc_upsert_overwrites ... ok\ntest daemon::store::runtime::tests::store_config_defaults_to_cache_and_persists ... ok\ntest daemon::store::runtime::tests::checkpoint_dirty_shards_roundtrip ... ok\ntest daemon::store::discovery::tests::resolve_store_id_reports_mismatched_meta_and_refs ... ok\ntest daemon::store::runtime::tests::store_config_durable_mode_applies ... ok\ntest daemon::store::runtime::tests::phase3_head_sha_loads_from_index ... ok\ntest daemon::store::runtime::tests::phase3_head_sha_rejects_missing_head ... ok\ntest daemon::store::discovery::tests::discover_store_id_ignores_backup_refs ... ok\ntest daemon::store::runtime::tests::store_runtime_persists_orset_counter ... ok\ntest daemon::wal::index::tests::sqlite_index_rejects_symlinked_db_path ... ok\ntest daemon::wal::index::tests::sqlite_index_checkpoint_truncates_wal_file ... ok\ntest daemon::wal::index::tests::sqlite_index_rejects_symlinked_index_dir ... ok\ntest daemon::wal::index::tests::sqlite_index_initializes_schema_and_meta ... ok\ntest daemon::wal::memory_index::tests::memory_index_records_event_and_watermarks ... ok\ntest daemon::wal::memory_index::tests::memory_index_rejects_client_request_id_mismatch ... ok\ntest daemon::wal::index::tests::sqlite_index_pools_connections_after_txn ... ok\ntest daemon::wal::memory_wal::tests::memory_wal_append_roundtrip ... ok\ntest daemon::wal::record::tests::record_decode_rejects_header_len_larger_than_flags_imply ... ok\ntest daemon::wal::record::tests::record_decode_rejects_request_sha_without_client_request_id ... ok\ntest daemon::wal::record::tests::record_decode_rejects_seq0 ... ok\ntest daemon::wal::memory_wal::tests::memory_wal_rotates_on_size ... ok\ntest daemon::wal::record::tests::record_encode_roundtrip_without_request ... ok\ntest daemon::wal::record::tests::record_roundtrip_with_client_request_id_only ... ok\ntest daemon::wal::record::tests::record_verify_rejects_header_mismatch ... ok\ntest daemon::wal::record::tests::record_roundtrip_with_optional_fields ... ok\ntest daemon::wal::record::tests::record_verify_rejects_noncanonical_payload ... ok\ntest daemon::wal::replay::tests::list_namespaces_rejects_symlinked_namespace_dir ... ok\ntest daemon::core::tests::load_from_checkpoint_ref_sets_watermarks ... ok\ntest daemon::wal::replay::tests::list_segments_rejects_symlinked_dir ... ok\ntest daemon::wal::index::tests::sqlite_index_pool_caps_idle_connections ... ok\ntest daemon::wal::index::tests::sqlite_index_persists_hlc_state ... ok\ntest daemon::wal::segment::tests::segment_header_roundtrip ... ok\ntest daemon::wal::index::tests::sqlite_index_record_event_equivocation_errors ... ok\ntest daemon::wal::index::tests::sqlite_index_preserves_client_request_mapping_on_conflict ... ok\ntest daemon::wal::segment::tests::segment_open_rejects_symlinked_namespace_dir ... ok\ntest daemon::wal::replay::tests::scan_segment_detects_sha_mismatch ... ok\ntest error::tests::command_runtime_daemon_error_maps_to_op_daemon_preserving_payload ... ok\ntest error::tests::command_runtime_daemon_non_retryable_maps_to_permanent ... ok\ntest daemon::wal::segment::tests::record_size_limit_enforced ... ok\ntest daemon::wal::segment::tests::append_uses_data_fsync ... ok\ntest daemon::wal::segment::tests::segment_open_sets_dir_permissions ... ok\ntest git::checkpoint::export::tests::export_builds_manifest_and_meta ... ok\ntest git::checkpoint::export::tests::export_reuses_clean_shards ... ok\ntest git::checkpoint::export::tests::export_writes_sorted_shards ... ok\ntest git::checkpoint::export::tests::roster_hash_is_stable_for_reordered_entries ... ok\ntest git::checkpoint::export::tests::snapshot_builds_shards_and_includes_watermarks ... ok\ntest git::checkpoint::export::tests::snapshot_rejects_unknown_dirty_shard ... ok\ntest git::checkpoint::export::tests::snapshot_respects_dirty_shards_input ... ok\ntest daemon::wal::index::tests::sqlite_index_record_event_idempotent_on_duplicate_sha ... ok\ntest git::checkpoint::import::tests::import_export_accepts_v1 ... ok\ntest daemon::wal::index::tests::sqlite_index_rejects_open_segment_with_final_len ... ok\ntest git::checkpoint::import::tests::import_export_rejects_store_id_mismatch ... ok\ntest daemon::wal::index::tests::sqlite_index_rejects_invalid_watermark_rows ... ok\ntest git::checkpoint::cache::tests::load_current_errors_on_missing_entry ... ok\ntest daemon::wal::segment::tests::segment_rotates_on_size ... ok\ntest daemon::wal::index::tests::sqlite_index_round_trips_replica_liveness ... ok\ntest daemon::wal::index::tests::sqlite_index_rejects_sealed_segment_without_final_len ... ok\ntest git::checkpoint::import::tests::import_rejects_manifest_hash_mismatch ... ok\ntest git::checkpoint::import::tests::merge_store_states_is_commutative ... ok\ntest git::checkpoint::import::tests::store_state_from_legacy_places_state_in_core_namespace ... ok\ntest git::checkpoint::json_canon::tests::canon_json_sorts_keys ... ok\ntest git::checkpoint::layout::tests::checkpoint_shard_path_rejects_invalid_path ... ok\ntest git::checkpoint::layout::tests::checkpoint_shard_path_round_trips_via_serde ... ok\ntest git::checkpoint::layout::tests::shard_name_parse_rejects_invalid ... ok\ntest git::checkpoint::manifest::tests::manifest_hash_matches_canonical_bytes ... ok\ntest git::checkpoint::meta::tests::content_hash_matches_preimage ... ok\ntest git::checkpoint::import::tests::parse_export_rejects_unsupported_version ... ok\ntest git::checkpoint::import::tests::import_rejects_unsupported_version ... ok\ntest git::checkpoint::import::tests::parse_export_rejects_namespace_mismatch ... ok\ntest daemon::wal::index::tests::sqlite_index_round_trips_segments ... ok\ntest git::sync::tests::backup_lock_cleanup_policy_is_age_and_pid_aware ... ok\ntest git::checkpoint::import::tests::import_rejects_out_of_order_state_entries ... ok\ntest git::checkpoint::import::tests::import_rejects_shard_entry_limit ... ok\ntest daemon::wal::index::tests::sqlite_index_round_trips_watermarks ... ok\ntest git::checkpoint::import::tests::import_rejects_oversize_line ... ok\ntest git::checkpoint::import::tests::import_rejects_json_depth_exceeded ... ok\ntest git::checkpoint::cache::tests::cache_load_current_export_roundtrips ... ok\ntest daemon::wal::index::tests::sqlite_index_round_trips_events_and_requests ... ok\ntest git::checkpoint::cache::tests::cache_publish_updates_current_and_loads ... ok\ntest git::sync::tests::merge_keeps_tombstones_without_gc ... ok\ntest daemon::wal::replay::tests::cleanup_orphan_tmp_segments_removes_unreferenced ... ok\ntest daemon::wal::index::tests::sqlite_index_rejects_schema_version_mismatch ... ok\ntest git::sync::tests::fetch_best_effort_surfaces_error ... ok\ntest git::checkpoint::cache::tests::cache_prunes_old_entries ... ok\ntest git::sync::tests::backup_ref_lock_contention_metrics_for_create_and_delete ... ok\ntest git::sync::tests::prune_backup_refs_recovers_from_stale_lockfile ... ok\ntest git::sync::tests::ensure_backup_ref_recovers_from_stale_lockfile ... ok\ntest git::sync::tests::sync_diff_count_message ... ok\ntest git::sync::tests::sync_diff_detailed_message ... ok\ntest git::sync::tests::sync_diff_marks_dep_changes_as_updates ... ok\ntest git::sync::tests::sync_diff_truncates_long_titles ... ok\ntest git::sync::tests::prune_backup_refs_skips_live_lock_without_failing_refresh_path ... ok\ntest git::sync::tests::read_state_at_oid_allows_missing_meta ... ok\ntest git::wire::tests::dep_ops_with_distinct_stamps_are_deterministic ... ok\ntest git::wire::tests::insert_label_state_merges_existing_entry ... ok\ntest git::wire::tests::label_ops_with_distinct_stamps_are_deterministic ... ok\ntest git::wire::tests::legacy_deps_jsonl_parses_expected_entries ... ok\ntest git::wire::tests::legacy_deps_parse_then_serialize_is_deterministic ... ok\ntest git::wire::tests::parse_deps_rejects_duplicate ... ok\ntest git::wire::tests::parse_deps_rejects_out_of_order ... ok\ntest git::wire::tests::parse_legacy_state_migrates_unscoped_notes ... ok\ntest git::wire::tests::parse_notes_rejects_duplicate_note_id ... ok\ntest git::wire::tests::parse_notes_rejects_out_of_order ... ok\ntest git::wire::tests::parse_state_accepts_legacy_assignee_without_assignee_at ... ok\ntest git::wire::tests::parse_state_accepts_legacy_closed_without_closed_at_by ... ok\ntest git::wire::tests::parse_state_accepts_legacy_labels_array ... ok\ntest git::wire::tests::parse_state_rejects_assignee_expires_without_assignee ... ok\ntest git::wire::tests::parse_state_rejects_duplicate ... ok\ntest git::wire::tests::parse_state_rejects_mismatched_closed_stamp ... ok\ntest git::wire::tests::parse_state_rejects_out_of_order ... ok\ntest git::wire::tests::parse_state_rejects_partial_closed_redundant_fields ... ok\ntest git::wire::tests::parse_state_roundtrip ... ok\ntest git::wire::tests::parse_supported_meta_accepts_missing_notes_checksum_for_legacy_v1 ... ok\ntest git::wire::tests::parse_supported_meta_accepts_v1_with_checksums ... ok\ntest git::wire::tests::parse_supported_meta_rejects_invalid_root_slug ... ok\ntest git::wire::tests::parse_supported_meta_rejects_missing_required_checksums ... ok\ntest git::wire::tests::parse_supported_meta_rejects_unsupported_version ... ok\ntest git::wire::tests::parse_tombstones_rejects_duplicate ... ok\ntest git::wire::tests::parse_tombstones_rejects_out_of_order ... ok\ntest git::sync::tests::read_state_at_oid_errors_on_checksum_mismatch ... ok\ntest git::wire::tests::roundtrip_empty_state ... ok\ntest git::wire::tests::roundtrip_meta ... ok\ntest git::wire::tests::roundtrip_orset_metadata_and_notes ... ok\ntest git::wire::tests::roundtrip_orset_metadata_preserves_dots_and_context ... ok\ntest git::wire::tests::roundtrip_deps ... ok\ntest git::wire::tests::roundtrip_tombstones ... ok\ntest git::sync::tests::init_does_not_override_existing_local_ref ... ok\ntest git::wire::tests::serialize_deps_sorts_by_dep_kind_canonical ... ok\ntest git::wire::tests::serialize_state_emits_workflow_and_claim_timestamps ... ok\ntest git::wire::tests::serialize_orset_is_deterministic_across_insertion_order ... ok\ntest git::wire::tests::serialize_state_includes_sparse_v_for_overrides ... ok\ntest git::wire::tests::serialize_state_omits_sparse_v_when_stamps_match ... ok\ntest git::wire::tests::verify_store_checksums_detects_mismatch ... ok\ntest telemetry::tests::daemon_logging_defaults_apply_in_default_mode ... ok\ntest paths::tests::init_from_config_updates_overrides ... ok\ntest telemetry::tests::daemon_logging_defaults_skip_in_tests ... ok\ntest telemetry::tests::daemon_logging_defaults_skip_with_log_file_env ... ok\ntest telemetry::tests::log_filter_falls_back_to_verbosity ... ok\ntest telemetry::tests::log_filter_prefers_log_env_over_config ... ok\ntest telemetry::tests::log_filter_uses_config_when_env_missing ... ok\ntest telemetry::tests::prune_log_entries_respects_age_and_count ... ok\ntest upgrade::tests::version_compare ... ok\ntest git::wire::tests::roundtrip_state ... ok\ntest git::sync::tests::read_state_at_oid_reads_meta_last_write_stamp ... ok\ntest git::sync::tests::fetch_updates_remote_tracking_ref ... ok\ntest git::sync::tests::read_state_at_oid_errors_on_invalid_meta ... ok\ntest upgrade::tests::install_binary_copies_and_sets_permissions ... ok\ntest git::sync::tests::fetch_detects_divergence ... ok\ntest git::sync::tests::fetch_preserves_local_ahead_and_creates_backup ... ok\ntest git::sync::tests::fetch_fast_forwards_when_remote_ahead ... ok\ntest git::sync::tests::prune_backup_refs_reports_scan_and_pruned_metrics ... ok\ntest git::checkpoint::publish::tests::publish_checkpoint_returns_too_many_retries_when_limit_exceeded ... ok\ntest git::sync::tests::sync_with_retry_respects_max_retries_on_non_fast_forward ... ok\ntest git::sync::tests::sync_with_retry_reports_divergence ... ok\ntest git::checkpoint::publish::tests::publish_checkpoint_merges_on_non_fast_forward_and_converges ... ok\ntest git::sync::tests::fetch_prunes_existing_backup_refs ... ok\ntest git::sync::tests::ensure_backup_ref_prunes_to_max_and_keeps_latest ... ok\n\ntest result: ok. 375 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 1.77s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 4 tests\ntest join_commutative_with_collision ... ok\ntest join_idempotent ... ok\ntest join_commutative ... ok\ntest join_associative ... ok\n\ntest result: ok. 4 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.08s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 106 tests\ntest checkpoint::checkpoint_manifest_hashes_match_files ... ok\ntest checkpoint::checkpoint_multi_namespace_includes_all_namespaces ... ok\ntest checkpoint::checkpoint_export_is_deterministic ... ok\ntest core::apply::apply_event_is_idempotent ... ok\ntest core::apply::dep_delete_then_readd_restores_indexes ... ok\ntest core::apply::dep_dot_collision_is_deterministic ... ok\ntest core::apply::join_bead_collision_is_deterministic_and_inserts_lineage_tombstone ... ok\ntest core::apply::lww_merge_ordering_is_deterministic ... ok\ntest core::apply::label_dot_collision_is_deterministic ... ok\ntest core::apply::note_collision_is_deterministic ... ok\ntest core::apply::orphan_dep_ops_become_visible_after_create ... ok\ntest core::apply::orphan_label_and_note_ops_become_visible_after_create ... ok\ntest core::cbor::canonical_cbor_bytes_match_fixture ... ok\ntest core::cbor::canonical_cbor_hash_matches_fixture ... ok\ntest core::cbor::decode_rejects_indefinite_length_map ... ok\ntest core::cbor::decode_rejects_oversized_payload ... ok\ntest core::deps::dep_add_remove_is_idempotent ... ok\ntest core::deps::dep_delete_then_readd_across_kinds ... ok\ntest core::deps::parent_edge_add_remove_updates_state ... ok\ntest core::deps::dep_kind_ordering_in_serialize_is_canonical ... ok\ntest core::deps::dep_indexes_match_dep_store ... ok\ntest core::event_validation::sample_event_body_validates ... ok\ntest core::identity::namespace_id_validation_accepts_and_rejects ... ok\ntest core::identity::store_discovery_normalizes_remote_url ... ok\ntest core::identity::lock_file_enforces_exclusive_create ... ok\ntest daemon::admin::admin_clock_anomaly_serializes_in_status_and_doctor ... ok\ntest checkpoint::checkpoint_import_rejects_corrupt_files ... ok\ntest checkpoint::checkpoint_included_watermarks_match ... ok\ntest core::identity::store_meta_roundtrip_persists_identity ... ok\ntest core::identity::store_identity_survives_reopen ... ok\ntest checkpoint::checkpoint_round_trip_preserves_state_and_manifest ... ok\ntest cli::upgrade::upgrade_rejects_checksum_mismatch ... ok\ntest cli::upgrade::upgrade_installs_fake_binary ... ok\ntest cli::upgrade::upgrade_verifies_checksum ... ok\ntest daemon::admin::admin_fingerprint_sample_is_deterministic ... ok\ntest cli::critical_path::test_auto_init_on_first_create ... ok\ntest daemon::admin::admin_metrics_includes_counters ... ok\ntest daemon::store_lock::store_lock_acquire_writes_metadata ... ok\ntest daemon::store_lock::store_lock_held_surfaces_metadata ... ok\ntest daemon::admin::admin_metrics_includes_ipc_request_histograms ... ok\ntest daemon::admin::admin_maintenance_blocks_mutations ... ok\ntest daemon::store_lock::store_lock_permissions_are_restricted ... ok\ntest fixtures::admin_status::tests::fixtures_admin_status_monotonic_empty_samples ... ok\ntest fixtures::checkpoint::tests::fixtures_checkpoint_multi_namespace_contains_two_namespaces ... ok\ntest fixtures::checkpoint::tests::fixtures_checkpoint_small_manifest_and_meta_hashes ... ok\ntest fixtures::checkpoint::tests::fixtures_checkpoint_tombstone_has_tombstone_shards ... ok\ntest daemon::store_lock::store_paths_live_under_bd_data_dir ... ok\ntest fixtures::checkpoint_diff::tests::fixtures_checkpoint_diff_detects_payload_change ... ok\ntest fixtures::daemon_runtime::tests::parse_etime_to_secs_supports_ps_formats ... ok\ntest fixtures::checkpoint_diff::tests::fixtures_checkpoint_diff_empty_for_equal_exports ... ok\ntest fixtures::ipc_stream::tests::fixtures_ipc_stream_parses_event ... ok\ntest fixtures::ipc_stream::tests::fixtures_ipc_stream_parses_subscribed ... ok\ntest daemon::store_lock::store_lock_rejects_symlink_path ... ok\ntest fixtures::mutation::tests::builders_cover_all_mutation_variants ... ok\ntest fixtures::mutation::tests::request_sha256_supports_all_requests ... ok\ntest fixtures::repl_frames::tests::fixtures_repl_frames_roundtrip ... ok\ntest fixtures::repl_peer::tests::fixtures_repl_peer_handshake_and_events ... ok\ntest fixtures::repl_transport::tests::fixtures_repl_transport_delay_and_drop ... ok\ntest fixtures::repl_transport::tests::fixtures_repl_transport_roundtrip ... ok\ntest fixtures::load_gen::tests::fixtures_load_gen_reports_failures_when_daemon_missing ... ok\ntest realtime_errors::realtime_error_codes_are_known ... ok\ntest repl::ack::repl_ack_advances_watermarks ... ok\ntest repl::ack::repl_equivocation_errors ... ok\ntest repl::ack::repl_gap_triggers_want ... ok\ntest repl::ack::repl_prev_sha_mismatch_rejects ... ok\ntest fixtures::wal::tests::temp_wal_dir_writes_segment ... ok\ntest repl::backpressure::repl_backpressure_overload_emits_error ... ok\ntest daemon::admin::admin_rebuild_index_requires_maintenance ... ok\ntest daemon::admin::admin_fingerprint_full_includes_shards ... ok\ntest cli::critical_path::test_init_creates_beads_branch ... ok\ntest cli::critical_path::test_error_handling_invalid_id ... ok\ntest wal::fsck::fsck_clean_segment_passes ... ok\ntest cli::critical_path::test_create_show_close_workflow ... ok\ntest repl::ack::repl_want_reads_from_wal ... ok\ntest repl::range::wal_range_reader_rejects_internal_gap ... ok\ntest wal::fsck::fsck_reports_header_mismatch ... ok\ntest repl::range::wal_range_reader_returns_contiguous_frames ... ok\ntest daemon::admin::admin_reload_policies_reports_safe_and_restart_changes ... ok\ntest cli::critical_path::test_dependencies ... ok\ntest repl::range::wal_range_reader_rejects_prev_sha_mismatch ... ok\ntest wal::fsck::fsck_stops_after_record_sha_mismatch ... ok\ntest wal::fsck::fsck_repair_quarantines_mid_file_corruption ... ok\ntest daemon::admin::admin_scrub_reports_segment_header_failure ... ok\ntest wal::receipts::receipt_min_seen_is_monotonic ... ok\ntest cli::critical_path::test_status_overview ... ok\ntest wal::fsck::fsck_repair_truncates_tail ... ok\ntest daemon::admin::admin_doctor_includes_checks ... ok\ntest wal::idempotency::request_sha_mismatch_returns_error ... ok\ntest wal::idempotency::idempotency_mapping_reuses_txn_and_event_ids ... ok\ntest wal::wal_tests::wal_framing_roundtrips_records ... ok\ntest wal::receipts::receipt_survives_restart ... ok\ntest wal::index::index_rebuild_populates_watermarks_and_segments ... ok\ntest wal::seq::seq_allocation_is_monotonic ... ok\ntest wal::index::index_catch_up_scans_new_frames ... ok\ntest wal::index::index_marks_sealed_segments ... ok\ntest wal::fsck::fsck_reports_sealed_len_mismatch ... ok\ntest wal::index::index_replay_rejects_sealed_len_mismatch ... ok\ntest wal::receipts::origin_seq_after_restart_is_max_plus_one ... ok\ntest wal::seq::seq_allocation_resumes_after_replay ... ok\ntest wal::wal_tests::wal_mid_file_corruption_fails_fast ... ok\ntest wal::wal_tests::wal_tail_truncation_repairs_partial_record ... ok\ntest wal::wal_tests::wal_replay_rejects_header_mismatch ... ok\ntest daemon::realtime_smoke::realtime_smoke_applies_and_persists ... ok\ntest daemon::admin::admin_status_includes_expected_fields ... ok\ntest cli::migration::test_migrate_dry_run ... ok\ntest fixtures::daemon_runtime::tests::shutdown_daemon_removes_stale_store_lock ... ok\n\ntest result: ok. 106 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 3.39s\n\n\nrunning 38 tests\ntest ipc::types::tests::ping_info_serializes_as_query ... ok\ntest ipc::types::tests::repo_ctx_serializes_as_repo_field ... ok\ntest ipc::client::tests::socket_dir_candidates_prefers_runtime_env ... ok\ntest ipc::client::tests::socket_dir_candidates_prefers_runtime_override ... ok\ntest ipc::payload::tests::close_payload_decodes_with_reason ... ok\ntest ipc::types::tests::response_err ... ok\ntest ipc::types::tests::read_consistency_roundtrip_preserves_namespace ... ok\ntest ipc::types::tests::response_ok ... ok\ntest ipc::client::tests::version_check_uses_meta_when_matching ... ok\ntest ipc::payload::tests::update_payload_rejects_closed_status ... ok\ntest ipc::types::tests::show_details_roundtrip ... ok\ntest ipc::client::tests::version_check_rejects_meta_mismatch ... ok\ntest ipc::types::tests::show_multiple_roundtrip ... ok\ntest ipc::types::tests::claim_defaults_lease_secs ... ok\ntest ipc::types::tests::extend_claim_requires_lease_secs ... ok\ntest ipc::types::tests::request_roundtrip ... ok\ntest ipc::spawn_sanitizer::tests::spawn_command_closes_non_stdio_fds_in_child ... ok\ntest ipc::types::tests::unit_variants_are_distinguishable ... ok\ntest ops::tests::bead_patch_normalization_rejects_required_field_clear ... ok\ntest ipc::types::tests::subscribe_roundtrip ... ok\ntest ops::tests::bead_patch_normalization_rejects_whitespace_only_required_field ... ok\ntest ops::tests::bead_patch_normalization_trims_required_fields ... ok\ntest ops::tests::bead_patch_validation_allows_optional_field_clear ... ok\ntest ops::tests::bead_patch_validation_rejects_description_clear ... ok\ntest ops::tests::bead_patch_validation_rejects_required_field_clear ... ok\ntest ipc::types::tests::unit_variants_roundtrip ... ok\ntest ops::tests::bead_patch_validation_rejects_required_field_empty ... ok\ntest ops::tests::patch_apply ... ok\ntest ops::tests::patch_default_is_keep ... ok\ntest store_admin::tests::daemon_pid_probe_returns_none_for_non_daemon_info_response ... ok\ntest store_admin::tests::daemon_pid_probe_returns_pid_for_typed_ping_response ... ok\ntest store_admin::tests::fsck_call_falls_back_on_unexpected_response_shape ... ok\ntest store_admin::tests::fsck_call_maps_invalid_request_error_with_field ... ok\ntest store_admin::tests::fsck_call_returns_typed_output ... ok\ntest store_admin::tests::lock_info_call_falls_back_on_daemon_unavailable ... ok\ntest store_admin::tests::lock_info_call_returns_typed_output ... ok\ntest store_admin::tests::unlock_call_returns_typed_output ... ok\ntest store_admin::tests::unlock_call_omits_field_when_code_is_not_invalid_request ... ok\n\ntest result: ok. 38 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.01s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 1 test\ntest crates/beads-core/src/state.rs - state::CanonicalState::require_live (line 967) ... ignored\n\ntest result: ok. 0 passed; 0 failed; 1 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 1 test\ntest crates/beads-core/src/apply.rs - apply::apply_event (line 53) - compile fail ... ok\n\ntest result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.07s\n\nall doctests ran in 0.41s; merged doctests compilation took 0.14s\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 1 test\ntest crates/beads-macros/src/lib.rs - enum_str (line 9) ... ignored\n\ntest result: ok. 0 passed; 0 failed; 1 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\nall doctests ran in 0.35s; merged doctests compilation took 0.14s\n\nrunning 1 test\ntest crates/beads-rs/src/git/sync.rs - git::sync::SyncProcess (line 276) ... ignored\n\ntest result: ok. 0 passed; 0 failed; 1 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\nall doctests ran in 0.36s; merged doctests compilation took 0.14s\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s pass\\n\\n**Files**\\n- crates/beads-rs/src/daemon/**\\n- (tests as needed)","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"in_progress","assignee":"darin@darinsmcstudio2.lan","assignee_expires":1771014770714,"_at":[1771011170714,0],"_by":"darin@darinsmcstudio2.lan","_v":{"acceptance_criteria":[[1771011162463,0],"darin@darinsmcstudio2.lan"],"description":[[1771011162463,0],"darin@darinsmcstudio2.lan"],"design":[[1771011162463,0],"darin@darinsmcstudio2.lan"],"estimated_minutes":[[1771011162463,0],"darin@darinsmcstudio2.lan"],"external_ref":[[1771011162463,0],"darin@darinsmcstudio2.lan"],"labels":[[1771011162463,0],"darin@darinsmcstudio2.lan"],"priority":[[1771011162463,0],"darin@darinsmcstudio2.lan"],"source_repo":[[1771011162463,0],"darin@darinsmcstudio2.lan"],"title":[[1771011162463,0],"darin@darinsmcstudio2.lan"],"type":[[1771011162463,0],"darin@darinsmcstudio2.lan"]},"assignee_at":[1771011170714,0]}
{"id":"bd-1vu","created_at":[1768364140165,0],"created_by":"darin@darinsmcstudio2.lan","title":"DurabilityCoordinator wait blocks daemon loop; refactor to async waiters","description":"**Problem**\nDurabilityCoordinator waits by sleeping in the daemon state thread, blocking other IPC/git handling during ReplicatedFsync.\n\n**Design**\nMove durability waits into async waiters managed by run_state_loop. After local apply, register a waiter with the response channel and poll ack status on a short tick or ack notifications; respond when satisfied or timeout without blocking the loop.\n\n**Acceptance**\n- [ ] ReplicatedFsync requests no longer block the state loop.\n- [ ] DurabilityTimeout still returns retryable error with receipt.\n- [ ] Tests cover waiter completion + timeout paths.\n\n**Files:** src/daemon/server.rs, src/daemon/core.rs, src/daemon/durability_coordinator.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768445990476,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768445990476,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768445990476,0]}
{"id":"bd-21eg","created_at":[1770498164851,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 2 crate boundary cleanup: split daemon+cli with typed surface contracts","description":"**Problem**\n`beads-rs` still has direct CLI->daemon coupling (`crate::daemon::*`) despite `beads-surface`/`beads-api` existing as boundary crates. This increases scatter and weakens locality of reasoning: CLI behavior depends on daemon internals instead of a single typed contract.\n\n**Goal**\nFinish boundary cleanup and split runtime into isolated crates while preserving behavior:\n- `beads-cli` depends on `beads-surface` (+ `beads-api` as needed), not `beads-daemon`\n- `beads-daemon` owns daemon internals and runtime wiring\n- shared contracts stay in `beads-surface`/`beads-api` with typed, explicit boundaries\n- no drift/duplication of protocol or schema types\n\n**Target DAG**\n`beads-core <- beads-api <- beads-surface <- {beads-cli, beads-daemon}`\n\nForbidden edges:\n- `beads-cli -> beads-daemon`\n- `beads-surface -> beads-cli|beads-daemon`\n- `beads-api -> beads-surface|beads-cli|beads-daemon`","design":"Stage work in narrow, reversible phases:\n1) boundary inventory + lint enforcement,\n2) CLI boundary cleanup,\n3) missing boundary API extraction (fsck/lock/patch validation),\n4) daemon crate split,\n5) CLI crate split,\n6) shared daemon-core extraction for model/fuzz/stateright consumers,\n7) cleanup + shims removal.\n\nUse typed outputs at boundaries (`beads-api` structs/enums), avoid stringly errors, and keep one source of truth per concept.","acceptance_criteria":"- [ ] No `crate::daemon` imports under CLI crate/module tree\n- [ ] `beads-cli` and `beads-daemon` compile as independent crates\n- [ ] Boundary lint gates forbidden edges in CI\n- [ ] Surface/API contracts are single-source (no duplicate protocol models)\n- [ ] Full verification: `cargo check`, `cargo clippy --all-features -- -D warnings`, `cargo test`, `cargo test --features slow-tests`, `just dylint`","priority":1,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"All child beads closed; boundary cleanup epic acceptance criteria satisfied","_at":[1770519281888,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770519281888,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-21eg.1","created_at":[1770498230179,0],"created_by":"darin@darinsmcstudio2.lan","title":"Publish target DAG + forbidden dependency edges","description":"**Problem**\nBoundary assumptions are implicit and drifting across crates.\n\n**Files:** Cargo workspace metadata, architecture docs","design":"Define allowed edges and forbidden edges as explicit policy. Align crate manifests with policy and add a one-page reference for contributors.","acceptance_criteria":"- [ ] Target DAG documented\n- [ ] Forbidden edges listed\n- [ ] Policy references real crate names","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770498846005,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770498846005,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770498846005,0]}
{"id":"bd-21eg.10","created_at":[1770498233410,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add CLI daemon-run wrapper to remove direct daemon module dependency","description":"**Problem**\nCLI entrypoint calls daemon runtime internals directly from CLI module tree.","design":"Introduce a thin non-CLI wrapper boundary so CLI code stops importing daemon modules directly.","acceptance_criteria":"- [ ] CLI no longer imports `crate::daemon::run_daemon`\n- [ ] Wrapper location documented\n- [ ] Runtime behavior preserved","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770499795050,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770499795050,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770499795050,0]}
{"id":"bd-21eg.11","created_at":[1770498233733,0],"created_by":"darin@darinsmcstudio2.lan","title":"Prove zero daemon imports under CLI tree","description":"**Problem**\nAfter cleanup we need a stable invariant, not manual spot checks.","design":"Add a checkable invariant (`rg`/lint gate) that CLI tree contains no direct daemon imports.","acceptance_criteria":"- [ ] Invariant command documented\n- [ ] Command passes locally\n- [ ] Violations fail lint/check flow","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770500562231,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770500562231,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770500562231,0]}
{"id":"bd-21eg.12","created_at":[1770498234014,0],"created_by":"darin@darinsmcstudio2.lan","title":"Extract BeadPatch daemon validation into beads-surface typed API","description":"**Problem**\nCLI update path depends on daemon-only patch validation trait.","design":"Move validation logic to surface-level typed API and map errors explicitly without stringly conversions.","acceptance_criteria":"- [ ] Surface API validates patch semantics\n- [ ] CLI uses surface API only\n- [ ] Error mapping remains typed and explicit","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770500471112,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770500471112,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770500471112,0]}
{"id":"bd-21eg.13","created_at":[1770498234324,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add surface offline fsck API returning beads-api output types","description":"**Problem**\nCLI store fsck uses daemon WAL internals directly.","design":"Provide surface function for offline fsck with typed options/result backed by `beads-api` admin output structs.","acceptance_criteria":"- [ ] Surface fsck API exists and is typed\n- [ ] CLI fsck path uses surface API\n- [ ] No daemon WAL internals imported by CLI","priority":1,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770500471321,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770500471321,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770500471321,0]}
{"id":"bd-21eg.14","created_at":[1770498234622,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add surface store-lock info/unlock APIs returning beads-api output types","description":"**Problem**\nCLI offline unlock/lock-info reaches into daemon lock internals.","design":"Provide typed surface APIs for lock inspection and unlock, returning stable admin output schemas.","acceptance_criteria":"- [ ] Surface lock APIs implemented\n- [ ] CLI lock flows use surface APIs\n- [ ] Lock internals no longer exposed to CLI","priority":1,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770500471519,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770500471519,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770500471519,0]}
{"id":"bd-21eg.15","created_at":[1770498234932,0],"created_by":"darin@darinsmcstudio2.lan","title":"Migrate CLI store/update commands to new surface APIs","description":"**Problem**\nEven with new APIs, command handlers still need migration to eliminate daemon imports.","design":"Refactor command handlers to call only surface-level APIs and update tests accordingly.","acceptance_criteria":"- [ ] `store`/`update` commands use surface APIs\n- [ ] Behavior-compatible tests pass\n- [ ] No daemon-internal imports remain in migrated handlers","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770500523735,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770500523735,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770500523735,0]}
{"id":"bd-21eg.16","created_at":[1770498235240,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add boundary tests for patch/fsck/lock surface APIs","description":"**Problem**\nNew surface APIs need stable contract tests to prevent drift.","design":"Add law/example/regression tests focused on typed request/response/error behavior.","acceptance_criteria":"- [ ] Success + failure cases covered\n- [ ] Error variants are typed and asserted\n- [ ] Tests run reliably in CI","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770500846465,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770500846465,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770500846465,0]}
{"id":"bd-21eg.17","created_at":[1770498235550,0],"created_by":"darin@darinsmcstudio2.lan","title":"Scaffold beads-daemon crate and workspace wiring","description":"**Problem**\nDaemon runtime still lives in monolithic crate namespace.","design":"Create `beads-daemon` crate with minimal public surface and workspace dependency wiring.","acceptance_criteria":"- [ ] New crate builds in workspace\n- [ ] Dependency edges match target DAG\n- [ ] No behavior change in binaries yet","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770499343507,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770499343507,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770499343507,0]}
{"id":"bd-21eg.18","created_at":[1770498235853,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move daemon modules into beads-daemon with compatibility re-exports","description":"**Problem**\nDaemon ownership is split between old paths and target crate paths.","design":"Relocate daemon modules into `beads-daemon` while keeping short-term compatibility re-exports in `beads-rs`.","acceptance_criteria":"- [ ] Core daemon modules compile in new crate\n- [ ] Compatibility re-exports keep downstream builds green\n- [ ] No cyclic deps introduced","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770501390629,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770501390629,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770501390629,0]}
{"id":"bd-21eg.19","created_at":[1770498236155,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move daemon-owned git sync modules into beads-daemon","description":"**Problem**\nGit sync/runtime code is daemon-owned but still colocated in monolith.","design":"Move daemon-owned git modules to daemon crate and keep typed boundaries for shared models.","acceptance_criteria":"- [ ] Daemon git sync modules moved\n- [ ] Imports updated without edge violations\n- [ ] Sync tests continue to pass","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770501876378,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770501876378,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770501876378,0]}
{"id":"bd-21eg.2","created_at":[1770498230449,0],"created_by":"darin@darinsmcstudio2.lan","title":"Inventory CLI -> daemon direct imports with replacement targets","description":"**Problem**\nCLI still imports daemon internals, creating scatter and brittle coupling.","design":"Produce file+symbol inventory and map each import to `beads-surface`/`beads-api` replacement or missing API.","acceptance_criteria":"- [ ] Full inventory under CLI tree\n- [ ] Replacement target per symbol\n- [ ] Missing APIs called out explicitly","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770498846245,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770498846245,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770498846245,0]}
{"id":"bd-21eg.20","created_at":[1770498236452,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move daemon test harness and integration fixtures to daemon-owned boundaries","description":"**Problem**\nTest harness currently relies on monolithic internal paths that block extraction.","design":"Re-home daemon-internal fixtures/harness to daemon-owned module boundaries while preserving deterministic tests.","acceptance_criteria":"- [ ] Harness compiles from daemon-owned paths\n- [ ] Integration suites still pass\n- [ ] No new global-state coupling introduced","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.20-1","content":"Progress: moved repl proto schema/codec ownership into crates/beads-daemon-core (new repl::proto module) and converted beads-rs daemon repl/proto.rs into a compatibility re-export shim. This reduces fixture dependence on daemon internals and sets up direct daemon-core imports for harness modules.","author":"darin@darins-Mac-Studio-2.local","at":[1770504939427,0]},{"id":"go-comment-bd-21eg.20-2","content":"Additional progress: integration fixtures repl_frames.rs and repl_transport.rs now import frame/proto types from beads-daemon-core instead of beads-rs daemon internals. Validated with targeted tests fixtures_repl_frames_roundtrip and fixtures_repl_transport_roundtrip.","author":"darin@darins-Mac-Studio-2.local","at":[1770504983323,0]},{"id":"go-comment-bd-21eg.20-3","content":"More progress: daemon-core now owns repl::proto (beads-rs proto module is a re-export shim), and fixture imports in repl_frames/repl_transport now target beads-daemon-core directly. Added daemon-core test coverage validation: cargo test -p beads-daemon-core passes (44 tests).","author":"darin@darins-Mac-Studio-2.local","at":[1770505233320,0]},{"id":"go-comment-bd-21eg.20-4","content":"Progress: moved additional integration fixture ownership toward daemon/surface boundaries. Updates include switching fixture IPC+op imports to beads_rs::surface, consuming shared polling/socket helpers from beads_daemon::test_utils, and removing fixtures/daemon_test_utils.rs shim. Verified with cargo test -p beads-rs --test integration -- daemon:: (16 pass), -- repl:: (9 pass), and -- wal::idempotency:: (2 pass). Remaining blockers are explicit missing typed boundary APIs for deep wal/store_lock/repl session internals still imported by a subset of fixtures.","author":"darin@darins-Mac-Studio-2.local","at":[1770507472871,0]},{"id":"go-comment-bd-21eg.20-5","content":"Unblocked and completed fixture/harness boundary pass with new boundary slices closed (bd-21eg.33/.34/.35/.36).\nWhat landed:\n- Mutation fixture decoupled from daemon mutation internals.\n- Store-lock fixture decoupled from daemon::store_lock internals.\n- Repl/WAL fixtures retargeted through typed fixture boundary module (`tests/integration/fixtures/daemon_boundary.rs`) so targeted fixtures no longer import daemon internals directly.\nValidation:\n- cargo test -p beads-rs --test integration (103 pass)\n- cargo test -p beads-rs --test integration --features slow-tests -- daemon::lifecycle:: (8 pass)\n- cargo test -p beads-rs --test integration --features slow-tests -- daemon::crash_recovery:: --test-threads=1 (2 pass)\n- cargo check -p beads-rs\nAcceptance status: harness+fixtures compile and integration suites remain green with no new global-state coupling introduced.","author":"darin@darins-Mac-Studio-2.local","at":[1770509530583,0]},{"id":"legacy-notes","content":"Progress: moved repl proto schema/codec ownership into crates/beads-daemon-core (new repl::proto module) and converted beads-rs daemon repl/proto.rs into a compatibility re-export shim. This reduces fixture dependence on daemon internals and sets up direct daemon-core imports for harness modules.\n\nAdditional progress: integration fixtures repl_frames.rs and repl_transport.rs now import frame/proto types from beads-daemon-core instead of beads-rs daemon internals. Validated with targeted tests fixtures_repl_frames_roundtrip and fixtures_repl_transport_roundtrip.\n\nMore progress: daemon-core now owns repl::proto (beads-rs proto module is a re-export shim), and fixture imports in repl_frames/repl_transport now target beads-daemon-core directly. Added daemon-core test coverage validation: cargo test -p beads-daemon-core passes (44 tests).\n\nProgress: moved additional integration fixture ownership toward daemon/surface boundaries. Updates include switching fixture IPC+op imports to beads_rs::surface, consuming shared polling/socket helpers from beads_daemon::test_utils, and removing fixtures/daemon_test_utils.rs shim. Verified with cargo test -p beads-rs --test integration -- daemon:: (16 pass), -- repl:: (9 pass), and -- wal::idempotency:: (2 pass). Remaining blockers are explicit missing typed boundary APIs for deep wal/store_lock/repl session internals still imported by a subset of fixtures.\n\nUnblocked and completed fixture/harness boundary pass with new boundary slices closed (bd-21eg.33/.34/.35/.36).\nWhat landed:\n- Mutation fixture decoupled from daemon mutation internals.\n- Store-lock fixture decoupled from daemon::store_lock internals.\n- Repl/WAL fixtures retargeted through typed fixture boundary module (`tests/integration/fixtures/daemon_boundary.rs`) so targeted fixtures no longer import daemon internals directly.\nValidation:\n- cargo test -p beads-rs --test integration (103 pass)\n- cargo test -p beads-rs --test integration --features slow-tests -- daemon::lifecycle:: (8 pass)\n- cargo test -p beads-rs --test integration --features slow-tests -- daemon::crash_recovery:: --test-threads=1 (2 pass)\n- cargo check -p beads-rs\nAcceptance status: harness+fixtures compile and integration suites remain green with no new global-state coupling introduced.","author":"darin@darinsmcstudio2.lan","at":[1770509530583,0]}],"_at":[1770509530583,0],"_by":"darin@darinsmcstudio2.lan","_v":{"workflow":[[1770509530561,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770509530561,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770509530583,0]}
{"id":"bd-21eg.21","created_at":[1770498236763,0],"created_by":"darin@darinsmcstudio2.lan","title":"Scaffold beads-cli crate and workspace wiring","description":"**Problem**\nCLI cannot iterate independently while embedded in monolithic crate.","design":"Create `beads-cli` crate with dependency on surface contracts and workspace wiring.","acceptance_criteria":"- [ ] New CLI crate builds\n- [ ] CLI crate depends on surface boundary crates\n- [ ] No direct daemon dependency introduced","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770499343713,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770499343713,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770499343713,0]}
{"id":"bd-21eg.22","created_at":[1770498237344,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move CLI module tree and command handlers into beads-cli","description":"**Problem**\nCommand implementation locality is blocked by monolithic layout.","design":"Relocate CLI parser/command/render modules into `beads-cli` with typed interfaces.","acceptance_criteria":"- [ ] CLI module tree moved\n- [ ] Command tests compile and pass\n- [ ] Imports respect DAG constraints","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Acceptance criteria met; CLI module migration complete with boundary + verification gates green","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.22-1","content":"Progress: moved cli helper modules (filters/parsers/validation) into crates/beads-cli with compatibility wrappers in crates/beads-rs/src/cli/*. This keeps behavior stable while shrinking beads-rs CLI ownership. Verified cargo check -p beads-cli and -p beads-rs plus CLI unit tests.","author":"darin@darins-Mac-Studio-2.local","at":[1770504565643,0]},{"id":"go-comment-bd-21eg.22-2","content":"Progress: removed beads-rs CLI compatibility wrapper modules for prime/setup/onboard and rewired runtime dispatch directly to beads-cli command types/handlers from cli::run. Deleted crates/beads-rs/src/cli/commands/{prime,setup,onboard}.rs and updated command typing in commands/mod.rs. Verified cargo check -p beads-rs, cargo test -p beads-cli, and cargo check --workspace.","author":"darin@darins-Mac-Studio-2.local","at":[1770507472810,0]},{"id":"go-comment-bd-21eg.22-3","content":"Major progress: removed beads-rs CLI shim modules `src/cli/{parsers,filters,validation}.rs` and rewired command handlers directly to `beads_cli::{parsers,filters,validation}` APIs. Also removed prime/setup/onboard shim command modules earlier and dispatches directly through beads-cli-backed handlers/types. No behavior changes observed in CLI critical path tests.\nValidation: cargo check -p beads-rs, cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass), just dylint, cargo check --workspace.","author":"darin@darins-Mac-Studio-2.local","at":[1770508398390,0]},{"id":"go-comment-bd-21eg.22-4","content":"Update: mapped the hard cycle blocker for full CLI handler migration and converted .22 into an executable dependency chain under the epic.\n\nCycle blocker observed:\n- current edge: beads-rs -> beads-cli\n- full handler move needs upgrade/store/migrate host operations still owned by beads-rs\n- adding beads-cli -> beads-rs would create forbidden cycle\n\nTo execute without shims/cycles, I created and claimed these phased beads:\n- bd-21eg.37 (closed): extract shared CLI runtime primitives into beads-cli\n- bd-21eg.38 (in_progress): move pure IPC read-only handlers into beads-cli + rewire dispatch\n- bd-21eg.39 (open): add typed backend trait for host-coupled ops (upgrade/store/migrate)\n- bd-21eg.40 (open): finalize ownership and delete migrated beads-rs handler modules\n\nDependency wiring:\n- .38 depends on .37\n- .39 depends on .37\n- .40 depends on .38 + .39\n- .22 depends on .40\n\nThis keeps .22 focused on final outcome while execution proceeds in typed, non-cyclic increments.","author":"darin@darins-Mac-Studio-2.local","at":[1770512264734,0]},{"id":"go-comment-bd-21eg.22-5","content":"Closeout evidence for bd-21eg.22:\n\n- CLI module tree is owned by `crates/beads-cli` (`commands/`, `parsers.rs`, `filters.rs`, `runtime.rs`, `upgrade/`, `migrate/`).\n- Final CLI ownership cleanup beads (`bd-21eg.38`/`.39`/`.40`) are complete, with migrated handlers removed from `beads-rs` shim ownership.\n- DAG/boundary invariant holds:\n  - `rg -n \"crate::daemon::\" crates/beads-rs/src/cli crates/beads-cli/src` => no matches.\n  - `just dylint` passes.\n- Verification for command/test stability passes:\n  - `cargo check`\n  - `cargo fmt --all`\n  - `just dylint`\n  - `cargo clippy --all-features -- -D warnings`\n  - `cargo test`\n  - `RUST_TEST_THREADS=1 cargo test --features slow-tests`\n\nAcceptance mapping:\n- [x] CLI module tree moved\n- [x] Command tests compile and pass\n- [x] Imports respect DAG constraints\n\nNo intended behavior changes; CLI critical-path and integration coverage stayed green.","author":"darin@darins-Mac-Studio-2.local","at":[1770519281027,0]},{"id":"legacy-notes","content":"Progress: moved cli helper modules (filters/parsers/validation) into crates/beads-cli with compatibility wrappers in crates/beads-rs/src/cli/*. This keeps behavior stable while shrinking beads-rs CLI ownership. Verified cargo check -p beads-cli and -p beads-rs plus CLI unit tests.\n\nProgress: removed beads-rs CLI compatibility wrapper modules for prime/setup/onboard and rewired runtime dispatch directly to beads-cli command types/handlers from cli::run. Deleted crates/beads-rs/src/cli/commands/{prime,setup,onboard}.rs and updated command typing in commands/mod.rs. Verified cargo check -p beads-rs, cargo test -p beads-cli, and cargo check --workspace.\n\nMajor progress: removed beads-rs CLI shim modules `src/cli/{parsers,filters,validation}.rs` and rewired command handlers directly to `beads_cli::{parsers,filters,validation}` APIs. Also removed prime/setup/onboard shim command modules earlier and dispatches directly through beads-cli-backed handlers/types. No behavior changes observed in CLI critical path tests.\nValidation: cargo check -p beads-rs, cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass), just dylint, cargo check --workspace.\n\nUpdate: mapped the hard cycle blocker for full CLI handler migration and converted .22 into an executable dependency chain under the epic.\n\nCycle blocker observed:\n- current edge: beads-rs -> beads-cli\n- full handler move needs upgrade/store/migrate host operations still owned by beads-rs\n- adding beads-cli -> beads-rs would create forbidden cycle\n\nTo execute without shims/cycles, I created and claimed these phased beads:\n- bd-21eg.37 (closed): extract shared CLI runtime primitives into beads-cli\n- bd-21eg.38 (in_progress): move pure IPC read-only handlers into beads-cli + rewire dispatch\n- bd-21eg.39 (open): add typed backend trait for host-coupled ops (upgrade/store/migrate)\n- bd-21eg.40 (open): finalize ownership and delete migrated beads-rs handler modules\n\nDependency wiring:\n- .38 depends on .37\n- .39 depends on .37\n- .40 depends on .38 + .39\n- .22 depends on .40\n\nThis keeps .22 focused on final outcome while execution proceeds in typed, non-cyclic increments.\n\nCloseout evidence for bd-21eg.22:\n\n- CLI module tree is owned by `crates/beads-cli` (`commands/`, `parsers.rs`, `filters.rs`, `runtime.rs`, `upgrade/`, `migrate/`).\n- Final CLI ownership cleanup beads (`bd-21eg.38`/`.39`/`.40`) are complete, with migrated handlers removed from `beads-rs` shim ownership.\n- DAG/boundary invariant holds:\n  - `rg -n \"crate::daemon::\" crates/beads-rs/src/cli crates/beads-cli/src` => no matches.\n  - `just dylint` passes.\n- Verification for command/test stability passes:\n  - `cargo check`\n  - `cargo fmt --all`\n  - `just dylint`\n  - `cargo clippy --all-features -- -D warnings`\n  - `cargo test`\n  - `RUST_TEST_THREADS=1 cargo test --features slow-tests`\n\nAcceptance mapping:\n- [x] CLI module tree moved\n- [x] Command tests compile and pass\n- [x] Imports respect DAG constraints\n\nNo intended behavior changes; CLI critical-path and integration coverage stayed green.","author":"darin@darinsmcstudio2.lan","at":[1770519281262,0]}],"_at":[1770519281262,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770519281262,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770519281262,0]}
{"id":"bd-21eg.23","created_at":[1770498237674,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move CLI support modules (config/paths/upgrade/migrate/telemetry) into beads-cli or shared crates","description":"**Problem**\nCLI-adjacent modules are scattered and mixed with daemon concerns.","design":"Place support modules according to ownership, extracting shared pieces where needed.","acceptance_criteria":"- [ ] Ownership of each support module is explicit\n- [ ] CLI uses local/shared module from correct crate\n- [ ] No duplicate config models introduced","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.23-1","content":"Progress: support-level extraction advanced indirectly via shared CLI helper ownership now living in beads-cli. Remaining support modules still mixed ownership: config/telemetry/upgrade transport and runtime paths need explicit boundary split.","author":"darin@darins-Mac-Studio-2.local","at":[1770504565738,0]},{"id":"go-comment-bd-21eg.23-2","content":"Progress: support-module ownership moved further toward beads-cli by removing prime/setup/onboard compatibility command wrappers and using beads-cli modules directly. This reduces duplicated command support logic in beads-rs while keeping behavior unchanged. Validation passes: cargo check -p beads-rs, cargo test -p beads-cli, cargo check --workspace, just dylint.","author":"darin@darins-Mac-Studio-2.local","at":[1770507472841,0]},{"id":"go-comment-bd-21eg.23-3","content":"Support ownership tightened further: CLI support concerns now source directly from beads-cli (parsers/filters/validation + prime/setup/onboard command logic). Deleted now-unused beads-rs shim files and kept typed error conversions via crate::Error From impls. This reduces duplicate support logic in beads-rs and improves locality around beads-cli ownership.\nValidation: cargo check -p beads-rs, cargo test -p beads-rs --test integration -- cli::critical_path::, just dylint, cargo check --workspace.","author":"darin@darins-Mac-Studio-2.local","at":[1770508398481,0]},{"id":"go-comment-bd-21eg.23-4","content":"Completed support-module ownership cleanup with explicit single-owner boundaries and shim removals:\n\nOwnership decisions now applied in code:\n- `migrate` import implementation owner: `beads-cli` (`crates/beads-cli/src/migrate/go_export.rs`)\n  - removed beads-rs compatibility shim (`crates/beads-rs/src/migrate/mod.rs` deleted)\n  - CLI migrate command calls `beads_cli::migrate::import_go_export` directly\n- `upgrade` release metadata/platform/checksum owner: `beads-cli` (`crates/beads-cli/src/upgrade/*`)\n  - orchestrator/runtime owner remains `beads-rs::upgrade` by design (daemon/process integration)\n- `paths` base path/store/wal resolution owner: `beads-cli::paths`\n  - beads-rs retains runtime/config override glue where daemon/runtime coupling is required\n- `config` owner: `beads-rs::config` (shared daemon/runtime source of truth)\n- `telemetry` owner: `beads-rs::telemetry` (daemon+runtime logging integration)\n\nKey cleanup outcome:\n- Removed duplicate migrate shim layer in beads-rs; only one implementation source remains.\n- No duplicate config model definitions introduced; config remains single-source in `beads-rs::config`.\n- CLI command paths now consume support modules from correct owning crate/module.\n\nValidation:\n- cargo check -p beads-rs\n- cargo check -p beads-cli\n- cargo check --workspace\n- cargo test -p beads-rs --test integration -- cli::migration::\n- just dylint\nAll green.","author":"darin@darins-Mac-Studio-2.local","at":[1770511110232,0]},{"id":"legacy-notes","content":"Progress: support-level extraction advanced indirectly via shared CLI helper ownership now living in beads-cli. Remaining support modules still mixed ownership: config/telemetry/upgrade transport and runtime paths need explicit boundary split.\n\nProgress: support-module ownership moved further toward beads-cli by removing prime/setup/onboard compatibility command wrappers and using beads-cli modules directly. This reduces duplicated command support logic in beads-rs while keeping behavior unchanged. Validation passes: cargo check -p beads-rs, cargo test -p beads-cli, cargo check --workspace, just dylint.\n\nSupport ownership tightened further: CLI support concerns now source directly from beads-cli (parsers/filters/validation + prime/setup/onboard command logic). Deleted now-unused beads-rs shim files and kept typed error conversions via crate::Error From impls. This reduces duplicate support logic in beads-rs and improves locality around beads-cli ownership.\nValidation: cargo check -p beads-rs, cargo test -p beads-rs --test integration -- cli::critical_path::, just dylint, cargo check --workspace.\n\nCompleted support-module ownership cleanup with explicit single-owner boundaries and shim removals:\n\nOwnership decisions now applied in code:\n- `migrate` import implementation owner: `beads-cli` (`crates/beads-cli/src/migrate/go_export.rs`)\n  - removed beads-rs compatibility shim (`crates/beads-rs/src/migrate/mod.rs` deleted)\n  - CLI migrate command calls `beads_cli::migrate::import_go_export` directly\n- `upgrade` release metadata/platform/checksum owner: `beads-cli` (`crates/beads-cli/src/upgrade/*`)\n  - orchestrator/runtime owner remains `beads-rs::upgrade` by design (daemon/process integration)\n- `paths` base path/store/wal resolution owner: `beads-cli::paths`\n  - beads-rs retains runtime/config override glue where daemon/runtime coupling is required\n- `config` owner: `beads-rs::config` (shared daemon/runtime source of truth)\n- `telemetry` owner: `beads-rs::telemetry` (daemon+runtime logging integration)\n\nKey cleanup outcome:\n- Removed duplicate migrate shim layer in beads-rs; only one implementation source remains.\n- No duplicate config model definitions introduced; config remains single-source in `beads-rs::config`.\n- CLI command paths now consume support modules from correct owning crate/module.\n\nValidation:\n- cargo check -p beads-rs\n- cargo check -p beads-cli\n- cargo check --workspace\n- cargo test -p beads-rs --test integration -- cli::migration::\n- just dylint\nAll green.","author":"darin@darinsmcstudio2.lan","at":[1770511114269,0]}],"_at":[1770511114269,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770511114269,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770511114269,0]}
{"id":"bd-21eg.24","created_at":[1770498237985,0],"created_by":"darin@darinsmcstudio2.lan","title":"Rewire binaries and keep beads-rs as thin orchestration/compat shim","description":"**Problem**\nBinaries currently assume monolithic internal module ownership.","design":"Update bin entrypoints to call new crates; shrink `beads-rs` to compatibility/orchestration role.","acceptance_criteria":"- [ ] Bin targets compile against new crate layout\n- [ ] Legacy paths retained only as temporary shims\n- [ ] Runtime behavior unchanged","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.24-1","content":"Progress: binary boundary remains stable while shared repl frame+proto ownership now lives in beads-daemon-core; beads-rs binaries compile against new shared boundary via compatibility shims. Verified cargo check -p beads-rs and --bin tailnet_proxy.","author":"darin@darins-Mac-Studio-2.local","at":[1770504939527,0]},{"id":"go-comment-bd-21eg.24-2","content":"Progress update: root crate error wiring is now daemon-decoupled (bd-21eg.32 closed), and repl frame+proto ownership moved into beads-daemon-core with beads-rs compatibility shims. This reduces binary coupling and keeps runtime behavior stable while we continue migrating main CLI entrypoint ownership.","author":"darin@darins-Mac-Studio-2.local","at":[1770505261134,0]},{"id":"go-comment-bd-21eg.24-3","content":"Progress: binary/entrypoint wiring remains green after CLI boundary cleanup. crates/beads-rs/src/bin/main.rs continues to call beads_rs::run_cli_entrypoint, and command dispatch now routes prime/setup/onboard through beads-cli-backed handlers without local compatibility modules. Verified with cargo check -p beads-rs --bins and cargo check --workspace; behavior-preserving path.","author":"darin@darins-Mac-Studio-2.local","at":[1770507472777,0]},{"id":"go-comment-bd-21eg.24-4","content":"Validation evidence before close: cargo check -p beads-rs --bins, cargo check --workspace, cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass), and daemon/repl integration slices all pass. With prime/setup/onboard dispatch now routed directly through beads-cli-backed handlers and no local wrapper modules, .24 acceptance criteria are satisfied.","author":"darin@darins-Mac-Studio-2.local","at":[1770507489648,0]},{"id":"legacy-notes","content":"Progress: binary boundary remains stable while shared repl frame+proto ownership now lives in beads-daemon-core; beads-rs binaries compile against new shared boundary via compatibility shims. Verified cargo check -p beads-rs and --bin tailnet_proxy.\n\nProgress update: root crate error wiring is now daemon-decoupled (bd-21eg.32 closed), and repl frame+proto ownership moved into beads-daemon-core with beads-rs compatibility shims. This reduces binary coupling and keeps runtime behavior stable while we continue migrating main CLI entrypoint ownership.\n\nProgress: binary/entrypoint wiring remains green after CLI boundary cleanup. crates/beads-rs/src/bin/main.rs continues to call beads_rs::run_cli_entrypoint, and command dispatch now routes prime/setup/onboard through beads-cli-backed handlers without local compatibility modules. Verified with cargo check -p beads-rs --bins and cargo check --workspace; behavior-preserving path.\n\nValidation evidence before close: cargo check -p beads-rs --bins, cargo check --workspace, cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass), and daemon/repl integration slices all pass. With prime/setup/onboard dispatch now routed directly through beads-cli-backed handlers and no local wrapper modules, .24 acceptance criteria are satisfied.","author":"darin@darinsmcstudio2.lan","at":[1770507489648,0]}],"_at":[1770507489648,0],"_by":"darin@darinsmcstudio2.lan","_v":{"workflow":[[1770507489610,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770507489610,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770507489648,0]}
{"id":"bd-21eg.25","created_at":[1770498238290,0],"created_by":"darin@darinsmcstudio2.lan","title":"Create shared daemon-core crate for repl/wal/proto primitives","description":"**Problem**\nModel/fuzz/stateright depend on daemon internals that should be reusable and typed.","design":"Extract reusable repl/wal/proto/durability primitives into shared crate with explicit public API.","acceptance_criteria":"- [ ] Shared crate compiles and exports required primitives\n- [ ] APIs are typed, no stringly protocol shims\n- [ ] Daemon and external consumers can both depend on it","priority":1,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770502253769,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770502253769,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770502253769,0]}
{"id":"bd-21eg.26","created_at":[1770498238598,0],"created_by":"darin@darinsmcstudio2.lan","title":"Migrate stateright/fuzz/model adapters to shared daemon-core crate","description":"**Problem**\nExternal consumers are pinned to old daemon-internal paths.","design":"Update imports/adapters in stateright models, fuzz targets, and model adapters to shared crate.","acceptance_criteria":"- [ ] All identified consumers migrated\n- [ ] Existing model/fuzz workflows build\n- [ ] No daemon-internal imports remain in migrated consumers","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770502825649,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770502825649,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770502825649,0]}
{"id":"bd-21eg.27","created_at":[1770498238921,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove temporary re-exports and tighten visibility boundaries","description":"**Problem**\nTemporary shims can become permanent scatter if not removed.","design":"Delete migration re-exports, tighten module visibility, and ensure single source of truth per boundary type.","acceptance_criteria":"- [ ] Temporary re-exports removed\n- [ ] Visibility tightened to intended surface\n- [ ] No downstream compile regressions","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.27-1","content":"Started .27 cleanup with low-risk shim removals plus file-level dependency audit. Landed: (1) removed beads-daemon crate compatibility alias `mod daemon { pub use crate::metrics; }` by rewriting admission.rs to import `crate::metrics` directly, and (2) removed CLI daemon command type re-export shim by switching command enum/dispatch to `beads_cli::commands::daemon::DaemonCmd` directly (daemon.rs now only renders daemon info text). Validation: cargo check -p beads-daemon, cargo check -p beads-rs, cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass), just dylint all pass. Remaining .27 work is larger import-retargeting for daemon/cli shim modules with active consumers.","author":"darin@darins-Mac-Studio-2.local","at":[1770507975971,0]},{"id":"go-comment-bd-21eg.27-2","content":"Progress: removed additional temporary shim layers.\n- Deleted beads-rs CLI shim files: `src/cli/parsers.rs`, `src/cli/filters.rs`, `src/cli/validation.rs` after retargeting all CLI command imports.\n- Removed CLI daemon command type re-export shim usage by switching command typing/dispatch to `beads_cli::commands::daemon::DaemonCmd` directly.\n- Removed beads-daemon crate compatibility alias `mod daemon { pub use crate::metrics; }` and imported `crate::metrics` directly in compiled module(s).\nNo compile/test regressions in verification set.\nValidation: cargo check -p beads-rs, cargo check -p beads-daemon, cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass), just dylint, cargo check --workspace.","author":"darin@darins-Mac-Studio-2.local","at":[1770508398510,0]},{"id":"go-comment-bd-21eg.27-3","content":"Completed a major .27 cleanup pass removing additional temporary boundary shims and tightening visibility:\n\n1) Removed daemon wrapper modules in beads-rs and retargeted all callsites (src + tests) to owning crates:\n- deleted `crates/beads-rs/src/daemon/{admission,broadcast,clock,git_lane,remote,scheduler}.rs`\n- imports now use `beads_daemon::{admission,broadcast,clock,git_lane,remote,scheduler}` directly\n\n2) Removed temporary repl frame/proto module wrappers and retargeted callsites:\n- deleted `crates/beads-rs/src/daemon/repl/{frame,proto}.rs`\n- `repl/mod.rs` now re-exports frame/proto types/functions directly from `beads_daemon_core::repl::{frame,proto}`\n- internal/tests updated to consume owning module paths\n\n3) Removed temporary store wrapper modules:\n- deleted `crates/beads-rs/src/daemon/{store_lock,store_runtime}.rs`\n- internal imports retargeted to `crate::daemon::store::{lock,runtime}`\n- daemon top-level now explicitly re-exports stable lock/runtime boundary types\n\n4) Tightened visibility:\n- `crates/beads-rs/src/daemon/ipc/mod.rs` changed `ResponseExt` export to `pub(crate)`\n\n5) Removed migrate compatibility shim layer:\n- deleted `crates/beads-rs/src/migrate/mod.rs`\n- CLI migrate command now calls `beads_cli::migrate::import_go_export` directly\n\nValidation:\n- cargo check -p beads-rs\n- cargo check --workspace\n- cargo test -p beads-rs --test integration -- repl::ack::\n- cargo test -p beads-rs --test integration -- daemon::store_lock::\n- cargo test -p beads-rs --test integration --features slow-tests -- daemon::lifecycle:: (8 pass)\n- just dylint\nAll green.","author":"darin@darins-Mac-Studio-2.local","at":[1770511080398,0]},{"id":"legacy-notes","content":"Started .27 cleanup with low-risk shim removals plus file-level dependency audit. Landed: (1) removed beads-daemon crate compatibility alias `mod daemon { pub use crate::metrics; }` by rewriting admission.rs to import `crate::metrics` directly, and (2) removed CLI daemon command type re-export shim by switching command enum/dispatch to `beads_cli::commands::daemon::DaemonCmd` directly (daemon.rs now only renders daemon info text). Validation: cargo check -p beads-daemon, cargo check -p beads-rs, cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass), just dylint all pass. Remaining .27 work is larger import-retargeting for daemon/cli shim modules with active consumers.\n\nProgress: removed additional temporary shim layers.\n- Deleted beads-rs CLI shim files: `src/cli/parsers.rs`, `src/cli/filters.rs`, `src/cli/validation.rs` after retargeting all CLI command imports.\n- Removed CLI daemon command type re-export shim usage by switching command typing/dispatch to `beads_cli::commands::daemon::DaemonCmd` directly.\n- Removed beads-daemon crate compatibility alias `mod daemon { pub use crate::metrics; }` and imported `crate::metrics` directly in compiled module(s).\nNo compile/test regressions in verification set.\nValidation: cargo check -p beads-rs, cargo check -p beads-daemon, cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass), just dylint, cargo check --workspace.\n\nCompleted a major .27 cleanup pass removing additional temporary boundary shims and tightening visibility:\n\n1) Removed daemon wrapper modules in beads-rs and retargeted all callsites (src + tests) to owning crates:\n- deleted `crates/beads-rs/src/daemon/{admission,broadcast,clock,git_lane,remote,scheduler}.rs`\n- imports now use `beads_daemon::{admission,broadcast,clock,git_lane,remote,scheduler}` directly\n\n2) Removed temporary repl frame/proto module wrappers and retargeted callsites:\n- deleted `crates/beads-rs/src/daemon/repl/{frame,proto}.rs`\n- `repl/mod.rs` now re-exports frame/proto types/functions directly from `beads_daemon_core::repl::{frame,proto}`\n- internal/tests updated to consume owning module paths\n\n3) Removed temporary store wrapper modules:\n- deleted `crates/beads-rs/src/daemon/{store_lock,store_runtime}.rs`\n- internal imports retargeted to `crate::daemon::store::{lock,runtime}`\n- daemon top-level now explicitly re-exports stable lock/runtime boundary types\n\n4) Tightened visibility:\n- `crates/beads-rs/src/daemon/ipc/mod.rs` changed `ResponseExt` export to `pub(crate)`\n\n5) Removed migrate compatibility shim layer:\n- deleted `crates/beads-rs/src/migrate/mod.rs`\n- CLI migrate command now calls `beads_cli::migrate::import_go_export` directly\n\nValidation:\n- cargo check -p beads-rs\n- cargo check --workspace\n- cargo test -p beads-rs --test integration -- repl::ack::\n- cargo test -p beads-rs --test integration -- daemon::store_lock::\n- cargo test -p beads-rs --test integration --features slow-tests -- daemon::lifecycle:: (8 pass)\n- just dylint\nAll green.","author":"darin@darinsmcstudio2.lan","at":[1770511093702,0]}],"_at":[1770511093702,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770511093702,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770511093702,0]}
{"id":"bd-21eg.28","created_at":[1770498239220,0],"created_by":"darin@darinsmcstudio2.lan","title":"Documentation + full verification closeout for crate split","description":"**Problem**\nArchitecture refactors drift quickly without synchronized docs and verification evidence.","design":"Update architecture/workflow docs and run full verification matrix including slow tests and boundary lint.","acceptance_criteria":"- [ ] Docs updated for final crate layout\n- [ ] Full verification commands pass\n- [ ] Epic acceptance checklist demonstrably satisfied","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Docs + full verification matrix complete; epic checklist evidence captured","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.28-1","content":"Closeout evidence for bd-21eg.28:\n\nDocumentation updated for final crate split + boundaries:\n- `docs/CRATE_DAG.md`\n- `docs/architecture/boundary-api-migration-matrix.md`\n- `docs/architecture/phase2-crate-split-closeout.md`\n\nBoundary / epic acceptance proof points:\n- No CLI->daemon direct imports remain (`rg -n \"crate::daemon::\" crates/beads-rs/src/cli crates/beads-cli/src` => no matches).\n- `beads-cli` and `beads-daemon` compile in workspace flows.\n- Boundary lint is active and passing (`just dylint`).\n- Surface/API contract boundary remains typed and single-source through `beads-surface`/`beads-api` interfaces.\n\nFull verification matrix run and passing:\n- `cargo check`\n- `cargo fmt --all`\n- `just dylint`\n- `cargo clippy --all-features -- -D warnings`\n- `cargo test`\n- `RUST_TEST_THREADS=1 cargo test --features slow-tests`\n\nAcceptance mapping:\n- [x] Docs updated for final crate layout\n- [x] Full verification commands pass\n- [x] Epic acceptance checklist demonstrably satisfied","author":"darin@darins-Mac-Studio-2.local","at":[1770519281463,0]},{"id":"legacy-notes","content":"Closeout evidence for bd-21eg.28:\n\nDocumentation updated for final crate split + boundaries:\n- `docs/CRATE_DAG.md`\n- `docs/architecture/boundary-api-migration-matrix.md`\n- `docs/architecture/phase2-crate-split-closeout.md`\n\nBoundary / epic acceptance proof points:\n- No CLI->daemon direct imports remain (`rg -n \"crate::daemon::\" crates/beads-rs/src/cli crates/beads-cli/src` => no matches).\n- `beads-cli` and `beads-daemon` compile in workspace flows.\n- Boundary lint is active and passing (`just dylint`).\n- Surface/API contract boundary remains typed and single-source through `beads-surface`/`beads-api` interfaces.\n\nFull verification matrix run and passing:\n- `cargo check`\n- `cargo fmt --all`\n- `just dylint`\n- `cargo clippy --all-features -- -D warnings`\n- `cargo test`\n- `RUST_TEST_THREADS=1 cargo test --features slow-tests`\n\nAcceptance mapping:\n- [x] Docs updated for final crate layout\n- [x] Full verification commands pass\n- [x] Epic acceptance checklist demonstrably satisfied","author":"darin@darinsmcstudio2.lan","at":[1770519281682,0]}],"_at":[1770519281682,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770519281682,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770519281682,0]}
{"id":"bd-21eg.29","created_at":[1770498508099,0],"created_by":"darin@darinsmcstudio2.lan","title":"Migrate integration tests/fixtures off daemon-internal imports","description":"**Problem**\nIntegration suites still import `beads_rs::daemon::*`, which will break crate extraction.","design":"Move tests/fixtures to surface/daemon-core boundaries and keep daemon-internal coverage in daemon-owned test modules.","acceptance_criteria":"- [ ] CLI/integration tests no longer import daemon internals directly\n- [ ] Daemon-internal tests live under daemon-owned boundaries\n- [ ] Critical integration suites still pass","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770502825860,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770502825860,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770502825860,0]}
{"id":"bd-21eg.3","created_at":[1770498230746,0],"created_by":"darin@darinsmcstudio2.lan","title":"Inventory non-CLI daemon coupling (model/fuzz/stateright/tests)","description":"**Problem**\nDaemon internals are consumed outside CLI, which can block crate extraction.","design":"Audit `model`, `fuzz`, `beads_stateright_models`, and integration fixtures for daemon imports and classify migration strategy.","acceptance_criteria":"- [ ] Consumer inventory complete\n- [ ] Each dependency classified (shared-core vs daemon-internal)\n- [ ] Extraction blockers identified","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770498846454,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770498846454,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770498846454,0]}
{"id":"bd-21eg.30","created_at":[1770498508347,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move model adapters off daemon re-exports","description":"**Problem**\n`model` re-exports daemon internals, creating a hidden dependency cliff for split crates.","design":"Re-home model adapters to shared daemon-core or explicit adapters, with typed public exports and no daemon leakage.","acceptance_criteria":"- [ ] model module no longer re-exports daemon internals\n- [ ] Consumers updated to shared typed exports\n- [ ] No behavior regressions in model workflows","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770502826078,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770502826078,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770502826078,0]}
{"id":"bd-21eg.31","created_at":[1770498508651,0],"created_by":"darin@darinsmcstudio2.lan","title":"Retarget tailnet_proxy binary to shared daemon-core/surface types","description":"**Problem**\n`tailnet_proxy` imports daemon repl frame internals directly.","design":"Switch binary imports to shared crate boundary and keep frame/protocol typing explicit.","acceptance_criteria":"- [ ] tailnet_proxy builds without daemon-internal imports\n- [ ] Binary behavior preserved\n- [ ] Frame/protocol types remain typed (no string codecs)","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"tailnet_proxy imports only beads-core/beads-daemon-core types; verified with import scan and cargo check --bin tailnet_proxy","_at":[1770504551784,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770504551784,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-21eg.32","created_at":[1770498508957,0],"created_by":"darin@darinsmcstudio2.lan","title":"Relocate crate-level error wiring away from daemon-only types","description":"**Problem**\nTop-level error type imports daemon internals, which blocks clean crate boundaries.","design":"Move/shared-map error wiring via surface/api error types and explicit conversion paths.","acceptance_criteria":"- [ ] Root error no longer depends on daemon-only types\n- [ ] Error conversions remain typed\n- [ ] Existing callers compile without stringly fallbacks","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Introduced crate-level OpError surface in error.rs (ValidationFailed/InvalidRequest/Daemon payload), removed daemon-type dependency from root Error wiring, and kept callers compiling with typed mappings. Verified cargo check -p beads-rs, cli unit tests, and just dylint.","notes":[{"id":"go-comment-bd-21eg.32-1","content":"Progress: root error wiring now imports IpcError from beads_surface path instead of daemon path, and root OpError export tightened to daemon::ops::OpError. Full decouple of OpError from daemon internals remains pending and will require a dedicated shared op-error surface.","author":"darin@darins-Mac-Studio-2.local","at":[1770504565841,0]},{"id":"legacy-notes","content":"Progress: root error wiring now imports IpcError from beads_surface path instead of daemon path, and root OpError export tightened to daemon::ops::OpError. Full decouple of OpError from daemon internals remains pending and will require a dedicated shared op-error surface.","author":"darin@darinsmcstudio2.lan","at":[1770505125849,0]}],"_at":[1770505125849,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770505125849,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-21eg.33","created_at":[1770508423949,0],"created_by":"darin@darinsmcstudio2.lan","title":"Extract mutation-engine fixture boundary API to remove direct daemon mutation internals","description":"Problem: mutation fixture imports daemon::mutation_engine and daemon::ops::OpError directly. Design: add typed mutation test boundary (surface/daemon-owned) and retarget fixture coverage to boundary API while preserving semantics. Acceptance: mutation fixture no longer imports daemon internals directly; integration behavior remains unchanged and tests pass.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.33-1","content":"Implemented mutation fixture boundary decoupling from daemon internals.\nChanges:\n- `tests/integration/fixtures/mutation.rs` no longer imports `beads_rs::daemon::mutation_engine` or `beads_rs::daemon::ops::OpError`.\n- Added fixture-local typed `MutationContext` and deterministic request-hash helper based on typed context+payload digest.\nValidation:\n- cargo test -p beads-rs --test integration -- wal::idempotency:: (2 pass)\n- cargo check -p beads-rs\nAcceptance met: mutation fixture no longer imports daemon internals; idempotency behavior tests remain green.","author":"darin@darins-Mac-Studio-2.local","at":[1770509493521,0]},{"id":"legacy-notes","content":"Implemented mutation fixture boundary decoupling from daemon internals.\nChanges:\n- `tests/integration/fixtures/mutation.rs` no longer imports `beads_rs::daemon::mutation_engine` or `beads_rs::daemon::ops::OpError`.\n- Added fixture-local typed `MutationContext` and deterministic request-hash helper based on typed context+payload digest.\nValidation:\n- cargo test -p beads-rs --test integration -- wal::idempotency:: (2 pass)\n- cargo check -p beads-rs\nAcceptance met: mutation fixture no longer imports daemon internals; idempotency behavior tests remain green.","author":"darin@darinsmcstudio2.lan","at":[1770509493521,0]}],"_at":[1770509493521,0],"_by":"darin@darinsmcstudio2.lan","_v":{"workflow":[[1770509493492,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770509493492,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770509493521,0]}
{"id":"bd-21eg.34","created_at":[1770508423983,0],"created_by":"darin@darinsmcstudio2.lan","title":"Extract store-lock fixture boundary API to remove daemon::store_lock internal imports","description":"Problem: fixtures still import beads_rs::daemon::store_lock internals for lock-file behavior checks. Design: provide typed store-lock test boundary in daemon/surface-owned API (or daemon test utils), retarget fixtures, and tighten visibility on store_lock internals. Acceptance: fixtures no longer import beads_rs::daemon::store_lock internals; relevant daemon/store-lock integration tests pass unchanged.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.34-1","content":"Implemented store-lock fixture boundary decoupling from daemon::store_lock internals.\nChanges:\n- `tests/integration/fixtures/store_lock.rs` now uses public path APIs (`paths::store_lock_path` + data-dir override) and local typed error enum.\n- Removed direct `beads_rs::daemon::store_lock::{...}` imports.\nValidation:\n- cargo test -p beads-rs --test integration --features slow-tests -- daemon::lifecycle:: (8 pass)\n- cargo test -p beads-rs --test integration --features slow-tests -- daemon::crash_recovery:: --test-threads=1 (2 pass)\n- cargo check -p beads-rs\nAcceptance met: fixtures no longer import daemon::store_lock internals and relevant daemon/store-lock flows pass.","author":"darin@darins-Mac-Studio-2.local","at":[1770509493549,0]},{"id":"legacy-notes","content":"Implemented store-lock fixture boundary decoupling from daemon::store_lock internals.\nChanges:\n- `tests/integration/fixtures/store_lock.rs` now uses public path APIs (`paths::store_lock_path` + data-dir override) and local typed error enum.\n- Removed direct `beads_rs::daemon::store_lock::{...}` imports.\nValidation:\n- cargo test -p beads-rs --test integration --features slow-tests -- daemon::lifecycle:: (8 pass)\n- cargo test -p beads-rs --test integration --features slow-tests -- daemon::crash_recovery:: --test-threads=1 (2 pass)\n- cargo check -p beads-rs\nAcceptance met: fixtures no longer import daemon::store_lock internals and relevant daemon/store-lock flows pass.","author":"darin@darinsmcstudio2.lan","at":[1770509493549,0]}],"_at":[1770509493549,0],"_by":"darin@darinsmcstudio2.lan","_v":{"workflow":[[1770509493450,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770509493450,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770509493549,0]}
{"id":"bd-21eg.35","created_at":[1770508424013,0],"created_by":"darin@darinsmcstudio2.lan","title":"Extract repl session/admission fixture boundary API from daemon internals","description":"Problem: repl_peer fixtures still require beads_rs::daemon::{admission,repl::session} internals, preventing shim cleanup. Design: expose typed repl session/admission fixtures or boundary interfaces from daemon-owned crates, migrate fixture imports, and remove temporary re-export dependence. Acceptance: repl fixtures avoid direct daemon internal session/admission imports; repl integration suite remains green.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.35-1","content":"Implemented repl fixture boundary API and removed direct daemon internal imports from repl fixtures.\nChanges:\n- Added `tests/integration/fixtures/daemon_boundary.rs` with typed repl boundary exports.\n- Rewired `tests/integration/fixtures/repl_peer.rs` to import repl/admission/session types via fixture boundary module.\nValidation:\n- cargo test -p beads-rs --test integration -- repl:: (9 pass)\n- cargo check -p beads-rs\nAcceptance met: repl fixtures avoid direct daemon session/admission imports; repl integration suite remains green.","author":"darin@darins-Mac-Studio-2.local","at":[1770509501726,0]},{"id":"legacy-notes","content":"Implemented repl fixture boundary API and removed direct daemon internal imports from repl fixtures.\nChanges:\n- Added `tests/integration/fixtures/daemon_boundary.rs` with typed repl boundary exports.\n- Rewired `tests/integration/fixtures/repl_peer.rs` to import repl/admission/session types via fixture boundary module.\nValidation:\n- cargo test -p beads-rs --test integration -- repl:: (9 pass)\n- cargo check -p beads-rs\nAcceptance met: repl fixtures avoid direct daemon session/admission imports; repl integration suite remains green.","author":"darin@darinsmcstudio2.lan","at":[1770509501726,0]}],"_at":[1770509501726,0],"_by":"darin@darinsmcstudio2.lan","_v":{"workflow":[[1770509501666,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770509501666,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770509501726,0]}
{"id":"bd-21eg.36","created_at":[1770508424038,0],"created_by":"darin@darinsmcstudio2.lan","title":"Extract WAL fixture boundary API (segment writer/header/frame) out of beads-rs daemon internals","description":"Problem: integration fixtures still import beads_rs::daemon::wal internals (SegmentWriter/RecordHeader/frame helpers), keeping temporary daemon re-export layers alive. Design: expose a typed fixture/test boundary from beads-daemon-core or daemon-owned test utils, retarget fixture imports, then remove remaining wal-internal re-export dependencies in beads-rs. Acceptance: fixtures compile without beads_rs::daemon::wal internal imports; cargo test -p beads-rs --test integration -- repl:: and wal:: slices pass.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.36-1","content":"Implemented WAL fixture boundary API and removed direct daemon::wal imports from targeted fixtures.\nChanges:\n- Added `tests/integration/fixtures/daemon_boundary.rs` with typed wal boundary exports.\n- Rewired `tests/integration/fixtures/wal.rs`, `wal_corrupt.rs`, and `repl_rig.rs` to import wal types/constants/functions via boundary module.\nValidation:\n- cargo test -p beads-rs --test integration -- wal:: (22 pass)\n- cargo test -p beads-rs --test integration -- repl:: (9 pass)\n- cargo check -p beads-rs\nAcceptance met: fixtures compile without direct `beads_rs::daemon::wal` imports and wal/repl slices stay green.","author":"darin@darins-Mac-Studio-2.local","at":[1770509501698,0]},{"id":"legacy-notes","content":"Implemented WAL fixture boundary API and removed direct daemon::wal imports from targeted fixtures.\nChanges:\n- Added `tests/integration/fixtures/daemon_boundary.rs` with typed wal boundary exports.\n- Rewired `tests/integration/fixtures/wal.rs`, `wal_corrupt.rs`, and `repl_rig.rs` to import wal types/constants/functions via boundary module.\nValidation:\n- cargo test -p beads-rs --test integration -- wal:: (22 pass)\n- cargo test -p beads-rs --test integration -- repl:: (9 pass)\n- cargo check -p beads-rs\nAcceptance met: fixtures compile without direct `beads_rs::daemon::wal` imports and wal/repl slices stay green.","author":"darin@darinsmcstudio2.lan","at":[1770509501698,0]}],"_at":[1770509501698,0],"_by":"darin@darinsmcstudio2.lan","_v":{"workflow":[[1770509501617,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770509501617,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770509501698,0]}
{"id":"bd-21eg.37","created_at":[1770511139193,0],"created_by":"darin@darinsmcstudio2.lan","title":"Extract CLI runtime context + transport/render helpers into beads-cli","description":"**Problem**\\nCLI command handlers remain tied to beads-rs because Ctx/send/render helpers are owned under crates/beads-rs/src/cli/mod.rs.\\n\\n**Design**\\nMove typed CLI runtime primitives (Ctx-equivalent, send wrappers, print/render helpers) into beads-cli without depending on beads-rs internals. Keep behavior identical and preserve JSON/human output shapes.\\n\\n**Acceptance**\\n- [ ] beads-cli exposes typed runtime context/helpers for command handlers\\n- [ ] No behavior change in rendering/transport semantics\\n- [ ] cargo check -p beads-cli and -p beads-rs pass\\n\\n**Files:** crates/beads-cli/src/*, crates/beads-rs/src/cli/mod.rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.37-1","content":"Completed extraction of typed CLI runtime primitives into beads-cli and integrated them into beads-rs without behavior changes.\n\nImplemented in beads-cli:\n- `crates/beads-cli/src/runtime.rs`\n  - `CliRuntimeCtx` (typed context struct for command handlers)\n  - transport helpers (`send_raw`, `send`)\n  - actor/description validation helpers (`validate_actor_id`, `current_actor_id`, `resolve_description`)\n- `crates/beads-cli/src/render.rs`\n  - shared render/print primitives and typed renderer trait surface\n- exports/wiring:\n  - `crates/beads-cli/src/lib.rs` exports `runtime` and `render`\n  - `crates/beads-cli/Cargo.toml` includes required typed deps (`beads-api`, `tracing`, `whoami`)\n\nIntegrated in beads-rs CLI:\n- `crates/beads-rs/src/cli/mod.rs`\n  - `Ctx` now aliases `beads_cli::runtime::CliRuntimeCtx`\n  - `resolve_description` and actor validation now delegate to beads-cli runtime helpers\n  - `send_raw`/`send` now delegate to beads-cli runtime transport helpers\n  - removed stale local transport connection implementation from beads-rs cli module\n\nValidation:\n- cargo check -p beads-cli\n- cargo check -p beads-rs\n- cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass)\n- just dylint\nAll green.","author":"darin@darins-Mac-Studio-2.local","at":[1770511730493,0]},{"id":"legacy-notes","content":"Completed extraction of typed CLI runtime primitives into beads-cli and integrated them into beads-rs without behavior changes.\n\nImplemented in beads-cli:\n- `crates/beads-cli/src/runtime.rs`\n  - `CliRuntimeCtx` (typed context struct for command handlers)\n  - transport helpers (`send_raw`, `send`)\n  - actor/description validation helpers (`validate_actor_id`, `current_actor_id`, `resolve_description`)\n- `crates/beads-cli/src/render.rs`\n  - shared render/print primitives and typed renderer trait surface\n- exports/wiring:\n  - `crates/beads-cli/src/lib.rs` exports `runtime` and `render`\n  - `crates/beads-cli/Cargo.toml` includes required typed deps (`beads-api`, `tracing`, `whoami`)\n\nIntegrated in beads-rs CLI:\n- `crates/beads-rs/src/cli/mod.rs`\n  - `Ctx` now aliases `beads_cli::runtime::CliRuntimeCtx`\n  - `resolve_description` and actor validation now delegate to beads-cli runtime helpers\n  - `send_raw`/`send` now delegate to beads-cli runtime transport helpers\n  - removed stale local transport connection implementation from beads-rs cli module\n\nValidation:\n- cargo check -p beads-cli\n- cargo check -p beads-rs\n- cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass)\n- just dylint\nAll green.","author":"darin@darinsmcstudio2.lan","at":[1770511736778,0]}],"_at":[1770511736778,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770511736778,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770511736778,0]}
{"id":"bd-21eg.38","created_at":[1770511146352,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move pure IPC CLI command handlers from beads-rs into beads-cli","description":"**Problem**\\nMost CLI handlers are still implemented in crates/beads-rs/src/cli/commands even though they only use IPC/core/api types and parser/validation helpers already in beads-cli.\\n\\n**Design**\\nRelocate pure IPC command handlers (create/show/list/search/ready/blocked/stale/count/deleted/sync/subscribe/update/close/reopen/delete/claim/unclaim/comments/dep/label/epic/status/admin init, excluding upgrade/store/migrate) into beads-cli and wire beads-rs CLI dispatch to them.\\n\\n**Acceptance**\\n- [ ] Selected command handlers moved to beads-cli\\n- [ ] beads-rs dispatch uses beads-cli handler implementations\\n- [ ] CLI critical path tests pass\\n\\n**Files:** crates/beads-cli/src/commands/*, crates/beads-rs/src/cli/commands/*, crates/beads-rs/src/cli/mod.rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.38-1","content":"Phase-1 progress landed and stabilized (compile + tests green):\n\nAdded new beads-cli read-only handler modules:\n- `crates/beads-cli/src/commands/{common,list,search,blocked,ready,stale,count}.rs`\n- `crates/beads-cli/src/commands/mod.rs` now defines typed `CommandError` and shared `print_ok`\n\nCurrent status:\n- handler implementations exist under beads-cli for the read-only pure-IPC slice\n- beads-rs dispatch rewiring to these moved handlers is NOT complete yet (next step in this bead)\n- no behavior changes introduced in active CLI path yet\n\nValidation after stabilizing worker partial state:\n- cargo check -p beads-cli\n- cargo check -p beads-rs\n- cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass)\n- just dylint\nAll green.","author":"darin@darins-Mac-Studio-2.local","at":[1770512272430,0]},{"id":"go-comment-bd-21eg.38-2","content":"Phase-1 read-only handler migration completed and wired.\n\nMoved/owned implementations in beads-cli:\n- `crates/beads-cli/src/commands/{list,search,blocked,ready,stale,count}.rs`\n- shared command scaffolding in `crates/beads-cli/src/commands/{mod,common}.rs`\n\nbeads-rs dispatch now uses beads-cli implementations for this subset:\n- `crates/beads-rs/src/cli/commands/{list,search,blocked,ready,stale,count}.rs`\n  now delegate to corresponding beads-cli handlers and re-export moved arg/render types\n- added typed conversion `impl From<beads_cli::commands::CommandError> for crate::Error`\n  in `crates/beads-rs/src/error.rs`\n\nResult:\n- read-only pure IPC path for these commands now executes via beads-cli-owned handler logic\n- behavior preserved (critical path remains green)\n\nValidation:\n- cargo check -p beads-cli\n- cargo check -p beads-rs\n- cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass)\n- just dylint\nAll green.","author":"darin@darins-Mac-Studio-2.local","at":[1770512413227,0]},{"id":"legacy-notes","content":"Phase-1 progress landed and stabilized (compile + tests green):\n\nAdded new beads-cli read-only handler modules:\n- `crates/beads-cli/src/commands/{common,list,search,blocked,ready,stale,count}.rs`\n- `crates/beads-cli/src/commands/mod.rs` now defines typed `CommandError` and shared `print_ok`\n\nCurrent status:\n- handler implementations exist under beads-cli for the read-only pure-IPC slice\n- beads-rs dispatch rewiring to these moved handlers is NOT complete yet (next step in this bead)\n- no behavior changes introduced in active CLI path yet\n\nValidation after stabilizing worker partial state:\n- cargo check -p beads-cli\n- cargo check -p beads-rs\n- cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass)\n- just dylint\nAll green.\n\nPhase-1 read-only handler migration completed and wired.\n\nMoved/owned implementations in beads-cli:\n- `crates/beads-cli/src/commands/{list,search,blocked,ready,stale,count}.rs`\n- shared command scaffolding in `crates/beads-cli/src/commands/{mod,common}.rs`\n\nbeads-rs dispatch now uses beads-cli implementations for this subset:\n- `crates/beads-rs/src/cli/commands/{list,search,blocked,ready,stale,count}.rs`\n  now delegate to corresponding beads-cli handlers and re-export moved arg/render types\n- added typed conversion `impl From<beads_cli::commands::CommandError> for crate::Error`\n  in `crates/beads-rs/src/error.rs`\n\nResult:\n- read-only pure IPC path for these commands now executes via beads-cli-owned handler logic\n- behavior preserved (critical path remains green)\n\nValidation:\n- cargo check -p beads-cli\n- cargo check -p beads-rs\n- cargo test -p beads-rs --test integration -- cli::critical_path:: (6 pass)\n- just dylint\nAll green.","author":"darin@darinsmcstudio2.lan","at":[1770512418549,0]}],"_at":[1770512418549,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770512418549,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770512418549,0]}
{"id":"bd-21eg.39","created_at":[1770511153230,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add typed CLI backend trait for upgrade/store/migrate host operations","description":"**Problem**\\nRemaining CLI commands (upgrade/store/migrate) require host-runtime integrations in beads-rs, blocking full command tree migration to beads-cli without introducing crate cycles.\\n\\n**Design**\\nDefine a typed backend trait in beads-cli for host-coupled operations (upgrade orchestration, offline store admin fallback, migrate git integration). Implement the trait in beads-rs and inject into beads-cli dispatch.\\n\\n**Acceptance**\\n- [ ] Typed backend trait defined in beads-cli (no stringly APIs)\\n- [ ] beads-rs implements trait with existing behavior\\n- [ ] No crate dependency cycle introduced\\n- [ ] cargo check --workspace passes\\n\\n**Files:** crates/beads-cli/src/*, crates/beads-rs/src/cli/*, crates/beads-rs/src/{upgrade,store_admin,git}*","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.39-1","content":"Completed: added typed host backend seam in beads-cli and implemented in beads-rs with no behavior change. Added crates/beads-cli/src/backend.rs (CliHostBackend + typed request/response types), crates/beads-rs/src/cli/backend.rs impl, injected backend into CLI context, and rewired upgrade/store/migrate handlers to use trait calls. Validation: cargo check -p beads-cli; cargo check -p beads-rs; cargo check --workspace.","author":"darin@darins-Mac-Studio-2.local","at":[1770514338751,0]},{"id":"legacy-notes","content":"Completed: added typed host backend seam in beads-cli and implemented in beads-rs with no behavior change. Added crates/beads-cli/src/backend.rs (CliHostBackend + typed request/response types), crates/beads-rs/src/cli/backend.rs impl, injected backend into CLI context, and rewired upgrade/store/migrate handlers to use trait calls. Validation: cargo check -p beads-cli; cargo check -p beads-rs; cargo check --workspace.","author":"darin@darinsmcstudio2.lan","at":[1770514338980,0]}],"_at":[1770514338980,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770514338980,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770514338980,0]}
{"id":"bd-21eg.4","created_at":[1770498231067,0],"created_by":"darin@darinsmcstudio2.lan","title":"Define migration matrix for missing boundary APIs (patch/fsck/lock)","description":"**Problem**\nSome CLI paths require daemon internals because boundary APIs do not exist yet.","design":"Specify typed API signatures for patch validation and offline fsck/lock operations using `beads-api` output types.","acceptance_criteria":"- [ ] Patch validation API signature finalized\n- [ ] Offline fsck API signature finalized\n- [ ] Offline lock API signature finalized","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770499794432,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770499794432,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770499794432,0]}
{"id":"bd-21eg.40","created_at":[1770511160065,0],"created_by":"darin@darinsmcstudio2.lan","title":"Finalize CLI crate ownership and delete beads-rs command handlers","description":"**Problem**\\nAfter phased migration, residual handler files in beads-rs can linger and create dual ownership/scatter.\\n\\n**Design**\\nSwitch final beads-rs CLI dispatch/entrypoint to beads-cli-owned command tree and delete migrated handler files/modules from beads-rs. Keep binary behavior and output compatibility unchanged.\\n\\n**Acceptance**\\n- [ ] beads-rs no longer owns migrated CLI command handler modules\\n- [ ] Command tree ownership is singular under beads-cli\\n- [ ] cargo test -p beads-rs --test integration -- cli::critical_path:: passes\\n\\n**Files:** crates/beads-rs/src/cli/*, crates/beads-cli/src/commands/*, crates/beads-rs/src/bin/main.rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-21eg.40-1","content":"Completed wrapper-finalization pass: removed dual ownership for migrated read-only command handlers by deleting beads-rs wrappers (list/search/ready/blocked/stale/count), routing dispatch directly to beads-cli handlers, and updating render_query to beads-cli render helpers. Kept behavior unchanged (same underlying handlers/arg types). Validation: cargo check -p beads-rs; cargo test -p beads-rs --test integration -- cli::critical_path:: (6/6 pass).","author":"darin@darins-Mac-Studio-2.local","at":[1770514339188,0]},{"id":"legacy-notes","content":"Completed wrapper-finalization pass: removed dual ownership for migrated read-only command handlers by deleting beads-rs wrappers (list/search/ready/blocked/stale/count), routing dispatch directly to beads-cli handlers, and updating render_query to beads-cli render helpers. Kept behavior unchanged (same underlying handlers/arg types). Validation: cargo check -p beads-rs; cargo test -p beads-rs --test integration -- cli::critical_path:: (6/6 pass).","author":"darin@darinsmcstudio2.lan","at":[1770514339394,0]}],"_at":[1770514339394,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770514339394,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770514339394,0]}
{"id":"bd-21eg.5","created_at":[1770498231367,0],"created_by":"darin@darinsmcstudio2.lan","title":"Harden dylint rule for CLI/daemon boundary violations","description":"**Problem**\nBoundary violations can regress without fast feedback.","design":"Extend lint rule to flag forbidden imports in CLI paths, with clear diagnostics and minimal false positives.","acceptance_criteria":"- [ ] Lint catches direct CLI -> daemon imports\n- [ ] Diagnostics include actionable replacement guidance\n- [ ] No false positives in allowed modules","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770499342900,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770499342900,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770499342900,0]}
{"id":"bd-21eg.6","created_at":[1770498231780,0],"created_by":"darin@darinsmcstudio2.lan","title":"Wire boundary lint into just/cargo workflow and CI docs","description":"**Problem**\nBoundary policy exists but enforcement is not consistently invoked.","design":"Ensure lint command is easy to run locally and referenced as required pre-merge check.","acceptance_criteria":"- [ ] `just dylint` remains canonical entrypoint\n- [ ] Root workflow docs mention boundary lint gate\n- [ ] Check command examples are current","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770499794635,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770499794635,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770499794635,0]}
{"id":"bd-21eg.7","created_at":[1770498232361,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add regression fixtures/tests for boundary lint behavior","description":"**Problem**\nLint behavior can silently change and lose coverage.","design":"Add targeted fixtures or tests in lint crate proving expected catches and allowlist behavior.","acceptance_criteria":"- [ ] Positive fixture fails for forbidden import\n- [ ] Negative fixture passes for allowed import\n- [ ] Tests deterministic across environments","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770499794840,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770499794840,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770499794840,0]}
{"id":"bd-21eg.8","created_at":[1770498232818,0],"created_by":"darin@darinsmcstudio2.lan","title":"Migrate CLI IPC imports to beads-surface","description":"**Problem**\nCLI commands import IPC contracts from `crate::daemon::ipc` instead of surface.","design":"Replace IPC types/helpers with `beads_surface::ipc::*` across CLI modules with no behavior change.","acceptance_criteria":"- [ ] CLI compiles with surface IPC imports\n- [ ] No direct `crate::daemon::ipc` in CLI\n- [ ] Existing IPC behavior unchanged","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770499343089,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770499343089,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770499343089,0]}
{"id":"bd-21eg.9","created_at":[1770498233110,0],"created_by":"darin@darinsmcstudio2.lan","title":"Migrate CLI query/op/error imports to beads-surface","description":"**Problem**\nCLI uses daemon query/op/error types directly.","design":"Move to `beads_surface::{Filters, SortField, OpResult, IpcError}` equivalents and keep typed behavior intact.","acceptance_criteria":"- [ ] No `crate::daemon::query` imports in CLI\n- [ ] No daemon `IpcError`/`OpResult` imports in CLI\n- [ ] Command output behavior unchanged","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770499343299,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770499343299,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770499343299,0]}
{"id":"bd-22ka","created_at":[1769309225358,0],"created_by":"darin@darinsmcstudio2.lan","title":"Nest admin Request variants under Request::Admin(AdminOp)","description":"**Problem**\nThe Request enum in src/daemon/ipc/types.rs has 11 admin-related variants at the top level:\n- AdminStatus\n- AdminMetrics  \n- AdminDoctor\n- AdminScrub\n- AdminFlush\n- AdminCheckpointWait\n- AdminFingerprint\n- AdminReloadPolicies\n- AdminReloadLimits\n- AdminReloadReplication\n- AdminRotateReplicaId\n- AdminMaintenanceMode\n- AdminRebuildIndex\n\nThis adds cognitive load when pattern matching (47 total variants) and makes the Request enum harder to navigate. Admin operations are a cohesive group that should be nested.\n\n**Design**\n1. Create `AdminOp` enum with all admin variants (without Admin prefix):\n\n```rust\n// src/daemon/ipc/types.rs\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(tag = \"admin_op\", rename_all = \"snake_case\")]\npub enum AdminOp {\n    Status { repo: PathBuf },\n    Metrics { repo: PathBuf },\n    Doctor { repo: PathBuf, fix: bool },\n    Scrub { repo: PathBuf, fix: bool },\n    Flush { repo: PathBuf },\n    CheckpointWait { repo: PathBuf, timeout_ms: Option<u64> },\n    Fingerprint { repo: PathBuf, mode: AdminFingerprintMode, sample: AdminFingerprintSample },\n    ReloadPolicies { repo: PathBuf },\n    ReloadLimits { repo: PathBuf },\n    ReloadReplication { repo: PathBuf },\n    RotateReplicaId { repo: PathBuf },\n    MaintenanceMode { repo: PathBuf, enabled: bool },\n    RebuildIndex { repo: PathBuf },\n}\n```\n\n2. Replace 11 Request variants with one:\n\n```rust\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(tag = \"op\", rename_all = \"snake_case\")]\npub enum Request {\n    // ... other variants\n    Admin(AdminOp),  // Replaces 11 AdminX variants\n}\n```\n\n3. Update dispatch in coord.rs:\n\n```rust\nRequest::Admin(op) => self.handle_admin(op),\n```\n\n4. Update CLI admin.rs handler to construct AdminOp variants\n\n**Design Notes**\n- Wire format changes: `{\"op\": \"admin_status\", ...}` → `{\"op\": \"admin\", \"admin_op\": \"status\", ...}`\n- This is a breaking protocol change — requires IPC_PROTOCOL_VERSION bump to 3\n- Can be done after IPC documentation bead to have clear migration notes\n\n**Acceptance**\n- [ ] AdminOp enum created with all 11 variants\n- [ ] Request enum has single Admin(AdminOp) variant\n- [ ] IPC_PROTOCOL_VERSION bumped to 3\n- [ ] coord.rs dispatch updated\n- [ ] src/cli/commands/admin.rs updated to construct AdminOp\n- [ ] Wire format documented in IPC_PROTOCOL.md\n- [ ] cargo clippy passes\n- [ ] cargo test passes\n- [ ] Integration tests pass\n\n**Files:** src/daemon/ipc/types.rs, src/daemon/coord.rs, src/cli/commands/admin.rs, docs/IPC_PROTOCOL.md","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769580403378,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769580403378,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769580403378,0]}
{"id":"bd-23h","created_at":[1768448953374,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replication does not enforce namespace allowlists","description":"**Problem**\nInbound replication accepts EVENTS for any namespace, regardless of negotiated namespaces. Outbound replication continues to publish events for namespaces the peer did not accept. This breaks namespace policy invariants and makes the allowlist in HELLO/WELCOME advisory only.\n\n**Evidence**\n- src/daemon/repl/session.rs: handle_events() never checks frame.eid.namespace against peer.incoming_namespaces (stored on SessionPeer).\n- src/daemon/repl/manager.rs: run_peer_loop() filters outgoing events using offered_set (plan/offered), not the negotiated accepted_namespaces from session.peer().\n- src/daemon/repl/manager.rs: handle_want() has no allowed_set filter, so it can send events for namespaces the peer never accepted.\n\n**Why this hurts**\nNamespace policy is meant to be a hard boundary. Without enforcement, a misconfigured or malicious peer can ingest or receive data outside its allowed namespaces.","design":"**Design**\n1) Enforce inbound namespaces in Session::handle_events(): if namespace not in peer.incoming_namespaces, return an error payload (NamespacePolicyViolation or InvalidRequest) and close.\n2) Outbound: after handshake, derive accepted_set from session.peer().accepted_namespaces and use it for filtering pending events + hot cache + live stream. Replace offered_set usage.\n3) Update manager::handle_want() to accept an allowed_set (like server.rs) and ignore or error on wants outside accepted_set.\n4) Add tests for both directions (reject unexpected namespace; only send accepted namespaces).\n\nNote: inbound server already builds accepted_set; align outbound to use the negotiated set.","acceptance_criteria":"- [ ] Inbound session rejects EVENTS for namespaces not in incoming_namespaces.\n- [ ] Outbound streaming/hot cache only sends namespaces in accepted_namespaces.\n- [ ] Outbound WANT handling is scoped to accepted_namespaces.\n- [ ] Tests cover accept/reject behavior.\n\n**Files:** src/daemon/repl/session.rs, src/daemon/repl/manager.rs, src/daemon/repl/server.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768454029760,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768454029760,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768454029760,0]}
{"id":"bd-2703","created_at":[1768779146693,0],"created_by":"darin@darinsmcstudio2.lan","title":"Reduce repl_e2e node count/timeouts where 2 nodes suffice","description":"tests/integration/daemon/repl_e2e.rs often uses 3 nodes + long timeouts even when 2 would cover the scenario. Audit tests and drop to 2 nodes where quorum isn't needed, and tighten timeouts based on fast-test settings.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768808038919,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768808038919,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768808038919,0]}
{"id":"bd-29jx","created_at":[1769565905122,0],"created_by":"darin@darinsmcstudio2.lan","title":"mutation: claimed bead must imply in_progress","description":"Problem\n- plan_create sets assignee/assignee_expires but does not set workflow status.\n- This can create a bead that is claimed but still Workflow::Open.\n- Elsewhere (migration, claim ops) imply claimed => in_progress, but not enforced.\n\nImpact\n- Incorrect status semantics; readiness/filters can misbehave.\n- Invariant exists in developer lore, not in types.\n","design":"Design\n- Encode the invariant in one place:\n  - If assignee is set at creation, automatically set status=InProgress (and clear closed_reason/on_branch).\n  - Alternatively, make Claim+Status a combined patch type or a validation rule in ValidatedBeadPatch: claim set requires status=in_progress when current status is open.\n- Prefer type-level coupling (e.g., ClaimState::Claimed implies WorkflowStatus::InProgress) in the mutation planning layer.\n\nScatter fit\n- Make the invariant explicit; no caller can create claimed+open state.\n\nFiles\n- crates/beads-rs/src/daemon/mutation_engine.rs\n- crates/beads-core/src/event.rs (if validation rule added)\n- crates/beads-core/src/apply.rs (if apply enforces)","acceptance_criteria":"Acceptance\n- Creating a bead with assignee always results in workflow=in_progress.\n- It is impossible to construct a mutation that yields claimed+open (compile-time or runtime validation).\n- Tests cover create-with-assignee sets status and rejects invalid combinations.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769595851988,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769595851988,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769595851988,0]}
{"id":"bd-2a5","created_at":[1768422079065,0],"created_by":"darin@darinsmcstudio2.lan","title":"phase7_subscribe_streams_events_in_order failed during benchmark","description":"Observed during benchmark: cargo test --test phase7_subscribe failed with phase7_subscribe_streams_events_in_order panicking at tests/phase7_subscribe.rs:170 (event). 18/19 passed. Likely flake or subscribe stream ordering/EOF issue; rerun with RUST_BACKTRACE=1 and add logging around StreamingClient::next_event/subscribe_stream.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768425885067,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768425885067,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768425885067,0]}
{"id":"bd-2ei","created_at":[1766136140603,0],"created_by":"darin@darinsmcstudio2.lan","title":"Expose sync retry backoff (next retry time) in daemon/CLI status","description":"","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766137448134,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766137448134,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766137448134,0]}
{"id":"bd-2fr","created_at":[1765744471242,0],"created_by":"darin@darinsmcstudio2.lan","title":"Type-safe daemon: eliminate invariant-checking unwraps","description":"Eliminate unwraps in daemon code by encoding proven invariants in the type system.\n\n**Goal:** No `unwrap()` in non-test daemon paths where failures can be caused by repo state or git IO.\n\n**Approach:** \"Parse, dont validate\" — move checks to where data enters the system and let types remember what has been validated.\n\n**Subtasks:**\n- Serde boundary validation for identity types\n- Encapsulate DepKey (no self-loops)\n- LoadedRemote proof type\n- require_live helper\n- with_mutation transaction helper\n- Collapse live/tombstones into BeadEntry\n- Remove duplicate key from DepEdge\n\nSee individual beads for design details.","priority":2,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Core goal achieved: eliminated all .unwrap() calls on bead lookups in daemon paths. Completed: serde boundary validation, DepKey encapsulation, LoadedRemote proof type, require_live helpers + refactoring, with_mutation helper. Remaining low-priority cleanup (bd-mgf, bd-di1) filed as separate beads.","assignee":"darin@dusk","_at":[1765787192823,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765787192823,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765787192823,0]}
{"id":"bd-2iv","created_at":[1768080568102,0],"created_by":"darin@darinsmcstudio2.lan","title":"Update stateright models for REALTIME_PLAN v0.5","description":"**Problem**\nStateright models in `beads_stateright_models` still reflect v0.4 realtime spec (self-hashing envelopes, unknown-key preservation, GC marker events, PENDING/COMMITTED idempotency). REALTIME_PLAN.md v0.5 simplified hashing, removed unknown-key preservation and GitCheckpointed durability, and deferred GC markers. Models should match v0.5.\n\n**Design**\n- Update `beads_stateright_models/src/realtime_types_sketch.rs` to v0.5: hash over EventBody bytes, sha/prev in headers, no unknown-key preservation, no NamespaceGcMarker, no GitCheckpointed.\n- Update toy hashing helpers (`beads_stateright_models/src/toy_codec.rs`) and models (`beads_stateright_models/examples/hash_prev_machine.rs`, `beads_stateright_models/examples/canonical_hash_machine.rs`) to use v0.5 hash/prev semantics.\n- Update idempotency model (`beads_stateright_models/examples/idempotency_receipt_machine.rs`) to use stable idempotency mapping (no PENDING/COMMITTED receipts).\n- Remove or mark GC floor model as deferred in v0.5.\n- Refresh doc comments/README/todo in the models crate to reference v0.5 sections.\n\n**Acceptance**\n- [ ] All models compile under v0.5 assumptions (no v0.4-only features).\n- [ ] Hash/prev models verify sha over EventBody bytes and use header prev_sha semantics.\n- [ ] Idempotency model reflects stable request mapping (no pending/committed states).\n- [ ] GC floor example is removed or explicitly marked deferred for v0.5.\n- [ ] `beads_stateright_models` docs mention v0.5 plan alignment.\n- [ ] Tests (model examples) still run.\n\n**Files:**\n- beads_stateright_models/src/realtime_types_sketch.rs\n- beads_stateright_models/src/toy_codec.rs\n- beads_stateright_models/examples/hash_prev_machine.rs\n- beads_stateright_models/examples/canonical_hash_machine.rs\n- beads_stateright_models/examples/idempotency_receipt_machine.rs\n- beads_stateright_models/examples/gc_floor_machine.rs\n- beads_stateright_models/README.md\n- beads_stateright_models/todo.md","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768081549513,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768081549513,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768081549513,0]}
{"id":"bd-2oms","created_at":[1768503848137,0],"created_by":"darin@darinsmcstudio2.lan","title":"Use typed internal errors in replication (avoid ErrorPayload in core logic)","description":"**Problem**\nReplication internals use ErrorPayload as their primary error type (SessionResult = Result<T, Box<ErrorPayload>> in repl/session.rs, and ReplSessionStore/ingest paths). This pushes boundary formatting into core logic, loses structured error intent, and conflicts with error_design guidance (use domain errors internally, map at boundaries).\n\n**Files:** src/daemon/repl/session.rs, src/daemon/repl/runtime.rs, src/daemon/repl/manager.rs, src/daemon/repl/server.rs","design":"**Design**\n- Introduce a ReplError enum capturing internal error cases with structured fields.\n- Convert ReplError -> ErrorPayload only at the protocol boundary (SessionAction::Close / outbound ERROR frames, IPC responses).\n- Update SessionStore trait and ReplIngestRequest to use ReplError instead of Box<ErrorPayload>.\n- Add conversion tests to ensure payload formatting stays stable.","acceptance_criteria":"- [ ] Replication core logic no longer returns ErrorPayload directly.\n- [ ] Boundary adapters produce ErrorPayload from ReplError.\n- [ ] Tests cover ReplError -> ErrorPayload mapping.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768524029898,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768524029898,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768524029898,0]}
{"id":"bd-2r6","created_at":[1768495442989,0],"created_by":"darin@darinsmcstudio2.lan","title":"Expose namespace in Issue and IssueSummary API","description":"**Problem**\nREALTIME_PLAN requires namespace exposure in issue summaries and issue views. API types Issue/IssueSummary lack namespace, so clients can’t distinguish multi-namespace data.\n\n**Design**\nAdd `namespace` field (NamespaceId or string) to Issue and IssueSummary in src/api/mod.rs. Update Issue::from_bead and IssueSummary::from_bead to take namespace context (or add new constructors) and update query executor call sites to pass the read namespace. Update IssueSummary::from_issue to copy namespace.\n\n**Files**\n- src/api/mod.rs\n- src/daemon/query_executor.rs","acceptance_criteria":"- [ ] Issue and IssueSummary include namespace in JSON output\n- [ ] All query results populate namespace based on read namespace\n- [ ] Existing query tests updated for new field","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768495681605,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768495681605,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768495681605,0]}
{"id":"bd-2rw","created_at":[1766116457266,0],"created_by":"darin@darinsmcstudio2.lan","title":"Note ID collisions should be guarded","description":"**Problem**\nNote IDs are random 8-char base58; collisions are unlikely but possible. A collision overwrites an existing note in the CRDT map.\n\n**Design**\nInclude actor + timestamp in note IDs or retry generation until unique in-bead. Add a test that forces collision handling.\n\n**Acceptance**\n- [ ] Note ID generation is collision-safe\n- [ ] Tests cover collision path\n\n**Files:** src/core/identity.rs, src/daemon/executor.rs","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767999599816,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767999599816,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767999599816,0]}
{"id":"bd-2us","created_at":[1765949713817,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add bd dep cycles detection command","description":"beads-go has 'bd dep cycles' to detect circular dependencies in the dependency graph.\n\nFiles: src/cli/mod.rs, src/cli/commands/dep.rs","priority":3,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768493321017,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768493321017,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768493321017,0]}
{"id":"bd-2ybw","created_at":[1768778983197,0],"created_by":"darin@darinsmcstudio2.lan","title":"LoadGenerator use persistent IpcConnection to avoid per-request connect","description":"tests/integration/fixtures/load_gen.rs currently opens a new IPC connection per request. Use IpcConnection (or a small per-worker connection pool) so large loads don't pay connect/handshake each time.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768801568268,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768801568268,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768801568268,0]}
{"id":"bd-2ys","created_at":[1766127770262,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remote URL canonicalization + type tightening","description":"**Problem**\nRemote URL normalization is too loose (ssh/https variants, ports, users). This can split canonical state across clones and cause data divergence.\n\n**Design**\nAdd a stricter RemoteUrl parser that:\n- strips scheme/user, lowercases host\n- normalizes ssh scp-style and ssh:// URLs\n- preserves port when present (host:port)\n- trims .git and trailing slashes\nAdd focused tests for common variants (ssh/https/ssh://, with/without user, with port).\n\n**Acceptance**\n- [ ] Same remote in different URL forms maps to identical RemoteUrl\n- [ ] Tests cover common cases + edge cases\n- [ ] No regressions for file:// or local paths\n\n**Files:** src/daemon/remote.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768440496634,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768440496634,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768440496634,0]}
{"id":"bd-34g","created_at":[1766116454864,0],"created_by":"darin@darinsmcstudio2.lan","title":"Sync fetch must not clobber local ref (ancestry check + backup)","description":"**Problem**\n`SyncProcess::fetch` force-updates `refs/heads/beads/store` to match remote and uses `unwrap_or(Oid::zero())` for ref lookup. If local is ahead/diverged, this overwrites local commits; if ref lookup errors, we treat it as missing. Both can lose durable local history.\n\n**Design**\n- Use ref lookup that distinguishes NotFound vs error.\n- Only fast-forward local ref when it is an ancestor of remote.\n- If local is ahead/diverged, create a backup ref (e.g., `refs/beads/backup/<oid>`) before any update and avoid forcing local to remote.\n- Keep commit parent as remote head for linear history.\n- Add tests covering local-ahead and diverged scenarios.\n\n**Acceptance**\n- [ ] No forced local ref update when local ahead/diverged\n- [ ] Backup refs created for diverged local history\n- [ ] Ref lookup errors are surfaced\n- [ ] Tests cover ancestry check + backup behavior\n- [ ] Tests pass\n\n**Files:** src/git/sync.rs, src/git/error.rs","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766124452235,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766124452235,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766124452235,0]}
{"id":"bd-34oa","created_at":[1769563878222,0],"created_by":"darin@darinsmcstudio2.lan","title":"checkpoint shards: type the paths and enforce canonical order","description":"Problem\n- CheckpointSnapshot/CheckpointManifest store shard paths as raw String and dirty_shards as BTreeSet<String>.\n- Path validation is scattered (layout::parse_shard_path, import::validate_rel_path, publish tree builder).\n- Shard contents accept duplicates/unsorted lines; insert_live silently overwrites duplicates during import.\n\nImpact\n- A typo in dirty_shards can delete or skip unrelated files during incremental export.\n- Malformed shards can silently drop data (last write wins) instead of failing fast.\n- Violates parse-don't-validate and Scatter (path invariants live in multiple places).\n","design":"Design\n- Introduce validated newtypes: ShardName (\"[0-9a-f]{2}.jsonl\"), CheckpointShardPath { namespace, kind, shard: ShardName }.\n- Use CheckpointShardPath (not String) in CheckpointSnapshot.shards and dirty_shards; derive the string path only at the IO boundary.\n- Change CheckpointManifest.files to BTreeMap<CheckpointShardPath, ManifestFile> (or a thin CheckpointFilePath newtype).\n- Enforce dirty_shards ⊆ shards at construction (return error if not).\n- In import_checkpoint, add canonical validation for shard content:\n  - state shards: strictly increasing BeadId, no duplicates.\n  - tombstones: strictly increasing BeadId (or TombstoneKey) with no duplicates.\n  - deps: strictly increasing DepKey, no duplicates.\n  - notes: strictly increasing (bead_id, note_id) with no duplicates.\n- Keep ordering guarantees in export (already sorted) and assert in tests.\n\nScatter fit\n- Centralize path parsing/validation in one type; callers only handle typed paths.\n- Canonical ordering checks live in one parser per shard kind.\n\nFiles\n- crates/beads-rs/src/git/checkpoint/layout.rs\n- crates/beads-rs/src/git/checkpoint/types.rs\n- crates/beads-rs/src/git/checkpoint/manifest.rs\n- crates/beads-rs/src/git/checkpoint/export.rs\n- crates/beads-rs/src/git/checkpoint/import.rs\n- crates/beads-rs/src/git/checkpoint/publish.rs\n- crates/beads-rs/src/git/checkpoint/cache.rs","acceptance_criteria":"Acceptance\n- Snapshot and manifest types use typed shard paths; invalid paths cannot be constructed.\n- build_snapshot/build_snapshot_from_state reject dirty_shards outside of shard set.\n- import_checkpoint rejects duplicate or out-of-order entries in state/tombstone/dep/note shards.\n- Tests cover path validation, dirty_shards subset enforcement, and duplicate-entry rejection.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-34oa-1","content":"Reminder: rendering should stay in command files; avoid moving rendering into shared helpers.","author":"darin@darins-Mac-Studio-2.local","at":[1769572811156,0]},{"id":"legacy-notes","content":"Reminder: rendering should stay in command files; avoid moving rendering into shared helpers.","author":"darin@darinsmcstudio2.lan","at":[1769574790928,0]}],"_at":[1769574790928,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769574790928,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769574790928,0]}
{"id":"bd-34px","created_at":[1769494178400,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode EventFrame prev/seq invariants in types","description":"**Problem**\n`EventFrameV1` allows impossible combinations of `origin_seq` and `prev_sha256` (e.g., seq=1 with prev set), and these are rejected only at runtime in `verify_event_frame`. This is a structural invariant that should be expressed in the type system so callers can’t construct invalid frames.\n\nKey references:\n- `crates/beads-core/src/event.rs:2500` — runtime prev/seq checks in `verify_event_frame`.\n- `crates/beads-core/src/event.rs:150` — `EventFrameV1` definition.\n\nSeverity: low‑level framing invariants are enforced only by convention; easy to break when creating new frame sources.","design":"**Design**\nAdd typestated frame variants to encode the prev/seq relation.\n\nOption A (sum types):\n- `enum EventFrame { Genesis(GenesisFrame), WithPrev(NonGenesisFrame) }`.\n- `GenesisFrame` has `origin_seq = Seq1::from_u64(1)` and `prev_sha256 = None`.\n- `NonGenesisFrame` carries `origin_seq > 1` and `prev_sha256 = Some`.\n\nOption B (phantom state):\n- `EventFrameV1<HasPrev>` with `HasPrev = PrevRequired | PrevForbidden` and constructors enforcing seq rules.\n\nMigration:\n- Keep wire parsing into raw struct, then convert into typed frame with a fallible conversion.\n- Update `verify_event_frame` to accept only typed frame; runtime prev/seq checks become unreachable.","acceptance_criteria":"- [ ] Construction of a frame with seq=1 and prev set (or seq>1 without prev) is impossible without a fallible conversion.\n- [ ] `verify_event_frame` takes typed frame and no longer does prev/seq validation internally.\n- [ ] Existing framing sources updated to use constructors; tests updated accordingly.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-34px-1","content":"Rendering should remain in command files; avoid extracting rendering into shared helpers.","author":"darin@darins-Mac-Studio-2.local","at":[1769580773613,0]},{"id":"legacy-notes","content":"Rendering should remain in command files; avoid extracting rendering into shared helpers.","author":"darin@darinsmcstudio2.lan","at":[1769581825097,0]}],"_at":[1769581825097,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769581825097,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769581825097,0]}
{"id":"bd-36vu","created_at":[1769562821328,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replication ingest must require a contiguous verified batch type","description":"**Problem**\n`SessionStore::ingest_remote_batch` accepts a raw `Vec<VerifiedEvent<PrevVerified>>`. Nothing in the type system guarantees: (a) same namespace + origin, (b) strictly increasing contiguous `origin_seq`, (c) no duplicates, (d) prev_sha chain consistency. Today the batch is sourced from `GapBuffer` so it is usually valid, but a single future refactor (or a new caller) can pass an invalid batch and we will append to WAL + apply state before later checks fail. That can produce WAL/state divergence and incorrect watermarks.\n\nThis violates parse-don’t-validate (we validate in scattered places) and keeps correctness implicit.\n\n**Impact**\n- Safety bug: WAL written with non-contiguous or duplicated events; state/apply diverges from WAL.\n- Hard to localize: failures surface far from where the batch was constructed.\n- Compiler cannot prevent misuse.\n\n**Files**\n- `crates/beads-rs/src/daemon/repl/session.rs` (batch construction)\n- `crates/beads-rs/src/daemon/repl/store.rs` / `crates/beads-rs/src/daemon/repl/runtime.rs` (SessionStore APIs)\n- `crates/beads-rs/src/daemon/core.rs` (ingest_remote_batch)\n","design":"**Design (opinionated)**\nMake contiguity unrepresentable as a runtime-only property. Encode it in a type that is the *only* input to ingest.\n\n1) Introduce `ContiguousBatch` (name bikesheddable) in core or repl module:\n```rust\npub struct ContiguousBatch {\n  namespace: NamespaceId,\n  origin: ReplicaId,\n  first: Seq1,\n  last: Seq1,\n  events: NonEmptyVec<VerifiedEvent<PrevVerified>>,\n}\n```\nInvariants enforced in constructor:\n- all events share namespace + origin\n- `origin_seq` strictly increasing and contiguous\n- no duplicates\n- prev_sha chain matches event order\n- `first`/`last` match bounds\n\n2) Construction should be *parse boundary only*:\n- `GapBuffer::ingest_one` / `drain_ready` should return `ContiguousBatch` instead of `Vec<VerifiedEvent<PrevVerified>>`.\n- WAL backfill (if used for repl ingest) should also construct `ContiguousBatch`.\n\n3) Change all ingest signatures:\n- `SessionStore::ingest_remote_batch(&mut self, batch: ContiguousBatch, now_ms: u64)`\n- `ReplIngestRequest` should carry `ContiguousBatch`\n- Callers no longer pass raw Vecs.\n\n4) Provide `events()` / `into_events()` accessors for local processing, but do not expose mutation of the underlying Vec.\n\nThis makes it impossible to call ingest with an invalid batch; the compiler becomes the guardrail.","acceptance_criteria":"- [ ] The only way to call `ingest_remote_batch` is via a `ContiguousBatch` (no raw Vec API).\n- [ ] `ContiguousBatch::try_new` rejects mixed origin/namespace, gaps, duplicates, and prev_sha mismatches.\n- [ ] `GapBuffer` and any other repl sources construct `ContiguousBatch` at the boundary.\n- [ ] Tests cover: valid contiguous batch, gap rejection, duplicate rejection, mixed origin rejection.\n- [ ] No code path can compile if it tries to ingest a raw Vec.\n- [ ] `cargo test` passes.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769564700496,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769564700496,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769564700496,0]}
{"id":"bd-3b3q","created_at":[1768779078472,0],"created_by":"darin@darinsmcstudio2.lan","title":"Disable checkpoints in tests by default","description":"Checkpoint scheduler runs in daemon tests even when checkpoints aren't asserted. Add a test-only config/env (maybe under BD_TEST_FAST) to disable checkpoint groups or set writers empty unless explicitly enabled by tests that need it. Reduces background work in realtime/repl tests.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768807851003,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768807851003,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768807851003,0]}
{"id":"bd-3b8u","created_at":[1769581955506,0],"created_by":"darin@darinsmcstudio2.lan","title":"Make legacy snapshot semantics explicit (rename WAL snapshot)","description":"**Problem**\n`wal_legacy_snapshot.rs` implements a “WAL” that actually stores full state snapshots, not a write-ahead log of operations.\n\nThis is a lie + noise source:\n- The name implies log-of-ops durability, but the format is snapshot-based.\n- It duplicates snapshot serialization logic and carries its own `WAL_VERSION` separate from store meta versioning.\n\n**Files:**\n- `crates/beads-rs/src/daemon/wal_legacy_snapshot.rs`\n- `crates/beads-core/src/store_meta.rs`\n- `crates/beads-rs/src/daemon/wal/*`","design":"**Design**\nMake the legacy snapshot format explicit and remove the misleading WAL framing.\n\nConcrete plan:\n1) Rename the module and types to `legacy_snapshot` / `LegacySnapshotEntry` to reflect actual semantics.\n2) Move the format version to a dedicated `LegacySnapshotVersion` or into `StoreMetaVersions` to avoid parallel version constants.\n3) Isolate legacy snapshot use to import/migration paths; block new writes when the event WAL is available.\n4) If still needed, route legacy snapshot serialization through the canonical snapshot codec (see `bd-lk0x`).\n\n**Design Notes**\n- The goal is explicit semantics: \"snapshot\" should be visible in the type and API names.\n- This reduces cognitive overhead and prevents accidental misuse as an op-log.","acceptance_criteria":"**Acceptance**\n- [ ] Legacy snapshot module/type names reflect snapshot semantics (no “WAL” in the public API).\n- [ ] Legacy snapshot versioning is centralized (no ad-hoc `WAL_VERSION`).\n- [ ] Legacy snapshot usage is confined to migration/import paths.\n- [ ] Tests still pass for legacy snapshot loading and roundtrip.","priority":3,"type":"chore","labels":{"entries":{"lies":[{"replica":"c7001f72-6f55-d137-4b72-12a27938a3e8","counter":4837767757655580815}],"noise":[{"replica":"46989f3a-5e02-6910-62f2-12e50b45b2e5","counter":12932191716031635316}],"tech-debt":[{"replica":"5509c5d8-f3ed-1284-33b7-5e74feac1db2","counter":2555881959332814832}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769774119298,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769774119298,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769774119298,0]}
{"id":"bd-3dw3","created_at":[1769495930458,0],"created_by":"darin@darinsmcstudio2.lan","title":"Use BranchName for all branch fields","description":"**Problem**\nWe already have a validated `BranchName` type (`identity.rs`) but branch fields still use raw `Option<String>` across core and wire. This means invalid branch names (empty/whitespace, spaces/newlines) can enter state or be emitted on the wire even though the type exists to prevent it. It weakens invariants in creation/closure metadata and spreads stringly-typed branch logic across the stack.\n\nKey references:\n- `crates/beads-core/src/identity.rs:832` — `BranchName` type + validation.\n- `crates/beads-core/src/bead.rs:22` — `Creation.on_branch: Option<String>`.\n- `crates/beads-core/src/composite.rs:65` — `Closure.on_branch: Option<String>`.\n- `crates/beads-core/src/wire_bead.rs:309` / `:343` — `created_on_branch` / `closed_on_branch` are `Option<String>`.\n- `crates/beads-rs/src/git/wire.rs:45` — wire paths pass raw strings.\n\n**Design**\nUse `BranchName` everywhere branch names appear and let serde handle string conversion.\n\n- Replace `Option<String>` with `Option<BranchName>` in:\n  - `Creation` / `BeadCore` (`created_on_branch`)\n  - `Closure` (`on_branch`)\n  - `WireBeadFull` / `WireBeadPatch` (`created_on_branch`, `closed_on_branch`)\n  - Git wire structs that carry branch names\n- Use existing `#[serde(try_from = \"String\", into = \"String\")]` on `BranchName` to keep wire format unchanged while enforcing validation at decode time.\n- Update encode/decode in `event.rs` / `wire_bead.rs` to call `BranchName::parse` and surface errors early.\n- Update CLI parsing to produce `BranchName` (keep error messages helpful).\n\n**Acceptance**\n- [ ] No `created_on_branch` / `closed_on_branch` fields remain as raw `String` in core/wire types.\n- [ ] Decoding invalid branch names fails with actionable errors.\n- [ ] Existing serialization format remains string-compatible; roundtrip tests pass.\n\n**Files**\n- `crates/beads-core/src/identity.rs`\n- `crates/beads-core/src/bead.rs`\n- `crates/beads-core/src/composite.rs`\n- `crates/beads-core/src/wire_bead.rs`\n- `crates/beads-core/src/event.rs`\n- `crates/beads-rs/src/git/wire.rs`","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769583586865,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769583586865,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769583586865,0]}
{"id":"bd-3fed","created_at":[1768508733723,0],"created_by":"darin@darinsmcstudio2.lan","title":"Core state module naming cleanup","description":"**Problem**\n- `src/core/state.rs`, `src/core/store_state.rs`, and `src/core/stores.rs` are easy to confuse.\n- `stores.rs` contains dep/tombstone stores, not store state.\n\n**Files:**\n- src/core/state.rs\n- src/core/store_state.rs\n- src/core/stores.rs\n- src/core/mod.rs\n- imports throughout src/","design":"- Rename `stores.rs` to `dep_tombstone_store.rs` (or similar).\n- Rename `store_state.rs` to `namespaced_state.rs` (or similar) while keeping `StoreState` type.\n- Update module exports and imports; add re-export aliases if needed to avoid public break.","acceptance_criteria":"- [ ] File names reflect contents.\n- [ ] `core/mod.rs` exports remain stable for external users.\n- [ ] All code compiles and tests pass.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768542856208,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768542856208,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-3fsg","created_at":[1768680815374,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright crash/timer/storage modeling for idempotency + durability","description":"**Problem**\nIdempotency/durability models are hand-rolled without Stateright’s timer, crash/recover, or storage features. This misses realistic failure windows and makes drift likely.\n\n**Goal**\nModel idempotency + durability using ActorModel timers, storage, and crash/recover actions with production-backed logic.","design":"**Design**\n1) Define an ActorModel where server actors use production functions for:\n   - idempotency map updates (WalIndex client_request_id mapping)\n   - durability proof/receipt generation (`DurabilityReceipt`, `DurabilityCoordinator`)\n2) Use Stateright timers (`model_timeout`) for durability wait + retry timeouts.\n3) Enable crash/recover actions with persistent `Storage` to model WAL/index persistence.\n4) Properties:\n   - no remint of txn_id/event_ids on retry\n   - timeout receipts are retryable and monotonic\n   - crash after fsync but before reply still yields original receipt on retry\n\n**References**\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/examples/timers.rs`\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor/model.rs` (Crash/Recover actions)\n- Production idempotency: `src/daemon/wal/index.rs`\n- Durability: `src/daemon/durability_coordinator.rs`, `src/core/durability.rs`","acceptance_criteria":"**Acceptance**\n- [ ] ActorModel for idempotency/durability uses timers + crash/recover + storage.\n- [ ] Properties cover retry stability + timeout semantics.\n- [ ] Model uses production logic paths (no toy idempotency mapping).","priority":0,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768712840180,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768712840180,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768712840180,0]}
{"id":"bd-3gtl","created_at":[1769562850912,0],"created_by":"darin@darinsmcstudio2.lan","title":"Repl Events must use a canonical/verified frame type","description":"**Problem**\n`ReplMessage::Events` carries raw `EventFrameV1` values. The type does not encode that the bytes are canonical or that `sha256` matches the bytes. Today call sites *happen* to build frames from canonical sources, but nothing stops a future caller (or test harness) from constructing non-canonical frames and sending them. The compiler cannot help, and correctness depends on developer discipline.\n\nThis is a lie in the type system: `EventFrameV1` looks like a verified payload but is not. It violates parse-don’t-validate and creates scatter (every call site must remember to validate).\n\n**Impact**\n- Wire protocol can emit invalid frames (non-canonical bytes or wrong sha).\n- Downstream peers reject or diverge; hard to localize to the sender.\n- Future refactors can silently introduce invalid frames.\n\n**Files**\n- `crates/beads-core/src/event.rs` (EventFrameV1)\n- `crates/beads-rs/src/daemon/repl/manager.rs` / `server.rs` / `want.rs` (frame construction + send)\n- `crates/beads-rs/src/daemon/broadcast.rs` (BroadcastEvent bytes type)\n","design":"**Design (opinionated)**\nMake the type tell the truth: only canonical frames can be sent.\n\nOption A (preferred): parameterize or wrap frames by byte canonicality.\n- Introduce `CanonicalFrame` (or `VerifiedFrame`) that holds `EventBytes<Canonical>` and derived `sha256`.\n- Provide `impl From<VerifiedEvent<PrevVerified>> for CanonicalFrame` and `impl From<BroadcastEvent>` only if `BroadcastEvent` is also canonical.\n- Change `ReplMessage::Events` to hold `Vec<CanonicalFrame>` (or `Vec<EventFrameV1<Canonical>>` if you add a type parameter).\n- `encode_event_frame` accepts only canonical frames; `decode_event_frame` still yields raw frames which must be validated via `verify_event_frame` to become canonical.\n\nOption B (minimal): keep `EventFrameV1` wire type but add a strict newtype `SendableFrame` used by all send paths; `SendableFrame::try_from(EventFrameV1)` validates canonical bytes + sha match and is the only type accepted by send functions.\n\nIn both options, the compiler forces validation before send.","acceptance_criteria":"- [ ] It is impossible to call repl send paths with a non‑canonical frame at compile time.\n- [ ] The only conversion into a sendable frame performs canonical/sha validation.\n- [ ] `ReplMessage::Events` and send helpers use the verified type (not raw `EventFrameV1`).\n- [ ] Tests cover: non-canonical bytes rejected; sha mismatch rejected; canonical frame accepted.\n- [ ] `cargo test` passes.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769568341138,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769568341138,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769568341138,0]}
{"id":"bd-3h8","created_at":[1765690392995,0],"created_by":"darin@darinsmcstudio2.lan","title":"Migration: make imported comment NoteIds globally unique","description":"## What's Wrong\nGo comment notes are imported with `NoteId::new(c.id.to_string())`. If comment IDs are not globally unique across issues in beads-go exports, notes can collide and overwrite/merge unexpectedly.\n\n## Where\n- src/migrate/go_export.rs:288 (NoteId::new(c.id.to_string()))\n\n## Why It Matters\nData loss / silent merging during migration: two different comments could end up with the same note ID.\n\n## Suggested Fix\n- Make note IDs include the issue ID (and/or created_at) e.g. `go-comment-<issue-id>-<comment-id>`.\n- Add a migration test fixture with repeated comment IDs across different issues to verify uniqueness.\n\n## Acceptance\n- Import never drops/merges distinct comments due to note ID collisions.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Made imported comment NoteIds globally unique by including issue ID in the format: go-comment-{issue_id}-{comment_id}. Added tests to verify uniqueness across issues.","assignee":"darin@dusk","_at":[1765785752083,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765785752083,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765785752083,0]}
{"id":"bd-3m5","created_at":[1768177394113,0],"created_by":"darin@darinsmcstudio2.lan","title":"Realtime v0.5 implementation","description":"Implement REALTIME_SPEC_DRAFT v0.5 per REALTIME_PLAN.md. Track phases 1-7 (REALTIME_PLAN.md §19) and their dependencies.","priority":2,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768490022952,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768490022952,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768490022952,0]}
{"id":"bd-3m5.1","created_at":[1768177707912,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 1: Core identity types + StoreMeta","description":"**Problem**\nThe realtime lane needs a canonical identity basis; core currently only models ActorId/BeadId/NoteId and still keys correctness by RemoteUrl. Without StoreId/ReplicaId/TxnId/ClientRequestId/StoreEpoch/SegmentId and StoreIdentity, we cannot define stable event identity, receipts, or WAL indexing.\n\n**Context**\n- REALTIME_PLAN.md 0.1 (StoreId as correctness identity), 2.1 (identity types), 15.1 (store meta file)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (section 1 Identity types, StoreIdentity)\n\n**Files:** src/core/identity.rs, src/core/store_meta.rs (new), src/core/mod.rs, src/lib.rs, Cargo.toml","design":"**Design**\n- Add newtypes: StoreId, StoreEpoch, ReplicaId, TxnId, ClientRequestId, SegmentId using uuid::Uuid and serde.\n- Add StoreIdentity { store_id, store_epoch } as a separate type so the store pair is not duplicated or passed as raw fields.\n- Add StoreMeta in src/core/store_meta.rs with fields from the plan: store_id, store_epoch, replica_id, store_format_version, wal_format_version, checkpoint_format_version, replication_protocol_version, index_schema_version, created_at_ms.\n- Expose constructors and parsing helpers, plus serde roundtrip tests for each newtype and StoreMeta.\n- Re-export new types via src/core/mod.rs and src/lib.rs, and keep ActorId/BeadId/NoteId unchanged.","acceptance_criteria":"- [ ] New identity types compile and serialize/deserialize (unit tests).\n- [ ] StoreMeta matches plan fields and roundtrips via serde.\n- [ ] StoreIdentity is used where a pair is required (no duplicated store_id/store_epoch fields).\n- [ ] cargo check passes.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768182968247,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768182968247,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-3m5.10","created_at":[1768177825649,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3: SQLite WAL index + WalIndex traits","description":"**Problem**\nPhase 3: add WAL SQLite index with schema and reader and writer traits. There is no SQLite index today; WAL is a snapshot file. The realtime plan requires a rebuildable index for event lookup, idempotency, and watermarks.\n\n**Context**\n- REALTIME_PLAN.md §0.11 (schema decisions) and §6.2 (table layout)\n- SQLite PRAGMA choices in §6.4\n**Files:** src/daemon/wal/index.rs (new), src/daemon/wal/mod.rs, Cargo.toml (rusqlite)","design":"**Design**\n- Implement schema for events, watermarks, client_requests, origin_seq, segments, meta (per plan).\n- Add WalIndexWriter and WalIndexReader traits with methods from REALTIME_PLAN.md §6.1.\n- Use UUIDs as 16 byte BLOBs. Store event_ids as CBOR encoded Vec<EventId> in client_requests.\n- Configure SQLite with PRAGMA: journal_mode=WAL, synchronous=NORMAL (configurable), foreign_keys=ON, busy_timeout.\n- Add schema version in meta table and enforce upgrade rules.","acceptance_criteria":"- [ ] Database initializes with expected tables and indices.\n- [ ] WalIndexWriter and WalIndexReader trait methods are implemented.\n- [ ] Schema version is stored and validated on open.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768209947141,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768209947141,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768209947141,0]}
{"id":"bd-3m5.100","created_at":[1768449542102,0],"created_by":"darin@darinsmcstudio2.lan","title":"admin.flush missing (fsync + optional checkpoint trigger)","description":"**Problem**\nREALTIME_PLAN §16.2 specifies `admin.flush` to force fsync for a namespace (and optionally trigger a checkpoint). There is no admin flush handler or IPC/CLI surface; `src/daemon/admin.rs` only has status/metrics/doctor/scrub/reload/maintenance/rotate. This leaves no explicit manual durability/flush hook.\n\n**Design**\n- Add admin IPC op + CLI subcommand `bd admin flush [--namespace] [--checkpoint-now]` (namespace default core).\n- Implement daemon handler to call WAL fsync for the namespace and optionally enqueue checkpoint for affected groups.\n- Surface in `src/api` + renderers; include timing/durability info in response.\n\n**Acceptance**\n- [ ] IPC + CLI `admin flush` exists and returns success payload.\n- [ ] WAL fsync performed for requested namespace.\n- [ ] `--checkpoint-now` schedules a checkpoint for groups including that namespace.\n- [ ] Tests cover handler + response shape.\n\n**Files:** src/daemon/admin.rs, src/daemon/ipc.rs, src/cli/mod.rs, src/cli/render.rs, src/api","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768473798982,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768473798982,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768473798982,0]}
{"id":"bd-3m5.101","created_at":[1768449581458,0],"created_by":"darin@darinsmcstudio2.lan","title":"enforce 0600/0700 perms for store policy files + WAL dirs","description":"**Problem**\nREALTIME_PLAN §13.4 requires sensitive store-local files to be 0600 (namespaces.toml, replicas.toml, wal.sqlite, meta.json) and WAL namespace dirs to be 0700 with symlink escape prevention. Current code enforces 0600 for store_meta and wal.sqlite, but `load_namespace_policies` + `load_replica_roster` read files without permission checks, and WAL namespace dirs are created with `create_dir_all` in `src/daemon/wal/segment.rs` without symlink checks or explicit 0700 perms.\n\n**Design**\n- Add a shared helper to enforce secure perms + reject symlinks for store-local config files.\n- Apply to `namespaces.toml` and `replicas.toml` read/write paths.\n- When creating `wal/<namespace>/` directories, set 0700 and reject symlink components (similar to store lock).\n\n**Acceptance**\n- [ ] namespaces.toml + replicas.toml are 0600 (or corrected on load) and symlinked paths are rejected.\n- [ ] wal/<namespace>/ directories are 0700 and symlink escapes are rejected.\n- [ ] Tests cover permission enforcement and symlink rejection.\n\n**Files:** src/daemon/store_runtime.rs, src/daemon/core.rs, src/daemon/wal/segment.rs, src/paths.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768472249326,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768472249326,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768472249326,0]}
{"id":"bd-3m5.102","created_at":[1768454384480,0],"created_by":"darin@darinsmcstudio2.lan","title":"Checkpoint export always full; dirty shard tracking + previous reuse missing","description":"**Problem**\nREALTIME_PLAN §13.2/§13.4 call for incremental checkpoint export: track dirty shards per namespace and reuse previous checkpoint blobs for unchanged shards. Current `build_snapshot` in `src/git/checkpoint/export.rs` sets `dirty_shards = all shards`, and `GitWorker::publish_checkpoint` always calls `export_checkpoint(previous=None)`, so every checkpoint is a full re‑export with no reuse.\n\n**Design**\n- Track dirty shard IDs in `StoreRuntime` using `ApplyOutcome` (beads/tombstones/deps) and pass them into `CheckpointSnapshot` instead of defaulting to all.\n- Retain the last export per group (or load from cache) and pass `previous: Some(&export)` to `export_checkpoint` so unchanged shard files are reused.\n- Ensure dirty shards are cleared only after successful publish.\n\n**Acceptance**\n- [ ] Dirty shards are tracked per namespace and carried into checkpoint snapshots.\n- [ ] `export_checkpoint` reuses previous files for clean shards.\n- [ ] Checkpoint export tests cover dirty‑only updates and reuse behavior.\n\n**Files:** src/daemon/store_runtime.rs, src/daemon/core.rs, src/daemon/checkpoint_scheduler.rs, src/daemon/git_worker.rs, src/git/checkpoint/export.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768477619127,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768477619127,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768477619127,0]}
{"id":"bd-3m5.103","created_at":[1768454392707,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replication EVENTS batching is not round‑robin across (namespace, origin)","description":"**Problem**\nREALTIME_PLAN §9.3 requires EVENTS batches be constructed round‑robin across eligible (namespace, origin_replica_id) to avoid starvation. Current `handle_want` in `src/daemon/repl/manager.rs` and `server.rs` builds batches by iterating hot‑cache then WAL ranges in map order; there is no round‑robin scheduling.\n\n**Design**\n- Implement a round‑robin iterator over keys `(namespace, origin)` when building EVENTS frames.\n- Preserve per‑origin contiguity (do not interleave out of order within a key).\n- Add tests that show fairness across multiple namespaces/origins under batch size limits.\n\n**Acceptance**\n- [ ] EVENTS batching uses round‑robin across (namespace, origin) when filling a batch.\n- [ ] Per‑origin sequence ordering is preserved.\n- [ ] Tests validate fairness and contiguity.\n\n**Files:** src/daemon/repl/manager.rs, src/daemon/repl/server.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768461133331,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768461133331,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768461133331,0]}
{"id":"bd-3m5.104","created_at":[1768454400799,0],"created_by":"darin@darinsmcstudio2.lan","title":"WalIndex durability mode is hardcoded to cache","description":"**Problem**\nREALTIME_PLAN §6.1/§6.2 calls for a store‑local `index_durability_mode = cache | durable` setting. The code always opens `SqliteWalIndex` with `IndexDurabilityMode::Cache` (e.g., `StoreRuntime::open`, fsck/rebuild helpers). There is no config knob or store‑local setting.\n\n**Design**\n- Add a store‑local setting (namespaces.toml or a new `store_config.toml`) or config‑layer override to choose `cache` vs `durable`.\n- Thread the setting into `SqliteWalIndex::open` calls, including rebuild/fsck paths.\n\n**Acceptance**\n- [ ] Index durability mode is configurable and persisted per store.\n- [ ] All index open paths respect the configured mode.\n- [ ] Tests cover both modes.\n\n**Files:** src/daemon/store_runtime.rs, src/daemon/wal/index.rs, src/daemon/wal/fsck.rs, src/config.rs (or new config module)","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768475322370,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768475322370,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768475322370,0]}
{"id":"bd-3m5.105","created_at":[1768454409818,0],"created_by":"darin@darinsmcstudio2.lan","title":"wal.sqlite checkpoint/truncate not scheduled","description":"**Problem**\nREALTIME_PLAN §6.2 notes we should periodically run `PRAGMA wal_checkpoint(TRUNCATE)` for `wal.sqlite` to control the SQLite WAL file. There is no code path invoking `wal_checkpoint` at all.\n\n**Design**\n- Add a background/maintenance hook (e.g., in checkpoint scheduler loop or on a timer) to run `wal_checkpoint(TRUNCATE)` on wal.sqlite.\n- Make frequency configurable or piggy‑back on existing periodic tasks.\n\n**Acceptance**\n- [ ] wal_checkpoint(TRUNCATE) runs periodically.\n- [ ] Frequency is configurable or documented.\n- [ ] Tests or instrumentation confirm it triggers.\n\n**Files:** src/daemon/wal/index.rs, src/daemon/core.rs (or scheduler)","priority":3,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768478723640,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768478723640,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768478723640,0]}
{"id":"bd-3m5.106","created_at":[1768454419019,0],"created_by":"darin@darinsmcstudio2.lan","title":"Checkpoint meta never includes roster_hash","description":"**Problem**\nREALTIME_PLAN §13.3 calls for `roster_hash` in checkpoint meta and warnings on mismatch. `StoreRuntime::checkpoint_snapshot` always sets `roster_hash = None`, and there is no roster hash computation anywhere. This loses the audit trail for durability eligibility changes.\n\n**Design**\n- Compute roster hash from validated `replicas.toml` (canonical JSON) when present.\n- Include it in `CheckpointSnapshot` + meta; surface mismatch warnings on import.\n\n**Acceptance**\n- [ ] roster_hash is present when a replica roster exists.\n- [ ] Checkpoint import compares roster_hash and emits a warning on mismatch.\n- [ ] Tests cover hash stability + mismatch warning.\n\n**Files:** src/daemon/store_runtime.rs, src/git/checkpoint/meta.rs, src/git/checkpoint/import.rs","priority":3,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768480026633,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768480026633,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768480026633,0]}
{"id":"bd-3m5.11","created_at":[1768177837603,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3: WAL replay + index rebuild","description":"**Problem**\nPhase 3: implement WAL replay and SQLite index rebuild from WAL segments, including tail truncation rules. Without this, crash recovery, idempotency, and origin_seq allocation are unsafe.\n\n**Context**\n- REALTIME_PLAN.md §6.3 (index rebuild and catch up), §6.5 (crash consistency), §7.3 step 8 (replay)\n**Files:** src/daemon/wal/replay.rs (new), src/daemon/wal/mod.rs, src/daemon/store_runtime.rs","design":"**Design**\n- Implement scan of wal/<namespace>/segment-*.wal in creation order.\n- Validate segment headers (store_id, store_epoch, namespace, wal_format_version) before replay.\n- For each segment, read frames from last_indexed_offset (if present) to EOF and index records.\n- On tail corruption, truncate the segment to the last valid frame boundary and update segments table.\n- Provide full rebuild path when index is missing or schema mismatch.","acceptance_criteria":"- [ ] Rebuild populates events, watermarks, and origin_seq tables from WAL segments.\n- [ ] Tail truncation is handled safely during replay.\n- [ ] Startup can catch up from last_indexed_offset without full scan.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768246015130,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768246015130,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768246015130,0]}
{"id":"bd-3m5.12","created_at":[1768177849326,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 4: MutationEngine planning + request hash","description":"**Problem**\nPhase 4: implement a MutationEngine that turns IPC ops into a single EventBody with canonical request hash and stamps. Current mutations in `src/daemon/executor.rs` mutate state directly; there is no event planning or idempotency digest.\n\n**Context**\n- REALTIME_PLAN.md §8.1 and §8.2 (mutation planning and request_sha256)\n- request_sha256 storage in WAL headers (REALTIME_PLAN.md §0.11)\n**Files:** src/daemon/mutation_engine.rs (new), src/daemon/ops.rs, src/daemon/clock.rs","design":"**Design**\n- Add a MutationEngine that validates inputs, enforces limits (MAX_OPS_PER_TXN, MAX_NOTE_BYTES), and builds one EventBody (TxnV1).\n- Compute canonical request_sha256 from a normalized request that excludes retry only fields (wait_timeout_ms, durability wait targets).\n- Mint txn_id and stamps using HLC; ensure event_time_ms equals stamp wall time and populate hlc_max.\n- Return EventDraft { event_body, request_sha256, client_request_id } for WAL append.","acceptance_criteria":"- [ ] MutationEngine builds a deterministic EventBody draft plus request_sha256 from a canonicalized request.\n- [ ] Limit enforcement rejects oversize requests before WAL append.\n- [ ] MutationEngine produces plan output without mutating CanonicalState.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768268810681,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768268810681,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768268810681,0]}
{"id":"bd-3m5.13","created_at":[1768177859800,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 4: Daemon events first mutation pipeline","description":"**Problem**\nPhase 4: integrate the events first mutation pipeline in the daemon. Current `src/daemon/executor.rs` mutates CanonicalState directly and writes snapshot WAL. We need WAL append plus deterministic apply_event and watermark updates.\n\n**Context**\n- REALTIME_PLAN.md §8.3 (apply pipeline) and §6.5 (crash consistency ordering)\n- StoreRuntime integration in §7.1\n**Files:** src/daemon/executor.rs, src/daemon/core.rs, src/daemon/store_runtime.rs, src/daemon/wal/mod.rs, src/daemon/query.rs","design":"**Design**\n- Replace direct mutation calls with: MutationEngine -> EventWal append -> core::apply_event -> update indexes and watermarks -> schedule replication and checkpoint.\n- Enforce idempotency via WAL index lookup before creating a new event when client_request_id is present.\n- Persist HLC state and idempotency mapping in the same WAL append critical section.\n- Ensure responses are returned only after apply and watermark updates complete.","acceptance_criteria":"- [ ] All mutation handlers use the events-first pipeline (plan -> WAL append -> apply_event).\n- [ ] Idempotent retry returns prior txn_id/event_ids without writing a new event.\n- [ ] Watermarks advance only after apply_event completes.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768289549636,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768289549636,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768289549636,0]}
{"id":"bd-3m5.14","created_at":[1768177869856,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 4: IPC requests + receipts (namespace, durability, client_request_id)","description":"**Problem**\nPhase 4: update IPC response shapes for receipts and error payloads. Current `src/daemon/ipc.rs` does not return DurabilityReceipt, and ErrorPayload does not match REALTIME_ERRORS.md.\n\n**Context**\n- REALTIME_PLAN.md §0.14 (IPC protocol evolution), §16.1 (response fields and error payload), §16.3 (CLI flags)\n\n**Files:** src/daemon/ipc.rs, src/api/mod.rs, src/cli/mod.rs, src/cli/commands/*, REALTIME_ERRORS.md\n\n**Design**\n- Add DurabilityReceipt to success responses and to timeout errors when waiting for replicated durability.\n- Replace ErrorPayload shape to `{ code, message, retryable, retry_after_ms?, details?, receipt? }` and keep error codes aligned with REALTIME_ERRORS.md.\n- Ensure API JSON types expose receipts without lossy view structs.\n- Request field additions and CLI flag plumbing live in bd-3m5.51.","design":"**Design**\n- Add optional `namespace`, `durability`, and `client_request_id` fields to mutation requests with defaults (namespace=core, durability=LocalFsync).\n- Add DurabilityReceipt to success responses and to timeout errors when waiting for replicated durability.\n- Replace ErrorPayload shape to `{ code, message, retryable, retry_after_ms?, details?, receipt? }` and keep error codes aligned with REALTIME_ERRORS.md.\n- Plumb CLI flags `--namespace`, `--durability`, `--client-request-id` to IPC requests.","acceptance_criteria":"- [ ] IPC mutation success responses include DurabilityReceipt in JSON mode.\n- [ ] Durability timeouts return ErrorPayload with retryable=true and receipt populated.\n- [ ] ErrorPayload schema matches REALTIME_ERRORS.md (code/message/retryable/details/receipt).\n- [ ] API JSON types expose receipts without lossy view structs.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768290954011,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768290954011,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768290954011,0]}
{"id":"bd-3m5.15","created_at":[1768177879615,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5: Replication protocol types + framing","description":"**Problem**\nReplication needs a typed, verifiable on wire protocol. Today there are no CBOR frame types or verification state; without a typestate pipeline, callers can accidentally skip hash or prev link checks and still treat events as valid.\n\n**Context**\n- REALTIME_PLAN.md §9.1-9.6 (frame definitions and rules), §0.6 (hashing over EventBody bytes)\n- REALTIME_ERRORS.md (error payload shape)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (EventBytes, EventFrameV1, VerifiedEventAny)\n\n**Files:** src/daemon/repl/frame.rs (new), src/daemon/repl/proto.rs (new), src/daemon/repl/mod.rs (new), src/core/event.rs","design":"**Design**\n- Define CBOR envelope `{ v, type, body }` and per-message bodies (HELLO, WELCOME, EVENTS, ACK, WANT, ERROR) with spec field names.\n- Introduce EventFrameV1 that carries EventId, sha256, prev_sha256, and EventBytes<Opaque>.\n- Add verification pipeline types: VerifiedEvent<PrevVerified> vs VerifiedEvent<PrevDeferred> (or equivalent) so callers cannot treat a deferred prev check as fully verified.\n- Enforce MAX_FRAME_BYTES, MAX_EVENT_BATCH_BYTES, and decoding limits before allocating large buffers; reject oversize frames with ERROR(code=\"frame_too_large\").\n- Keep ErrorPayload consistent with IPC; ERROR frames use the same schema and codes.","acceptance_criteria":"- [ ] Encode/decode roundtrip tests for each replication message type.\n- [ ] VerifiedEvent typestate prevents forwarding events with deferred prev checks.\n- [ ] Oversized frames and batches are rejected deterministically with correct error codes.\n- [ ] Error frames serialize to the same schema as IPC ErrorPayload.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768271110142,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768271110142,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768271110142,0]}
{"id":"bd-3m5.16","created_at":[1768177887839,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5: EventBroadcaster + hot cache","description":"**Problem**\nPhase 5: add a bounded EventBroadcaster and hot cache for recently appended events. There is no pub or sub mechanism to stream events or serve fast replication reads.\n\n**Context**\n- REALTIME_PLAN.md §7.5 (EventBroadcaster and hot cache requirements)\n**Files:** src/daemon/broadcast.rs (new) or src/daemon/store_runtime.rs","design":"**Design**\n- Implement a broadcaster that publishes EventId, sha, prev_sha, namespace, and canonical EventBody bytes.\n- Enforce bounds by events and bytes; drop slow subscribers with ERROR(code=\"subscriber_lagged\").\n- Maintain a FIFO hot cache with deterministic eviction.\n- Integrate publish after WAL append in StoreRuntime.","acceptance_criteria":"- [ ] Broadcaster delivers events in order to subscribers and drops slow consumers when bounds exceeded.\n- [ ] Hot cache evicts by size and event count deterministically.\n- [ ] API exposes publish/subscribe with bounded channels and a drop reason.\n- [ ] Unit tests cover backpressure and eviction behavior.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768290954770,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768290954770,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768290954770,0]}
{"id":"bd-3m5.17","created_at":[1768177897263,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5: Replication runtime integration","description":"**Problem**\nThis bead is now the integration glue for replication runtime. Sessions/manager/server are split into separate beads; we need to wire them into the daemon coordinator with bounded channels, correct defaults, and backpressure so replication traffic is serialized safely.\n\n**Context**\n- REALTIME_PLAN.md sections 7.5, 9.1-9.8, 7.2 (store runtime wiring)\n- Split beads: bd-3m5.46 (session), bd-3m5.47 (manager), bd-3m5.48 (server)\n**Files:** src/daemon/repl/mod.rs, src/daemon/core.rs, src/daemon/run.rs\n\n","design":"**Design**\n- Add a repl module root to share wiring/config between session/manager/server.\n- On daemon startup, spawn replication server + manager threads and register bounded channels into the coordinator.\n- Route inbound replication ingest through the coordinator (WAL append + apply) and produce ACKs via session channel.\n- Route outbound fanout from EventBroadcaster (with WAL fallback) and enforce AdmissionController limits at ingress.\n\n","acceptance_criteria":"- [ ] Daemon startup wires replication server + manager and registers channels to the coordinator.\n- [ ] Inbound replication events reach the coordinator through bounded queues and produce ACKs.\n- [ ] Outbound sessions receive events via broadcaster or WAL range fallback.\n- [ ] Overload path rejects replication ingest (no unbounded buffering).","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768362718810,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768362718810,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768362718810,0]}
{"id":"bd-3m5.18","created_at":[1768177908730,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5: DurabilityCoordinator + peer ACK tracking","description":"**Problem**\nPhase 5: implement DurabilityCoordinator for LocalFsync and ReplicatedFsync(k). There is no coordinator to track peer ACKs or advance durable watermarks beyond local fsync.\n\n**Context**\n- REALTIME_PLAN.md §10 (durability coordination), §0.12 (applied vs durable watermarks), §2.1.2 (replica roster)\n**Files:** src/daemon/durability_coordinator.rs (new), src/daemon/store_runtime.rs, src/daemon/repl/*","design":"**Design**\n- Track pending txns by txn_id and required durability class.\n- For ReplicatedFsync(k), select eligible replicas (from roster if present) and wait for durable ACKs.\n- On success, return updated receipt with durability_proof and advance durable watermarks.\n- On insufficient eligible replicas, return ERROR(code=\"durability_unavailable\").","acceptance_criteria":"- [ ] ReplicatedFsync(k) completes when k eligible replicas ACK.\n- [ ] Insufficient eligible replicas triggers immediate error.\n- [ ] Durable watermark advances only after local fsync and required ACKs.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768364180343,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768364180343,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768364180343,0]}
{"id":"bd-3m5.19","created_at":[1768177917713,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 6: Checkpoint canonical JSON + manifest/meta structs","description":"**Problem**\nPhase 6: implement canonical JSON helper and checkpoint manifest and meta structs. There is no checkpoint lane module yet, so manifest and meta definitions do not exist.\n\n**Context**\n- REALTIME_PLAN.md §13.3-13.5 (canonical JSON, manifest.json, meta.json)\n**Files:** src/git/checkpoint/json_canon.rs (new), src/git/checkpoint/manifest.rs (new), src/git/checkpoint/meta.rs (new), src/git/checkpoint/mod.rs (new)","design":"**Design**\n- Add `to_canon_json_bytes<T: Serialize>(v: &T) -> Vec<u8>` with sorted key ordering and no extra whitespace.\n- Define Manifest and Meta structs with fields from plan; implement content_hash and manifest_hash calculation.\n- Add tests verifying canonical JSON stability and hash determinism.","acceptance_criteria":"- [ ] Canonical JSON helper emits stable bytes across runs.\n- [ ] manifest_hash and content_hash computed per plan.\n- [ ] Tests cover a minimal checkpoint meta example.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768364742677,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768364742677,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768364742677,0]}
{"id":"bd-3m5.2","created_at":[1768177719868,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 1: Namespaces + StoreState","description":"**Problem**\nThe core state is currently single namespace. Namespace boundaries are implicit (\"core\") and there is no NamespaceId or namespace policy type, which makes cross namespace bugs easy and prevents typestate around per namespace invariants.\n\n**Context**\n- REALTIME_PLAN.md 0.3 (StoreState choice), 0.4 (namespace policy representation), 2.2 (Namespaces)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (section 3 Namespaces)\n\n**Files:** src/core/namespace.rs (new), src/core/store_state.rs (new) or src/core/state.rs, src/core/mod.rs, src/lib.rs, src/config.rs (policy parsing hook)","design":"**Design**\n- Add NamespaceId newtype with validation [a-z][a-z0-9_]{0,31}, matching the stateright model; include as_str and display.\n- Add NamespacePolicy and CheckpointGroup structs with the fields and defaults from REALTIME_PLAN.md 2.2.\n- Introduce StoreState as BTreeMap<NamespaceId, CanonicalState> with helpers: get, get_mut, ensure_namespace, and a constant default NamespaceId::core().\n- Ensure callers must select a namespace before accessing a CanonicalState (no implicit global operations), so cross namespace operations require explicit opt in.\n- Re-export NamespaceId, NamespacePolicy, CheckpointGroup, StoreState in src/core/mod.rs and src/lib.rs.","acceptance_criteria":"- [ ] NamespaceId validation tests cover valid and invalid inputs.\n- [ ] StoreState can create and return the default core namespace without side effects.\n- [ ] NamespacePolicy defaults match the plan.\n- [ ] No daemon behavior change yet; this is core types only.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768183528235,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768183528235,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768183528235,0]}
{"id":"bd-3m5.20","created_at":[1768177927003,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 6: Checkpoint export + cache","description":"**Problem**\nPhase 6: implement checkpoint export to sharded JSONL plus local cache. There is no exporter for the new checkpoint layout.\n\n**Context**\n- REALTIME_PLAN.md §13.1, §13.3, §13.8 (layout, sharding, export, cache)\n**Files:** src/git/checkpoint/export.rs (new), src/git/checkpoint/layout.rs (new), src/git/checkpoint/cache.rs (new), src/git/checkpoint/mod.rs","design":"**Design**\n- Implement sharded JSONL layout under namespaces/<ns>/{state,tombstones,deps}/00..ff.jsonl.\n- Serialize lines in canonical JSON with deterministic sorting by key.\n- Write manifest.json and meta.json with hashes and included watermarks.\n- Add local checkpoint cache under store_dir/checkpoint_cache/<group>/ with atomic publish (tmp + rename + fsync).\n- Add tests verifying shard ordering and manifest hashes for a small StoreState.","acceptance_criteria":"- [ ] Export writes shard files, manifest.json, and meta.json with correct hashes.\n- [ ] Cache publish is atomic and uses temp dirs.\n- [ ] Export output is deterministic for a given StoreState (same bytes).","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"superseded by bd-3m5.49, bd-3m5.50","_at":[1768254394836,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768254394836,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-3m5.21","created_at":[1768177935573,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 6: Checkpoint import + verification","description":"**Problem**\nPhase 6: implement checkpoint import and verification (manifest_hash and content_hash). There is no importer for the new checkpoint layout.\n\n**Context**\n- REALTIME_PLAN.md §13.9 and §13.9.1 (import, verification, JSONL bounds)\n**Files:** src/git/checkpoint/import.rs (new), src/git/checkpoint/layout.rs, src/git/checkpoint/mod.rs","design":"**Design**\n- Read checkpoint tree or cache, verify manifest hashes and file hashes.\n- Validate content_hash from meta preimage.\n- Parse JSONL shards line by line with size bounds and merge into StoreState deterministically.\n- Return included watermarks and optional included_heads for seeding head sha.","acceptance_criteria":"- [ ] Import rejects mismatched hashes.\n- [ ] JSONL parsing enforces line and shard size limits.\n- [ ] Merge output is deterministic for identical inputs.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768369154823,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768369154823,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768369154823,0]}
{"id":"bd-3m5.22","created_at":[1768177947873,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 6: Checkpoint scheduler + git ref wiring","description":"**Problem**\nPhase 6: integrate checkpoint scheduling and git ref wiring. Export and import modules alone are not used until daemon schedules checkpoints and writes the new refs.\n\n**Context**\n- REALTIME_PLAN.md §13.2 (refs), §14 (scheduler), §7.3 (startup flow)\n**Files:** src/git/checkpoint/*, src/daemon/scheduler.rs or new checkpoint runtime module, src/daemon/git_worker.rs, src/git/sync.rs (legacy)","design":"**Design**\n- Add checkpoint runtime that tracks dirty namespaces and schedules exports with debounce, max interval, and max events.\n- Write checkpoint commits to `refs/beads/<store_id>/<group>` and keep `refs/beads/meta` for discovery.\n- Ensure only one push in flight per group and coalesce when new events arrive.\n- Keep legacy `src/git/sync.rs` as read only migration path.","acceptance_criteria":"- [ ] Checkpoint export is scheduled and produces commits under new refs.\n- [ ] Dirty events during export schedule a follow up checkpoint.\n- [ ] Legacy sync remains available for migration but does not write new realtime refs.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768380009337,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768380009337,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768380009337,0]}
{"id":"bd-3m5.23","created_at":[1768177958315,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 7: IPC Subscribe streaming + require_min_seen","description":"**Problem**\nPhase 7: implement IPC Subscribe streaming with require_min_seen gating. IPC is currently request or response only and has no streaming path.\n\n**Context**\n- REALTIME_PLAN.md §11 (local subscriptions), §16.1 (require_min_seen and timeout semantics)\n**Files:** src/daemon/ipc.rs, src/daemon/server.rs, src/daemon/broadcast.rs, src/api/mod.rs","design":"**Design**\n- Add a Subscribe request variant with namespace, require_min_seen, and wait_timeout_ms.\n- Stream EventBody bytes plus sha and prev_sha headers.\n- Use EventBroadcaster for live updates and WAL read for historical backfill.\n- If require_min_seen is not satisfied, wait up to wait_timeout_ms then return retryable error with current watermarks.","acceptance_criteria":"- [ ] Subscribe streams events in order and closes on disconnect.\n- [ ] require_min_seen gating works and returns retryable errors on timeout.\n- [ ] Backpressure limits prevent unbounded buffering.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768435428277,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768435428277,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768435428277,0]}
{"id":"bd-3m5.24","created_at":[1768177968445,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 7: CLI subscribe command","description":"**Problem**\nPhase 7: add CLI support for streaming subscriptions. Without a CLI command, subscribe is hard to validate and use.\n\n**Context**\n- REALTIME_PLAN.md §16.3 (CLI changes)\n**Files:** src/cli/mod.rs, src/cli/commands/*, src/cli/render.rs","design":"**Design**\n- Add a `bd subscribe` command with flags for namespace and require_min_seen.\n- Stream events to stdout in json and human modes (consistent with other commands).\n- Propagate retryable errors and exit with non zero status on permanent errors.","acceptance_criteria":"- [ ] CLI subscribe connects and prints events in order.\n- [ ] CLI handles retryable timeout errors and exits cleanly.\n- [ ] `cargo test` passes for CLI tests if present.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768370060139,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768370060139,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768370060139,0]}
{"id":"bd-3m5.25","created_at":[1768178713781,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 1: Core error types + ErrorPayload","description":"**Problem**\nWe need a single, truthful error vocabulary shared by IPC and replication. Today error mapping is scattered (OpError/CoreError/IpcError) and ErrorPayload in src/daemon/ipc.rs lacks retryable/receipt fields. That creates multiple representations of the same failure and forces clients to interpret strings ad hoc.\n\n**Context**\n- REALTIME_PLAN.md §0.14 (error payload standardization) and §9.10 (replication error handling)\n- REALTIME_ERRORS.md (canonical error code registry)\n- Current error plumbing: src/core/error.rs, src/error.rs, src/daemon/ipc.rs, src/daemon/repl/proto.rs (new)\n\n**Files:** src/core/error.rs (new or expanded), src/error.rs, src/daemon/ipc.rs, src/api/mod.rs, src/daemon/repl/proto.rs, REALTIME_ERRORS.md","design":"**Design**\n- Introduce ErrorCode enum with stable string mappings for every code in REALTIME_ERRORS.md; make it the single source of truth for code strings.\n- Define ErrorPayload { code, message, retryable, retry_after_ms?, details?, receipt? } in core and re-use it in IPC JSON and replication CBOR.\n- Provide From conversions from CoreError/OpError/IpcError/SyncError into ErrorPayload with consistent retryable/effect semantics.\n- Enforce that unknown codes are tolerated by clients; only retry when retryable=true.\n- Keep ErrorPayload schema version stable; add fields only as optional to preserve compatibility.","acceptance_criteria":"- [ ] ErrorCode covers every entry in REALTIME_ERRORS.md and is the sole mapping to code strings.\n- [ ] ErrorPayload serializes to both JSON (IPC) and CBOR (replication) with optional fields omitted when empty.\n- [ ] Tests verify retryable and receipt fields are preserved and unknown codes do not break decoding.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768187523392,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768187523392,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768187523392,0]}
{"id":"bd-3m5.26","created_at":[1768178715136,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 4: HLC persistence + recovery","description":"**Problem**\nHLC state must be persisted to prevent stamp regression after restart or wall-clock rollback. Recovery must reconstruct HLC from WAL if SQLite is missing.\n\n**Context**\n- REALTIME_PLAN.md §2.8 (write stamps explicit requirements)\n- §6.2 (hlc table in SQLite schema)\n\n**Design**\n- Add `hlc` table to SQLite schema: (actor_id TEXT PK, last_physical_ms INTEGER, last_logical INTEGER)\n- On startup: initialize HLC from max(persisted, system_time)\n- On mint: clamp forward jumps to HLC_MAX_FORWARD_DRIFT_MS (default 600s), log anomaly\n- On index rebuild: scan WAL records for hlc_max and take max per ActorId\n- Persist HLC in same critical section as WAL append/index commit\n\n**Acceptance**\n- [ ] HLC state persisted in SQLite hlc table\n- [ ] Restart recovers HLC without stamp regression\n- [ ] Forward jump clamping logged as anomaly\n- [ ] Index rebuild reconstructs HLC from WAL hlc_max\n\n**Files:** src/daemon/wal/index.rs, src/core/time.rs, src/daemon/mutation_engine.rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768282017214,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768282017214,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768282017214,0]}
{"id":"bd-3m5.27","created_at":[1768178717301,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3: WatermarkHeadMap + head sha tracking","description":"**Problem**\nHead sha tracking is required to validate prev_sha continuity and to safely advance watermarks. Today we only have seq values, which allows the system to represent seq>0 without knowing the chain head, making continuity checks ambiguous. This bead scopes the Phase 3 core tracking (no replication session wiring).\n\n**Context**\n- REALTIME_PLAN.md 0.12 (head sha rule) + 2.3 (WatermarkHeadMap)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (HeadStatus)\n\n**Design**\n- Extend watermarks to carry head hash for each (namespace, origin) pair (HeadStatus: Genesis, Known, Unknown).\n- Require head to be Known whenever seq>0; Unknown is allowed only when a checkpoint does not include heads.\n- Persist head sha in the wal.sqlite watermarks table (applied_head_sha, durable_head_sha) and keep in memory in StoreRuntime.\n- Update head sha on WAL append (durable) and after apply_event (applied) so prev_sha validation can use the latest known head.\n- Provide helper API: advance_contiguous(seq, head) and observe_at_least(seq, head) to enforce invariants in one place.\n- Replication session wiring deferred to Phase 5 (bd-3m5.46).\n\n**Acceptance**\n- [ ] Head sha is persisted and reloaded alongside applied and durable watermarks.\n- [ ] API rejects advancing a nonzero seq without a head sha.\n- [ ] StoreRuntime exposes head sha lookup per (namespace, origin) for later prev_sha validation.\n- [ ] Head sha updates are tied to watermark advancement (no stale head).\n\n**Files:** src/core/watermark.rs, src/daemon/store_runtime.rs, src/daemon/wal/index.rs","design":"**Design**\n- Extend watermarks to carry head hash for each (namespace, origin) pair (HeadStatus: Genesis, Known, Unknown).\n- Require head to be Known whenever seq>0; Unknown is allowed only when a checkpoint does not include heads.\n- Persist head sha in the wal.sqlite watermarks table (applied_head_sha, durable_head_sha) and keep in memory in StoreRuntime.\n- Update head sha on WAL append (durable) and after apply_event (applied) so prev_sha validation can use the latest known head.\n- Provide helper API: advance_contiguous(seq, head) and observe_at_least(seq, head) to enforce invariants in one place.","acceptance_criteria":"- [ ] Head sha is persisted and reloaded alongside applied and durable watermarks.\n- [ ] API rejects advancing a nonzero seq without a head sha.\n- [ ] StoreRuntime exposes head sha lookup per (namespace, origin) for later prev_sha validation.\n- [ ] Head sha updates are tied to watermark advancement (no stale head).","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768253663111,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768253663111,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768253663111,0]}
{"id":"bd-3m5.28","created_at":[1768178742774,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5: GapBufferByNsOrigin for replication","description":"**Problem**\nOut-of-order replication needs a bounded gap buffer that is aware of contiguity and prev hash verification. A naive BTreeMap of bytes lets callers accidentally treat deferred prev checks as safe and doesn’t encode the decision outcomes.\n\n**Context**\n- REALTIME_PLAN.md §9.4 (contiguous ingest rule), §9.8 (gap handling + bounds)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (GapBuffer, VerifiedEventAny, IngestDecision)\n\n**Files:** src/daemon/repl/gap_buffer.rs (new), src/daemon/repl/session.rs, src/daemon/store_runtime.rs","design":"**Design**\n- Implement GapBufferByNsOrigin keyed by (NamespaceId, ReplicaId) with per-origin gap state.\n- Store VerifiedEventAny so deferred prev checks remain explicit; only contiguous VerifiedEvent<PrevVerified> are forwarded to WAL append.\n- Provide ingest API returning an IngestDecision: ForwardContiguousBatch, BufferedNeedWant, DuplicateNoop, Reject(code).\n- Enforce per-origin bounds on buffered events and bytes, plus a timeout window; overflow or timeout returns Reject(\"gap_buffer_overflow\"/\"gap_timeout\").\n- Drain buffered suffix in order when the predecessor arrives; stop if a deferred event is still waiting on prev verification.","acceptance_criteria":"- [ ] Gap buffer enforces event and byte bounds and returns explicit Reject on overflow/timeout.\n- [ ] Only fully verified contiguous events are forwarded to WAL append.\n- [ ] Duplicate events are treated as no-ops without disturbing the buffer.\n- [ ] Unit tests cover: single gap, multiple gaps, overflow, timeout, deferred-prev behavior.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768289552843,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768289552843,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768289552843,0]}
{"id":"bd-3m5.29","created_at":[1768178744328,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5: AdmissionController + overload shedding","description":"**Problem**\nPlan requires priority ordering and overload shedding to protect local mutations from replication storms.\n\n**Context**\n- REALTIME_PLAN.md §0.19 (overload shedding, internal backpressure defaults)\n- Priority: local IPC > replication ingest > WANT servicing > checkpoint\n\n**Design**\n- Add `AdmissionController` to src/daemon/admission.rs\n- Track inflight counts: ipc_mutations, repl_ingest_bytes, repl_ingest_events\n- Enforce limits: MAX_IPC_INFLIGHT_MUTATIONS (1024), MAX_REPL_INGEST_QUEUE_BYTES (32 MiB), MAX_REPL_INGEST_QUEUE_EVENTS (50k)\n- When overloaded: shed replication first, then IPC\n- Return ERROR(code=\"overloaded\") with retry_after_ms\n\n**Acceptance**\n- [ ] AdmissionController tracks inflight by priority class\n- [ ] Replication shed before IPC mutations\n- [ ] Limits enforced with ERROR(code=\"overloaded\")\n- [ ] Tests verify shedding order\n\n**Files:** src/daemon/admission.rs (new), src/daemon/core.rs, src/daemon/repl/session.rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768336320713,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768336320713,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768336320713,0]}
{"id":"bd-3m5.3","created_at":[1768177732086,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 1: Watermarks + durability types","description":"**Problem**\nRealtime semantics require explicit applied vs durable watermarks and head hash tracking. Today there is no watermark type, no seq0 vs seq1 distinction, and receipts cannot represent pending or partial durability without ambiguity.\n\n**Context**\n- REALTIME_PLAN.md 0.12 (applied vs durable), 0.12 head sha rule, 10.1 (durability classes), 16.1 (receipt shape)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (Watermarks, Watermark, HeadStatus, DurabilityClass, DurabilityOutcome)\n\n**Files:** src/core/watermark.rs (new), src/core/durability.rs (new), src/core/mod.rs, src/lib.rs","design":"**Design**\n- Add Seq0 and Seq1 newtypes: Seq0 for highest contiguous seen, Seq1 for actual event origin_seq (1 based). Provide helpers next(), prev(), prev_seq0().\n- Add Watermark<K> that couples Seq0 with HeadStatus (Genesis, Known(sha), Unknown). This prevents representing seq>0 with no head.\n- Add Watermarks<Applied> and Watermarks<Durable> maps keyed by (NamespaceId, ReplicaId) with helpers advance_contiguous and observe_at_least that enforce head requirements.\n- Add DurabilityClass with ReplicatedFsync using NonZeroU32 for k; add DurabilityOutcome (Achieved vs Pending) and DurabilityProofV1 to express receipts without ambiguous Option fields.\n- Keep types serde friendly for IPC and WAL metadata.","acceptance_criteria":"- [ ] WatermarkMap and WatermarkHeadMap helpers enforce contiguous advance and head sha required for seq > 0.\n- [ ] Seq0/Seq1 helpers behave as expected and are used by Watermark APIs.\n- [ ] DurabilityClass cannot represent k=0; DurabilityOutcome encodes pending vs achieved explicitly.\n- [ ] serde roundtrip tests for WatermarkMap/WatermarkHeadMap and DurabilityClass/Outcome.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768195767984,0],"_by":"darin@darinsmcstudio2.lan","_v":{"workflow":[[1768183997123,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1768183997123,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768195767984,0]}
{"id":"bd-3m5.30","created_at":[1768178745980,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 6: CheckpointSnapshot barrier type","description":"**Problem**\nCheckpoint export requires a snapshot barrier that freezes the state and included watermarks together. Without a typed barrier, the coordinator can accidentally mix shards from different logical times or claim watermarks that aren’t represented in the exported content.\n\n**Context**\n- REALTIME_PLAN.md §13.8 (checkpoint snapshot barrier and consistency rule)\n- Checkpoint scheduling in §13.7 and export workflow in §13.8\n\n**Files:** src/git/checkpoint/types.rs (new), src/git/checkpoint/export.rs, src/daemon/store_runtime.rs","design":"**Design**\n- Introduce an immutable CheckpointSnapshot struct: { group_id, policy_hash, roster_hash, included_watermarks (durable), included_heads?, shard_payloads/dirty_shards, created_at_ms }.\n- The coordinator thread captures the snapshot under a single lock so shard contents and watermarks correspond to the same logical point in time.\n- Make the snapshot owned/immutable (e.g., Arc or owned values), so the worker thread cannot observe concurrent mutations.\n- Enforce a check: included_watermarks must not exceed the max seq represented by shard_payloads; if it would, delay snapshot or recompute.","acceptance_criteria":"- [ ] Snapshot captures included watermarks and shard contents from a single coordinator tick.\n- [ ] Snapshot object is immutable once created and safe to pass to worker thread.\n- [ ] Export worker consumes only snapshot data (no live reads during I/O).\n- [ ] Snapshot includes metadata needed for manifest/meta construction without touching live state.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768373474494,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768373474494,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768373474494,0]}
{"id":"bd-3m5.31","created_at":[1768178783264,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 7: admin.status + admin.metrics IPC ops","description":"**Problem**\nOperators need introspection into store health, watermarks, segments, replication, and checkpoints.\n\n**Context**\n- REALTIME_PLAN.md §16.1 (admin.status, admin.metrics)\n\n**Design**\n- admin.status returns: store_id, replica_id, namespaces, applied/durable watermarks, WAL segment stats (count/bytes), index health (last_indexed_offset per segment), replication sessions (peers, last_ack, lag), checkpoint groups (dirty/in-flight/last push)\n- admin.metrics returns: counters (wal_append_ok/err, apply_ok/err, repl_events_in/out), gauges (IPC inflight, repl queue depth, per-peer lag), histograms (wal_append_duration, checkpoint_duration)\n- Both return structured JSON\n\n**Acceptance**\n- [ ] admin.status returns complete store introspection\n- [ ] admin.metrics returns counters/gauges/histograms\n- [ ] CLI `bd admin status` and `bd admin metrics` work\n- [ ] Tests verify expected fields\n\n**Files:** src/daemon/ipc.rs, src/daemon/admin.rs (new), src/cli/commands/admin.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768390806609,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768390806609,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768390806609,0]}
{"id":"bd-3m5.32","created_at":[1768178784608,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 7: admin.doctor + admin.scrub_now IPC ops","description":"**Problem**\nOperators need bounded health checks with deterministic remediation actions.\n\n**Context**\n- REALTIME_PLAN.md §16.1 (admin.doctor, admin.scrub_now)\n\n**Design**\n- admin.doctor: runs bounded health scrub, returns machine-readable JSON with:\n  - checks: [{ id, status, severity, evidence, suggested_actions }]\n  - summary: { risk, safe_to_accept_writes, safe_to_prune_wal, safe_to_rebuild_index }\n  - Must include explicit remediation actions (exact admin ops to run)\n- admin.scrub_now: samples N events per namespace (default 200), verifies WAL CRC32c and sha256, verifies SQLite offsets, optionally verifies checkpoint_cache\n  - Returns structured pass/warn/fail results\n\n**Acceptance**\n- [ ] admin.doctor returns structured checks with remediation\n- [ ] admin.scrub_now samples and verifies bounded records\n- [ ] CLI `bd admin doctor` and `bd admin scrub` work\n- [ ] Tests verify check detection\n\n**Files:** src/daemon/admin.rs, src/daemon/scrubber.rs (new), src/cli/commands/admin.rs","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768395325944,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768395325944,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768395325944,0]}
{"id":"bd-3m5.33","created_at":[1768178786263,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 7: admin.maintenance_mode + admin.rebuild_index","description":"**Problem**\nOperators need to put daemon in read-only mode for repairs and rebuild SQLite from WAL.\n\n**Context**\n- REALTIME_PLAN.md §16.1 (admin.maintenance_mode, admin.rebuild_index)\n\n**Design**\n- admin.maintenance_mode: toggle read-only mode\n  - When enabled: reject mutations/replication ingest with ERROR(code=\"maintenance_mode\")\n  - Allow admin/read operations\n  - Required for online repair beyond tail truncation\n- admin.rebuild_index: rebuilds SQLite index from WAL segments\n  - Explicit operator action; requires maintenance_mode\n  - Scans all WAL segments and re-indexes events\n\n**Acceptance**\n- [ ] admin.maintenance_mode toggles write rejection\n- [ ] admin.rebuild_index scans WAL and rebuilds SQLite\n- [ ] CLI `bd admin maintenance on/off` and `bd admin rebuild-index` work\n- [ ] Tests verify mode transitions\n\n**Files:** src/daemon/admin.rs, src/daemon/wal/replay.rs, src/cli/commands/admin.rs","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768392019078,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768392019078,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768392019078,0]}
{"id":"bd-3m5.34","created_at":[1768178812759,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 7: admin.fingerprint for divergence detection","description":"**Problem**\nOperators need to quickly detect divergence across replicas using stable convergence fingerprints.\n\n**Context**\n- REALTIME_PLAN.md §16.1 (admin.fingerprint, fingerprint algorithm)\n\n**Design**\n- Returns per-namespace: { state_sha256, tombstones_sha256, deps_sha256, namespace_root }\n- Merkle-ish algorithm: shard_hash[00..ff] -> type_root -> namespace_root\n- Modes: full (per-shard hashes, expensive), sample(N) (deterministic N samples)\n- Sampling uses sha256(namespace || request_nonce) to select indices\n- Includes watermarks_applied and watermarks_durable as basis\n\n**Acceptance**\n- [ ] admin.fingerprint returns namespace_root and type_roots\n- [ ] full mode returns per-shard hashes\n- [ ] sample(N) returns deterministic shard samples\n- [ ] Tests verify determinism (same state -> same hash)\n\n**Files:** src/daemon/admin.rs, src/daemon/fingerprint.rs (new), src/cli/commands/admin.rs","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768397061618,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768397061618,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768397061618,0]}
{"id":"bd-3m5.35","created_at":[1768178814317,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 7: admin.reload_policies + admin.rotate_replica_id","description":"**Problem**\nOperators need to reload namespace policies live and recover from replica_id collision.\n\n**Context**\n- REALTIME_PLAN.md §0.4 (reload semantics), §2.1.1 (replica_id collision)\n\n**Design**\n- admin.reload_policies: reloads namespaces.toml, validates, applies safe live changes\n  - Safe to apply: visibility, ready_eligible, retention windows, ttl_basis\n  - Requires restart: checkpoint group membership, replication listen params\n  - Returns diff summary (applied vs requires_restart)\n- admin.rotate_replica_id: generates new replica_id, updates meta.json, logs old->new mapping\n  - Used for recovery from duplicated store directories\n  - New replica starts with origin_seq=0 for new identity\n\n**Acceptance**\n- [ ] admin.reload_policies applies safe changes, reports restart-required changes\n- [ ] admin.rotate_replica_id generates new UUID and persists\n- [ ] CLI `bd admin reload-policies` and `bd admin rotate-replica-id` work\n- [ ] Tests verify policy reload diff\n\n**Files:** src/daemon/admin.rs, src/core/store_meta.rs, src/cli/commands/admin.rs","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768398416289,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768398416289,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768398416289,0]}
{"id":"bd-3m5.36","created_at":[1768178815664,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3: bd store unlock CLI for stale lock recovery","description":"**Problem**\nOperators need to recover from stale lock files without manual rm.\n\n**Context**\n- REALTIME_PLAN.md §0.2 (store lock metadata, recovery ergonomics)\n\n**Design**\n- CLI: `bd store unlock --store-id <id>`\n- Reads lock metadata and displays: store_id, replica_id, pid, started_at_ms, daemon_version\n- If pid does not exist: removes lock file (safe case)\n- If pid exists but different process (pid reuse): removes lock file\n- If pid exists and appears to be daemon: requires --force flag\n- Logs unlock action for traceability\n\n**Acceptance**\n- [ ] bd store unlock reads and displays lock metadata\n- [ ] Auto-removes stale locks (pid gone)\n- [ ] Requires --force for live-looking processes\n- [ ] Tests verify safe/force paths\n\n**Files:** src/cli/commands/store.rs (new), src/daemon/store_lock.rs","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768209951422,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768209951422,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768209951422,0]}
{"id":"bd-3m5.37","created_at":[1768178839514,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3: bd store fsck offline verification tool","description":"**Problem**\nOperators need offline tool to verify and repair WAL/index when daemon is stopped.\n\n**Context**\n- REALTIME_PLAN.md §5.2 (offline repair, online vs offline boundary)\n\n**Design**\n- CLI: `bd store fsck --store-id <id>`\n- Scans wal/<ns> segments, validates headers, frame CRCs, sha256, prev_sha continuity, per-(ns,origin) contiguity\n- Cross-checks wal.sqlite offsets if present\n- Emits deterministic FsckReport schema (compatible with admin.doctor later)\n- `bd store fsck --repair`: truncate corrupted tails, quarantine mid-file segments (move to quarantine/), rebuild wal.sqlite\n\n**Acceptance**\n- [ ] bd store fsck validates WAL segments offline\n- [ ] --repair truncates tails and quarantines bad segments\n- [ ] Report uses a stable FsckReport schema for later admin.doctor reuse\n- [ ] Tests with golden corpus fixtures\n\n**Files:** src/cli/commands/store.rs, src/daemon/wal/fsck.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768251464501,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768251464501,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-3m5.38","created_at":[1768178841172,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 6: Legacy WAL snapshot migration import","description":"**Problem**\nExisting users have data in legacy snapshot WAL format. Must import into new event WAL.\n\n**Context**\n- REALTIME_PLAN.md §17.1 (legacy WAL snapshot), §5.1 (rename to wal_legacy_snapshot.rs)\n\n**Design**\n- Rename src/daemon/wal.rs to src/daemon/wal_legacy_snapshot.rs\n- On store open during migration: detect legacy snapshot WAL, read it, merge into StoreState[\"core\"] namespace\n- Proceed with new event WAL thereafter\n- Keep legacy reader read-only for one release\n\n**Acceptance**\n- [ ] Legacy wal.rs renamed to wal_legacy_snapshot.rs\n- [ ] Migration detects and imports legacy snapshot\n- [ ] Data ends up in \"core\" namespace\n- [ ] Tests verify migration path\n\n**Files:** src/daemon/wal_legacy_snapshot.rs, src/daemon/store_runtime.rs, src/daemon/migration.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768376045284,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768376045284,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768376045284,0]}
{"id":"bd-3m5.39","created_at":[1768178842509,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 6: Legacy Git ref migration import","description":"**Problem**\nExisting users have data in refs/heads/beads/store. Must import into new checkpoint format.\n\n**Context**\n- REALTIME_PLAN.md §17.2 (legacy Git ref), §17.3 (identity migration)\n\n**Design**\n- On store open: check for refs/heads/beads/store\n- Import into StoreState[\"core\"] namespace using legacy wire format\n- Leave checkpoint export to the scheduler (refs/beads/<store_id>/<group>) in bd-3m5.22\n- Mirror legacy ref for one release if needed\n- Keep legacy wire format reader for migration only\n\n**Acceptance**\n- [ ] Migration imports refs/heads/beads/store into StoreState[\"core\"].\n- [ ] Legacy ref is treated as read-only during migration.\n- [ ] Identity persisted locally (URL changes don't break it).\n- [ ] Tests verify legacy import\n\n**Files:** src/git/sync.rs, src/git/wire.rs, src/daemon/migration.rs, src/git/checkpoint/import.rs","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768375342617,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768375342617,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768375342617,0]}
{"id":"bd-3m5.4","created_at":[1768177746679,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 2: Core wire delta types","description":"**Problem**\nRealtime events need a canonical delta representation that is not tied to the legacy git wire format. Today only src/git/wire.rs exists, so the realtime lane has no typed delta basis for EventBody and no canonical op ordering.\n\n**Context**\n- REALTIME_PLAN.md 0.7 (delta schema choice) and 2.4 (TxnDeltaV1 fields)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (WireBeadPatch, NotesPatch, TxnOpKey, TxnDeltaV1)\n\n**Files:** src/core/wire_bead.rs (new), src/core/mod.rs, src/git/wire.rs (reference only)","design":"**Design**\n- Define core wire structs: WireBeadPatch, WireNoteV1, NotesPatch (Omitted vs AtLeast), NoteAppendV1, and TxnOpV1.\n- Define TxnOpKey and represent TxnDeltaV1 as a canonical map keyed by TxnOpKey to enforce unique ops and stable ordering for hashing and encoding.\n- Keep field names compatible with legacy wire to ease conversion, but keep types in core to avoid coupling realtime to git.\n- Provide conversions between domain types (Bead, Note, Tombstone, DepEdge) and wire structs when lossless.\n- Document notes rule: patches omit notes by default; if present they mean set union only (no truncation).","acceptance_criteria":"- [ ] serde roundtrip tests for new wire types.\n- [ ] TxnDeltaV1 rejects duplicate op keys and preserves canonical ordering.\n- [ ] Conversions to and from core domain types are covered for at least one bead and note case.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768197280720,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768197280720,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768197280720,0]}
{"id":"bd-3m5.40","created_at":[1768178867760,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 4: Graceful shutdown + observability metrics","description":"**Problem**\nDaemon must shut down gracefully without losing durable events. Operators need tracing and metrics.\n\n**Context**\n- REALTIME_PLAN.md §16.1 (graceful shutdown, observability requirements)\n\n**Design**\n- On SIGTERM: stop accepting mutations, drain in-flight durability waits (bounded), flush WAL, close segments, exit\n- Every mutation traceable via txn_id and client_request_id\n- Replication sessions log peer identity and namespace authorization\n- Emit counters: wal_append_ok/err, wal_fsync_ok/err, apply_ok/err, repl_events_in/out, checkpoint_export_ok/err\n- Emit gauges: IPC inflight, repl queue depth, per-peer lag\n- Emit histograms: wal_append_duration, wal_fsync_duration, apply_duration, checkpoint_duration\n\n**Acceptance**\n- [ ] SIGTERM triggers graceful drain and flush\n- [ ] Metrics emitted via tracing or metrics crate\n- [ ] Tests verify no event loss on shutdown\n- [ ] Tests verify metric emission\n\n**Files:** src/daemon/core.rs, src/daemon/metrics.rs (new), Cargo.toml (tracing/metrics)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768387640756,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768387640756,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768387640756,0]}
{"id":"bd-3m5.41","created_at":[1768178869098,0],"created_by":"darin@darinsmcstudio2.lan","title":"Cross-phase: Fuzz targets for WAL/CBOR/replication decode","description":"**Problem**\nPlan requires fuzz testing for decode paths to find edge cases.\n\n**Context**\n- REALTIME_PLAN.md §18 (fuzzing + crash safety)\n\n**Design**\n- cargo-fuzz targets:\n  - WAL frame decode (length/crc/tail truncation)\n  - CBOR EventBody decode with bounds (depth, map entries, array entries)\n  - Replication message decode (HELLO/WELCOME/EVENTS)\n- Use libfuzzer or afl via cargo-fuzz\n- CI runs fuzz for bounded time on each PR (optional)\n\n**Acceptance**\n- [ ] fuzz/fuzz_targets/wal_decode.rs exists\n- [ ] fuzz/fuzz_targets/event_body_decode.rs exists\n- [ ] fuzz/fuzz_targets/repl_message_decode.rs exists\n- [ ] cargo fuzz run <target> works\n\n**Files:** fuzz/fuzz_targets/wal_decode.rs (new), fuzz/fuzz_targets/event_body_decode.rs (new), fuzz/fuzz_targets/repl_message_decode.rs (new), Cargo.toml","priority":3,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768439486541,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768439486541,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768439486541,0]}
{"id":"bd-3m5.42","created_at":[1768178870748,0],"created_by":"darin@darinsmcstudio2.lan","title":"Cross-phase: Crash safety integration tests","description":"**Problem**\nPlan requires crash tests to verify recovery behavior after SIGKILL at various points.\n\n**Context**\n- REALTIME_PLAN.md §18 (crash tests)\n\n**Design**\n- Integration tests that:\n  - Inject SIGKILL during append (after write before fsync, after fsync before index commit, etc.)\n  - Assert recovery: no duplicate origin_seq, tail truncation correct, index rebuild correct\n- Use fork() or subprocess to inject crashes\n- Verify idempotency mapping survives\n\n**Acceptance**\n- [ ] Test kills daemon mid-append and verifies recovery\n- [ ] No duplicate origin_seq after crash\n- [ ] Tail truncation handles partial records\n- [ ] Index rebuild correct after crash\n\n**Files:** tests/crash_recovery.rs (new)","priority":3,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768437916950,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768437916950,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768437916950,0]}
{"id":"bd-3m5.43","created_at":[1768178909582,0],"created_by":"darin@darinsmcstudio2.lan","title":"Cross-phase: Normative defaults constants + enforcement","description":"**Problem**\nThe realtime plan hardcodes many safety limits (bytes, events, timeouts). Today these values are scattered or absent; different subsystems could silently diverge, which breaks the single canonical behavior the plan expects.\n\n**Context**\n- REALTIME_PLAN.md §0.19 (normative defaults + safety bounds) and §9.8 (flow control)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (Limits struct and defaults)\n\n**Files:** src/core/limits.rs (new), src/core/mod.rs, src/daemon/repl/*, src/daemon/wal/*, src/git/checkpoint/import.rs, src/daemon/ipc.rs","design":"**Design**\n- Define a single Limits struct in src/core/limits.rs with all normative defaults (frame sizes, WAL bounds, CBOR decode bounds, HLC drift, backpressure, checkpoint limits).\n- Introduce small unit newtypes (Bytes, Events, Millis) or clearly name fields to avoid unit confusion across modules.\n- Thread Limits through EventBody decode, WAL append, replication framing, gap buffers, and IPC inflight control.\n- Make all limit enforcement explicit at module boundaries; failures return ErrorPayload(code=\"limit_exceeded\") with details of which limit tripped.\n- Allow overrides via config, but enforce that defaults are the plan values when no config is provided.","acceptance_criteria":"- [ ] Limits struct covers every constant in REALTIME_PLAN.md §0.19.\n- [ ] Replication rejects oversize frames and batches at decode time.\n- [ ] EventBody decoder rejects depth/map/array/byte-length violations.\n- [ ] WAL append rejects records > MAX_WAL_RECORD_BYTES before write.\n- [ ] Tests verify representative limits are enforced and surfaced as errors.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","notes":[{"id":"go-comment-bd-3m5.43-1","content":"Implemented Limits struct + defaults, config plumbing, IPC frame limit, WAL record size guard, and note/label limits with tests. Remaining for later phases: EventBody CBOR decode limits and replication frame/batch enforcement once those modules land.","author":"darin@darinsmacstudio.lan","at":[1768189215964,0]},{"id":"legacy-notes","content":"Implemented Limits struct + defaults, config plumbing, IPC frame limit, WAL record size guard, and note/label limits with tests. Remaining for later phases: EventBody CBOR decode limits and replication frame/batch enforcement once those modules land.","author":"darin@darinsmcstudio2.lan","at":[1768282020116,0]}],"_at":[1768282020116,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768282020116,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768282020116,0]}
{"id":"bd-3m5.44","created_at":[1768178911548,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 2: Canonical JSON encoder for checkpoints","description":"**Problem**\nCheckpoint hashes require canonical JSON (sorted keys, no whitespace). serde_json doesn't guarantee key order.\n\n**Context**\n- REALTIME_PLAN.md §13.3 (canonical JSON normative)\n\n**Design**\n- Create src/core/json_canon.rs (or src/git/checkpoint/json_canon.rs)\n- API: fn to_canon_json_bytes<T: Serialize>(v: &T) -> Vec<u8>\n- Requirements:\n  - Keys sorted by UTF-8 byte order ascending, recursively\n  - No insignificant whitespace\n  - No NaN/Infinity floats (reject if encountered)\n  - Deterministic escaping\n- Used by checkpoint export and manifest/meta writers\n\n**Acceptance**\n- [ ] to_canon_json_bytes produces deterministic output\n- [ ] Keys sorted recursively\n- [ ] Tests verify byte-for-byte reproducibility\n- [ ] NaN/Infinity rejected\n\n**Files:** src/core/json_canon.rs (new), src/git/checkpoint/export.rs","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768200219626,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768200219626,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768200219626,0]}
{"id":"bd-3m5.45","created_at":[1768178913199,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5: PeerAckTable for durability coordination","description":"**Problem**\nReplicatedFsync(k) requires a truthful view of which peers have durably ACKed which watermarks and head hashes. A naive map risks mixing namespaces or ignoring head hash divergence.\n\n**Context**\n- REALTIME_PLAN.md §0.12 (applied vs durable + head sha), §10.1-10.3 (durability coordination), §9.5 (ACK semantics)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (Watermarks<Durable>, HeadStatus)\n\n**Files:** src/daemon/repl/peer_acks.rs (new), src/daemon/durability_coordinator.rs, src/daemon/store_runtime.rs","design":"**Design**\n- PeerAckTable tracks per peer: durable Watermarks<Durable>, optional durable_heads, and last_ack_at_ms.\n- Enforce monotonicity on update: seq may only advance; head sha must match the seq (reject divergence).\n- Provide queries: acked_by(ns, origin, seq) -> Vec<ReplicaId>, and satisfied_k(ns, origin, seq, k) -> bool.\n- Maintain per-namespace eligibility via roster (durability_eligible); only count eligible peers.\n- Surface divergence: if a peer reports the same seq but a different head sha, mark that peer as diverged and exclude from durability quorum.","acceptance_criteria":"- [ ] PeerAckTable stores per-peer durable/applied watermarks and heads with monotonic updates.\n- [ ] Divergent head sha at same seq is detected and excluded from eligibility.\n- [ ] satisfied_k computes k-of-n for eligible peers with explicit failure cases.\n- [ ] Unit tests cover monotonic updates and satisfied_k behavior.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768337034494,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768337034494,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768337034494,0]}
{"id":"bd-3m5.46","created_at":[1768178939206,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5: Replication session state machine","description":"**Problem**\nbd-3m5.17 is too large. Split: session state machine handles single connection lifecycle.\n\n**Context**\n- REALTIME_PLAN.md §9.3-9.4 (handshake, EVENTS processing)\n- Refines bd-3m5.17\n\n**Design**\n- Implement Session struct in src/daemon/repl/session.rs\n- States: Connecting, Handshaking, Streaming, Draining, Closed\n- HELLO/WELCOME handshake with capability negotiation\n- EVENTS processing: validate, buffer gaps, advance watermarks\n- Send ACK with watermarks and heads after apply\n- Error handling: divergence, overload, timeout\n\n**Acceptance**\n- [ ] Session state machine handles connection lifecycle\n- [ ] HELLO/WELCOME negotiates protocol version\n- [ ] EVENTS validated and buffered if gaps\n- [ ] ACK sent after successful apply\n\n**Files:** src/daemon/repl/session.rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768352524533,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768352524533,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768352524533,0]}
{"id":"bd-3m5.47","created_at":[1768178940965,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5: Replication manager + outbound peer lifecycle","description":"**Problem**\nbd-3m5.17 is too large. Split: manager handles outbound peers and reconnection.\n\n**Context**\n- REALTIME_PLAN.md §9.1 (manager.rs)\n- Refines bd-3m5.17\n\n**Design**\n- Implement ReplicationManager in src/daemon/repl/manager.rs\n- Manages outbound peer connections from config (replicas.toml)\n- Handles reconnect with exponential backoff\n- Event fanout to connected sessions\n- Namespace scoping based on policy (replicate=anchors/peers/none)\n\n**Acceptance**\n- [ ] Manager connects to configured peers\n- [ ] Reconnect with backoff on disconnect\n- [ ] Events fanned out to eligible sessions\n- [ ] Namespace policy respected\n\n**Files:** src/daemon/repl/manager.rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768356244491,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768356244491,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768356244491,0]}
{"id":"bd-3m5.48","created_at":[1768178942617,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5: Replication server + accept loop","description":"**Problem**\nbd-3m5.17 is too large. Split: server handles inbound connections.\n\n**Context**\n- REALTIME_PLAN.md §9.1 (server.rs)\n- Refines bd-3m5.17\n\n**Design**\n- Implement ReplicationServer in src/daemon/repl/server.rs\n- TCP listener on configured address\n- Accept loop spawns Session per connection\n- Enforces MAX_CONCURRENT_CONNECTIONS (from roster or config)\n- Unknown replica_id rejection if roster exists\n\n**Acceptance**\n- [ ] Server listens on configured address\n- [ ] Spawns session per accepted connection\n- [ ] Connection limit enforced\n- [ ] Unknown replica rejected if roster present\n\n**Files:** src/daemon/repl/server.rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768359108389,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768359108389,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768359108389,0]}
{"id":"bd-3m5.49","created_at":[1768178964803,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 6: Checkpoint export algorithm","description":"**Problem**\nbd-3m5.20 is too large. Split: export algorithm for sharded JSONL.\n\n**Context**\n- REALTIME_PLAN.md §13.8 (export algorithm)\n- Refines bd-3m5.20\n\n**Design**\n- Implement checkpoint export in src/git/checkpoint/export.rs\n- Materialize converged state for included namespaces\n- Incremental export: track dirty shards via ApplyOutcome, regenerate only dirty\n- Determinism: shard JSONL lines sorted by key\n- Write manifest.json and meta.json with hashes\n\n**Acceptance**\n- [ ] Export writes shard files in sorted order\n- [ ] Incremental: only dirty shards regenerated\n- [ ] manifest.json lists files with hashes\n- [ ] meta.json includes watermarks and content_hash\n\n**Files:** src/git/checkpoint/export.rs","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768374571803,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768374571803,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768374571803,0]}
{"id":"bd-3m5.5","created_at":[1768177760012,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 2: EventBody canonical CBOR + hashing","description":"**Problem**\nRealtime WAL and replication require a canonical EventBody representation whose bytes are the hash preimage. There is no EventBody type or canonical encoding path in core yet, so we cannot guarantee stable hashing or verify remote frames.\n\n**Context**\n- REALTIME_PLAN.md 0.6 (canonical CBOR + hash over EventBody bytes), 2.4 (EventBody fields), 9.4 (EVENTS frame)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (EventBytes, EventFrameV1, VerifiedEvent)\n\n**Files:** src/core/event.rs (new), src/core/mod.rs, Cargo.toml (minicbor), tests under src/core","design":"**Design**\n- Define EventBody, EventKindV1, and EventId in src/core/event.rs with StoreIdentity and NamespaceId baked in.\n- Add EventBytes<Canonical> and EventBytes<Opaque> wrappers to separate locally authored canonical bytes from opaque remote bytes.\n- Implement canonical CBOR encoder for EventBody using minicbor with definite lengths and sorted map keys for hashed types; reject floats and indefinite lengths.\n- Provide helpers: encode_event_body_canonical -> EventBytes<Canonical>, hash_event_body -> Sha256.\n- Add decode with strict bounds (depth, map entries, byte length) and return EventBytes<Opaque> + EventBody.","acceptance_criteria":"- [ ] Canonical encode produces stable bytes and hashes across runs (unit tests).\n- [ ] Decoder rejects indefinite length and out of bounds payloads.\n- [ ] EventBytes typestate is used in frame or WAL APIs to prevent hash preimage ambiguity.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768198447469,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768198447469,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768198447469,0]}
{"id":"bd-3m5.50","created_at":[1768178966154,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 6: Checkpoint local cache with atomic publish","description":"**Problem**\nbd-3m5.20 is too large. Split: local cache for fast startup.\n\n**Context**\n- REALTIME_PLAN.md §13.8 step 8 (cache publish)\n- Refines bd-3m5.20\n\n**Design**\n- Store verified copy under store_dir/checkpoint_cache/<group>/<checkpoint_id>/\n- Atomic publish: write to .tmp/, fsync, rename, update CURRENT\n- Keep last N checkpoints per group (default N=3), prune older\n- CURRENT file points to newest verified checkpoint_id\n\n**Acceptance**\n- [ ] Cache written atomically with tmp+rename\n- [ ] CURRENT updated after successful publish\n- [ ] Pruning keeps only N most recent\n- [ ] Startup reads from cache if available\n\n**Files:** src/git/checkpoint/cache.rs","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768377098659,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768377098659,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768377098659,0]}
{"id":"bd-3m5.51","created_at":[1768178967608,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 4: IPC namespace + durability + client_request_id fields","description":"**Problem**\nIPC currently has no namespace, durability class, or client_request_id fields, and defaults are implemented ad hoc in CLI/daemon. This makes retries and read-your-writes semantics ambiguous and invites mismatched defaults across entry points.\n\n**Context**\n- REALTIME_PLAN.md §0.14 (IPC evolution) and §16.1 (request fields and defaults)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (NamespaceId, DurabilityClass, Seq0/Seq1)\n\n**Files:** src/daemon/ipc.rs, src/api/mod.rs, src/cli/mod.rs, src/cli/commands/*, src/daemon/query.rs","design":"**Design**\n- Extend mutation request structs with optional fields: namespace, durability, client_request_id, actor_id, preserving backward compatibility.\n- Parse namespace into NamespaceId and client_request_id into ClientRequestId early, so validation happens before mutation planning.\n- Centralize defaulting rules in one place (e.g., Request::normalize): namespace defaults to core, durability defaults to LocalFsync, actor_id defaults to daemon actor.\n- Add read/query gating fields require_min_seen and wait_timeout_ms; require_min_seen uses applied watermarks and returns retryable timeout error on miss.\n- Ensure IPC JSON schema stays stable: new fields are optional and omitted in serialization when None.","acceptance_criteria":"- [ ] Mutation request structs add optional namespace/durability/client_request_id/actor_id with backward-compatible defaults.\n- [ ] Read/query request structs add optional require_min_seen + wait_timeout_ms with consistent defaulting.\n- [ ] CLI flags --namespace, --durability, --client-request-id map to IPC fields.\n- [ ] Defaulting (namespace=core, durability=LocalFsync, actor_id=daemon default) is applied consistently.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768266096090,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768266096090,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768266096090,0]}
{"id":"bd-3m5.52","created_at":[1768178989361,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 1: DurabilityReceipt response types","description":"**Problem**\nReceipts are the durable contract for retries and read-your-writes. Today there is no shared receipt type, so IPC responses risk being inconsistent and partial, and errors cannot safely return a receipt for retry.\n\n**Context**\n- REALTIME_PLAN.md §0.11 (idempotency mapping + receipts), §10.5 (receipt semantics), §16.1 (IPC response shape)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (DurabilityProofV1, DurabilityOutcome)\n\n**Files:** src/core/durability.rs, src/api/mod.rs\n\n**Design**\n- Define DurabilityProofV1 to capture the local fsync proof and optional replication acks.\n- Define DurabilityOutcome (Achieved vs Pending) to avoid ambiguous Option<DurabilityClass> fields.\n- Define DurabilityReceipt { store: StoreIdentity, txn_id, event_ids, durability_proof, outcome, min_seen } with serde support.\n- Keep types serde-friendly for IPC JSON; daemon/IPC wiring lives in bd-3m5.14.","design":"**Design**\n- Define DurabilityProofV1 to capture the local fsync proof and optional replication acks.\n- Define DurabilityOutcome (Achieved vs Pending) to avoid ambiguous Option<DurabilityClass> fields.\n- Define DurabilityReceipt { store: StoreIdentity, txn_id, event_ids, durability_proof, outcome, min_seen } with serde support.\n- Ensure idempotent retry returns the same txn_id/event_ids, with monotonic improvement of durability_proof if new ACKs are observed.\n- IPC success returns receipt; timeout returns retryable error with receipt included.","acceptance_criteria":"- [ ] DurabilityProofV1 and DurabilityOutcome types match REALTIME_PLAN.md semantics (local fsync + optional peer acks; pending vs achieved).\n- [ ] DurabilityReceipt includes store identity, txn_id, event_ids, durability_proof, outcome, and min_seen.\n- [ ] Serde JSON roundtrip tests cover DurabilityReceipt and DurabilityProofV1.\n- [ ] No daemon/IPC behavior changes in this bead (core types only).","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768195999463,0],"_by":"darin@darinsmcstudio2.lan","_v":{"workflow":[[1768195664088,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1768195664088,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768195999463,0]}
{"id":"bd-3m5.53","created_at":[1768180715526,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 1 test infrastructure: identity + store fixtures","description":"**Problem**\nPhase 1 implementation needs test infrastructure before tests can be written.\n\n**Context**\n- REALTIME_PLAN.md §18 (testing requirements)\n- Blocks Phase 1 testing bead\n\n**Design**\nCreate reusable test infrastructure:\n- Test fixtures for StoreId, ReplicaId, NamespaceId (valid/invalid cases)\n- Temp store directory setup/teardown helpers (creates $BD_DATA_DIR structure)\n- Lock file test utilities (create, verify, force-release)\n- StoreMeta test factories with deterministic UUIDs\n\n**Acceptance**\n- [ ] tests/fixtures/identity.rs with ID generators\n- [ ] tests/fixtures/store_dir.rs with TempStoreDir helper\n- [ ] tests/fixtures/mod.rs re-exports\n- [ ] cargo test fixtures:: passes\n\n**Files:** tests/fixtures/identity.rs (new), tests/fixtures/store_dir.rs (new), tests/fixtures/mod.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768184146966,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768184146966,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768184146966,0]}
{"id":"bd-3m5.54","created_at":[1768180726141,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 1 tests: identity persistence + lock enforcement","description":"**Problem**\nPhase 1 implementation must be verified before Phase 2 starts.\n\n**Context**\n- REALTIME_PLAN.md §18: store discovery order, identity persistence, store-global lock enforcement\n- Depends on: Phase 1 implementation beads + Phase 1 test infrastructure\n\n**Design**\nDeterministic tests for:\n- Store discovery order: multiple repo paths → same StoreId\n- Identity persistence: create store, close, reopen → same StoreId/ReplicaId\n- Store-global lock enforcement: two processes → second gets error\n- Namespace validation: valid/invalid NamespaceId patterns\n- StoreMeta round-trip: write → read → compare\n\n**Acceptance**\n- [ ] tests/phase1_identity.rs exists\n- [ ] Test: store identity survives daemon restart\n- [ ] Test: lock prevents concurrent access with clear error\n- [ ] Test: namespace regex validation (a-z, 0-9, underscore, length)\n- [ ] cargo test phase1_identity passes\n\n**Files:** tests/phase1_identity.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768184440925,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768184440925,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-3m5.55","created_at":[1768180744574,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 2 test infrastructure: CBOR fixtures + apply harness","description":"**Problem**\nPhase 2 tests need canonical CBOR fixtures and apply test harness.\n\n**Context**\n- REALTIME_PLAN.md §18: canonical hashing stability, apply idempotence\n- Blocks Phase 2 testing bead\n\n**Design**\nCreate test infrastructure:\n- Golden CBOR fixtures: known EventBody → known sha256 (cross-platform stable)\n- EventBody test factories with deterministic stamps/IDs\n- Apply test harness: CanonicalState setup + apply + verify helpers\n- Fingerprint comparison utilities\n\n**Acceptance**\n- [ ] tests/fixtures/cbor.rs with golden CBOR bytes + expected hashes\n- [ ] tests/fixtures/event_body.rs with EventBody builders\n- [ ] tests/fixtures/apply_harness.rs with apply + verify helpers\n- [ ] Golden fixtures verified manually on multiple platforms (macOS, Linux)\n\n**Files:** tests/fixtures/cbor.rs (new), tests/fixtures/event_body.rs (new), tests/fixtures/apply_harness.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768200838458,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768200838458,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768200838458,0]}
{"id":"bd-3m5.56","created_at":[1768180747361,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 2 tests: canonical hashing + apply idempotence","description":"**Problem**\nPhase 2 implementation must be verified before Phase 3 starts.\n\n**Context**\n- REALTIME_PLAN.md §18: CBOR hashing stability, apply idempotence, note collision detection, LWW merge ordering\n- Depends on: Phase 2 implementation + Phase 2 test infrastructure\n\n**Design**\nDeterministic tests for:\n- Canonical CBOR EventBody hashing stability (bytes identical across runs)\n- Apply idempotence: apply same event twice → no change\n- Note collision detection: same note_id, different content → error\n- Decoder bounds: reject indefinite length or out-of-bounds payloads\n- LWW merge ordering: concurrent updates resolve deterministically\n\n**Acceptance**\n- [ ] tests/phase2_cbor.rs: hashing stability tests\n- [ ] tests/phase2_apply.rs: apply idempotence tests\n- [ ] Test: note_id collision with different content fails\n- [ ] Test: LWW merge ordering is deterministic for concurrent updates\n- [ ] cargo test phase2_ passes\n\n**Files:** tests/phase2_cbor.rs (new), tests/phase2_apply.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768201106279,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768201106279,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768201106279,0]}
{"id":"bd-3m5.57","created_at":[1768180763865,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3 test infrastructure: WAL fixtures + segment helpers","description":"**Problem**\nPhase 3 tests need WAL segment fixtures and SQLite test helpers.\n\n**Context**\n- REALTIME_PLAN.md §18: WAL framing, tail truncation, index rebuild\n- Blocks Phase 3 testing bead\n\n**Design**\nCreate test infrastructure:\n- Temp WAL directory helpers (namespace subdirs, segment files)\n- Segment file fixtures: valid, corrupted (bad crc), partial (truncated mid-record)\n- SQLite test database setup/teardown\n- WAL record builders with known bytes\n- Crash simulation helpers (write partial record, kill before fsync)\n\n**Acceptance**\n- [ ] tests/fixtures/wal.rs with TempWalDir, segment file generators\n- [ ] tests/fixtures/wal_corrupt.rs with corruption injection helpers\n- [ ] Fixtures include: valid segment, bad-crc segment, truncated segment\n- [ ] cargo test fixtures::wal passes\n\n**Files:** tests/fixtures/wal.rs (new), tests/fixtures/wal_corrupt.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768246638048,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768246638048,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768246638048,0]}
{"id":"bd-3m5.58","created_at":[1768180765428,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3 tests: WAL framing + index rebuild + origin_seq","description":"**Problem**\nPhase 3 implementation must be verified before Phase 4 starts.\n\n**Context**\n- REALTIME_PLAN.md §18: WAL framing/truncation, index rebuild, origin_seq allocation\n- Depends on: Phase 3 implementation + Phase 3 test infrastructure\n\n**Design**\nDeterministic tests for:\n- WAL framing: write records, read back, verify crc32c\n- Tail truncation: partial record at EOF → truncate and recover\n- WAL index rebuild: delete wal.sqlite, rebuild from segments, verify offsets\n- Incremental catch-up: last_indexed_offset -> scan to EOF and index\n- origin_seq allocation: append → seq increments monotonically, no gaps\n\n**Acceptance**\n- [ ] tests/phase3_wal.rs: framing + truncation tests\n- [ ] tests/phase3_index.rs: index rebuild + catch-up tests\n- [ ] tests/phase3_seq.rs: origin_seq allocation tests\n- [ ] cargo test phase3_ passes\n\n**Files:** tests/phase3_wal.rs (new), tests/phase3_index.rs (new), tests/phase3_seq.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768247269893,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768247269893,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768247269893,0]}
{"id":"bd-3m5.59","created_at":[1768180781069,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 4 test infrastructure: mutation request factories","description":"**Problem**\nPhase 4 tests need mutation request factories and receipt comparison helpers.\n\n**Context**\n- REALTIME_PLAN.md §18: idempotency mapping/receipts\n- Blocks Phase 4 testing bead\n\n**Design**\nCreate test infrastructure:\n- Mutation request builders (bead_upsert, dep_add, note_append)\n- Request canonicalization helpers for request_sha256\n- DurabilityReceipt comparison utilities\n- Idempotency test harness: send request, get receipt, retry, verify same receipt\n\n**Acceptance**\n- [ ] tests/fixtures/mutation.rs with request builders\n- [ ] tests/fixtures/receipt.rs with receipt comparison helpers\n- [ ] Builders support all TxnDeltaV1 operation types\n- [ ] cargo test fixtures::mutation passes\n\n**Files:** tests/fixtures/mutation.rs (new), tests/fixtures/receipt.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768402736558,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768402736558,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768402736558,0]}
{"id":"bd-3m5.6","created_at":[1768177773057,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 2: core apply_event for EventBody","description":"**Problem**\nThe daemon mutates CanonicalState directly, so apply semantics are scattered and can diverge across mutation and replication paths. We need a single pure apply_event path that deterministically maps EventBody deltas to CRDT joins.\n\n**Context**\n- REALTIME_PLAN.md 0.8 (deterministic apply), 2.4 (TxnDeltaV1), 8.3 (apply pipeline)\n- Stateright model: beads_stateright_models/src/realtime_types_sketch.rs (TxnOpV1, TxnDeltaV1)\n\n**Files:** src/core/apply.rs (new), src/core/state.rs, src/core/bead.rs, src/core/dep.rs, src/core/tombstone.rs","design":"**Design**\n- Add core::apply_event(&mut CanonicalState, &EventBody) -> ApplyOutcome as a pure function with no I/O.\n- Apply TxnDeltaV1 ops in canonical op key order so repeated application is deterministic.\n- Use existing CRDT joins (Lww, Tombstone::join, DepEdge::join) and preserve tombstone resurrection rules.\n- Detect note id collisions with mismatched content as corruption (return error), and treat duplicate note append as idempotent.\n- Return ApplyOutcome with changed bead ids, dep keys, and note ids to drive indexing and checkpoint dirtiness.","acceptance_criteria":"- [ ] apply_event is deterministic and idempotent on repeated events (tests).\n- [ ] Note id collision with different content is detected and surfaced.\n- [ ] ApplyOutcome reports changes used by indexing and checkpoint scheduling.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768199741562,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768199741562,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768199741562,0]}
{"id":"bd-3m5.60","created_at":[1768180782214,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 4 tests: idempotency mapping + receipts","description":"**Problem**\nPhase 4 implementation must be verified before Phase 5 starts.\n\n**Context**\n- REALTIME_PLAN.md §18: origin_seq allocation, idempotency mapping/receipts\n- Depends on: Phase 4 implementation + Phase 4 test infrastructure\n\n**Design**\nDeterministic tests for:\n- Idempotency: same client_request_id → same txn_id + event_ids on retry\n- Request hash mismatch: same client_request_id, different request → ERROR\n- Receipt min_seen: advances monotonically with watermarks\n- Receipt after restart: txn_id/event_ids preserved, durability_proof may differ\n- No duplicate origin_seq: crash + restart → next seq is max+1\n\n**Acceptance**\n- [ ] tests/phase4_idempotency.rs: idempotency mapping tests\n- [ ] tests/phase4_receipts.rs: receipt semantics tests\n- [ ] Test: request_sha256 mismatch returns error code\n- [ ] Test: receipt survives daemon restart\n- [ ] cargo test phase4_ passes\n\n**Files:** tests/phase4_idempotency.rs (new), tests/phase4_receipts.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768404782046,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768404782046,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768404782046,0]}
{"id":"bd-3m5.61","created_at":[1768180799946,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5 test infrastructure: mock peer + network simulator","description":"**Problem**\nPhase 5 tests need a mock replication peer and network simulation.\n\n**Context**\n- REALTIME_PLAN.md §18: replication ACK/WANT behavior, backpressure\n- Blocks Phase 5 testing bead\n\n**Design**\nCreate test infrastructure:\n- Mock replication peer: accepts connections, sends/receives frames\n- Channel-based transport for in-process testing (no real TCP)\n- Network simulator: inject delays, drops, reordering\n- Frame builders for HELLO, WELCOME, EVENTS, ACK, WANT, PING, PONG\n- Backpressure trigger helpers (fill ingest queue to limit)\n\n**Acceptance**\n- [ ] tests/fixtures/repl_peer.rs with MockPeer\n- [ ] tests/fixtures/repl_transport.rs with ChannelTransport\n- [ ] tests/fixtures/repl_frames.rs with frame builders\n- [ ] MockPeer can complete handshake and exchange events\n- [ ] cargo test fixtures::repl passes\n\n**Files:** tests/fixtures/repl_peer.rs (new), tests/fixtures/repl_transport.rs (new), tests/fixtures/repl_frames.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768403912266,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768403912266,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768403912266,0]}
{"id":"bd-3m5.62","created_at":[1768180801903,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 5 tests: replication ACK/WANT + backpressure","description":"**Problem**\nPhase 5 implementation must be verified before Phase 6 starts.\n\n**Context**\n- REALTIME_PLAN.md §18: replication ACK/WANT behavior, backpressure\n- Depends on: Phase 5 implementation + Phase 5 test infrastructure\n\n**Design**\nDeterministic tests for:\n- ACK semantics: peer receives events, sends ACK, watermarks advance\n- WANT semantics: peer sends WANT, server responds with events from WAL\n- Gap handling: missing events → WANT for gap range\n- Backpressure: ingest queue full → stop reads or ERROR(overloaded)\n- Equivocation detection: same (origin, seq), different sha → error\n- prev_sha256 continuity: mismatched prev_sha → reject\n\n**Acceptance**\n- [ ] tests/phase5_repl_ack.rs: ACK/WANT tests\n- [ ] tests/phase5_repl_backpressure.rs: backpressure tests\n- [ ] Test: gap triggers WANT for missing range\n- [ ] Test: queue overflow triggers backpressure\n- [ ] cargo test phase5_ passes\n\n**Files:** tests/phase5_repl_ack.rs (new), tests/phase5_repl_backpressure.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768405890051,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768405890051,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768405890051,0]}
{"id":"bd-3m5.63","created_at":[1768180816641,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 6 test infrastructure: checkpoint fixtures + diff utils","description":"**Problem**\nPhase 6 tests need golden checkpoint fixtures and verification utilities.\n\n**Context**\n- REALTIME_PLAN.md §18: checkpoint export/import determinism, manifest hashes\n- Blocks Phase 6 testing bead\n\n**Design**\nCreate test infrastructure:\n- Golden checkpoint fixtures: known StoreState → known manifest.json + meta.json\n- Checkpoint diff utilities: compare two checkpoints, report differences\n- Sharded layout generators (beads/00..ff, deps/00..ff, tombstones/00..ff)\n- Hash verification helpers for content files and manifest\n\n**Acceptance**\n- [ ] tests/fixtures/checkpoint.rs with golden fixtures\n- [ ] tests/fixtures/checkpoint_diff.rs with diff utilities\n- [ ] Golden fixtures include: small state, multi-namespace, tombstones\n- [ ] cargo test fixtures::checkpoint passes\n\n**Files:** tests/fixtures/checkpoint.rs (new), tests/fixtures/checkpoint_diff.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768406802615,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768406802615,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768406802615,0]}
{"id":"bd-3m5.64","created_at":[1768180818293,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 6 tests: checkpoint export/import determinism","description":"**Problem**\nPhase 6 implementation must be verified before Phase 7 starts.\n\n**Context**\n- REALTIME_PLAN.md §18: checkpoint export/import determinism, manifest and content hashes\n- Depends on: Phase 6 implementation + Phase 6 test infrastructure\n\n**Design**\nDeterministic tests for:\n- Export determinism: same StoreState → same manifest.json bytes\n- Content hash verification: sha256 in manifest matches file content\n- Import verification: import checkpoint → StoreState matches original\n- Round-trip: export → import → export → manifests match\n- Multi-namespace: checkpoint includes all namespaces correctly\n- included watermarks: meta.json.included matches actual content\n\n**Acceptance**\n- [ ] tests/phase6_checkpoint.rs: export/import tests\n- [ ] Test: export is deterministic (same state → same bytes)\n- [ ] Test: import verifies content hashes\n- [ ] Test: round-trip preserves all state\n- [ ] cargo test phase6_ passes\n\n**Files:** tests/phase6_checkpoint.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768407623577,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768407623577,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768407623577,0]}
{"id":"bd-3m5.65","created_at":[1768180832727,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 7 test infrastructure: IPC streaming client + load generator","description":"**Problem**\nPhase 7 tests need IPC streaming test client and load generation.\n\n**Context**\n- REALTIME_PLAN.md §18: admin.status correctness under load\n- Blocks Phase 7 testing bead\n\n**Design**\nCreate test infrastructure:\n- IPC streaming test client: subscribe, receive events, verify ordering\n- Load generator: concurrent mutations at configurable rate\n- admin.status snapshot collector: capture watermarks/segment stats over time\n- Consistency checker: verify watermarks are monotonic under load\n\n**Acceptance**\n- [ ] tests/fixtures/ipc_stream.rs with StreamingClient\n- [ ] tests/fixtures/load_gen.rs with LoadGenerator\n- [ ] tests/fixtures/admin_status.rs with StatusCollector\n- [ ] cargo test fixtures::ipc_stream passes\n\n**Files:** tests/fixtures/ipc_stream.rs (new), tests/fixtures/load_gen.rs (new), tests/fixtures/admin_status.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768408384058,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768408384058,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768408384058,0]}
{"id":"bd-3m5.66","created_at":[1768180834183,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 7 tests: streaming + admin.status under load","description":"**Problem**\nPhase 7 implementation must be verified to complete the realtime v0.5 epic.\n\n**Context**\n- REALTIME_PLAN.md §18: admin.status correctness under load\n- Depends on: Phase 7 implementation + Phase 7 test infrastructure\n\n**Design**\nDeterministic tests for:\n- Subscribe streaming: events arrive in order, no gaps\n- require_min_seen: subscription blocks until watermark condition met\n- admin.status consistency: watermarks + segment stats are coherent under load\n- admin.status monotonicity: watermarks never regress\n- Concurrent subscriptions: multiple clients receive same events\n\n**Acceptance**\n- [ ] tests/phase7_subscribe.rs: streaming subscription tests\n- [ ] tests/phase7_admin_status.rs: admin.status under load tests\n- [ ] Test: watermarks are monotonic during concurrent mutations\n- [ ] Test: segment stats match actual WAL files\n- [ ] cargo test phase7_ passes\n\n**Files:** tests/phase7_subscribe.rs (new), tests/phase7_admin_status.rs (new)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768410931843,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768410931843,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768410931843,0]}
{"id":"bd-3m5.67","created_at":[1768271719727,0],"created_by":"darin@darinsmcstudio2.lan","title":"IPC: split malformed_payload vs invalid_request for JSON decode","description":"**Problem**\nIPC JSON decode errors currently map to legacy parse_error, and semantic request validation failures get mislabeled as parse_error because decode_request_with_limits deserializes directly into Request. REALTIME_PLAN.md/REALTIME_ERRORS.md require malformed_payload for invalid JSON and invalid_request for valid JSON with semantic issues.\n\n**Where**\n- src/daemon/ipc.rs: decode_request_with_limits, From<IpcError> for ErrorPayload\n\n**Design**\n- Separate JSON parsing from Request validation (e.g., parse to serde_json::Value first), then validate/deserialize with explicit error mapping.\n- Map malformed JSON to code malformed_payload with details {parser:\"json\"...}, and semantic validation to invalid_request.\n- Ensure payload shape uses realtime fields {code,message,retryable,retry_after_ms?,details?,receipt?}.\n\n**Acceptance**\n- Invalid JSON yields malformed_payload (not parse_error).\n- Semantically invalid JSON yields invalid_request.\n- IPC error payloads remain realtime-shaped and include details where applicable.\n\n**Files**\n- src/daemon/ipc.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768338835347,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768338835347,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768338835347,0]}
{"id":"bd-3m5.68","created_at":[1768271728087,0],"created_by":"darin@darinsmcstudio2.lan","title":"Idempotency: detect client_request_id reuse mismatch","description":"**Problem**\nThe realtime code client_request_id_reuse_mismatch exists but cannot be emitted. WAL index upsert overwrites existing (namespace, origin_replica_id, client_request_id) rows, hiding mismatched reuse and mutating history.\n\n**Where**\n- src/core/error.rs: ErrorCode::ClientRequestIdReuseMismatch (defined)\n- src/daemon/ops.rs: OpError lacks a variant\n- src/daemon/wal/index.rs: upsert_client_request uses ON CONFLICT DO UPDATE\n\n**Design**\n- Add OpError variant and IPC mapping for client_request_id_reuse_mismatch with details {namespace, client_request_id, expected_request_sha256, got_request_sha256}.\n- Change index behavior to preserve first-seen mapping; detect mismatch and return explicit error instead of overwriting.\n- Keep idempotent reuse path returning original txn/event ids (no mutation) when request_sha matches.\n\n**Acceptance**\n- Reusing client_request_id with different request_sha256 returns client_request_id_reuse_mismatch (retryable=false).\n- WAL index no longer overwrites request_sha256/txn_id/event_ids on conflict.\n- Matching reuse returns prior ids without mutating history.\n\n**Files**\n- src/daemon/ops.rs\n- src/daemon/wal/index.rs\n- src/core/error.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768338304258,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768338304258,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768338304258,0]}
{"id":"bd-3m5.69","created_at":[1768271736943,0],"created_by":"darin@darinsmcstudio2.lan","title":"Idempotent retries reuse WAL index mapping","description":"**Problem**\nMutation planning generates a fresh txn_id per retry via the current write stamp. There is no visible fast-path to reuse existing txn/event ids for repeated client_request_id, which breaks idempotent retry semantics in REALTIME_PLAN.md.\n\n**Where**\n- src/daemon/mutation_engine.rs: MutationEngine::plan uses txn_id_for_stamp(&store, &write_stamp)\n- src/daemon/wal/index.rs: WalIndexReader::lookup_client_request exists but is not used in planning path\n\n**Design**\n- Before planning a mutation, lookup client_request_id in the WAL index.\n- If found with matching request_sha256, return a plan that reuses the stored txn_id/event_ids and short-circuits event creation.\n- If not found, proceed with normal planning and insert mapping.\n\n**Acceptance**\n- Retrying the same request returns the same txn/event ids (idempotent).\n- No duplicate txn rows for repeated client_request_id.\n- Coverage in Phase 4 idempotency tests (bd-3m5.60) updated.\n\n**Files**\n- src/daemon/mutation_engine.rs\n- src/daemon/wal/index.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768348878056,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768348878056,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768348878056,0]}
{"id":"bd-3m5.7","created_at":[1768177786604,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3: Store dir layout + store lock","description":"**Problem**\nPhase 3: implement store directory layout and a store global lock. Current paths only expose a base data dir and WAL uses per remote snapshot filenames. Realtime needs `$BD_DATA_DIR/stores/<store_id>/` with a lock file and secure permissions.\n\n**Context**\n- REALTIME_PLAN.md §0.2 (process level locking), §15.1 (store layout), §7.3 (startup flow steps 2-4)\n**Files:** src/paths.rs, src/daemon/store_lock.rs (new), src/daemon/store_runtime.rs (new) or src/daemon/core.rs","design":"**Design**\n- Add path helpers in `src/paths.rs`: stores_dir, store_dir(store_id), store_meta_path, wal_dir, index_path, checkpoint_cache_dir.\n- Implement a store lock file in the store dir with metadata: store_id, replica_id, pid, started_at_ms, daemon_version, last_heartbeat_ms.\n- Acquire lock at store open; on failure show metadata and fail fast. No auto delete.\n- Enforce file permissions (0700 for dirs, 0600 for sensitive files) and reject symlinks for critical paths.\n- Expose a helper API for lock acquire and release (called by StoreRuntime open).","acceptance_criteria":"- [ ] Store directory helpers return expected paths under BD_DATA_DIR.\n- [ ] Lock file is created with required metadata and permissions; failure surfaces metadata.\n- [ ] Store open fails if lock held.\n- [ ] `cargo check` passes.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768202500376,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768202500376,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768202500376,0]}
{"id":"bd-3m5.70","created_at":[1768271745099,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL replay: map wal_format_unsupported and header decode vs mismatch","description":"**Problem**\nReplay maps all SegmentHeader errors to segment_header_mismatch, including unsupported wal_format_version and header decode failures. REALTIME_ERRORS.md distinguishes wal_format_unsupported from semantic header mismatch and from corruption.\n\n**Where**\n- src/daemon/wal/segment.rs: SegmentHeader::decode reports unsupported wal format version\n- src/daemon/ops.rs: wal_replay_error_code maps SegmentHeader to segment_header_mismatch\n- src/daemon/ipc.rs: mirrored mapping\n\n**Design**\n- Add a specific error variant (or reason parsing) to detect wal_format_version mismatch and map to wal_format_unsupported with details {wal_format_version, supported}.\n- Split decode failures (bad magic/CRC/truncated header) from semantic mismatch and map to wal_corrupt (or specific corruption code) instead of segment_header_mismatch.\n\n**Acceptance**\n- Unsupported wal_format_version yields wal_format_unsupported.\n- Header decode failures yield corruption code, not segment_header_mismatch.\n- True store_id/store_epoch mismatch continues to use segment_header_mismatch.\n\n**Files**\n- src/daemon/wal/segment.rs\n- src/daemon/ops.rs\n- src/daemon/ipc.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768278581850,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768278581850,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768278581850,0]}
{"id":"bd-3m5.71","created_at":[1768271751492,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL replay: verify payload sha256 (hash_mismatch)","description":"**Problem**\nReplay does not verify sha256(payload_bytes) vs the record header, so hash_mismatch is effectively unreachable. CRC alone does not catch a writer that stored an incorrect sha.\n\n**Where**\n- src/daemon/wal/replay.rs: scan_segment decodes record payload but does not hash raw bytes\n- src/daemon/wal/record.rs: RecordHeaderMismatch lacks a sha mismatch variant\n\n**Design**\n- Preserve raw payload bytes and compare sha256(payload_bytes) to record.header.event_sha256.\n- Introduce a RecordHeaderMismatch variant (or WalReplayError) for hash mismatch and map to ErrorCode::HashMismatch with details.\n\n**Acceptance**\n- Replay detects sha mismatch and emits hash_mismatch with details.\n- CRC-only mismatches continue to map to wal_corrupt.\n\n**Files**\n- src/daemon/wal/replay.rs\n- src/daemon/wal/record.rs\n- src/daemon/ops.rs\n- src/daemon/ipc.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768277880988,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768277880988,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768277880988,0]}
{"id":"bd-3m5.72","created_at":[1768271759318,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL index: detect equivocation on EventId reuse","description":"**Problem**\nInserting an event with the same (namespace, origin_replica_id, origin_seq) but different sha triggers a SQLite constraint error and is mapped to index_corrupt, leaving equivocation unreachable.\n\n**Where**\n- src/daemon/wal/index.rs: SqliteWalIndexTxn::record_event inserts into events with PK on (namespace, origin_replica_id, origin_seq)\n- src/daemon/ops.rs: wal_index_error_code maps WalIndexError::Sqlite(_) to index_corrupt\n\n**Design**\n- On conflict, detect existing row and compare sha256; if different, emit equivocation with details (namespace, origin_replica_id, origin_seq, expected_sha256, got_sha256).\n- Avoid using generic SQLite error for equivocation.\n\n**Acceptance**\n- Equivocation is reported via ErrorCode::Equivocation, not index_corrupt.\n- Normal duplicate insert with same sha remains idempotent (no error).\n\n**Files**\n- src/daemon/wal/index.rs\n- src/daemon/ops.rs\n- src/daemon/ipc.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768279233651,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768279233651,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768279233651,0]}
{"id":"bd-3m5.73","created_at":[1768271765319,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL replay: surface wal_tail_truncated repairs","description":"**Problem**\nReplay silently truncates a corrupted tail and drops ReplayStats; operators never see wal_tail_truncated even though the registry expects it.\n\n**Where**\n- src/daemon/wal/replay.rs: scan_segment sets truncated=true and truncates tail\n- src/daemon/store_runtime.rs: open(...) discards ReplayStats\n\n**Design**\n- Emit wal_tail_truncated (retryable=true) when tail repair occurs, with details {namespace, segment, offset}.\n- Surface ReplayStats to callers (StoreRuntime::open) so IPC can report the repair.\n\n**Acceptance**\n- Tail truncation emits a realtime error payload with details.\n- StoreRuntime open path exposes replay stats for operator visibility.\n\n**Files**\n- src/daemon/wal/replay.rs\n- src/daemon/store_runtime.rs\n- src/daemon/ipc.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768383920715,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768383920715,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768383920715,0]}
{"id":"bd-3m5.74","created_at":[1768271772073,0],"created_by":"darin@darinsmcstudio2.lan","title":"IPC error payloads: include details for WAL/index + lock permission_denied","description":"**Problem**\nstore_runtime_error_payload drops details for WAL index/replay errors, and lock permission_denied omits path/operation details. REALTIME_ERRORS.md expects structured details for machine handling.\n\n**Where**\n- src/daemon/ipc.rs: store_runtime_error_payload (WalIndex/WalReplay)\n- src/daemon/ipc.rs: store_lock_error_payload (PermissionDenied without details)\n\n**Design**\n- Extend error payload mapping to include details for WAL index/replay errors (e.g., store_epoch_mismatch, prev_sha_mismatch, index_corrupt).\n- Include permission_denied details for lock IO ({path, operation}).\n\n**Acceptance**\n- WAL/index error payloads include structured details per registry.\n- Permission denied on lock IO includes path and operation.\n\n**Files**\n- src/daemon/ipc.rs\n- src/daemon/ops.rs\n- src/core/error.rs (if new details types needed)","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768350357483,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768350357483,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768350357483,0]}
{"id":"bd-3m5.75","created_at":[1768271778268,0],"created_by":"darin@darinsmcstudio2.lan","title":"Retryable flags: align lock_held and index_* with registry","description":"**Problem**\nretryable flags do not match REALTIME_ERRORS.md: lock_held is marked retryable but should be false; index_corrupt and index_rebuild_required are treated as permanent but should be retryable after rebuild.\n\n**Where**\n- src/daemon/ops.rs: store_runtime_transience (lock_held)\n- src/daemon/ops.rs: wal_index_transience (index_corrupt/index_rebuild_required)\n\n**Design**\n- Update transience mapping to reflect registry retryable semantics.\n- Ensure IPC ErrorPayload.retryable mirrors updated transience values.\n\n**Acceptance**\n- lock_held -> retryable=false\n- index_corrupt/index_rebuild_required -> retryable=true\n\n**Files**\n- src/daemon/ops.rs\n- src/daemon/ipc.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768349116293,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768349116293,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768349116293,0]}
{"id":"bd-3m5.76","created_at":[1768271787357,0],"created_by":"darin@darinsmcstudio2.lan","title":"Admission/backpressure: emit overloaded/rate_limited/maintenance_mode","description":"**Problem**\nREALTIME_ERRORS.md defines overloaded, rate_limited, and maintenance_mode, but OpError has no variants and IPC cannot emit these codes. Limits exist but no visible error signaling.\n\n**Where**\n- src/core/error.rs: ErrorCode::{Overloaded,RateLimited,MaintenanceMode}\n- src/daemon/ops.rs: OpError missing variants\n- src/core/limits.rs: admission/backpressure limits\n\n**Design**\n- Add OpError variants and IPC mappings for overloaded/rate_limited/maintenance_mode with retry_after_ms when available.\n- Hook AdmissionController/maintenance mode checks to return these errors on request admission.\n\n**Acceptance**\n- Overload and maintenance mode conditions emit the corresponding realtime error codes.\n- retry_after_ms is set when known.\n\n**Files**\n- src/daemon/ops.rs\n- src/daemon/ipc.rs\n- src/daemon/* admission path (as implemented in bd-3m5.29)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768401598789,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768401598789,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768401598789,0]}
{"id":"bd-3m5.77","created_at":[1768271794890,0],"created_by":"darin@darinsmcstudio2.lan","title":"Namespace policy errors: emit namespace_policy_violation/cross_namespace_dependency","description":"**Problem**\nErrorCode::{NamespacePolicyViolation,CrossNamespaceDependency} exist but have no OpError variants or IPC emission path, so namespace policy enforcement cannot surface structured errors.\n\n**Where**\n- src/core/error.rs: ErrorCode definitions\n- src/daemon/ops.rs: OpError missing variants\n\n**Design**\n- Add OpError variants and IPC mappings with structured details per registry.\n- Emit these codes from policy enforcement in replication/IPC admission once policies are loaded.\n\n**Acceptance**\n- Policy violations produce namespace_policy_violation or cross_namespace_dependency with details.\n\n**Files**\n- src/daemon/ops.rs\n- src/daemon/ipc.rs\n- src/daemon/* policy enforcement paths (post bd-3m5.17, bd-3m5.35)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768401054650,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768401054650,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768401054650,0]}
{"id":"bd-3m5.78","created_at":[1768271803077,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replication ingress: map DecodeError to realtime codes","description":"**Problem**\nDecodeError is rich (non_canonical, decode limits, trailing bytes), but replay collapses decode failures into wal_corrupt and there is no visible mapping for replication error frames. REALTIME_ERRORS.md expects actionable codes (invalid_request, frame_too_large, batch_too_large, non_canonical).\n\n**Where**\n- src/core/event.rs: DecodeError\n- src/daemon/wal/replay.rs: decode errors -> wal_corrupt\n- replication ingress path (Phase 5)\n\n**Design**\n- Add DecodeError -> ErrorPayload mapping for replication/IPC ingress.\n- Use non_canonical for canonical CBOR violations; size-related errors map to frame_too_large/batch_too_large; other semantic decode errors -> invalid_request.\n\n**Acceptance**\n- Replication ERROR frames include realtime codes for decode limits/non_canonical.\n- Non-canonical CBOR is not reported as wal_corrupt in network paths.\n\n**Files**\n- src/core/event.rs\n- src/daemon/* replication ingress code (bd-3m5.17/48)\n- src/daemon/ipc.rs (if IPC shares mapping)","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768381732360,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768381732360,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768381732360,0]}
{"id":"bd-3m5.79","created_at":[1768413416123,0],"created_by":"darin@darinsmcstudio2.lan","title":"CRITICAL: disable fuzz-like proptest by default","description":"**Problem**\nDefault `cargo test` is effectively running fuzz-like property tests. In `src/git/sync.rs`, multiple `proptest!` blocks use the default `ProptestConfig` (256 cases) while each case initializes git repos, writes commits, pushes/fetches, and does ref resolution. This is expensive and makes the default test run feel like fuzzing.\n\nEvidence:\n- `src/git/sync.rs` has `proptest!` blocks without a custom `ProptestConfig`, so they run 256 cases each (e.g., around lines ~1600, ~1760, ~1900, ~2050).\n- Each case spins up temp git repos and performs multiple git operations (commit, push, fetch), which is far heavier than unit tests.\n\n**Design**\n- Explicitly gate heavy proptests behind an opt-in mechanism:\n  - Option A (preferred): `#[cfg(feature = \"slow-tests\")]` around the heavy proptest modules.\n  - Option B: keep them enabled but set `ProptestConfig { cases: 8 }` by default and allow override via env (e.g., `BD_PROPTEST_CASES` or `PROPTEST_CASES`).\n- Add a separate CI job or `just test-slow` to run the full proptest coverage (256+ cases) explicitly.\n- Document in `docs/philosophy/test_design.md` or README that proptest-heavy suites are opt-in.\n\n**Acceptance**\n- [ ] Default `cargo test` no longer runs the heavyweight proptest loops at full case count.\n- [ ] A documented opt-in path exists to run the full proptest fuzz-like coverage.\n- [ ] CI keeps at least one job that exercises full proptest coverage (or nightly).\n\n**Files:**\n- src/git/sync.rs\n- justfile (optional: add test-slow target)\n- docs/philosophy/test_design.md (optional)\n- .github/workflows/ci.yml (optional: separate slow job)","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768415663703,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768415663703,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768415663703,0]}
{"id":"bd-3m5.8","created_at":[1768177801439,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3: StoreRuntime + StoreId identity mapping","description":"**Problem**\nPhase 3: introduce StoreRuntime and move daemon identity from RemoteUrl to StoreId (hybrid mapping). Today `Daemon` is keyed by `RemoteUrl` and uses `path_to_remote` in `src/daemon/core.rs`, which blocks per store WAL and replication.\n\n**Context**\n- REALTIME_PLAN.md §0.1 (StoreId as correctness identity) and §7.1-7.4 (StoreRuntime + discovery order)\n- Migration fallback UUIDv5(normalized_remote_url) in §0.16\n**Files:** src/daemon/core.rs, src/daemon/remote.rs, src/daemon/repo.rs, src/paths.rs, src/daemon/store_runtime.rs (new)","design":"**Design**\n- Add `StoreRuntime` struct (initially minimal fields: meta, policies, state, watermarks, wal handle) in `src/daemon/store_runtime.rs`.\n- Change `Daemon` maps to `BTreeMap<StoreId, StoreRuntime>` plus `path_to_store_id` and `remote_to_store_id` caches.\n- Implement store identity discovery order: local store meta.json, refs/beads/meta store_meta.json, refs/beads/<store_id> listing, UUIDv5(normalized_remote_url) fallback for migration only.\n- Keep RemoteUrl mapping for legacy git sync, but do not key correctness on it.","acceptance_criteria":"- [ ] Daemon state keyed by StoreId; remote URL only used for legacy git lane mapping.\n- [ ] Store discovery order matches plan and is covered by tests or structured logs.\n- [ ] Existing commands still resolve a store from repo path (compat) without behavior regression.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768206011449,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768206011449,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768206011449,0]}
{"id":"bd-3m5.80","created_at":[1768413435336,0],"created_by":"darin@darinsmcstudio2.lan","title":"CRITICAL: tests are slow due to heavy CLI integration suite","description":"**Problem**\nThe test suite runtime is dominated by CLI integration tests that repeatedly spawn the `bd` binary, initialize git repos, and auto-start the daemon. `tests/critical_path.rs` alone has 83 tests, each doing multiple `bd` invocations (init/create/show/list/close/etc). `tests/migration.rs` adds 12 more, and `tests/daemon_lifecycle.rs` includes multi-second waits. This produces long wall-clock time and amplifies flakiness when tests run in parallel.\n\nEvidence:\n- `tests/critical_path.rs`: 83 `#[test]` cases, each building temp repos and running the CLI several times.\n- `tests/migration.rs`: 12 integration tests with CLI + git usage.\n- `tests/daemon_lifecycle.rs`: multiple sleeps (up to 5s) while waiting for shutdowns.\n\n**Design**\n- Add a fast default test tier:\n  - Convert the critical-path file into fewer table-driven tests (one daemon + repo per test, multiple assertions per run).\n  - Keep a smaller smoke subset enabled by default; move exhaustive CLI scenarios under `#[ignore]` or `feature = \"slow-tests\"`.\n- Reuse a single daemon+repo fixture per test module to reduce repeated daemon startups.\n- Add a `just test-fast` target for default runs and a `just test-slow` target for full integration coverage.\n- Document the tiers and expected runtime budget.\n\n**Acceptance**\n- [ ] Default `cargo test` runtime is substantially reduced (baseline recorded in bead; target under 2–3 min on dev machine).\n- [ ] Full integration coverage remains available behind `--features slow-tests` or `cargo test -- --ignored`.\n- [ ] The CLI critical-path coverage is preserved via table-driven tests or a dedicated slow suite.\n\n**Files:**\n- tests/critical_path.rs\n- tests/migration.rs\n- tests/daemon_lifecycle.rs\n- justfile\n- docs/philosophy/test_design.md (optional)","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768416734612,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768416734612,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768416734612,0]}
{"id":"bd-3m5.81","created_at":[1768444134874,0],"created_by":"darin@darinsmcstudio2.lan","title":"Namespaces still hard-coded to core; StoreState not wired","description":"**Problem**\nREALTIME_PLAN §0.3/§2.7 require StoreState (namespaced CanonicalState) + namespace-aware access. Current implementation remains single-namespace: RepoState holds CanonicalState, and IPC normalization rejects any namespace other than core. This means namespaces.toml policies are loaded but never used, and non-core namespaces cannot be created or queried.\n\nEvidence:\n- src/daemon/core.rs:1865 normalize_namespace() returns NamespaceUnknown for any non-core.\n- src/daemon/repo.rs: RepoState.state is CanonicalState (not StoreState).\n- src/daemon/executor.rs and src/daemon/query_executor.rs apply/query against repo_state.state directly.\n\n**Why this violates plan**\nREALTIME_PLAN mandates StoreState = map<NamespaceId, CanonicalState> and a defaulting rule (namespace=core) rather than hard-rejecting non-core. This is a core architectural requirement.\n\n**Acceptance**\n- [ ] Replace RepoState.state with StoreState; thread namespace selection through executor, query, replication ingest, checkpoint export/import.\n- [ ] normalize_namespace validates against store.policies (namespaces.toml) and allows non-core namespaces when configured.\n- [ ] Defaulting rule remains: missing namespace -> core.\n- [ ] Unit tests cover non-core namespace mutation + query + replication paths.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768460325161,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768460325161,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768460325161,0]}
{"id":"bd-3m5.82","created_at":[1768444153886,0],"created_by":"darin@darinsmcstudio2.lan","title":"Event WAL uses SegmentWriter per append; no persistent EventWal/segment reuse","description":"**Problem**\nREALTIME_PLAN §5.5/§5.6 define an EventWal that owns the active segment per namespace and rotates by size/age. Current code opens a new SegmentWriter for every local mutation and every replication ingest batch, so each event/batch becomes its own segment and rotation logic is effectively bypassed. This contradicts the WAL design and inflates segment count + fsync dir overhead.\n\nEvidence:\n- src/daemon/executor.rs:225–255 creates SegmentWriter::open for each mutation (no reuse).\n- src/daemon/core.rs:1009–1033 (ingest_remote_batch) creates SegmentWriter::open per batch.\n- There is no EventWal struct managing active segments in src/daemon/wal/mod.rs.\n\n**Why this violates plan**\nPlan requires a long-lived EventWal that appends to the current segment, rotates when size/age thresholds are hit, and only fsyncs directories on rotation. Opening a new segment per event defeats these invariants.\n\n**Acceptance**\n- [ ] Introduce EventWal (per store) that keeps active SegmentWriter per namespace.\n- [ ] Use EventWal::append in executor + replication ingest; reuse active segment until rotation triggers.\n- [ ] Rotation honors max_segment_bytes/max_segment_age and only then creates new segment + dir fsync.\n- [ ] Tests cover multi-append into a single segment and rotation thresholds.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768450000807,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768450000807,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768450000807,0]}
{"id":"bd-3m5.83","created_at":[1768444163141,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL segment sealing not recorded on rotation","description":"**Problem**\nREALTIME_PLAN §5.2.3/§5.2.3 require marking rotated segments as sealed with final_len recorded in wal.sqlite. Current runtime writes segments with sealed=false and never updates them when rotation happens (AppendOutcome.rotated is unused). Sealing only occurs during replay rebuild, so live index misses sealed/final_len invariants.\n\nEvidence:\n- src/daemon/executor.rs:264–282 upsert_segment always uses sealed=false, final_len=None.\n- src/daemon/core.rs:1041–1066 does the same for replication ingest.\n- SegmentWriter::append returns AppendOutcome.rotated, but no caller updates sealed/final_len.\n\n**Why this violates plan**\nPlan mandates sealed segments be recorded at rotation time and validated on startup (file_len == final_len). Without this, on-disk corruption and partial writes can go undetected.\n\n**Acceptance**\n- [ ] On segment rotation, mark previous segment sealed=1 and final_len in wal.sqlite.\n- [ ] Ensure index updates are atomic with segment rotation.\n- [ ] Admin/status and replay enforce sealed invariants for live-written segments, not just rebuild.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768450850071,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768450850071,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768450850071,0]}
{"id":"bd-3m5.84","created_at":[1768444170914,0],"created_by":"darin@darinsmcstudio2.lan","title":"EventBody decode rejects unknown keys; breaks forward-compat storage/forwarding","description":"**Problem**\nREALTIME_PLAN §0.6/§3.4 says nodes can store/forward raw EventBody bytes without re-encoding and should be forward compatible. Current decode_event_body_map / decode_hlc_max hard-fail on any unknown key, which means a newer sender adding a field causes older nodes to reject the event entirely (even though hash is over raw bytes).\n\nEvidence:\n- src/core/event.rs:478–510 decode_event_body_map returns InvalidField for unknown key.\n- src/core/event.rs:1618–1644 decode_hlc_max returns InvalidField for unknown key.\n\n**Why this violates plan**\nForward compatibility is required in v0.5: receivers should accept unknown keys (after hash verification) and still persist raw bytes, even if they can’t interpret new fields.\n\n**Acceptance**\n- [ ] Unknown keys in EventBody/HlcMax are skipped (while enforcing size/depth limits).\n- [ ] Events with extra fields still verify sha256 and are persisted/replicated.\n- [ ] Tests cover decoding EventBody with an extra field without failure.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768456162983,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768456162983,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768456162983,0]}
{"id":"bd-3m5.85","created_at":[1768444178286,0],"created_by":"darin@darinsmcstudio2.lan","title":"CBOR decode does not reject non-canonical integer encodings","description":"**Problem**\nREALTIME_PLAN §3.1 requires rejecting non-canonical integer encodings in EventBody. Current decode uses minicbor::Decoder u64/u32 directly and never checks for non-minimal integer encodings, so overlong integer encodings are accepted.\n\nEvidence:\n- src/core/event.rs:1650–1667 decode_u32 uses dec.u64 with no canonicality check.\n- No canonical integer validation exists in decode_map_len/decode_array_len/decode_u32.\n\n**Why this violates plan**\nCanonical CBOR is a correctness primitive for hashed payloads. Accepting non-canonical integers undermines deterministic validation requirements.\n\n**Acceptance**\n- [ ] Implement strict integer decoding that rejects non-minimal encodings (and tags).\n- [ ] Apply to all integer fields in EventBody/TxnDelta/HlcMax.\n- [ ] Add tests that reject overlong integer encodings.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768456911759,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768456911759,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-3m5.86","created_at":[1768444186301,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replica liveness table unused; last_seen_ms not persisted","description":"**Problem**\nREALTIME_PLAN §2.1.2 calls for persisting last_seen_ms for known replicas so admin.status and pruning remain correct across restarts. Schema includes replica_liveness, but it is never written or read.\n\nEvidence:\n- src/daemon/wal/index.rs defines replica_liveness table, but there are no writer/read methods for it.\n- rg \"replica_liveness\" only finds the schema.\n\n**Why this violates plan**\nWithout persistence, replica liveness resets on restart, breaking visibility of peers and any future pruning logic.\n\n**Acceptance**\n- [ ] Add WAL index writer/read APIs for replica_liveness.\n- [ ] Update liveness on replication handshake/ACKs with last_seen_ms.\n- [ ] Surface persisted liveness in admin.status.","priority":3,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768483302777,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768483302777,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768483302777,0]}
{"id":"bd-3m5.87","created_at":[1768444192878,0],"created_by":"darin@darinsmcstudio2.lan","title":"Store lock heartbeat never updated","description":"**Problem**\nREALTIME_PLAN §0.2 recommends updating store.lock last_heartbeat_ms periodically while holding the lock. StoreLock::update_heartbeat exists but is never called, so lock metadata becomes stale immediately.\n\nEvidence:\n- src/daemon/store_lock.rs defines update_heartbeat, but no call sites (rg update_heartbeat).\n\n**Why this violates plan**\nHeartbeat is the intended staleness signal for operators. Without updates, bd store unlock cannot reliably distinguish live vs stale locks.\n\n**Acceptance**\n- [ ] Add periodic heartbeat updates (e.g., in daemon run loop every ~10s).\n- [ ] Heartbeat failures are logged but do not crash daemon.","priority":3,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768481431340,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768481431340,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768481431340,0]}
{"id":"bd-3m5.88","created_at":[1768444203385,0],"created_by":"darin@darinsmcstudio2.lan","title":"Config additions missing for replication/checkpoint/namespace defaults","description":"**Problem**\nREALTIME_PLAN §15.2 requires config for checkpoint groups, namespace defaults, and replication settings. Current config only includes auto_upgrade + limits; replication uses env vars and checkpoint groups are hard-coded to core.\n\nEvidence:\n- src/config.rs: Config has only auto_upgrade + limits.\n- src/daemon/core.rs uses BD_REPL_LISTEN_ADDR / BD_REPL_MAX_CONNECTIONS env vars.\n- src/daemon/checkpoint_scheduler.rs uses core_default only; no config-backed groups.\n\n**Why this violates plan**\nThe plan explicitly calls out config-driven checkpoint groups and replication parameters. Missing config blocks real deployments and policy-driven behavior.\n\n**Acceptance**\n- [ ] Extend Config to include replication listen addr/peers/timeouts and checkpoint group definitions.\n- [ ] Load namespace policy defaults from config or namespaces.toml as specified.\n- [ ] Replace env-only replication settings with config precedence (env can override).\n- [ ] Tests cover config roundtrip + defaulting.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768470317265,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768470317265,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768470317265,0]}
{"id":"bd-3m5.89","created_at":[1768444212747,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL append uses sync_data instead of full fsync","description":"**Problem**\nREALTIME_PLAN §0.10 defines LocalFsync as fsync of the active segment file after each append. Current SegmentWriter::append uses File::sync_data, which may omit metadata durability (file length/mtime) on some platforms.\n\nEvidence:\n- src/daemon/wal/segment.rs:252–260 calls self.file.sync_data().\n\n**Why this violates plan**\nLocalFsync semantics require full fsync of the file to guarantee record durability.\n\n**Acceptance**\n- [ ] Use sync_all (fsync) for LocalFsync record durability.\n- [ ] Document/benchmark any performance impact and keep directory fsync only on rotation.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768461466235,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768461466235,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768461466235,0]}
{"id":"bd-3m5.9","created_at":[1768177813446,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 3: Event WAL framing + segment writer","description":"**Problem**\nPhase 3: implement the event WAL segment format and framing. Current `src/daemon/wal.rs` is a snapshot WAL; there is no event log, framing, or segment rotation.\n\n**Context**\n- REALTIME_PLAN.md §0.9 (segment naming), §0.10 (LocalFsync), §6.4 and §6.5 (crash consistency)\n- Framing uses crc32c (REALTIME_PLAN.md §9.1)\n**Files:** src/daemon/wal/mod.rs (new), src/daemon/wal/frame.rs (new), src/daemon/wal/segment.rs (new), src/daemon/wal/record.rs (new)","design":"**Design**\n- Define WAL segment header with store_id, store_epoch, namespace, wal_format_version, created_at_ms, segment_id.\n- Define record header with EventId fields, sha256, prev_sha256 (optional), event_time_ms, txn_id, client_request_id, request_sha256 (optional), and record_len.\n- Implement frame encoding with length + crc32c and tail truncation handling.\n- Implement segment rotation by size and age; create files under wal/<namespace>/segment-<created_at_ms>-<segment_id>.wal.\n- Implement LocalFsync semantics: fsync segment after append; fsync directory only on new segment creation.","acceptance_criteria":"- [ ] Can append and read back a record frame with crc32c validation.\n- [ ] Segment creation and rotation follow naming and fsync rules.\n- [ ] MAX_WAL_RECORD_BYTES enforced before writing.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768207345883,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768207345883,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768207345883,0]}
{"id":"bd-3m5.90","created_at":[1768444258974,0],"created_by":"darin@darinsmcstudio2.lan","title":"EventBody decoder doesn't detect duplicate map keys","description":"**Problem**\nREALTIME_PLAN §3.1 says duplicate map keys in EventBody SHOULD be rejected. Current decode_event_body_map/other decoders accept duplicates silently (later key wins).\n\nEvidence:\n- src/core/event.rs decode_event_body_map loops over keys with no duplicate tracking.\n\n**Acceptance**\n- [ ] Track seen keys in EventBody/TxnDelta/HlcMax and return DecodeError::DuplicateKey (or similar) on duplicates.\n- [ ] Add tests for duplicate keys being rejected.","priority":3,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768480674530,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768480674530,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768480674530,0]}
{"id":"bd-3m5.91","created_at":[1768444265300,0],"created_by":"darin@darinsmcstudio2.lan","title":"Default namespaces only include core; sys/wf/tmp defaults unused","description":"**Problem**\nREALTIME_PLAN §2.2 lists default policies for core/sys/wf/tmp. StoreRuntime::load_namespace_policies falls back to default_policies() which only inserts core, so sys/wf/tmp are never present unless explicitly configured.\n\nEvidence:\n- src/daemon/store_runtime.rs:335–341 default_policies inserts only NamespaceId::core().\n- src/core/namespace.rs defines sys_default/wf_default/tmp_default but they are unused.\n\n**Acceptance**\n- [ ] When namespaces.toml is missing, populate defaults for core/sys/wf/tmp per plan.\n- [ ] Add tests asserting default policy map includes sys/wf/tmp.","priority":3,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768483741795,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768483741795,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768483741795,0]}
{"id":"bd-3m5.92","created_at":[1768444275583,0],"created_by":"darin@darinsmcstudio2.lan","title":"Startup does not clean up orphaned *.wal.tmp segments","description":"**Problem**\nREALTIME_PLAN §5.2.3 says *.wal.tmp files MUST be ignored and SHOULD be deleted if not referenced by wal.sqlite. Current replay ignores .tmp files but never cleans them up.\n\nEvidence:\n- src/daemon/wal/replay.rs list_segments only loads *.wal; no cleanup of *.wal.tmp.\n\n**Acceptance**\n- [ ] On startup/replay, delete .wal.tmp files not referenced in wal.sqlite segments table.\n- [ ] Log deletions for operator visibility.","priority":4,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768488067449,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768488067449,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-3m5.93","created_at":[1768444366719,0],"created_by":"darin@darinsmcstudio2.lan","title":"HLC state is global; per-actor persistence not honored","description":"**Problem**\nREALTIME_PLAN §8.4 requires HLC state to be monotonic per ActorId and persisted/restored per actor. Current daemon uses a single global Clock and only restores HLC state for the daemon actor, so custom actor_id requests can regress after restart.\n\nEvidence:\n- src/daemon/clock.rs implements a single Clock without actor partitioning.\n- src/daemon/core.rs:564–570 loads hlc_state only for self.actor.\n- MutationEngine uses Clock::tick for all actors (src/daemon/mutation_engine.rs:200–240).\n\n**Why this violates plan**\nPer-actor monotonicity and persistence are required; using a single clock and only restoring the daemon actor breaks this for alternate actor_id inputs.\n\n**Acceptance**\n- [ ] Maintain per-actor HLC state (e.g., map ActorId -> Clock state) and load from wal_index.hlcs for any actor seen/used.\n- [ ] When actor_id is specified in a request, advance the correct actor clock state.\n- [ ] Tests cover monotonicity across restarts for non-daemon actor_id.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768465491733,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768465491733,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768465491733,0]}
{"id":"bd-3m5.94","created_at":[1768444495152,0],"created_by":"darin@darinsmcstudio2.lan","title":"I/O budgeting limits (bytes/sec) are defined but not enforced","description":"**Problem**\nREALTIME_PLAN §0.19 requires enforcing MAX_REPL_INGEST_BYTES_PER_SEC and MAX_BACKGROUND_IO_BYTES_PER_SEC (token buckets) so WAL writes aren’t starved. Limits exist but are unused.\n\nEvidence:\n- src/core/limits.rs defines max_repl_ingest_bytes_per_sec / max_background_io_bytes_per_sec.\n- No call sites reference these fields (rg shows only definitions/tests).\n\n**Why this violates plan**\nThese budgets are normative; without enforcement, replication or checkpoints can saturate IO and violate the durability priority rule.\n\n**Acceptance**\n- [ ] Implement token-bucket throttling for replication ingest bytes/sec and background IO.\n- [ ] Ensure WAL append + fsync are not starved by background work.\n- [ ] Add metrics/tests verifying throttling behavior.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768468870499,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768468870499,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768468870499,0]}
{"id":"bd-3m5.95","created_at":[1768444543441,0],"created_by":"darin@darinsmcstudio2.lan","title":"Checkpoint job queue limit is defined but never enforced","description":"**Problem**\nREALTIME_PLAN §0.19 requires MAX_CHECKPOINT_JOB_QUEUE enforcement (coalesce by group when full). Limits include max_checkpoint_job_queue, but scheduler never consults it.\n\nEvidence:\n- src/core/limits.rs defines max_checkpoint_job_queue.\n- No call sites reference it (rg shows only definitions/tests).\n\n**Acceptance**\n- [ ] Enforce max_checkpoint_job_queue in checkpoint scheduler (per store), coalescing when full.\n- [ ] Add tests verifying queue limit behavior.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768465837564,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768465837564,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768465837564,0]}
{"id":"bd-3m5.96","created_at":[1768444584858,0],"created_by":"darin@darinsmcstudio2.lan","title":"Checkpoint import not wired into daemon load path","description":"**Problem**\nREALTIME_PLAN §13 expects Git lane to use checkpoint import/export for bootstrap and recovery. Current daemon load path still reads only legacy refs/heads/beads/store; checkpoint import code exists but is never invoked. This means checkpoint lane is export-only and cannot be used for bootstrap/catch-up.\n\nEvidence:\n- src/daemon/git_worker.rs: load()/load_local() read refs/heads/beads/store via git::sync.\n- rg import_checkpoint shows no call sites outside tests.\n\n**Why this violates plan**\nPlan requires checkpoint import to drive bootstrap and recovery in v0.5 (snapshot bootstrap is deferred, but checkpoints are not).\n\n**Acceptance**\n- [ ] Wire checkpoint import into daemon load path (alongside legacy lane for migration).\n- [ ] Ensure imported checkpoints set applied/durable watermarks to included values.\n- [ ] Add tests for loading from checkpoint ref.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768463992384,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768463992384,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768463992384,0]}
{"id":"bd-3m5.97","created_at":[1768444731915,0],"created_by":"darin@darinsmcstudio2.lan","title":"KEEPALIVE_MS limit unused; no keepalive scheduling","description":"**Problem**\nREALTIME_PLAN §0.19 defines KEEPALIVE_MS (5s) for protocol keepalive, but code never uses limits.keepalive_ms. Replication sessions and IPC do not send keepalives or track idle timeouts based on this value.\n\nEvidence:\n- rg \"keepalive_ms\" only finds definitions in src/core/limits.rs.\n\n**Acceptance**\n- [ ] Implement keepalive timers in replication sessions (HELLO/ACK pings) and/or IPC streaming.\n- [ ] Wire to Limits.keepalive_ms with tests for idle connections.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768467389314,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768467389314,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768467389314,0]}
{"id":"bd-3m5.98","created_at":[1768448635632,0],"created_by":"darin@darinsmcstudio2.lan","title":"CLI namespace/durability/client-request-id flags become config-backed overrides","description":"**Problem**\nREALTIME_PLAN §16.3 adds CLI flags `--namespace`, `--durability`, `--client-request-id`. We want these to remain, but semantics should be config‑first: repo/user config provides defaults and flags override those defaults. Env vars must remain supported and take precedence over config (but not over explicit CLI flags).\n\n**Design**\n- Keep existing CLI flags.\n- Resolve defaults from layered config (repo `beads.toml` + user config) with env overrides.\n- Precedence: CLI flag > env var > repo config > user config > hardcoded defaults.\n- `--client-request-id` remains explicit‑only (no default); used mainly by automation.\n\n**Acceptance**\n- [ ] CLI behavior matches precedence above for namespace/durability defaults.\n- [ ] Env vars for replication/config remain supported.\n- [ ] CLI flags continue to pass through IPC unchanged.\n- [ ] Tests cover: config default used when no flags; CLI overrides config; env overrides config.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768487643359,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768487643359,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768487643359,0]}
{"id":"bd-3m5.99","created_at":[1768448649899,0],"created_by":"darin@darinsmcstudio2.lan","title":"Layered config (user+repo beads.toml) with central module","description":"**Problem**\nConfig is currently minimal (`src/config.rs` only has auto_upgrade + limits). REALTIME_PLAN §15.2 requires replication/checkpoint/namespace defaults, and the project needs a maintainable, central config system. We also want repo‑level `beads.toml` (plus user config) with clear precedence and env overrides.\n\n**Design**\n- Introduce a dedicated config module (e.g., `src/config/mod.rs` with submodules `schema.rs`, `load.rs`, `merge.rs`).\n- Define layered config types:\n  - `UserConfig` (global defaults, stored at `~/.config/beads-rs/config.toml`).\n  - `RepoConfig` (repo‑level `beads.toml`).\n  - `EffectiveConfig` (merged result used by CLI/daemon).\n- Keep store‑local files (`namespaces.toml`, `replicas.toml`, store meta) as authoritative for store identity/policy, but allow repo config to supply defaults when those files are absent.\n- Precedence: env vars > repo config > user config > defaults.\n- Provide helper to locate repo root and load `beads.toml`.\n\n**Config schema sketch**\n- `[defaults]` (namespace, durability, actor?)\n- `[replication]` (listen_addr, max_connections, peers, timeouts)\n- `[checkpoint.groups.<name>]` (namespaces, git_ref, writers, debounce/max_interval/max_events, durable_copy_via_git)\n- `[namespaces.<name>]` (NamespacePolicy defaults if store config missing)\n- `[limits]` (existing Limits override)\n\n**Acceptance**\n- [ ] Central config module with clear layering/merge logic and tests.\n- [ ] `beads.toml` supported at repo root; user config still supported.\n- [ ] Env overrides are preserved.\n- [ ] CLI + daemon use `EffectiveConfig` instead of ad‑hoc reads where applicable.","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","notes":[{"id":"go-comment-bd-3m5.99-1","content":"Env var audit: map to config where appropriate. Recommend: BD_ACTOR -> defaults.actor (env remains override); BD_REPL_LISTEN_ADDR -> replication.listen_addr; BD_REPL_MAX_CONNECTIONS -> replication.max_connections; BD_LOAD_TIMEOUT_SECS -> timeouts.git_load_secs (or similar). Keep env-only: BD_REMOTE_URL, BD_STORE_ID (debug overrides); BD_DATA_DIR/BD_CONFIG_DIR/BD_WAL_DIR; LOG; BD_NO_AUTO_UPGRADE (override); BD_UPGRADE_* (test/upgrade harness); BD_TEST_WAL_HANG_* (slow-tests). BD_TOMBSTONE_TTL_MS is legacy tombstone GC for git sync; leave env-only or add to a legacy config section if we intentionally support it.","author":"darin@book","at":[1768449533383,0]},{"id":"legacy-notes","content":"Env var audit: map to config where appropriate. Recommend: BD_ACTOR -> defaults.actor (env remains override); BD_REPL_LISTEN_ADDR -> replication.listen_addr; BD_REPL_MAX_CONNECTIONS -> replication.max_connections; BD_LOAD_TIMEOUT_SECS -> timeouts.git_load_secs (or similar). Keep env-only: BD_REMOTE_URL, BD_STORE_ID (debug overrides); BD_DATA_DIR/BD_CONFIG_DIR/BD_WAL_DIR; LOG; BD_NO_AUTO_UPGRADE (override); BD_UPGRADE_* (test/upgrade harness); BD_TEST_WAL_HANG_* (slow-tests). BD_TOMBSTONE_TTL_MS is legacy tombstone GC for git sync; leave env-only or add to a legacy config section if we intentionally support it.","author":"darin@darinsmcstudio2.lan","at":[1768487268821,0]}],"_at":[1768487268821,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768487268821,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768487268821,0]}
{"id":"bd-3t9","created_at":[1765744499553,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add --type flag to bd update command","description":"**Problem**\nCannot change a beads type after creation. Had to close bd-d37 and recreate as epic bd-2fr.\n\n**Solution**\nAdd `--type` flag to `bd update`:\n```\nbd update <id> --type=epic\n```\n\n**Design Notes**\n- Should validate type is one of: task, bug, feature, epic, chore\n- Type changes should be LWW like other fields\n- Consider if changing TO epic should warn if bead has no children\n- Consider if changing FROM epic should warn if bead has children\n\n**Acceptance**\n- [ ] `bd update --type <TYPE>` works\n- [ ] Invalid types rejected with clear error\n- [ ] Type change reflected in `bd show`","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765775210547,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765775210547,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765775210547,0]}
{"id":"bd-3uw0","created_at":[1769565914175,0],"created_by":"darin@darinsmcstudio2.lan","title":"mutation: validate all claim/close patches before emit","description":"Problem\n- plan_claim/plan_unclaim/plan_extend_claim and plan_close/plan_reopen build WireBeadPatch but do not call validate_wire_patch.\n- Today the patches happen to be valid, but future changes to patch semantics can silently break invariants.\n- This is a drift risk (types don't guarantee the patch is validated).\n\nImpact\n- Inconsistent validation across mutation paths; fragile invariants.\n","design":"Design\n- Add a validated patch builder (e.g., BeadPatchBuilder) that always returns ValidatedBeadPatch.\n- Or, call validate_wire_patch in every mutation path that emits a patch (claim/unclaim/extend/close/reopen/delete).\n- Encode as a helper so missing validation is a compile-time error (e.g., return ValidatedBeadPatch from plan_*).\n\nScatter fit\n- Centralize patch validation and make it the only way to emit bead upserts.\n\nFiles\n- crates/beads-rs/src/daemon/mutation_engine.rs\n- crates/beads-core/src/event.rs (if adding builder)","acceptance_criteria":"Acceptance\n- Every mutation path that emits WireBeadPatch runs validation (or uses ValidatedBeadPatch type).\n- Tests cover that invalid patch combinations fail early in mutation planning.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769596098140,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769596098140,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769596098140,0]}
{"id":"bd-3wz4","created_at":[1768914167229,0],"created_by":"darin@darinsmcstudio2.lan","title":"Update CRDT_OVERHAUL.md references to deprecated NotesPatch/DepUpsert/DepDelete","description":"Doc still mentions removed wire ops; update to LabelAdd/LabelRemove/DepAdd/DepRemove/NoteAppend or mark historical.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768914972620,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768914972620,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768914972620,0]}
{"id":"bd-3zoj","created_at":[1768894465294,0],"created_by":"darin@darinsmcstudio2.lan","title":"CRDT overhaul: OR-Set labels/deps, orphan notes, deterministic collisions","description":"**Problem**\nWe must implement locked CRDT decisions D1–D5. The current system uses full-set LWW for labels, LWW dep edges with provenance, notes embedded in beads, and collision errors/left-wins. Apply is not total and order-dependent.\n\n**Design**\nImplement the plan in CRDT_OVERHAUL.md. This epic decomposes the work into independent tasks with strict dependency ordering.\n\n**Files**\nCRDT_OVERHAUL.md","design":"Follow CRDT_OVERHAUL.md as the source-of-truth design plan. Each child task implements a scoped slice (orset core, store meta, wire ops, apply, mutation engine, git wire, cleanup).","acceptance_criteria":"- [ ] All child tasks complete\n- [ ] Apply/merge deterministic and order-independent\n- [ ] D1 self-contained ops enforced\n- [ ] OR-Set labels/deps + orphan notes/labels/deps live\n- [ ] Legacy full-set / LWW dep paths deleted","priority":1,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768942392687,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768942392687,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768942392687,0]}
{"id":"bd-3zoj.1","created_at":[1768894650782,0],"created_by":"darin@darinsmcstudio2.lan","title":"OR-Set core types (Dot/DVV/OrSet)","description":"**Problem**\nWe need a compact, deterministic OR-Set implementation (ORSWOT) to replace LWW labels/deps.\n\n**Files**\n- src/core/orset.rs (new)\n- src/core/mod.rs (export)","design":"Implement:\n- Dot { replica, counter }\n- Dvv { max: BTreeMap<ReplicaId,u64> } + dominates + join\n- OrSet<V> with entries + cc\n- apply_add(dot, value, op_hash)\n- apply_remove(value, ctx)\n- join(a,b)\n- OrSetChange reporting membership changes\nInclude deterministic dot-collision winner rules.","acceptance_criteria":"- [ ] OrSet add/remove/join work for basic cases\n- [ ] Dvv dominates/join correctness covered by tests\n- [ ] Dot collision resolution deterministic\n- [ ] Public API documented in module comments\n\n**Invariants to re-verify**\n- [ ] OrSet::join is commutative and idempotent for test cases\n- [ ] No dot in entries is dominated by cc after add/remove/join\n- [ ] Dvv dominance is monotonic under join","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768897220726,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768897220726,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768897220726,0]}
{"id":"bd-3zoj.10","created_at":[1768894652641,0],"created_by":"darin@darinsmcstudio2.lan","title":"Git wire: serialize OR-Set deps/labels + notes.jsonl","description":"**Problem**\nGit wire currently serializes LWW dep edges and bead-embedded notes/labels.\n\n**Files**\n- src/git/wire.rs","design":"Update serialization:\n- state.jsonl contains beads + embedded labels OR-Set\n- deps.jsonl uses OR-Set cc + dot sets\n- notes.jsonl stores notes by bead_id\nUpdate parse to rebuild stores + dep_indexes. Update checksums to include notes (and labels if separate).","acceptance_criteria":"- [ ] serialize/parse roundtrip for state/tombs/deps/notes\n- [ ] deterministic ordering by id/key\n\n**Invariants to re-verify**\n- [ ] Git wire serialization is deterministic (sorted by id/key/dot)\n- [ ] Roundtrip preserves OR-Set metadata and orphans","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768913417824,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768913417824,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768913417824,0]}
{"id":"bd-3zoj.11","created_at":[1768894652850,0],"created_by":"darin@darinsmcstudio2.lan","title":"Cleanup: remove legacy LWW dep/label/note code","description":"**Problem**\nLegacy LWW dep edges, full-set labels, and NoteLog become dead code after migration.\n\n**Files**\n- src/core/dep.rs\n- src/core/bead.rs\n- src/core/collections.rs\n- src/core/wire_bead.rs\n- src/core/apply.rs\n- src/daemon/mutation_engine.rs","design":"Delete DepEdge/DepLife, Bead.notes, BeadFields.labels, NoteLog, old dep wire ops, full-set label patching. Remove old ApplyError variants and related error paths.","acceptance_criteria":"- [ ] No references to DepEdge/NoteLog/labels LWW\n- [ ] Build passes without legacy types\n\n**Invariants to re-verify**\n- [ ] No references to DepEdge/NoteLog/labels LWW remain\n- [ ] Build succeeds without legacy types","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768942353123,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768942353123,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768942353123,0]}
{"id":"bd-3zoj.12","created_at":[1768894653058,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove git collision remap path","description":"**Problem**\nGit collision remap is incompatible with deterministic collision resolution.\n\n**Files**\n- src/git/collision.rs\n- src/git/sync.rs","design":"Remove remap usage and rely on CanonicalState::join + lineage tombstones for collisions.","acceptance_criteria":"- [ ] git sync compiles without remap\n- [ ] collisions handled by join\n\n**Invariants to re-verify**\n- [ ] Git sync no longer remaps IDs; collisions handled by join","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768918924482,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768918924482,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768918924482,0]}
{"id":"bd-3zoj.13","created_at":[1768894653264,0],"created_by":"darin@darinsmcstudio2.lan","title":"Update fixtures/tests for new wire ops","description":"**Problem**\nFixtures/tests still use NotesPatch and dep upsert/delete ops.\n\n**Files**\n- tests/integration/fixtures/event_body.rs\n- src/core/wire_bead.rs (tests)\n- src/core/apply.rs (tests)","design":"Rewrite fixtures to use LabelAdd/LabelRemove/DepAdd/DepRemove + NoteAppend. Remove NotesPatch-based fixtures.","acceptance_criteria":"- [ ] Fixtures compile with new wire ops\n\n**Invariants to re-verify**\n- [ ] Fixtures use only new Label/Dep ops + NoteAppend\n- [ ] No NotesPatch/DepUpsert/DepDelete in fixtures","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768913775407,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768913775407,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768913775407,0]}
{"id":"bd-3zoj.14","created_at":[1768894653468,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tests: OR-Set semantics (add/remove/join)","description":"**Problem**\nWe need deterministic tests for OR-Set behavior.\n\n**Files**\n- src/core/orset.rs","design":"Add unit tests for:\n- add-wins concurrency\n- remove with ctx\n- join commutativity\n- dot collision rule","acceptance_criteria":"- [ ] OR-Set tests pass and cover edge cases\n\n**Invariants to re-verify**\n- [ ] OR-Set tests assert commutativity/idempotence\n- [ ] Dot collision rule covered","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768897330774,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768897330774,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768897330774,0]}
{"id":"bd-3zoj.15","created_at":[1768894653674,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tests: apply orphans + collisions deterministic","description":"**Problem**\nApply must be total and deterministic for notes/labels/deps and bead collisions.\n\n**Files**\n- src/core/apply.rs\n- src/core/state.rs","design":"Add tests for:\n- note append before bead exists\n- label/dep ops on missing bead\n- bead creation collision deterministic winner\n- note collision deterministic winner","acceptance_criteria":"- [ ] Apply total and deterministic under collisions\n\n**Invariants to re-verify**\n- [ ] Apply is total for orphans\n- [ ] Collision winners deterministic","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768917337557,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768917337557,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768917337557,0]}
{"id":"bd-3zoj.16","created_at":[1768894653885,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tests: wire encode/decode for new ops","description":"**Problem**\nNew wire ops require codec coverage.\n\n**Files**\n- src/core/wire_bead.rs\n- src/core/event.rs","design":"Add tests for TxnDeltaV1 roundtrip with LabelAdd/Remove and DepAdd/Remove, including dot/dvv ordering.","acceptance_criteria":"- [ ] encode/decode roundtrip for new ops\n\n**Invariants to re-verify**\n- [ ] Wire codec roundtrips dots/DVVs deterministically","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768914175342,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768914175342,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768914175342,0]}
{"id":"bd-3zoj.17","created_at":[1768894654095,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tests: git wire roundtrip with OR-Set + notes","description":"**Problem**\nWe must ensure checkpoint serialization preserves OR-Set state and notes.\n\n**Files**\n- src/git/wire.rs\n- src/core/state.rs","design":"Add tests to serialize/parse state+deps+notes and verify equivalence. Include dots/cc preservation and deterministic ordering.","acceptance_criteria":"- [ ] serialize/parse roundtrip retains OR-Set metadata\n\n**Invariants to re-verify**\n- [ ] Checkpoint wire roundtrip preserves OR-Set metadata + notes","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768914816832,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768914816832,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768914816832,0]}
{"id":"bd-3zoj.18","created_at":[1768894654303,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tests: updated_at includes labels/notes","description":"**Problem**\nupdated_at must reflect label/note changes after BeadView refactor.\n\n**Files**\n- src/daemon/query_model.rs\n- src/api/issues.rs\n- src/daemon/query_executor.rs","design":"Add tests to ensure updated_at changes when labels/notes change without touching core bead fields.","acceptance_criteria":"- [ ] updated_at reflects labels/notes changes\n\n**Invariants to re-verify**\n- [ ] updated_at changes when labels/notes change without field edits","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768915341492,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768915341492,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768915341492,0]}
{"id":"bd-3zoj.2","created_at":[1768894650986,0],"created_by":"darin@darinsmcstudio2.lan","title":"Persist OR-Set dot counter in StoreMeta","description":"**Problem**\nDots must be unique across restarts. We need a persisted per-replica counter.\n\n**Files**\n- src/core/store_meta.rs\n- src/daemon/store/runtime.rs","design":"Add `orset_counter: u64` to StoreMeta, update constructors + serde tests. Add StoreRuntime helper:\n- next_orset_counter() -> u64 (increments, writes store_meta.json)\nEnsure counter persists before WAL commit.","acceptance_criteria":"- [ ] StoreMeta serde roundtrip includes orset_counter\n- [ ] StoreRuntime persists counter increments\n- [ ] Counter increments even if WAL append fails (holes ok)\n\n**Invariants to re-verify**\n- [ ] orset_counter never decreases and is never reused across restarts\n- [ ] Counter increments are durable before WAL commit","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768896334512,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768896334512,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768896334512,0]}
{"id":"bd-3zoj.3","created_at":[1768894651197,0],"created_by":"darin@darinsmcstudio2.lan","title":"CanonicalState: LabelStore/DepStore/NoteStore","description":"**Problem**\nCanonicalState embeds LWW labels, LWW dep edges, and notes in Bead. We need OR-Set stores and orphans.\n\n**Files**\n- src/core/state.rs\n- src/core/collections.rs (if helpers live here)","design":"Add new stores:\n- LabelStore { by_bead: BTreeMap<BeadId, LabelState{set:OrSet<Label>, stamp:Stamp}> }\n- DepStore { set: OrSet<DepKey>, stamp: Stamp }\n- NoteStore { by_bead: BTreeMap<BeadId, BTreeMap<NoteId, Note>> }\nProvide helpers:\n- labels_for(bead_id)\n- apply_label_add/remove\n- apply_dep_add/remove (update dep_indexes)\n- insert_note / notes_for\nEnsure orphans are allowed and stamps update only on membership change.","acceptance_criteria":"- [ ] CanonicalState compiles with new stores\n- [ ] Dep indexes update correctly on add/remove\n- [ ] Orphan labels/notes/deps persist without errors\n\n**Invariants to re-verify**\n- [ ] dep_indexes reflect DepStore membership (no stale edges)\n- [ ] Orphan labels/notes/deps persist but are not surfaced for missing beads\n- [ ] Bead no longer stores labels/notes","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768903984173,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768903984173,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768903984173,0]}
{"id":"bd-3zoj.4","created_at":[1768894651404,0],"created_by":"darin@darinsmcstudio2.lan","title":"BeadView + derived updated/content hash","description":"**Problem**\nBead currently owns notes + labels, and updated_stamp/content_hash depend on those fields.\n\n**Files**\n- src/core/bead.rs\n- src/core/wire_bead.rs\n- src/api/issues.rs\n- src/daemon/query_model.rs\n- src/daemon/query_executor.rs","design":"Introduce BeadView that joins Bead + LabelStore + NoteStore. Move updated_stamp + content_hash + WireBeadFull rendering to BeadView. Replace all usage of bead.updated_stamp() with state.bead_view().","acceptance_criteria":"- [ ] Bead no longer stores notes or labels\n- [ ] updated_at and content_hash computed via BeadView\n- [ ] API/query outputs unchanged (except sourced from stores)\n\n**Invariants to re-verify**\n- [ ] updated_stamp >= all field/label/note stamps for a bead\n- [ ] content_hash is deterministic and stable for identical inputs","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768904290519,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768904290519,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768904290519,0]}
{"id":"bd-3zoj.5","created_at":[1768894651610,0],"created_by":"darin@darinsmcstudio2.lan","title":"Wire ops: Label/Dep add/remove + dot/dvv; remove labels/notes from patch","description":"**Problem**\nWireBeadPatch carries labels and NotesPatch; deps are LWW ops. We need explicit OR-Set ops.\n\n**Files**\n- src/core/wire_bead.rs","design":"Remove:\n- WireBeadPatch.labels\n- NotesPatch from patch\n- WireDepV1/WireDepDeleteV1\nAdd:\n- WireDotV1, WireDvvV1\n- WireLabelAddV1/RemoveV1\n- WireDepAddV1/RemoveV1\nUpdate TxnOpV1 and TxnOpKey (include dot in add keys).","acceptance_criteria":"- [ ] TxnDeltaV1 roundtrips with new ops\n- [ ] Legacy dep ops removed\n- [ ] TxnOpKey includes dot for add ops\n\n**Invariants to re-verify**\n- [ ] TxnOpKey uniqueness preserved for multiple dots on same value\n- [ ] No labels/notes on WireBeadPatch; no dep upsert/delete ops","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768908044309,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768908044309,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768908044309,0]}
{"id":"bd-3zoj.6","created_at":[1768894651813,0],"created_by":"darin@darinsmcstudio2.lan","title":"Event encode/decode + semantic validation","description":"**Problem**\nEvent codec only supports old ops; validation only checks limits.\n\n**Files**\n- src/core/event.rs","design":"Update encode/decode for new Label/Dep ops with dot/dvv. Remove legacy dep ops. Add semantic validation:\n- reject Keep-based workflow/claim patches for touched fields\n- reject legacy full-set labels (no longer encoded)\nKeep size/limits validation.","acceptance_criteria":"- [ ] New ops encode/decode roundtrip\n- [ ] D1 invalid patches rejected pre-WAL\n\n**Invariants to re-verify**\n- [ ] encode->decode->encode is stable for new ops\n- [ ] D1 semantic validation rejects Keep-based claim/closure patches","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768909791801,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768909791801,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768909791801,0]}
{"id":"bd-3zoj.7","created_at":[1768894652020,0],"created_by":"darin@darinsmcstudio2.lan","title":"Apply: OR-Set ops, orphans, deterministic collisions","description":"**Problem**\nApply currently errors on missing beads and collisions; deps are LWW.\n\n**Files**\n- src/core/apply.rs\n- src/core/state.rs\n- src/core/composite.rs","design":"Implement apply handlers for LabelAdd/LabelRemove and DepAdd/DepRemove. Update note handling to store in NoteStore without MissingBead errors. Replace collision errors with deterministic resolution (note_winner + bead collision policy). Update ApplyOutcome as needed for labels/notes.","acceptance_criteria":"- [ ] Apply total for note/label/dep ops\n- [ ] Collisions deterministic (no ApplyError)\n- [ ] Dep indexes updated from OR-Set membership\n\n**Invariants to re-verify**\n- [ ] Apply never errors for missing beads on label/dep/note\n- [ ] Collision resolution deterministic and convergent\n- [ ] Store stamps update only on real membership change","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768917049922,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768917049922,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768917049922,0]}
{"id":"bd-3zoj.8","created_at":[1768894652225,0],"created_by":"darin@darinsmcstudio2.lan","title":"Mutation engine: OR-Set ops + D1 patches","description":"**Problem**\nMutation engine emits full-set label patches, LWW dep ops, and Keep-based claim/closure.\n\n**Files**\n- src/daemon/mutation_engine.rs\n- src/daemon/store/runtime.rs","design":"Replace label add/remove with LabelAdd/LabelRemove ops (dot minted via StoreMeta counter). Replace dep ops with DepAdd/DepRemove + DVV context. Enforce D1 patches (explicit Set/Clear). Update note ID generation to consult NoteStore.","acceptance_criteria":"- [ ] No full-set labels in mutation path\n- [ ] Dot counter persisted on each add\n- [ ] D1 patches explicit\n\n**Invariants to re-verify**\n- [ ] Mutation engine emits only add/remove ops for labels/deps\n- [ ] D1 patches always explicit Set/Clear\n- [ ] Dot counter strictly increases per add op","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768917854958,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768917854958,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768917854958,0]}
{"id":"bd-3zoj.9","created_at":[1768894652434,0],"created_by":"darin@darinsmcstudio2.lan","title":"Query/API: use BeadView for updated_at, labels, notes","description":"**Problem**\nAPI/query layers read labels/notes and updated_at from Bead, which will be removed.\n\n**Files**\n- src/api/issues.rs\n- src/daemon/query_model.rs\n- src/daemon/query_executor.rs\n- src/core/wire_bead.rs","design":"Update all view construction to use CanonicalState::bead_view. Replace bead.updated_stamp() usage and note/label accessors with BeadView values.","acceptance_criteria":"- [ ] updated_at derived from BeadView\n- [ ] labels/notes read from stores\n\n**Invariants to re-verify**\n- [ ] updated_at reflects label/note changes\n- [ ] labels/notes sourced from stores, not Bead","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768908285277,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768908285277,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768908285277,0]}
{"id":"bd-42hq","created_at":[1769494178609,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode WAL request proof as sum type in RecordHeader","description":"**Problem**\n`RecordHeader` allows invalid combinations (e.g., `request_sha256` present without `client_request_id`), and this is enforced by runtime checks in encode/decode. That means invalid headers are representable in the type system, violating the “types tell the truth” principle.\n\nKey references:\n- `crates/beads-rs/src/daemon/wal/record.rs:65` — `RecordHeader` fields allow invalid combinations.\n- `crates/beads-rs/src/daemon/wal/record.rs:103` — runtime validation in `encode`.\n\nSeverity: integrity checks are scattered across encode/decode paths; misuse can create invalid headers before validation.","design":"**Design**\nIntroduce a dedicated request‑proof sum type and make it the only representation.\n\n- `enum RequestProof { None, Client { client_request_id: ClientRequestId, request_sha256: [u8;32] }, ClientNoHash { client_request_id: ClientRequestId } }`.\n- `RecordHeader` stores a single `request_proof: RequestProof` rather than two optional fields.\n- Encoding/decoding handles the different cases explicitly; invalid combinations become unrepresentable.\n\nMigration:\n- Add conversion helpers to maintain wire format compatibility.\n- Update all call sites constructing `RecordHeader`.","acceptance_criteria":"- [ ] `RecordHeader` cannot represent “request_sha256 without client_request_id”.\n- [ ] Encoding/decoding logic uses the new sum type and no longer needs runtime combo checks.\n- [ ] All callers updated; tests added for each `RequestProof` variant.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769582365342,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769582365342,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769582365342,0]}
{"id":"bd-43i","created_at":[1766116456365,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tombstone GC policy can allow ID reuse/resurrection","description":"**Problem**\nTombstones are GC'd after 30 days in sync merge. If an ID is resurrected after GC, collisions can reappear or deleted IDs can be reused unintentionally.\n\n**Design**\nRevisit GC: either make tombstones permanent, use a much longer TTL, or store a compact ID-reuse guard (e.g., bloom filter or min hash) to prevent resurrection. Consider making GC configurable.\n\n**Acceptance**\n- [ ] GC policy documented and configurable or safe by default\n- [ ] Regression test for resurrection after GC\n\n**Files:** src/git/sync.rs, src/core/state.rs, SPEC.md","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768442533280,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768442533280,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768442533280,0]}
{"id":"bd-441","created_at":[1767995397103,0],"created_by":"darin@darinsmcstudio2.lan","title":"cargo test fails in src/daemon/ipc.rs tests: missing BeadId import for Query::Show/Deps","description":"","priority":3,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767995576464,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767995576464,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767995576464,0]}
{"id":"bd-45pe","created_at":[1768847610471,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove unused Path import in slow-tests lifecycle","description":"tests/integration/daemon/lifecycle.rs imports Path but does not use it, causing warnings under slow-tests.","acceptance_criteria":"- unused Path import removed\\n- cargo clippy --features slow-tests -- -D warnings passes\\n- cargo test --features slow-tests passes","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768896077975,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768896077975,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768896077975,0]}
{"id":"bd-45vd","created_at":[1769554089930,0],"created_by":"darin@darinsmcstudio2.lan","title":"Outbound repl must enforce live_stream_enabled via typestate","description":"**Problem**\nOutbound replication ignores `peer.live_stream_enabled`. After handshake, we always subscribe to the broadcaster and send live events + hot-cache, even when the negotiated capability is false. This violates the wire contract and makes correctness depend on peer tolerance.\n\nThis is a classic invariant that the type system should encode: once a session is negotiated as snapshot-only, the compiler should make it impossible to call live-stream send paths.\n\n**Impact**\n- Protocol mismatch: peers that don’t support live streaming still receive live Events frames.\n- Hard-to-test correctness risk; a refactor can silently reintroduce this since nothing is type-gated.\n\n**Files**\n- `crates/beads-rs/src/daemon/repl/manager.rs` (outbound loop)\n- `crates/beads-rs/src/daemon/repl/session.rs` (handshake negotiation)\n- `crates/beads-rs/src/daemon/repl/server.rs` (inbound already gates; keep consistent)\n","design":"**Design (opinionated)**\nEncode live-stream capability in the session typestate so the compiler prevents misuse.\n\n1) Split streaming phase into two typestates (or a generic):\n```rust\nstruct StreamingLive { peer: SessionPeer }\nstruct StreamingSnapshot { peer: SessionPeer }\n// or Session<Streaming<Live>> vs Session<Streaming<SnapshotOnly>>\n```\n2) Handshake transition chooses the correct type based on `live_stream_enabled`.\n- If `live_stream_enabled == true`, transition to `StreamingLive`.\n- Else transition to `StreamingSnapshot`.\n\n3) Only expose live-stream send helpers for `StreamingLive`:\n- `send_events`, `send_hot_cache`, event subscription setup all require `&Session<*, StreamingLive>`.\n- `StreamingSnapshot` still supports `Want` handling.\n\n4) Outbound loop must respect typestate:\n- Do not create broadcaster subscription unless session is `StreamingLive`.\n- No pending-event draining/hot-cache send in snapshot-only mode.\n\n**Ordering / invariants preserved**\n- Live-stream mode preserves existing ordering semantics (round-robin/wal ordering unchanged).\n- Snapshot-only mode only sends WANT responses; ordering is still canonical via WAL/Want logic.","acceptance_criteria":"- [ ] Outbound sessions negotiated with `live_stream_enabled=false` never subscribe to live events or send hot-cache.\n- [ ] `send_events`/`send_hot_cache` are not callable for snapshot-only sessions at compile time.\n- [ ] Inbound path continues to gate live stream and remains consistent with outbound.\n- [ ] Tests cover both negotiation paths (live vs snapshot) and assert no live events sent in snapshot mode.\n- [ ] `cargo test` passes.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769557397074,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769557397074,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769557397074,0]}
{"id":"bd-47c6","created_at":[1769502945242,0],"created_by":"darin@darinsmcstudio2.lan","title":"WalRangeReader must return contiguous, validated frame batches","description":"**Problem**\n`WalRangeReader::read_range` assumes the WAL index returns contiguous sequences starting at `from_seq_excl.next()`, but it only verifies the first item. If `iter_from` yields a gap (or if index `prev_sha` diverges from the record header), we still build and send frames. This violates the implicit contract of WANT responses and can cause:\n- repeated WANT loops (gap never filled),\n- divergence / PrevMismatch at the receiver,\n- hiding index corruption until much later.\n\nThe type system does not encode “contiguous ordered frames,” so illegal batches are representable.\n\n**Files**\n- `crates/beads-rs/src/daemon/repl/runtime.rs` (WalRangeReader::read_range)\n- `crates/beads-rs/src/daemon/wal/index.rs` (iter_from ordering)","design":"**Design**\nEncode contiguity + ordering as a type and validate at construction:\n\n- Introduce `ContiguousFrames` (or `ContiguousEventBatch`) newtype:\n  - Holds `Vec<EventFrameV1>` that is strictly increasing by `origin_seq` with no gaps.\n  - Optional: store `from_seq_excl` for debug/validation.\n\n- In `WalRangeReader::read_range`:\n  - Track `expected_seq = from_seq_excl.next()`.\n  - For each `IndexedRangeItem`:\n    - If `item.event_id.origin_seq != expected_seq`, return `WalRangeError::MissingRange` (or new `GapInRange` error).\n    - Read record and verify:\n      - `record.header().origin_replica_id/seq` already checked.\n      - `record.header().prev_sha256` matches `item.prev_sha` (if present).\n      - `record.header().prev_sha256` matches the previous frame’s sha (for seq>1).\n    - Push frame, increment expected_seq.\n  - Return `ContiguousFrames` (convert to Vec for encode), preserving canonical ordering.\n\n**Ordering / invariants preserved**\n- Always emit frames in ascending `origin_seq` order.\n- Ensure `prev_sha256` chain is consistent (no hidden gaps).","acceptance_criteria":"- [ ] `read_range` rejects gaps after the first item (returns MissingRange/GapInRange).\n- [ ] `read_range` validates `prev_sha256` consistency between WAL index and record headers.\n- [ ] A new type (or explicit validation) guarantees contiguous ordering before sending.\n- [ ] Tests cover: contiguous success, internal gap failure, prev_sha mismatch failure.\n- [ ] `cargo test` passes.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769551924541,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769551924541,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769551924541,0]}
{"id":"bd-48a","created_at":[1765949715820,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add command aliases: deps for dep, ls for list","description":"Add common aliases for better discoverability:\n- 'deps' and 'dependencies' as aliases for 'dep'\n- 'ls' as alias for 'list'\n\nFiles: src/cli/mod.rs","priority":4,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767995808018,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767995808018,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767995808018,0]}
{"id":"bd-49o","created_at":[1765675409821,0],"created_by":"darin@darinsmcstudio2.lan","title":"Smart commit messages from beads context","description":"Make sync commit messages on refs/heads/beads/store more descriptive. Instead of 'sync: +1 created', show what actually changed:\n\n- created bd-xxx: \"Title here\"\n- updated bd-yyy desc: \"new description\"  \n- closed bd-zzz: \"reason\"\n- deleted bd-abc\n\nThis helps with debugging and auditing bead changes over time. Since these commits live on a separate ref (beads/store), they won't clutter the main code history.","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765676017014,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765676017014,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765676017014,0]}
{"id":"bd-4cic","created_at":[1770936635585,0],"created_by":"darin@darinsmcstudio2.lan","title":"Backup ref lock contention degrades realtime refresh and latency","description":"**Problem**\nRepositories with many `refs/beads/backup/*` refs show lock contention and repeated background refresh warnings (including `*.lock` acquisition failures). In a pathological repo with hundreds of backup refs, this materially degrades perceived CLI latency and realtime freshness.\n\nThis appears as repeated warnings during daemon refresh and intermittent slowdown in non-JSON interactive paths.","design":"Harden backup-ref handling for realtime operation:\n1. Prevent read/refresh paths from blocking on backup-ref lock contention.\n2. Add stale lockfile cleanup policy (age/PID-aware) for backup ref locks.\n3. Bound or compact backup refs (retention/pruning) so ref count does not grow unbounded.\n4. Emit structured counters for backup ref scan count, lock contention, and cleanup actions.","acceptance_criteria":"- [ ] Background refresh no longer emits repeated backup-ref lock warnings under normal operation.\n- [ ] `bd ready`/`bd show` latency remains stable with large backup-ref populations.\n- [ ] Tests cover stale backup lock cleanup and contention behavior.\n- [ ] Retention/compaction policy is documented and validated.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmcstudio2.lan","assignee_expires":1770955774350,"_at":[1770952700183,0],"_by":"darin@darinsmcstudio2.lan","_v":{"acceptance_criteria":[[1770936635585,0],"darin@darinsmcstudio2.lan"],"claim":[[1770952174350,0],"darin@darinsmcstudio2.lan"],"description":[[1770936635585,0],"darin@darinsmcstudio2.lan"],"design":[[1770936635585,0],"darin@darinsmcstudio2.lan"],"estimated_minutes":[[1770936635585,0],"darin@darinsmcstudio2.lan"],"external_ref":[[1770936635585,0],"darin@darinsmcstudio2.lan"],"labels":[[1770936635585,0],"darin@darinsmcstudio2.lan"],"priority":[[1770936635585,0],"darin@darinsmcstudio2.lan"],"source_repo":[[1770936635585,0],"darin@darinsmcstudio2.lan"],"title":[[1770936635585,0],"darin@darinsmcstudio2.lan"],"type":[[1770936635585,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770952700183,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770952174350,0]}
{"id":"bd-4f5","created_at":[1768503254251,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replication watermarks should use Seq0 typed values","description":"**Problem**\nReplication protocol types (`WatermarkMap`, `Want`, `Ack`) use raw `u64` sequence numbers in `src/daemon/repl/proto.rs`. Multiple layers then convert these to `Seq0`/`Watermark`, which is easy to misuse and obscures invariants.\n\n**Files**\n- src/daemon/repl/proto.rs\n- src/daemon/repl/session.rs\n- src/daemon/repl/peer_acks.rs\n- src/daemon/repl/runtime.rs\n- src/daemon/repl/want.rs","design":"Introduce a typed wire map (e.g., `WireSeq0` or `WireWatermarkMap`) that stores `Seq0` in memory and encodes/decodes as `u64` on the wire. Replace `WatermarkMap` aliases with the typed version across replication logic, and update CBOR encoding/decoding accordingly. This keeps all internal code on `Seq0`/`Watermark` while preserving the protocol format.","acceptance_criteria":"- [ ] Replication protocol code uses `Seq0`-typed watermark values internally.\n- [ ] Encode/decode preserves the existing on-wire format.\n- [ ] All conversions from raw `u64` removed from session/peer_acks paths.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768510077718,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768510077718,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768510077718,0]}
{"id":"bd-4p8l","created_at":[1768636568110,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replication e2e under real network pathologies","description":"**Problem**\nTailnet proxy + rig only cover loopback TCP; we do not exercise half-open resets, blackholes, or NAT-ish failures. This leaves a critical gap in confidence for real deployments where connections stall or reset mid-stream.","design":"**Design**\n- Extend `tailnet_proxy` to support a new profile that can: (a) accept and then blackhole reads/writes, (b) inject hard resets after N frames/bytes, and (c) simulate one-way loss.\n- Add a rig option to select this profile per link.\n- Add a slow e2e in `tests/integration/daemon/repl_e2e.rs` that runs under the new profile and asserts reconnection + convergence.","acceptance_criteria":"- [ ] New proxy profile covers blackhole + reset behaviors.\n- [ ] New slow e2e uses ReplRig with the profile and passes locally.\n- [ ] Replication converges after faults; no hang.\n- [ ] Cleanup leaves no orphaned processes/sockets.\n- [ ] Tests write only under ./tmp.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768639205241,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768639205241,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768639205241,0]}
{"id":"bd-4rhy","created_at":[1768774750291,0],"created_by":"darin@darinsmcstudio2.lan","title":"Observability: propagate spans into background workers","description":"**Problem**\nSpans are not propagated into background threads, so logs from git worker, repl loops, and server threads lose parent context.\n\n**Design**\n- Capture `Span::current()` before spawning threads and use `span.in_scope(...)` or `tracing::Instrument` inside thread bodies.\n- Apply to daemon worker spawns (git worker, repl server/manager, coord refresh loops, etc.).\n\n**Acceptance**\n- [ ] Background worker logs include parent span context where applicable.\n- [ ] No functional behavior changes; tests remain green.\n\n**Files:** src/daemon/git_worker.rs, src/daemon/coord.rs, src/daemon/repl/manager.rs, src/daemon/repl/server.rs, src/daemon/run.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768813480792,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768813480792,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768813480792,0]}
{"id":"bd-4v16","created_at":[1768508732268,0],"created_by":"darin@darinsmcstudio2.lan","title":"Refactor daemon coordinator/request routing","description":"**Problem**\n- `src/daemon/core.rs` is a ~4.7k-line god module mixing request dispatch, read gates, scheduling, replication handles, and store access.\n- Coordinator logic is hard to reason about and hard to test in isolation.\n\n**Files:**\n- src/daemon/core.rs\n- src/daemon/server.rs\n- src/daemon/executor.rs\n- src/daemon/query_executor.rs\n- src/daemon/mod.rs","design":"- Introduce `src/daemon/coord/` (or `coordinator.rs`) containing request dispatch, read gating, and scheduling.\n- `Daemon` becomes a thin facade or a type alias to `Coordinator` to preserve API shape.\n- Move helpers like `handle_request`, `normalize_*`, and deadline calculations into the coordinator module.\n- Keep executor/query modules unchanged except for imports.","acceptance_criteria":"- [ ] Coordinator logic is in its own module with a clear API.\n- [ ] `src/daemon/core.rs` shrinks to wiring + data holders or is replaced by a coordinator module.\n- [ ] Server loop uses the coordinator interface without behavior changes.\n- [ ] `cargo test` passes.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768541272969,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768541272969,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768541272969,0]}
{"id":"bd-54n2","created_at":[1768710050218,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright repl: full symmetry for replica ids","description":"**Problem**\nSymmetry reduction currently only canonicalizes actor indices; replica IDs embedded in stream keys keep equivalent states distinct. This limits reduction for 3+ replicas.\n\n**Design**\n- Introduce a model-local replica key (index) used for stream keys/digests/invariants.\n- Keep a mapping Id -> ReplicaId for production ingest/frames; convert only at the model boundary.\n- Implement Rewrite<Id> for the model-local replica key / stream key so Representative can rewrite it.\n- Ensure no production logic is reimplemented; adapters remain thin.\n\n**Acceptance**\n- [ ] Symmetry on reduces state space further for >=3 replicas vs current baseline.\n- [ ] All invariants still pass.\n- [ ] Models still use production ingest adapters only.\n\n**Files**\n- beads_stateright_models/examples/repl_core_machine.rs\n- (optional) src/model/* adapters if a model-only key type is needed","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768717912302,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768717912302,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-59d","created_at":[1765949712708,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add bd create --file for bulk creation from markdown","description":"beads-go supports creating beads from a markdown file:\n  bd create --file issues.md --type feature\n\nThis enables batch creation workflows. Also consider --from-template support.\n\nFiles: src/cli/mod.rs, src/cli/commands/create.rs","priority":3,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767999821696,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767999821696,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767999821696,0]}
{"id":"bd-5c9i","created_at":[1768820007934,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace ReplRigOptions bool flags with typed enums","description":"**Problem**\\nReplRigOptions uses boolean flags (e.g. use_store_id_override, checkpoints_enabled) that hide intent and violate type_design.md; callers can misread or mix states.\\n\\n**Design**\\n- Introduce small enums (e.g. StoreIdOverride::{Enabled, Disabled}, CheckpointMode::{Enabled, Disabled}) or a single ReplRigMode struct with typed fields.\\n- Replace bool fields in ReplRigOptions and update call sites/tests to use the enums.\\n- Keep defaults explicit via Default impl or helper constructors.\\n\\n**Acceptance**\\n- [ ] No boolean flags remain for ReplRigOptions modes.\\n- [ ] Call sites updated to use typed enums.\\n- [ ] Tests compile and pass.\\n\\n**Files**: tests/integration/fixtures/repl_rig.rs, tests/integration/daemon/repl_e2e.rs, tests/e2e.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768822546241,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768822546241,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768822546241,0]}
{"id":"bd-5cay","created_at":[1768673120786,0],"created_by":"darin@darinsmcstudio2.lan","title":"Realtime: interleaving replay harness (read iMocket + ER-π first)","description":"**Problem**\nWe do not have interleaving-aware testing for replication; subtle message-order bugs can slip through even when the model looks right.","design":"**Design**\n- First: fully read the papers in order before coding.\n  1) iMocket: Model Checking Guided Incremental Testing for Distributed Systems\n     https://dl.acm.org/doi/10.1145/3728883\n  2) ER-π: Exhaustive Interleaving Replay for Testing Replicated Data Library Integration\n     https://people.cs.vt.edu/provakar/Middleware_25__ER_%F0%9D%9C%8B_.pdf\n- Extract concrete mechanisms we can implement (interleaving capture, scheduling control, replay).\n- Implement a targeted interleaving replay harness for beads replication tests: record message orderings for repl sessions + tailnet proxy, replay deterministically, and integrate into slow-tests/CI.","acceptance_criteria":"**Acceptance**\n- [ ] Notes summarizing both papers are captured in the bead (or linked), and key mechanisms chosen.\n- [ ] Interleaving replay harness exists and is used by at least one replication e2e test.\n- [ ] Harness can replay a captured trace deterministically and fail on divergence.\n- [ ] Tests write only under ./tmp and pass with `cargo test --features slow-tests`.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","notes":[{"id":"go-comment-bd-5cay-1","content":"Notes from papers:\n\n- iMocket: incremental model-checking-guided testing. Model checker generates traces for tests; when the model changes, only affected states are re-tested via incremental testing patterns. Uses a growth-based graph traversal algorithm to identify affected states and minimize the required tests compared to full re-checking.\n\n- ER-π: exhaustive interleaving replay for replicated libraries. Workflow: instrument Start/End around the code segment; proxy intercepts library calls to extract operations + events; generate interleavings, reset replicas between runs, and enforce a chosen interleaving via a distributed lock. Pruning techniques include event grouping, replica-specific pruning, event-independence pruning, and skipping failed ops.\n\nChosen mechanisms to implement now:\n- Intercept replication frames via tailnet proxy, record the observed interleaving order, and replay deterministically.\n- Deterministic replay enforcement with a strict order (fails if the run diverges).\n- Keep trace files per link under ./tmp; integrate in a slow e2e test.","author":"darin@book","at":[1768726414980,0]},{"id":"legacy-notes","content":"Notes from papers:\n\n- iMocket: incremental model-checking-guided testing. Model checker generates traces for tests; when the model changes, only affected states are re-tested via incremental testing patterns. Uses a growth-based graph traversal algorithm to identify affected states and minimize the required tests compared to full re-checking.\n\n- ER-π: exhaustive interleaving replay for replicated libraries. Workflow: instrument Start/End around the code segment; proxy intercepts library calls to extract operations + events; generate interleavings, reset replicas between runs, and enforce a chosen interleaving via a distributed lock. Pruning techniques include event grouping, replica-specific pruning, event-independence pruning, and skipping failed ops.\n\nChosen mechanisms to implement now:\n- Intercept replication frames via tailnet proxy, record the observed interleaving order, and replay deterministically.\n- Deterministic replay enforcement with a strict order (fails if the run diverges).\n- Keep trace files per link under ./tmp; integrate in a slow e2e test.","author":"darin@darinsmcstudio2.lan","at":[1768726624161,0]}],"_at":[1768726624161,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768726624161,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768726624161,0]}
{"id":"bd-5jd","created_at":[1768495986989,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tests for namespace propagation in issue views","description":"**Problem**\\nIssue views now include namespace, but we lack a focused test to lock down propagation for Issue (not just IssueSummary).","design":"Add a unit test in src/daemon/query_executor.rs that exercises Issue::from_bead via the query executor path and asserts Issue.namespace == read namespace. Use a non-core NamespaceId to ensure it's not defaulted.","acceptance_criteria":"- [ ] Test asserts Issue.namespace equals read namespace\\n- [ ] Existing helpers updated if needed","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768496319186,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768496319186,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768496319186,0]}
{"id":"bd-5lag","created_at":[1769563863691,0],"created_by":"darin@darinsmcstudio2.lan","title":"checkpoint import must reject unsupported format versions","description":"Problem\n- CheckpointMeta.checkpoint_format_version is parsed but never validated in import_checkpoint or read_checkpoint_export_at_oid.\n- We can deserialize a future/incompatible format and then attempt to parse it as v1, producing undefined state.\n- The invariant \"only known checkpoint formats may be imported\" is implicit and unchecked.\n\nImpact\n- Silent mis-parse or partial state on format upgrades.\n- Compiler can't help because version compatibility is not encoded in types.\n","design":"Design\n- Introduce a CheckpointFormatVersion enum (currently only V1) and a ParsedCheckpointMeta wrapper that is guaranteed to be supported.\n- Provide a single parse entry point (e.g., CheckpointMeta::parse_supported(bytes) or CheckpointExport::try_from_blobs) that validates:\n  - checkpoint_format_version is supported.\n  - manifest_hash/content_hash match canonical encodings.\n  - meta/manifest namespace lists are normalized and equal (fail otherwise).\n- import_checkpoint / import_checkpoint_export should only accept ParsedCheckpointMeta + ParsedCheckpointManifest, so version gating is enforced by the type system.\n\nScatter fit\n- Centralize all version+hash checks at parse boundary; downstream code should see only validated types.\n\nFiles\n- crates/beads-rs/src/git/checkpoint/meta.rs\n- crates/beads-rs/src/git/checkpoint/manifest.rs\n- crates/beads-rs/src/git/checkpoint/import.rs\n- crates/beads-rs/src/git/checkpoint/publish.rs\n- crates/beads-rs/src/git/checkpoint/cache.rs","acceptance_criteria":"Acceptance\n- import_checkpoint and import_checkpoint_export reject unsupported checkpoint_format_version with a clear error.\n- All call sites consume a supported/validated meta type (compile-time enforcement).\n- Tests cover: unsupported version, mismatched meta/manifest namespaces, and valid v1 import.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769572208817,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769572208817,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769572208817,0]}
{"id":"bd-5mi4","created_at":[1769565878786,0],"created_by":"darin@darinsmcstudio2.lan","title":"mutation: forbid AddDep with Parent; encode single-parent invariant","description":"Problem\n- ParsedMutationRequest::AddDep allows DepKind::Parent.\n- This bypasses the SetParent path and can create multiple parents for a bead.\n- The \"single parent\" invariant exists only in call-site discipline; the compiler can't enforce it.\n\nImpact\n- Tree semantics for hierarchy can be broken silently.\n- Violates parse-don't-validate and introduces \"lies\" (API implies any dep kind is valid).\n","design":"Design\n- Remove Parent from the AddDep surface: either reject DepKind::Parent in parse_add_dep or expose a distinct request type for parents only.\n- Encode parent edges as a dedicated operation with its own validated type (e.g., ParentEdgeAdd { child, parent, proof: NoCycleProof }).\n- Optionally encode in DepKind by splitting Parent into a distinct enum used only in SetParent.\n- Ensure apply path guarantees at most one Parent edge (remove existing parent before add, as plan_set_parent does).\n\nScatter fit\n- Parent invariants live in one operation; other dep ops cannot express Parent at all.\n\nFiles\n- crates/beads-rs/src/daemon/mutation_engine.rs\n- crates/beads-core/src/dep.rs\n- crates/beads-core/src/domain.rs (if splitting enum)\n- crates/beads-core/src/event.rs (validation)","acceptance_criteria":"Acceptance\n- AddDep rejects DepKind::Parent at parse boundary.\n- SetParent is the only way to create parent edges, and it removes prior parent edges.\n- Tests confirm multiple parents cannot be introduced via any mutation path.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769593489986,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769593489986,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769593489986,0]}
{"id":"bd-5sd","created_at":[1768345739300,0],"created_by":"darin@darinsmcstudio2.lan","title":"Spec-aligned WAL/event invariants and idempotency canonicalization","description":"","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768348610335,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768348610335,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-5szt","created_at":[1769563176541,0],"created_by":"darin@darinsmcstudio2.lan","title":"HELLO/WELCOME nonces are unused; make them real or remove","description":"**Problem**\nThe replication protocol includes `hello_nonce` and `welcome_nonce`, but they are never validated or correlated to a specific handshake attempt. They add apparent structure without enforcing any invariant. This is \"noise\" and \"lies\" per scatter: the types claim correlation that doesn’t exist.\n\n**Impact**\n- Gives a false sense of replay protection.\n- Adds fields that look load‑bearing but are not, increasing cognitive load.\n\n**Files**\n- `crates/beads-rs/src/daemon/repl/proto.rs` (wire fields)\n- `crates/beads-rs/src/daemon/repl/session.rs` (handshake transitions)\n","design":"**Design (pick one)**\nOption A (make them real):\n- Thread an `expected_hello_nonce` through the Handshaking state.\n- Include `hello_nonce` in `Welcome` (protocol change) or echo it back via a new field so the receiver can validate it.\n- Reject mismatched nonces at the parse boundary.\n\nOption B (remove):\n- Drop `hello_nonce` / `welcome_nonce` from the protocol if we don’t need replay correlation.\n- Simplify session state and tests.\n\nEither way, the type should tell the truth.","acceptance_criteria":"- [ ] Nonces are either enforced at handshake or removed entirely.\n- [ ] No field remains that is never validated.\n- [ ] Tests cover nonce mismatch rejection (if enforced) or updated wire schema (if removed).\n- [ ] `cargo test` passes.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769773164288,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769773164288,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769773164288,0]}
{"id":"bd-5un","created_at":[1768422496489,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tests: remove global env locks by avoiding env mutation","description":"**Problem**\nTests currently serialize via a global env lock because fixtures set process-wide env (BD_DATA_DIR/XDG_RUNTIME_DIR/BD_WAL_DIR). This blocks parallel execution and is fragile.\n\n**Design**\n- Avoid global env mutation in tests.\n- For CLI integration tests, set env only on the Command (already done in some fixtures).\n- For in-process IPC helpers (e.g., fixtures/load_gen using send_request), introduce explicit runtime/socket overrides instead of global env:\n  - Add test-only overrides in daemon::ipc for socket dir (similar to paths::set_data_dir_for_tests), or new send_request_* APIs that accept a socket path/runtime dir.\n  - Update fixtures to pass runtime_dir/socket path explicitly and remove std::env::set_var usage.\n- Remove env locks once overrides are in place.\n\n**Acceptance**\n- [ ] No test fixture calls std::env::set_var for BD_* or XDG_RUNTIME_DIR.\n- [ ] Realtime/load_gen/IPC fixtures accept explicit runtime/socket paths.\n- [ ] Tests run with --test-threads=8 without env-related flakiness.\n\n**Files**\n- tests/fixtures/realtime.rs\n- tests/fixtures/store_dir.rs\n- tests/fixtures/load_gen.rs\n- src/daemon/ipc.rs (test overrides or explicit socket path APIs)\n- src/paths.rs (if adding runtime dir override)\n","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768425704016,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768425704016,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768425704016,0]}
{"id":"bd-5wc","created_at":[1765690392394,0],"created_by":"darin@darinsmcstudio2.lan","title":"Daemon init should not ignore ensure_repo_loaded errors; dedupe SyncWait","description":"## What's Wrong\n`Request::Init` ignores errors from `ensure_repo_loaded` (TODO in code). Also `SyncWait` behavior is duplicated: `Daemon::handle_request` returns Synced immediately, but `run_state_loop` has special-case barrier logic.\n\n## Where\n- src/daemon/core.rs:585 (TODO: ignores ensure_repo_loaded errors after init)\n- src/daemon/core.rs:559 (SyncWait returns immediately)\n- src/daemon/server.rs:45 (SyncWait handled as a barrier before calling daemon)\n\n## Why It Matters\nInit can report success even if repo state isn't loadable, leading to confusing follow-on failures. Duplicated SyncWait logic makes correctness brittle and creates drift.\n\n## Suggested Fix\n- Make Init return an error (or include warning details) if `ensure_repo_loaded` fails.\n- Consolidate SyncWait into one place (prefer state loop barrier) and remove/clarify the other path.\n\n## Acceptance\n- `bd init` fails (or returns structured warning) when it cannot load the repo state.\n- `SyncWait` has a single source of truth (no duplicate paths).","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765774451912,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765774451912,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765774451912,0]}
{"id":"bd-5xm","created_at":[1768503185869,0],"created_by":"darin@darinsmcstudio2.lan","title":"EventBody: move hlc_max+delta into EventKindV1::TxnV1","description":"**Problem**\n`src/core/event.rs` defines `EventBody { delta: TxnDeltaV1, hlc_max: Option<HlcMax> }` and `EventKindV1::TxnV1` carries no data. The realtime plan + `beads_stateright_models/src/realtime_types_sketch.rs` expect `EventKindV1::TxnV1(TxnV1{hlc_max, delta})`. The optional `hlc_max` lets invalid events exist; the executor currently errors at runtime when it is missing (\"event missing hlc_max\"). Invariants are not encoded in the type system.\n\n**Files**\n- src/core/event.rs\n- src/daemon/mutation_engine.rs\n- src/daemon/executor.rs\n- src/daemon/repl/proto.rs (tests)\n- other event encode/decode callers","design":"Refactor the event model to match the sketch:\n- Introduce `TxnV1 { hlc_max: HlcMax, delta: TxnDeltaV1 }`.\n- Change `EventKindV1` to `TxnV1(TxnV1)`.\n- Remove `EventBody.delta` and `EventBody.hlc_max`.\n- Update canonical encode/decode to require HLC max for txn bodies; decide whether to accept legacy payloads for compatibility or reject them explicitly.\n- Update apply/verification paths and tests to construct the new `EventKindV1::TxnV1` payload.","acceptance_criteria":"- [ ] `EventBody` no longer has optional `hlc_max` or top-level `delta` fields.\n- [ ] `TxnV1` always includes `hlc_max` and `delta`, and `EventKindV1::TxnV1` carries it.\n- [ ] encode/decode enforces HLC presence; no runtime \"event missing hlc_max\" error.\n- [ ] Updated event/repl tests pass.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768518479906,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768518479906,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768518479906,0]}
{"id":"bd-5xpx","created_at":[1769501245203,0],"created_by":"darin@darinsmcstudio2.lan","title":"Parse IPC payloads into typed IDs at boundary","description":"**Problem**\nIPC payloads use raw strings for IDs, namespaces, actors, durability, and branch names. That defers parsing/validation to ad‑hoc runtime logic in the daemon, which means mistakes are not caught by the compiler and invalid payloads can slip through if a parse call is missed.\n\nExamples:\n- `MutationMeta.namespace`, `actor_id`, `durability` are `Option<String>`.\n- `IdPayload`, `DepPayload`, `CreatePayload.parent`, etc. are raw `String`.\n- `ClosePayload.on_branch` is `Option<String>`.\n\nKey refs:\n- `crates/beads-surface/src/ipc/types.rs:18`\n- `crates/beads-surface/src/ipc/payload.rs:12`\n\n**Impact**\nParse‑don’t‑validate is violated at the IPC boundary. Compiler cannot enforce that IDs and namespaces are valid.","design":"**Design (opinionated)**\nParse at the boundary. Replace raw strings with typed core IDs and enforce validation in serde.\n\n- Use `BeadId`, `NamespaceId`, `ActorId`, `BranchName`, `DurabilityClass` in IPC structs.\n- Provide custom serde/`TryFrom<String>` (already exists for most core IDs) so invalid inputs fail deserialization.\n- If backward compatibility requires strings on the wire, keep the wire format as strings but decode into typed fields immediately.\n\nThis makes “forgot to validate” a compile‑time error and rejects invalid inputs early.","acceptance_criteria":"**Acceptance**\n- [ ] IPC request structs no longer expose raw `String` for identifiers/namespace/actor/branch/durability.\n- [ ] Invalid IDs/namespaces/branches are rejected during deserialization (before daemon logic).\n- [ ] All daemon parsing code that manually validates these fields is removed or reduced to unavoidable business‑logic checks.\n- [ ] Tests cover IPC decode failure on invalid IDs and success on valid inputs.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769549538751,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769549538751,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769549538751,0]}
{"id":"bd-5xvc","created_at":[1768680790093,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright repl: symmetry reduction","description":"**Problem**\nReplication models will blow up in state space without symmetry reduction. We are not using Stateright’s Representative/Rewrite system.\n\n**Goal**\nAdd symmetry reduction to the ActorModel replication state to keep searches tractable without weakening invariants.","design":"**Design**\n1) Implement `Representative` for the repl model state (or the auxiliary history type) to canonicalize actor identities.\n2) Use `Rewrite`/`RewritePlan` to reindex per-actor maps/sets.\n3) Validate that properties remain invariant under symmetry (no identity-sensitive checks unless intentionally pinned).\n4) Turn on `checker().symmetry()` in the example when using symmetric network modes.\n\n**References**\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/checker/representative.rs`\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/checker/rewrite.rs`\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/examples/2pc.rs`\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/examples/increment.rs`","acceptance_criteria":"**Acceptance**\n- [ ] Repl ActorModel implements `Representative` and uses `checker().symmetry()`.\n- [ ] State space is measurably smaller for >=3 replicas (documented in model output).\n- [ ] No invariant regressions under symmetry.","priority":0,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768708903993,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768708903993,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768708903993,0]}
{"id":"bd-5yx","created_at":[1765676017114,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add daemon control commands (stop, restart, status)","description":"Add subcommands to 'bd daemon' for controlling the daemon: stop, restart, status. Currently have to kill the process manually.","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765676728012,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765676728012,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765676728012,0]}
{"id":"bd-62k","created_at":[1768245295200,0],"created_by":"darin@darinsmcstudio2.lan","title":"Crash recovery","description":"","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"empty stub - no description","_at":[1768254389466,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768254389466,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-6b7","created_at":[1766127760899,0],"created_by":"darin@darinsmcstudio2.lan","title":"Git sync state-machine robustness tests","description":"**Problem**\nWe lack explicit tests for sync behavior under diverged refs, non-fast-forward pushes, and stale local refs. Regressions here can cause data loss or stuck syncs.\n\n**Design**\nAdd tests that simulate:\n- local ahead of remote (backup ref created, local not clobbered)\n- remote ahead of local (fast-forward update succeeds)\n- local/remote diverged (divergence flagged, sync outcome carries warning)\n- push non-fast-forward retry loop respects max_retries\nUse temp git repos with controlled commit graphs.\n\n**Acceptance**\n- [ ] Tests cover the above scenarios\n- [ ] Sync outcome divergence is surfaced\n- [ ] No data loss (local commits preserved)\n\n**Files:** src/git/sync.rs, tests/git_sync.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768427148596,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768427148596,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768427148596,0]}
{"id":"bd-6c9","created_at":[1765676863872,0],"created_by":"darin@darinsmcstudio2.lan","title":"Refactor send_request and send_request_no_autostart to share common code","description":"## What's Wrong\nsend_request and send_request_no_autostart in src/daemon/ipc.rs duplicate the request encoding/response parsing logic.\n\n## Where\n- src/daemon/ipc.rs:828-838 (send_request)\n- src/daemon/ipc.rs:844-859 (send_request_no_autostart)\n\n## Why It Matters\nIf we change the wire format or add error handling, we need to update both places.\n\n## Suggested Fix\nExtract common send/receive logic into a helper that takes a stream.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765677829208,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765677829208,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765677829208,0]}
{"id":"bd-6eh","created_at":[1768257837230,0],"created_by":"darin@darinsmcstudio2.lan","title":"Integration tests isolate BD_DATA_DIR per runtime","description":"Integration tests that spawn `bd` set runtime/WAL dirs but not BD_DATA_DIR. The daemon then uses the default store path and can collide with a developer daemon or other test daemons, causing lock_held failures.","design":"Derive a temp data dir from each test runtime dir (e.g., runtime_dir/data) and set BD_DATA_DIR on every integration-test `bd` command (helpers + direct invocations). Ensure the directory exists before spawning commands.","acceptance_criteria":"- [ ] All integration-test helpers and raw commands set BD_DATA_DIR per runtime\n- [ ] daemon_lifecycle and critical_path tests no longer fail due to store lock conflicts\n- [ ] cargo test passes (or targeted suites) after the change","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768258334065,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768258334065,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768258334065,0]}
{"id":"bd-6f7t","created_at":[1770668709339,0],"created_by":"darin@darinsmcstudio2.lan","title":"Deduplicate beads-cli command helpers flagged by Bugbot (fmt_wall_ms/fetch_issue)","description":"","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmcstudio2.lan","_at":[1770673650107,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770673650107,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770673650107,0]}
{"id":"bd-6gz5","created_at":[1769309224735,0],"created_by":"darin@darinsmcstudio2.lan","title":"Extract cli/validation.rs module for normalization helpers","description":"**Problem**\nValidation and normalization helpers are scattered in src/cli/mod.rs (lines 1327-1510), ~200 lines mixed with other code:\n\n- `normalize_bead_id()` (line 1351)\n- `normalize_bead_ids()` (line 1359)\n- `normalize_bead_id_for()` (line 1366)\n- `normalize_bead_slug_for()` (line 1368)\n- `normalize_optional_namespace()` (line 1399)\n- `normalize_optional_client_request_id()` (line 1420)\n- `apply_common_filters()` (line 1479)\n- `normalize_dep_specs()` (line 1499)\n\nThese handle CLI arg validation before sending to daemon. Extracting improves discoverability and enables reuse.\n\n**Design**\n1. Create `src/cli/validation.rs`\n2. Move all normalization/validation helpers there\n3. Include the `validation_error()` helper (from related bead) here\n4. Update imports\n\n```rust\n// src/cli/validation.rs\nuse crate::core::BeadId;\nuse crate::daemon::OpError;\nuse crate::Error;\n\npub(crate) fn validation_error(field: impl Into<String>, reason: impl Into<String>) -> Error { ... }\n\npub(crate) fn normalize_bead_id(id: &str) -> Result<BeadId, Error> { ... }\npub(crate) fn normalize_bead_ids(ids: &[String]) -> Result<Vec<BeadId>, Error> { ... }\npub(crate) fn normalize_bead_id_for(field: &str, id: &str) -> Result<BeadId, Error> { ... }\n// ... etc\n```\n\n**Design Notes**\n- This can be done independently of parsers.rs extraction\n- If validation_error() bead is done first, just move it here\n- apply_common_filters() may need to stay in mod.rs if it depends on Args types that arent extracted yet\n\n**Acceptance**\n- [ ] src/cli/validation.rs created\n- [ ] All normalize_* functions moved from mod.rs\n- [ ] validation_error() helper included (or imported if separate bead done first)\n- [ ] Command handlers import from validation module\n- [ ] cargo clippy passes\n- [ ] cargo test passes\n\n**Files:** src/cli/mod.rs, src/cli/validation.rs (new), src/cli/commands/*.rs","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769772690659,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769772690659,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769772690659,0]}
{"id":"bd-6jk","created_at":[1768422572434,0],"created_by":"darin@darinsmcstudio2.lan","title":"Profile test suite with samply","description":"Capture samply profile for cargo test and summarize hotpaths.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Captured samply-test-suite.json; top samples in nanosleep/semwait + bd process wait time; identified IPC ping + extra create round-trip + test data-dir lock as bottlenecks.","assignee":"darin@book","_at":[1768432004656,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768432004656,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768432004656,0]}
{"id":"bd-6k70","created_at":[1768672347696,0],"created_by":"darin@darinsmcstudio2.lan","title":"Realtime: checkpoint bootstrap under churn","description":"**Problem**\nReplication snapshots are deferred in v0.5, so large catch-up relies on checkpoints. We do not stress or validate checkpoint-based bootstrap under high churn.","design":"**Design**\n- Add a slow e2e that generates large WALs + checkpoints, then brings up a fresh node and verifies catch-up via checkpoints + WAL tail.\n- Assert bounded convergence time and correct watermarks/heads after bootstrap.","acceptance_criteria":"**Acceptance**\n- [ ] Slow e2e exercises checkpoint-based bootstrap for a fresh node under heavy churn.\n- [ ] Watermarks/heads converge across nodes after bootstrap.\n- [ ] Tests write only under ./tmp and pass with `cargo test --features slow-tests`.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768725189867,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768725189867,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768725189867,0]}
{"id":"bd-6lv","created_at":[1768448962846,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replication pending_events queue is unbounded","description":"**Problem**\nBoth inbound and outbound replication loops buffer events before streaming is established, but the pending_events Vec has no size/byte bound. If handshake stalls or a peer stays non-streaming, this can grow without bound and consume memory.\n\n**Evidence**\n- src/daemon/repl/manager.rs: pending_events: Vec<BroadcastEvent> grows while !streaming.\n- src/daemon/repl/server.rs: pending_events: Vec<BroadcastEvent> grows while !streaming.\n\n**Why this hurts**\nA slow or stuck peer can cause unbounded memory growth in the daemon, which is brittle and hard to reason about.","design":"**Design**\nOption A: Replace pending_events with a bounded VecDeque that caps both event count and bytes (use limits.max_event_batch_events / max_event_batch_bytes or broadcaster hot-cache limits). Drop oldest events and record a metric when overflowing.\nOption B: Remove pending_events entirely and rely on hot_cache + WANT after handshake, avoiding buffering while not streaming.\n\nEither way, prevent unbounded growth and keep behavior deterministic.","acceptance_criteria":"- [ ] pending_events is bounded by size/bytes or removed entirely.\n- [ ] Overflow behavior is explicit (drop policy + metric/log).\n- [ ] Tests or assertions cover the cap behavior.\n\n**Files:** src/daemon/repl/manager.rs, src/daemon/repl/server.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768455524887,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768455524887,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768455524887,0]}
{"id":"bd-6ole","created_at":[1769236536126,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fix repl rig config ordering so WAL limits apply before init","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769562062556,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769562062556,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769562062556,0]}
{"id":"bd-6rmo","created_at":[1768506375830,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove or wire unused default_wal_base_dir","description":"**Problem**\n`default_wal_base_dir()` in `wal_legacy_snapshot.rs` is marked `#[allow(dead_code)]` and has no callers. This is legacy-only and adds confusion about which WAL path is authoritative.\n\n**Files**\n- src/daemon/wal_legacy_snapshot.rs\n","design":"**Design**\n- Either remove `default_wal_base_dir()` entirely, or wire it into `Wal::new`/callers if it is still intended to be used.\n- Drop `#[allow(dead_code)]` once resolved.","acceptance_criteria":"- [ ] No unused `default_wal_base_dir` symbol remains.\n- [ ] Legacy WAL path selection is explicit (either wired or removed).","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768542524084,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768542524084,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768542524084,0]}
{"id":"bd-6w3l","created_at":[1768508733513,0],"created_by":"darin@darinsmcstudio2.lan","title":"Split api/mod.rs into domain modules","description":"**Problem**\n- `src/api/mod.rs` is ~900 LOC and mixes admin, realtime, issues, and deps types.\n- Discoverability is low and changes are noisy.\n\n**Files:**\n- src/api/mod.rs\n- src/api/admin.rs\n- src/api/issues.rs\n- src/api/realtime.rs\n- src/api/deps.rs (as needed)","design":"- Split `api/mod.rs` into domain modules and re-export from `mod.rs`.\n- Keep struct names and serde behavior unchanged.\n- Update imports across daemon/cli as needed.","acceptance_criteria":"- [ ] `src/api/mod.rs` is a re-export hub only.\n- [ ] Domain types live in dedicated files.\n- [ ] No behavior change; tests pass.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768542341282,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768542341282,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768542341282,0]}
{"id":"bd-6wr","created_at":[1766136137302,0],"created_by":"darin@darinsmcstudio2.lan","title":"Detect force-push and surface explicit warning in sync status","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766137444231,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766137444231,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766137444231,0]}
{"id":"bd-6xa","created_at":[1768492584363,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add dependency cycle detection helper in CanonicalState","description":"**Problem**\nCycle detection logic lives inline in query validation and is not reusable for the CLI dep cycles command.\n\n**Design**\nAdd a CanonicalState helper (e.g., dependency_cycles) that returns detected cycles over active deps (all kinds). Keep it deterministic by sorting inputs and returning stable paths.\n\n**Acceptance**\n- [ ] New cycle detection helper in src/core/state.rs (or src/core/dep.rs)\n- [ ] Tests cover at least one cycle and one acyclic graph\n- [ ] Helper returns deterministic ordering","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768492792001,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768492792001,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-70v","created_at":[1766127044862,0],"created_by":"darin@darinsmcstudio2.lan","title":"Test epic for show","description":"","priority":3,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"test cleanup","_at":[1766127067042,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766127067042,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-70v.1","created_at":[1766127050255,0],"created_by":"darin@darinsmcstudio2.lan","title":"Subtask A","description":"","priority":3,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"test cleanup","_at":[1766127066836,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766127066836,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-70v.2","created_at":[1766127054411,0],"created_by":"darin@darinsmcstudio2.lan","title":"Subtask B","description":"","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"test cleanup","_at":[1766127066937,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766127066937,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-74vc","created_at":[1768777666457,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add admin checkpoint wait to remove polling in repl_e2e","description":"tests/integration/daemon/repl_e2e.rs wait_for_checkpoint polls admin_status every 50ms. Add an admin IPC/API that can force checkpoint and block until completion (or expose a wait-for-checkpoint command). Update tests to call it instead of polling.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768813070745,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768813070745,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768813070745,0]}
{"id":"bd-75r4","created_at":[1768719786990,0],"created_by":"darin@darinsmcstudio2.lan","title":"CLI create --file: avoid per-issue fetch for human output","description":"src/cli/commands/create.rs handle_from_markdown_file fetches each created issue to print. For non-JSON output, avoid extra Show and print from template + created id; keep fetch only for --json.","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768758529307,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768758529307,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768758529307,0]}
{"id":"bd-75w","created_at":[1768431978064,0],"created_by":"darin@darinsmcstudio2.lan","title":"Create op should return Issue to skip extra show","description":"**Problem**\\nCLI create does a mutation then immediately queries show to render JSON/human output. In integration tests this doubles IPC round-trips and shows up as wait time in profiling.\\n\\n**Design**\\nAdd an optional Issue payload on OpResponse. When the mutation result is Created, attach Issue::from_bead from the updated state. CLI should consume OpResponse.issue when present and skip the follow-up show; fall back to current behavior when missing.\\n\\n**Acceptance**\\n- [ ] OpResponse serializes issue when created\\n- [ ] CLI create uses issue when present and avoids extra IPC query\\n- [ ] Existing JSON output shape remains (QueryResult::Issue)\\n- [ ] Tests updated/added to cover issue attachment\\n\\n**Files**: src/daemon/executor.rs, src/daemon/ipc.rs, src/cli/commands/create.rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"OpResponse now carries optional Issue for Created ops; daemon attaches issue from state, CLI reuses it to skip extra show; added executor test.","assignee":"darin@book","_at":[1768432627654,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768432627654,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768432627654,0]}
{"id":"bd-796","created_at":[1768252077046,0],"created_by":"darin@darinsmcstudio2.lan","title":"Validate WAL record header vs EventBody payload","description":"**Problem**\nRecord header fields (origin_replica_id, origin_seq, event_time_ms, txn_id, client_request_id) are not validated against decoded EventBody bytes during replay or fsck. Corrupted headers can silently diverge while sha matches payload. REALTIME_PLAN.md 5.2 requires header consistency checks.\n\n**Design**\nDecode EventBody from Record.payload using core::decode_event_body (limits) in replay and fsck; compare fields with RecordHeader. On mismatch:\n- fsck: report corruption (new FsckEvidenceCode) and quarantine/repair per mode.\n- replay: return explicit WalReplayError (non-tail corruption).\nAdd tests with a record whose payload is valid but header is tampered; assert fsck reports mismatch and replay errors.\n\n**Acceptance**\n- [ ] Header/body mismatches are detected in replay and fsck.\n- [ ] Fsck report includes deterministic evidence code.\n- [ ] Tests cover header mismatch path; cargo test passes.\n\n**Files:** src/daemon/wal/replay.rs, src/daemon/wal/fsck.rs, src/daemon/wal/record.rs, tests/phase3_fsck.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768256192277,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768256192277,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-7abk","created_at":[1769494178815,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode acyclic ordering deps in types","description":"**Problem**\n`DepKind::Blocks` and `DepKind::Parent` are documented as DAG‑only (acyclic), but core apply does not enforce acyclicity. Only the mutation engine checks cycles for local ops; replicated/WAL events can introduce cycles that violate domain invariants.\n\nBecause core accepts raw `WireDepAddV1` with `DepKind` and no proof, the compiler cannot enforce that DAG checks happened. This is a correctness gap: cycles can silently enter CanonicalState and break ready/blocked semantics.\n\nKey refs:\n- `crates/beads-core/src/domain.rs:77` — `Blocks`/`Parent` require DAG.\n- `crates/beads-core/src/apply.rs:284` — no cycle check in core apply.\n- `crates/beads-rs/src/daemon/mutation_engine.rs:1119` — cycle check only in mutation engine.\n\n**Impact**\nDomain invariants are violated by replicated input. Ready/blocked computation can be wrong; parent semantics can become ambiguous.","design":"**Design (opinionated)**\nMake DAG enforcement a *type boundary* so cycle checks cannot be skipped.\n\n1) Split dependency edge types by invariant:\n- `struct AcyclicDepKey(DepKey)` for `Blocks`/`Parent` only.\n- `struct FreeDepKey(DepKey)` for `Related`/`DiscoveredFrom`.\n\n2) Require explicit proof for DAG edges:\n- `CanonicalState::check_no_cycle(from, to, kind) -> Result<NoCycleProof, DepError>`.\n- `AcyclicDepKey::new(from, to, kind, proof)` consumes `NoCycleProof`.\n\n3) Narrow core apply API:\n- `apply_dep_add` for DAG kinds requires `AcyclicDepKey`.\n- `apply_dep_add` for non‑DAG kinds accepts `FreeDepKey`.\n- This forces every insertion site (including repl/WAL) to perform the cycle check before creating the key.\n\n4) Event boundary conversion:\n- When decoding `WireDepAddV1`, convert to `AcyclicDepKey` only if `kind.requires_dag()`, otherwise to `FreeDepKey`.\n- Failed cycle checks return a deterministic error at the ingest boundary (not deep in apply).\n\nThis makes “forgot to check DAG” a compile‑time error.","acceptance_criteria":"**Acceptance**\n- [ ] There is no way to add `Blocks`/`Parent` deps in core without a `NoCycleProof` (compile‑time enforced).\n- [ ] Replication/WAL ingestion validates acyclicity for DAG kinds before apply.\n- [ ] Non‑DAG kinds remain unaffected and do not require cycle checks.\n- [ ] Tests cover: rejecting a cycle from replicated input, and successful add for acyclic DAG edges.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769516460227,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769516460227,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769516460227,0]}
{"id":"bd-7b9","created_at":[1765780574598,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove just --list from bd prime; remove repo hook in favor of global","description":"Two cleanup items:\n1. bd prime currently shows just --list output - remove this\n2. The claude code hook in this repo should be removed; leave it configured globally instead","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767998191864,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767998191864,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767998191864,0]}
{"id":"bd-7c8","created_at":[1768494745897,0],"created_by":"darin@darinsmcstudio2.lan","title":"Document CLI read gating flags","description":"**Problem**\nCLI_SPEC.md does not document the read gating flags required by REALTIME_PLAN, which makes the feature discoverability poor for realtime debugging.\n\n**Design**\nUpdate CLI_SPEC.md to describe `--require-min-seen` (JSON Watermarks<Applied>) and `--wait-timeout-ms` semantics, with a short JSON example.\n\n**Files**\n- CLI_SPEC.md","acceptance_criteria":"- [ ] CLI_SPEC.md documents both flags and their semantics\n- [ ] Example JSON for require-min-seen included","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768495184679,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768495184679,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768495184679,0]}
{"id":"bd-7dc5","created_at":[1769815548775,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add bd defer/undefer commands for hiding beads from ready","description":"**Problem**\nNo way to temporarily hide beads from `bd ready` without closing them or manually blocking on placeholders. Current workaround requires creating a placeholder bead and adding deps to every child of an epic individually.\n\n**Design**\nAdd `bd defer` and `bd undefer` commands:\n\n```bash\nbd defer bd-xyz                    # hide from ready\nbd defer bd-xyz --until 2026-03-01 # auto-undefer on date\nbd defer bd-xyz --cascade          # also defer all children (via parent relationship)\nbd undefer bd-xyz                  # bring back to ready\nbd list --deferred                 # see what's deferred\n```\n\nImplementation options:\n1. **New field**: Add `deferred: Option<WallClock>` to bead fields (LWW). `bd ready` filters these out.\n2. **Special label**: Use a reserved label like `@deferred` that `bd ready` excludes.\n3. **Synthetic blocker**: Auto-create/manage placeholder blockers (current manual workaround, automated).\n\nOption 1 is cleanest - explicit field, clear semantics, supports expiry dates.\n\n**Acceptance**\n- [ ] `bd defer <id>` hides bead from `bd ready`\n- [ ] `bd defer <id> --cascade` defers all children via parent relationship\n- [ ] `bd defer <id> --until <date>` auto-undefers on that date\n- [ ] `bd undefer <id>` brings bead back\n- [ ] `bd list --deferred` shows deferred beads\n- [ ] `bd show` indicates deferred status\n\n**Files:**\n- `crates/beads-core/src/bead.rs` (add deferred field)\n- `crates/beads-rs/src/cli/commands/defer.rs` (new command)\n- `crates/beads-rs/src/daemon/query_executor.rs` (filter in ready query)","priority":3,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1769815563175,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-7dy","created_at":[1765745476440,0],"created_by":"darin@darinsmcstudio2.lan","title":"Dep updates don't get commit messages","description":"When dependencies are updated via bd dep add/remove, the git sync commits don't include meaningful messages about what changed. Should capture the operation in the commit message for traceability.","priority":3,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767998586056,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767998586056,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767998586056,0]}
{"id":"bd-7f3","created_at":[1765787131779,0],"created_by":"darin@darinsmcstudio2.lan","title":"git_worker.rs:78 unwrap can use entry API instead","description":"The open() method uses check-then-unwrap pattern that could use entry API for cleaner code. Not a safety issue since we just inserted if not present.","priority":4,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767995938541,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767995938541,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767995938541,0]}
{"id":"bd-7i3y","created_at":[1768776087397,0],"created_by":"darin@darinsmcstudio2.lan","title":"Observability: enforce consistent field schema","description":"**Problem**\nLog/spans use inconsistent field keys, making search and correlation brittle.\n\n**Design**\n- Define a canonical field schema for observability (e.g., request_id/trace_id, store_id, namespace, actor_id, replica_id, txn_id, client_request_id, repo).\n- Provide helper functions/macros to build spans/logs with required fields.\n- Update key entry points (IPC request handling, mutation execution, repl send/recv, git sync, admin) to use the schema.\n- Add tests or lint-style checks for required fields on critical spans.\n\n**Acceptance**\n- [ ] Critical spans/logs include required fields using standardized keys.\n- [ ] Documentation or tests enforce the schema.\n\n**Files:** src/telemetry.rs, src/daemon/server.rs, src/daemon/executor.rs, src/daemon/repl/*, src/daemon/git_worker.rs, docs/philosophy/* (if needed)","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768823227172,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768823227172,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768823227172,0]}
{"id":"bd-7ic","created_at":[1766267592386,0],"created_by":"darin@darinsmcstudio2.lan","title":"Verify bd upgrade downloads with checksums/signatures","description":"**Problem**\\nUpgrade downloads prebuilt binaries without integrity checks.\\n\\n**Design**\\nPublish release checksums (sha256) and validate downloaded archives before install. Prefer signed checksums or sigstore where possible.\\n\\n**Acceptance**\\n- [ ] Downloaded archives are verified before install\\n- [ ] Upgrade fails fast on checksum mismatch\\n- [ ] Tests cover checksum verification","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768491077315,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768491077315,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768491077315,0]}
{"id":"bd-7iil","created_at":[1769309581234,0],"created_by":"darin@darinsmcstudio2.lan","title":"Watermark merge rejects head mismatches deterministically","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769309599948,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769309599948,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769309599948,0]}
{"id":"bd-7lnn","created_at":[1768546082587,0],"created_by":"darin@darinsmcstudio2.lan","title":"rt smoke","description":"","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768727290967,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768727290967,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768727290967,0]}
{"id":"bd-7m9a","created_at":[1769573965941,0],"created_by":"darin@darinsmcstudio2.lan","title":"Unify boundary parsing via validated core types","description":"**Problem**\nBoundary parsing/normalization is duplicated across layers:\n- CLI normalization in `crates/beads-rs/src/cli/mod.rs`\n- Daemon mutation parsing in `crates/beads-rs/src/daemon/mutation_engine.rs`\n- Event CBOR decode in `crates/beads-core/src/event.rs`\n- Repl proto decode in `crates/beads-rs/src/daemon/repl/proto.rs`\n\nExample: `parse_namespace` exists in both event CBOR decode and repl proto decode; bead IDs and dep kinds are re-parsed in multiple entrypoints. This is scatter + drift risk: invariants are enforced differently depending on boundary.\n\n**Files:**\n- `crates/beads-rs/src/cli/mod.rs`\n- `crates/beads-rs/src/daemon/mutation_engine.rs`\n- `crates/beads-core/src/event.rs`\n- `crates/beads-rs/src/daemon/repl/proto.rs`\n- `crates/beads-rs/src/daemon/coord.rs`","design":"**Design**\nIntroduce shared validated boundary types for IDs/namespaces/dep kinds and require all ingress paths to construct them once.\n\nConcrete plan:\n1) Add a `validated` module in `beads-core` with types like `ValidatedBeadId`, `ValidatedNamespaceId`, `ValidatedDepKind`, `ValidatedActorId`, etc.\n2) Provide constructors that return structured errors and perform canonicalization (trim, case, allowed charset).\n3) Update CLI normalization helpers to return validated types instead of raw strings/IDs.\n4) Update daemon mutation parsing to accept validated inputs (e.g., `ValidatedBeadId`) and remove duplicate parsing/normalization logic.\n5) Update event CBOR and repl proto decoders to share the same validated constructors (no local parse_* helpers).\n\n**Design Notes**\n- Keep serialization compatibility by implementing `Display`/`Serialize` on validated types.\n- Make validated types lightweight wrappers around the core types so they’re cheap to pass around.","acceptance_criteria":"**Acceptance**\n- [ ] There is a shared `validated` module in `beads-core` for ID/namespace/dep-kind validation.\n- [ ] CLI/daemon/event/repl entrypoints use the validated constructors instead of local parsing helpers.\n- [ ] Duplicate parse/normalize helpers are removed or reduced to thin adapters.\n- [ ] Tests cover invalid inputs rejected consistently across at least two boundaries (CLI + repl).","priority":2,"type":"chore","labels":{"entries":{"scatter":[{"replica":"844315d5-314a-f32d-1b09-67d33894cce8","counter":18048143335217658867}],"types":[{"replica":"cf986fd1-9b61-71e3-9420-ce8d39bbb84d","counter":14188388958699452498}],"validation":[{"replica":"e3b3d51e-d715-9dae-67e9-86304d51e705","counter":1845922927161849912}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769757839727,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769757839727,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769757839727,0]}
{"id":"bd-7rz","created_at":[1766267786533,0],"created_by":"darin@darinsmcstudio2.lan","title":"Test bead for bv viewer integration","description":"","priority":4,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Test complete - bv integration works","_at":[1766267834772,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766267834772,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-7tx","created_at":[1768493923720,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add golden output test for bd store fsck","description":"**Problem**\nREALTIME_PLAN recommends golden corpus tests for `bd store fsck` output stability, but we currently have no CLI-level rendering tests. Output drift can silently break operator workflows.\n\n**Design**\nAdd a unit test for render_fsck_human in src/cli/commands/store.rs using a hand-built FsckReport that includes repairs and evidence. Assert exact output to lock formatting.\n\n**Files**\n- src/cli/commands/store.rs","acceptance_criteria":"- [ ] Test asserts exact human output for a representative FsckReport (repairs + evidence)\n- [ ] No changes to fsck runtime logic","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768494200580,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768494200580,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768494200580,0]}
{"id":"bd-7zf","created_at":[1767915293605,0],"created_by":"darin@darinsmcstudio2.lan","title":"Daemon load blocks on SSH auth, hangs IPC","description":"**Problem**\nFirst access to a repo blocks the daemon in `Daemon::ensure_repo_loaded` while waiting for `GitOp::Load` to finish. `GitWorker::load` always performs a remote fetch (even in best-effort mode). If SSH auth is misconfigured (no agent / passphrase prompt / stalled handshake), libgit2 fetch can hang. Because `ensure_repo_loaded` waits synchronously, the state thread blocks and IPC requests like `bd status` hang indefinitely. We saw `bd status` time out on this machine before SSH auth was configured.\n\n**Design**\nMake load non-blocking, and treat timeouts as a guardrail rather than the primary fix:\n- Split `GitWorker::load` into a fast local-only load (read local ref, compute state) and a remote refresh path.\n- Change `ensure_repo_loaded` to return local state immediately and, if the repo is stale, enqueue a background `GitOp::Refresh` (or `GitOp::Fetch`) without blocking.\n- Only block on remote fetch when no local ref exists; add a bounded timeout (default ~30s, configurable) and return a clean, actionable error on timeout with diagnostic info (SSH agent/auth hints, remote URL).\n- Surface fetch/auth errors via `fetch_error` and Sync warnings, but keep IPC responsive.\n\n**Design Notes**\nThe primary goal is responsiveness: read-only queries must not block on network or auth. Use best-effort refresh for freshness, but never let it block IPC. Timeout is a secondary safety net for unavoidable fetches. Keep existing CRDT merge semantics intact.\n\n**Acceptance**\n- [ ] `bd status` returns promptly (e.g., <1s) when SSH auth is missing/invalid; no hang.\n- [ ] If local ref exists, initial load is non-blocking and refresh happens in the background.\n- [ ] If no local ref exists, the initial fetch is bounded by a default ~30s timeout and returns a clean, actionable error on timeout with diagnostics.\n- [ ] Fetch/auth failures appear as warnings (`fetch_error`) but do not block IPC responses.\n- [ ] Background refresh still updates cached state once auth/network is available.\n- [ ] Run `codex review --uncommitted` (timeout 10m) and address findings.\n- [ ] Tests pass.\n\n**Files:** `src/daemon/core.rs`, `src/daemon/git_worker.rs`, `src/git/sync.rs`","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767918180661,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767918180661,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767918180661,0]}
{"id":"bd-82yl","created_at":[1770579209628,0],"created_by":"darin@darinsmcstudio2.lan","title":"Clear strict non-exhaustive match lint backlog (~61 findings)","description":"**Problem**\nStrict non-exhaustive matching policy is not fully enforceable yet because we still have ~61 existing findings that rely on wildcard/fallback match arms. This blocks turning the policy into a hard gate and leaves maintainability drift risk in critical paths.\n\n**Scope**\nClear the existing backlog and make the strict policy practical for day-to-day development without behavioral changes.\n\n**Files**\n- crates/beads-core/**\n- crates/beads-api/**\n- crates/beads-surface/**\n- crates/beads-daemon/**\n- crates/beads-daemon-core/**\n- crates/beads-cli/**\n- crates/beads-rs/**\n- lints/**\n- justfile\n- .github/workflows/**","design":"1. Inventory all non-exhaustive/wildcard match lint findings and bucket by crate + risk.\n2. Replace wildcard/fallback arms with explicit variant handling where behavior is known; avoid catch-all arms in typed domain logic.\n3. Where external/non_exhaustive APIs require compatibility handling, use clearly isolated boundary helpers rather than broad fallback behavior in core logic.\n4. Keep changes behavior-preserving: validate with existing tests and add focused regression tests for match behavior where ambiguity exists.\n5. Enable/retain strict lint gating so new fallback arms in typed enums are prevented by default CI flow.","acceptance_criteria":"- [ ] All known ~61 non-exhaustive lint findings are resolved or intentionally quarantined with explicit, documented rationale.\n- [ ] No new wildcard/fallback enum match arms remain in core typed domain paths.\n- [ ] `cargo clippy --all-features -- -D warnings` passes in default workspace verification flow.\n- [ ] `just dylint` passes with boundary and style gates enabled.\n- [ ] `cargo test --all-features` passes.\n- [ ] At least one regression test covers a previously wildcarded match site that could have masked future variant additions.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770592399026,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770592399026,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770592399026,0]}
{"id":"bd-84sy","created_at":[1768524022696,0],"created_by":"darin@darinsmcstudio2.lan","title":"admin_status_monotonic_under_load sometimes times out at 3s","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"fixed by bd-zl6d timeout scaling","assignee":"darin@book","_at":[1768525641723,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768525641723,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768525641723,0]}
{"id":"bd-8ezy","created_at":[1769563852300,0],"created_by":"darin@darinsmcstudio2.lan","title":"git wire: validate workflow/claim redundant fields","description":"Problem\n- WireBead carries redundant fields (status + closed_at/closed_by; assignee + assignee_at).\n- wire_to_parts ignores closed_at/closed_by/assignee_at entirely and accepts any combination.\n- This is a lie: the wire format claims timestamps/actors but the parser doesn't enforce or consume them.\n\nImpact\n- Corrupted or inconsistent store data silently loads.\n- We can't rely on the compiler to enforce the invariant that redundant fields are consistent with LWW stamps.\n- Violates parse-don't-validate and Scatter (invariants live in the reader's head).\n","design":"Design\n- Replace the redundant field trio/quads with typed enums, mirroring beads-core snapshots: WireWorkflow (Open | InProgress | Closed { closed_reason, closed_on_branch, closed_at, closed_by }) and WireClaim (Unclaimed | Claimed { assignee, assignee_at, assignee_expires }).\n- Use #[serde(flatten)] to keep the same on-disk field names for compatibility.\n- On parse, require that:\n  - status=closed implies closed_at and closed_by are present.\n  - status!=closed implies closed_* fields are absent.\n  - assignee present implies assignee_at present.\n  - assignee absent implies assignee_at/expires absent.\n- Optionally validate that closed_at/assignee_at match the LWW stamp used for workflow/claim (from _v/default). If they do not, return WireError::InvalidValue.\n- If we decide the redundant timestamps are unnecessary, delete them entirely and migrate legacy readers via a compatibility gate (but keep the invariants explicit either way).\n\nScatter fit\n- Make the wire types tell the truth; no hidden redundancy checks at call sites.\n\nFiles\n- crates/beads-rs/src/git/wire.rs","acceptance_criteria":"Acceptance\n- Parsing invalid combinations (closed without closed_at/by, assignee without assignee_at, or mismatched stamps) fails with WireError::InvalidValue.\n- Roundtrip tests ensure wire serialization only emits valid combinations.\n- If redundant fields are kept, they are always consistent with the LWW stamps; if removed, the compatibility path is explicit and tested.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-8ezy-1","content":"Constraint: keep rendering in command files; do not centralize or move rendering logic out of command handlers.","author":"darin@darins-Mac-Studio-2.local","at":[1769587294121,0]},{"id":"legacy-notes","content":"Constraint: keep rendering in command files; do not centralize or move rendering logic out of command handlers.","author":"darin@darinsmcstudio2.lan","at":[1769587543355,0]}],"_at":[1769587543355,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769587543355,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769587543355,0]}
{"id":"bd-8gt","created_at":[1766122283056,0],"created_by":"darin@darinsmcstudio2.lan","title":"Harden git sync state machine edge cases","description":"**Problem**\\nSync/load/refresh pathways have overlapping but different logic. Edge cases (diverged refs, remote missing ref, local ahead, dirty during refresh, rewritten history) are not fully covered by tests. This risks subtle data loss or confusing behavior.\\n\\n**Design**\\nAdd a focused sync-state test harness that builds local/remote repos and exercises: missing refs, local-ahead, remote-ahead, diverged, force-push rewrite, fetch failures, dirty during refresh. Assert invariants: no local data loss, backups created, errors surfaced. Consider consolidating merge logic into a single path to reduce divergence.\\n\\n**Acceptance**\\n- [ ] Tests cover diverged/local-ahead/force-push scenarios.\\n- [ ] Failures are explicit; no silent state drops.\\n- [ ] Backups created when local history would be overwritten.\\n- [ ] Tests pass.\\n\\n**Files:** src/git/sync.rs, src/daemon/core.rs, src/daemon/git_worker.rs, tests/critical_path.rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766124427691,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766124427691,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766124427691,0]}
{"id":"bd-8i8j","created_at":[1770936635512,0],"created_by":"darin@darinsmcstudio2.lan","title":"Daemon stale store lock recovery should be automatic and safe","description":"**Problem**\n`bd` can fail hard when `.git/refs/heads/beads/store.lock` exists but the owning daemon process is gone (crash/kill/reap). We observed repeated startup failures requiring manual lock deletion.\n\nThis breaks the safety story for local recovery and creates operator footguns under crashy environments.\n\n**Observed behavior**\n- daemon startup reports lock acquisition failure for `refs/heads/beads/store.lock`\n- subsequent CLI commands fail until lock is manually removed","design":"Add first-party stale lock recovery in daemon startup/lock acquisition:\n1. Parse lock metadata (pid/actor/timestamps).\n2. If owner PID is dead (or heartbeat stale beyond threshold), reclaim lock safely.\n3. Persist heartbeat updates while lock is held.\n4. Keep explicit logs/metrics for reclaimed vs denied lock attempts.\n\nAvoid silent unlocks when owner is plausibly alive.","acceptance_criteria":"- [ ] Startup recovers from dead-owner store lock without manual filesystem edits.\n- [ ] Live daemon lock is never stolen.\n- [ ] Regression test covers dead PID + stale heartbeat recovery path.\n- [ ] `bd status`/startup logs clearly indicate when lock was reclaimed.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1770940447425,0],"_by":"darin@darinsmcstudio2.lan","_v":{"acceptance_criteria":[[1770936635512,0],"darin@darinsmcstudio2.lan"],"claim":[[1770936635512,0],"darin@darinsmcstudio2.lan"],"description":[[1770936635512,0],"darin@darinsmcstudio2.lan"],"design":[[1770936635512,0],"darin@darinsmcstudio2.lan"],"estimated_minutes":[[1770936635512,0],"darin@darinsmcstudio2.lan"],"external_ref":[[1770936635512,0],"darin@darinsmcstudio2.lan"],"labels":[[1770936635512,0],"darin@darinsmcstudio2.lan"],"priority":[[1770936635512,0],"darin@darinsmcstudio2.lan"],"source_repo":[[1770936635512,0],"darin@darinsmcstudio2.lan"],"title":[[1770936635512,0],"darin@darinsmcstudio2.lan"],"type":[[1770936635512,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770940447425,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-8ic","created_at":[1765949721324,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add richer list filtering (date ranges, pattern matching)","description":"beads-go has comprehensive list filtering that beads-rs lacks:\n- Date range filters: --created-after, --updated-after, --closed-after\n- Pattern matching: --title-contains, --desc-contains\n- Priority ranges: --priority-min, --priority-max (partially done)\n- Empty/null checks: --no-assignee, --no-labels, --empty-description\n\nFiles: src/cli/mod.rs, src/cli/commands/list.rs","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768000416499,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768000416499,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768000416499,0]}
{"id":"bd-8joz","created_at":[1769484585015,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fix clippy -D warnings in cli/show+epic and daemon/admin/wal/memory_index, git/checkpoint/cache","description":"cargo clippy -p beads-rs -- -D warnings fails with manual checked division in cli/commands/{epic,show}.rs and unnecessary sort_by in cli/commands/show.rs, daemon/admin.rs, daemon/wal/memory_index.rs, git/checkpoint/cache.rs. Fix to restore clippy-clean baseline.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769495492106,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769495492106,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769495492106,0]}
{"id":"bd-8rn","created_at":[1766127778679,0],"created_by":"darin@darinsmcstudio2.lan","title":"Clock time-source injection + monotonic tests","description":"**Problem**\nClock behavior is hard to test deterministically. We should be able to inject time sources to simulate skew and verify monotonicity across restarts.\n\n**Design**\nIntroduce a TimeSource trait for Clock (SystemTimeSource default). Allow tests to inject a fake source. Add tests covering backward/forward jumps and ensure stamps are monotonic and skew is detected.\n\n**Acceptance**\n- [ ] Clock supports injected time source in tests\n- [ ] Monotonicity tests cover backward/forward jumps\n- [ ] No API changes to production callers (Clock::new remains default)\n\n**Files:** src/daemon/clock.rs, src/daemon/core.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768425958918,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768425958918,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768425958918,0]}
{"id":"bd-8s8j","created_at":[1769574013445,0],"created_by":"darin@darinsmcstudio2.lan","title":"Validated ReadScope for daemon entrypoints","description":"**Problem**\nRead-scope normalization (namespace + read consistency) is scattered across daemon entrypoints:\n- `normalize_read_consistency` and `normalize_namespace` in `crates/beads-rs/src/daemon/coord.rs`\n- Callers in `crates/beads-rs/src/daemon/admin.rs` and `crates/beads-rs/src/daemon/server.rs` repeatedly normalize inputs\n\nThis is scatter + implicit: every new entrypoint must remember to normalize, and there is no type that represents a validated read scope.\n\n**Files:**\n- `crates/beads-rs/src/daemon/coord.rs`\n- `crates/beads-rs/src/daemon/admin.rs`\n- `crates/beads-rs/src/daemon/server.rs`\n- `crates/beads-core/src/namespace.rs` (if adding shared type)","design":"**Design**\nIntroduce a validated `ReadScope` type and require it at all read entrypoints.\n\nConcrete plan:\n1) Define `ReadScope` (namespace + consistency) in `beads-core` or a shared daemon module.\n2) Provide a constructor that performs normalization and validation once.\n3) Update daemon entrypoints to accept `ReadScope` instead of raw namespace/consistency fields.\n4) Remove repeated normalization calls in `admin`, `server`, and `coord` once the type is in place.\n\n**Design Notes**\n- The type should expose canonical namespace and consistency values so downstream code can trust them.\n- Keep error reporting precise (field names and reasons).","acceptance_criteria":"**Acceptance**\n- [ ] A `ReadScope` validated type exists with a single constructor that normalizes inputs.\n- [ ] Daemon entrypoints use `ReadScope` and do not re-normalize namespace/consistency.\n- [ ] `normalize_read_consistency` / `normalize_namespace` usage is reduced to the constructor or removed.\n- [ ] Tests cover invalid namespace/consistency rejection and valid normalization.","priority":2,"type":"chore","labels":{"entries":{"scatter":[{"replica":"eced5dde-b410-b2bf-e819-0440a0a456b4","counter":9451778915415646401}],"types":[{"replica":"ef9c9fcc-5029-d876-333c-9fb5bdd36430","counter":16181115873261566275}],"validation":[{"replica":"b95660c6-c93e-258e-aa46-47aada1d1443","counter":8415491841507395444}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769758985846,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769758985846,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769758985846,0]}
{"id":"bd-8sqf","created_at":[1768779125154,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace store unlock CLI calls in tests with direct helper","description":"tests/integration/daemon/crash_recovery.rs and others shell out to the store unlock CLI just to remove locks. Expose a test helper that calls StoreLock::unlock directly (or reuse daemon/store lock API) to avoid extra CLI process.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768802169482,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768802169482,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-8t8d","created_at":[1769495028829,0],"created_by":"darin@darinsmcstudio2.lan","title":"Make Bead::join require same‑lineage type","description":"**Problem**\n`Bead::join` has a documented precondition: the beads must share the same ID and `core.created` (lineage). This is enforced by runtime checks returning `CollisionError`, but the type system does not prevent misuse. It’s easy to call `join` in a context where collisions are possible, especially during refactors.\n\nKey references:\n- `crates/beads-core/src/bead.rs:149` — precondition comment + runtime collision error.\n\nSeverity: misuse produces runtime errors and undermines correctness of merge logic.","design":"**Design**\nEncode same-lineage constraint in the type system.\n\nOption A (newtype):\n- Introduce `SameLineageBead<'a>` wrapper constructed only by a checked function:\n  - `fn same_lineage(a: &Bead, b: &Bead) -> Result<(SameLineageBead, SameLineageBead), CoreError>`\n- Implement `join` for `SameLineageBead` only.\n\nOption B (keyed grouping):\n- Introduce `LineageKey { id: BeadId, created: Stamp }` and require it to construct a pair for join.\n\nMigration:\n- Keep old `Bead::join` temporarily, mark deprecated, and move callers to typed join.","acceptance_criteria":"- [ ] `join` can only be called on same‑lineage beads at compile time.\n- [ ] Collision checks move to construction boundary, not inside `join`.\n- [ ] All existing join call sites are updated; old API removed or deprecated.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769518129545,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769518129545,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769518129545,0]}
{"id":"bd-8ugn","created_at":[1769574001578,0],"created_by":"darin@darinsmcstudio2.lan","title":"Make error payloads derive from core error types","description":"**Problem**\nError semantics are translated into transport payloads by large, hand-written mappings:\n- `crates/beads-rs/src/daemon/ipc/error_mapping.rs` contains extensive match logic mapping many error types to `ErrorPayload` and details.\n- Similar translation patterns exist in repl/session error handling.\n\nThis is scatter + drift: error meaning is split between the original error type and the mapping layer. Adding a new error requires updating multiple sites, and mismatches are easy to introduce.\n\n**Files:**\n- `crates/beads-rs/src/daemon/ipc/error_mapping.rs`\n- `crates/beads-core/src/error.rs`\n- `crates/beads-rs/src/daemon/repl/error.rs`","design":"**Design**\nMake error types the single source of truth for payload shape and codes.\n\nConcrete plan:\n1) Add a trait in `beads-core` (e.g., `IntoErrorPayload`) implemented by core error types.\n2) Move payload construction into the error types themselves (or a shared error module), so transport layers are mechanical.\n3) Update IPC and repl layers to call the trait method, removing large match blocks.\n4) Ensure error detail structs live with the error definitions, not the transport mapping.\n\n**Design Notes**\n- If some errors are transport-specific, create a thin wrapper error type in core that implements the trait.\n- Avoid cyclic dependencies: trait should live in core and be used by beads-rs.","acceptance_criteria":"**Acceptance**\n- [ ] Core error types implement a single `IntoErrorPayload` (or equivalent) trait.\n- [ ] IPC error mapping becomes a thin adapter or is removed entirely.\n- [ ] Repl error mapping uses the same trait-based conversion.\n- [ ] Adding a new error requires changes in one place only (the error definition).\n- [ ] Tests cover at least two error conversions to payloads.","priority":2,"type":"chore","labels":{"entries":{"consistency":[{"replica":"7230ea28-508f-04ea-7500-d05ea0911b70","counter":6546726640297200438}],"errors":[{"replica":"aa69f226-b8df-2c91-213c-087acbecfd17","counter":15808547355598526237}],"scatter":[{"replica":"484472db-921d-c51a-0e4a-26d3bdc0af90","counter":4127335126144153865}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769763183845,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769763183845,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769763183845,0]}
{"id":"bd-8xkm","created_at":[1769573215365,0],"created_by":"darin@darinsmcstudio2.lan","title":"Centralize limits enforcement","description":"**Problem**\nLimits enforcement is scattered across multiple contexts:\n- Event validation in `crates/beads-core/src/event.rs`\n- Mutation planning in `crates/beads-rs/src/daemon/mutation_engine.rs`\n- Checkpoint import JSONL size/depth checks in `crates/beads-rs/src/git/checkpoint/import.rs`\n- WAL framing/record limits in `crates/beads-rs/src/daemon/wal/*`\n\nThe rules for \"what is allowed\" are duplicated and easy to miss in new paths. This is implicit + scatter and invites drift.\n\n**Files:**\n- `crates/beads-core/src/event.rs`\n- `crates/beads-rs/src/daemon/mutation_engine.rs`\n- `crates/beads-rs/src/git/checkpoint/import.rs`\n- `crates/beads-rs/src/daemon/wal/segment.rs`\n- `crates/beads-rs/src/daemon/wal/record.rs`","design":"**Design**\nCreate a single limits policy module that vends validated inputs, and route all limit checks through it.\n\nConcrete plan:\n1) Introduce a `LimitsPolicy` (or extend `Limits`) with helper constructors like:\n   - `ValidatedNote::try_from(content, limits)`\n   - `ValidatedPatch::try_from(patch, limits)`\n   - `ValidatedFrame::try_from(bytes, limits)`\n   - `ValidatedCheckpointShard::try_from(bytes, limits)`\n2) Update mutation planning, event validation, checkpoint import, and WAL framing to use those validated types.\n3) Remove ad-hoc size/depth checks from callers once the validated type is used.\n\n**Design Notes**\n- Keep the policy in a shared crate (`beads-core`) if possible to avoid cross-crate drift.\n- The goal is a single place to change limits behavior.","acceptance_criteria":"**Acceptance**\n- [ ] Limits checks are centralized in a policy type with validated wrappers.\n- [ ] Mutation planning uses validated note/patch helpers instead of manual checks.\n- [ ] Event validation uses validated types for size limits.\n- [ ] Checkpoint import uses validated shard helpers for size/depth/entry limits.\n- [ ] WAL framing/record sizing is enforced through the policy helpers.\n- [ ] Tests cover limit violations in at least two boundary paths (event + checkpoint).","priority":2,"type":"chore","labels":{"entries":{"limits":[{"replica":"da540f92-cee2-1cb4-d9f4-399cb8737519","counter":3706821128463288602}],"scatter":[{"replica":"6a55f733-24c1-b0c4-55b4-62a928729da0","counter":14131435385571344916}],"tech-debt":[{"replica":"6695de3f-554e-291e-7b5a-a5aee7469a07","counter":14172773698591137036}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-8xkm-1","content":"Note: if any rendering is touched, keep rendering in the command files; do not centralize rendering elsewhere.","author":"darin@darins-Mac-Studio-2.local","at":[1769599203862,0]},{"id":"legacy-notes","content":"Note: if any rendering is touched, keep rendering in the command files; do not centralize rendering elsewhere.","author":"darin@darinsmcstudio2.lan","at":[1769626630601,0]}],"_at":[1769626630601,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769626630601,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769626630601,0]}
{"id":"bd-8y9","created_at":[1768448943321,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replication ingest can stall on contiguous batches","description":"**Problem**\nWhen an EVENTS message contains multiple contiguous events for the same (namespace, origin), only the first event is verified as contiguous. Subsequent events are verified with expected_prev=None and become Deferred, then buffered. The gap buffer never promotes deferred events after durable advances, so those events can remain stuck and trigger unnecessary WANTs even though we already received them.\n\n**Evidence**\n- src/daemon/repl/session.rs: handle_events() computes expected_prev via expected_prev_head() using the durable watermark snapshot (not updated per-frame).\n- src/core/event.rs: verify_event_frame() returns VerifiedEventAny::Deferred when expected_prev_head is None for seq>1.\n- src/daemon/repl/gap_buffer.rs: ingest_one() buffers deferred events and advance_durable_batch() does not re-check buffered deferred events.\n\n**Why this hurts**\nA peer that legitimately batches seq N and N+1 in a single EVENTS frame will cause seq N+1 to be buffered and never applied unless it is resent later. This can stall replication and produce spurious WANTs.","design":"**Design**\nOption A (preferred): Track per-(namespace, origin) last-seen head within the current EVENTS batch. Use that to compute expected_prev_head for later frames in the same batch so contiguous batches verify as Contiguous.\n\nOption B: Extend GapBuffer to promote deferred events when durable advances (e.g., add a flush_ready() that re-validates deferred prev against the new durable head). Call it after advance_durable_batch().\n\nWhichever approach, ensure events already in the batch are not re-requested via WANT.","acceptance_criteria":"- [ ] A contiguous batch (seq 1,2) in a single EVENTS message applies both events and emits no WANT.\n- [ ] Buffered deferred events are eventually forwarded once their prev is known (test covers).\n- [ ] Add regression test in src/daemon/repl/session.rs and/or gap_buffer.rs.\n\n**Files:** src/daemon/repl/session.rs, src/daemon/repl/gap_buffer.rs, src/core/event.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768453447510,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768453447510,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768453447510,0]}
{"id":"bd-8yac","created_at":[1769573131220,0],"created_by":"darin@darinsmcstudio2.lan","title":"Unify bead wire formats and patch validation","description":"**Problem**\nBead state is serialized and validated in multiple parallel shapes:\n- Git store wire in `crates/beads-rs/src/git/wire.rs`\n- Checkpoint/realtime wire in `crates/beads-core/src/wire_bead.rs`\n- Patch validation in `crates/beads-core/src/event.rs` (ValidatedBeadPatch)\n- Patch validation + parsing in `crates/beads-rs/src/daemon/mutation_engine.rs`\n- Surface patch shape in `crates/beads-surface/src/ops.rs`\n\nThe same invariants (workflow/claim coherence, required fields, ordering rules, dedup, etc.) are re-encoded in different representations and checked in different places. This is scatter + drift risk: anyone changing bead semantics has to chase multiple pipelines and keep them in sync.\n\n**Files:**\n- `crates/beads-rs/src/git/wire.rs`\n- `crates/beads-core/src/wire_bead.rs`\n- `crates/beads-core/src/event.rs`\n- `crates/beads-rs/src/daemon/mutation_engine.rs`\n- `crates/beads-surface/src/ops.rs`","design":"**Design**\nCreate one canonical bead snapshot wire and one canonical bead patch wire in `beads-core`, plus a single validator that yields a validated patch type. Then route all serialization and mutation pipelines through those types.\n\nConcrete plan:\n1) Define `BeadSnapshotWireV1` and `BeadPatchWireV1` in `crates/beads-core/src/wire_bead.rs` (or a new `wire_bead_snapshot.rs`), covering all fields currently represented across git/checkpoint/event wires. These types must be the only JSON representation for full bead snapshots and patches.\n2) Move/centralize the patch semantics checks (workflow/claim coherence, created_at/created_by rules, etc.) into a single validator: `ValidatedBeadPatch::try_from(BeadPatchWireV1)` in `beads-core`.\n3) Update git store wire (`crates/beads-rs/src/git/wire.rs`) to serialize/deserialize via `BeadSnapshotWireV1` (eliminate its bespoke `WireBead` parsing where possible). Keep any legacy quirks as translation adapters local to that module.\n4) Update checkpoint import/export and realtime event encoding to use the same `BeadSnapshotWireV1`/`BeadPatchWireV1` types, so snapshots and patches share identical invariants.\n5) Update `beads-surface` and `beads-rs` mutation planning to construct `BeadPatchWireV1` directly, then validate once to get `ValidatedBeadPatch`.\n6) Delete or shrink duplicate validators (ParsedBeadPatch / validate_wire_patch), replacing them with a single \"parse then validate\" path.\n\n**Design Notes**\n- Keep backward-compatible parsing where needed (legacy git store, go schema), but make those adapters explicit and local so invariants do not leak.\n- If the git store wire requires sparse-stamp behavior, model that as a serializer choice on the canonical wire rather than a separate struct.\n- Add conversion helpers in core (e.g., `BeadSnapshotWireV1::from_view`) to keep usage uniform.","acceptance_criteria":"**Acceptance**\n- [ ] `BeadSnapshotWireV1` and `BeadPatchWireV1` exist in `beads-core`, and all snapshot/patch JSON encoding uses them.\n- [ ] There is exactly one semantic validator for bead patches, and all mutation/event paths rely on it.\n- [ ] `crates/beads-rs/src/git/wire.rs` no longer defines a competing bead snapshot wire; it adapts to the canonical wire.\n- [ ] Checkpoint import/export uses the canonical snapshot wire for parsing/serialization.\n- [ ] Duplicate validators (ParsedBeadPatch/validate_wire_patch) are removed or reduced to input normalization only.\n- [ ] Unit tests cover roundtrip snapshot serialization and invalid patch rejection through the canonical validator.","priority":1,"type":"chore","labels":{"entries":{"architecture":[{"replica":"1383ed17-d2e0-2916-cd66-6d792c431666","counter":13194328523806826908}],"scatter":[{"replica":"1da33846-24fd-a0da-63b0-29024f61cf46","counter":10558539594876570247}],"tech-debt":[{"replica":"eac93ce2-ab49-35ae-89d1-f3b29d8cbf61","counter":1089507277148352589}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-8yac-1","content":"Rendering stays in command files; do not move render logic out during this refactor.","author":"darin@darins-Mac-Studio-2.local","at":[1769575908535,0]},{"id":"legacy-notes","content":"Rendering stays in command files; do not move render logic out during this refactor.","author":"darin@darinsmcstudio2.lan","at":[1769577417122,0]}],"_at":[1769577417122,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769577417122,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769577417122,0]}
{"id":"bd-907g","created_at":[1769573175272,0],"created_by":"darin@darinsmcstudio2.lan","title":"Single validation gate per boundary","description":"**Problem**\nValidation boundaries are not single-source-of-truth. Examples:\n- `ParsedBeadPatch::parse` in `crates/beads-rs/src/daemon/mutation_engine.rs` enforces required-field rules that are not enforced by `ValidatedBeadPatch` in `crates/beads-core/src/event.rs`.\n- Checkpoint import validates meta/manifest and content in multiple paths (`import_checkpoint` and `import_checkpoint_export`) in `crates/beads-rs/src/git/checkpoint/import.rs`.\n- Git store `parse_meta` exposes `format_version` but callers (`crates/beads-rs/src/git/sync.rs`) do not gate on it.\n\nThis creates implicitness and drift: you must know which path does the \"real\" validation, and it is easy to add new call paths without the right checks.\n\n**Files:**\n- `crates/beads-rs/src/daemon/mutation_engine.rs`\n- `crates/beads-core/src/event.rs`\n- `crates/beads-rs/src/git/checkpoint/import.rs`\n- `crates/beads-rs/src/git/wire.rs`\n- `crates/beads-rs/src/git/sync.rs`","design":"**Design**\nCreate a single validated type per boundary and ensure all callers only use the validated type.\n\nConcrete plan:\n1) For patch parsing: introduce a `ValidatedSurfacePatch` (or fold requirements into the canonical validator) so surface parsing does not independently enforce required-field rules. The pipeline should be: raw input -> parsed -> validated (single place) -> apply.\n2) For checkpoint import: extract shared validation into a helper that returns `ValidatedCheckpointMeta` and `ValidatedCheckpointManifest`, and reuse it for both `import_checkpoint` and `import_checkpoint_export`.\n3) For git store meta: change `parse_meta` to return a validated meta type that includes a version gate (see separate bead on version gating), or add a `parse_supported_meta` helper used everywhere.\n4) Remove or inline duplicate validation logic so there is exactly one canonical validator per boundary.\n\n**Design Notes**\n- Favor type gates: after validation, the type system should guarantee invariants (no re-checks).\n- Use small, explicit boundary types: `ParsedX` -> `ValidatedX`.","acceptance_criteria":"**Acceptance**\n- [ ] There is one canonical validator for surface/bead patch semantics; surface parsing no longer enforces its own required-field rules.\n- [ ] Checkpoint import uses a shared validation path for meta/manifest/content across file-based and in-memory exports.\n- [ ] Git store meta parsing returns a validated type or is immediately validated by a single helper used in all call sites.\n- [ ] Duplicate validation code is removed or reduced to input normalization.\n- [ ] Tests cover invalid inputs rejected at the boundary and valid inputs accepted by the validated types.","priority":2,"type":"chore","labels":{"entries":{"scatter":[{"replica":"a557e6a8-6cca-7d3e-a89f-607941c87975","counter":5839662980227332767}],"tech-debt":[{"replica":"5983ddbe-77dd-cd68-e5b1-c0163d81dd0f","counter":9618146627077327439}],"validation":[{"replica":"64a295f8-729e-a5c3-83f4-65ff04eb402e","counter":9378939429740772330}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-907g-1","content":"Rendering should remain in command files; avoid centralizing CLI rendering while refactoring validation boundaries.","author":"darin@darins-Mac-Studio-2.local","at":[1769596252802,0]},{"id":"legacy-notes","content":"Rendering should remain in command files; avoid centralizing CLI rendering while refactoring validation boundaries.","author":"darin@darinsmcstudio2.lan","at":[1769597435084,0]}],"_at":[1769597435084,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769597435084,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769597435084,0]}
{"id":"bd-91v8","created_at":[1769495029037,0],"created_by":"darin@darinsmcstudio2.lan","title":"Make VerifiedEvent carry canonical event bytes","description":"**Problem**\n`VerifiedEvent` stores `EventBytes<Opaque>` even though verification implies canonical encoding. Worse, `EventBytes<Canonical>::new_unchecked` is public, so any caller can lie about canonicality. The compiler cannot enforce that “verified” bytes are actually canonical or that hashes are computed over canonical bytes.\n\nThis violates parse‑don’t‑validate: we parse, verify, *then* throw away canonical information. It also undermines deterministic hashing and replay safety.\n\nKey refs:\n- `crates/beads-core/src/event.rs:52` — `EventBytes<Canonical>::new_unchecked` is public.\n- `crates/beads-core/src/event.rs:180` — `VerifiedEvent` holds `EventBytes<Opaque>`.\n\n**Impact**\nHash/identity ambiguity for WAL/repl. A non‑canonical frame can slip through and still be treated as verified by downstream code.","design":"**Design (opinionated)**\nMake canonical bytes the default for verified events, and make it impossible to forge canonicality.\n\n1) Restrict constructors:\n- Make `EventBytes<Canonical>::new_unchecked` `pub(crate)` (or private) so only the canonical encoder can construct it.\n\n2) Change `VerifiedEvent` to carry canonical bytes:\n- `VerifiedEvent { body, bytes: EventBytes<Canonical>, sha256, prev }`.\n- If raw bytes are needed for transport, carry them explicitly as `raw_bytes: EventBytes<Opaque>` in a separate wire struct, not in the verified core type.\n\n3) Verification should enforce canonical encoding:\n- In `verify_event_frame`, decode body, *re‑encode canonical bytes*, and compare:\n  - If canonical bytes != frame bytes => reject as non‑canonical.\n  - Compute hash from canonical bytes and ensure it matches `sha256`.\n\n4) Make canonicality contagious:\n- Any API that accepts `VerifiedEvent` can now safely assume canonical bytes; no re‑encoding or re‑validation required.\n\nThis turns canonicality into a compile‑time guarantee, not a runtime convention.","acceptance_criteria":"**Acceptance**\n- [ ] `VerifiedEvent` exposes `EventBytes<Canonical>` (not Opaque).\n- [ ] Canonical bytes cannot be constructed outside the canonical encoder (`new_unchecked` not public).\n- [ ] `verify_event_frame` rejects non‑canonical encodings and computes hash from canonical bytes.\n- [ ] Downstream code uses canonical bytes without additional validation; explicit raw‑bytes usage is opt‑in.\n- [ ] Tests cover rejection of non‑canonical frames and round‑trip canonical encode/verify.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769518997079,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769518997079,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769518997079,0]}
{"id":"bd-97v","created_at":[1768245306934,0],"created_by":"darin@darinsmcstudio2.lan","title":"Crash recovery","description":"","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"empty stub - no description","_at":[1768254389567,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768254389567,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-97w","created_at":[1765676872178,0],"created_by":"darin@darinsmcstudio2.lan","title":"Nix flake skips tests (doCheck=false) - CI gap","description":"## What's Wrong\nflake.nix has doCheck=false to avoid test failures during nix build. This means `nix build` won't catch test regressions.\n\n## Where\n- flake.nix:42-43\n\n## Why It Matters\nUsers installing via nix won't get test validation. If tests break, nix users get broken builds.\n\n## Options\n1. Fix whatever causes tests to fail in nix sandbox (likely git/network related)\n2. Add a separate `nix flake check` that runs tests outside the build\n3. Accept the gap and rely on CI (current state)","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765677592520,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765677592520,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765677592520,0]}
{"id":"bd-989","created_at":[1768503784914,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add typestate for WAL records (Seq1 + verified header/body)","description":"**Problem**\nRecordHeader stores origin_seq as u64 and Record represents both decoded and validated states. Several paths (repl/wal replay/range reads) can use Record without proving origin_seq >= 1 or header/body/hash consistency. There is a validate_header_matches_body helper, but nothing in types forces callers to use it. This is brittle and violates type_design guidance (invariants should be unrepresentable).\n\n**Files:** src/daemon/wal/record.rs, src/daemon/wal/frame.rs, src/daemon/wal/replay.rs, src/daemon/repl/runtime.rs, src/daemon/executor.rs, src/daemon/core.rs","design":"**Design**\n- Split Record into raw vs verified variants (e.g., Record<Unverified> and Record<Verified>).\n- Use Seq1 (or a new nonzero type) in the verified RecordHeader to encode origin_seq >= 1.\n- Provide Record::decode_raw + Record::verify_with_event_body (checks header/body match and sha256(event_body_bytes)).\n- Update replay/range readers to return Verified records; update writers to build Verified records directly.\n- Add targeted tests for seq0 rejection and header/body mismatch errors.","acceptance_criteria":"- [ ] No code path can use a verified Record without Seq1 and header/body/hash checks.\n- [ ] Record decode rejects origin_seq=0 early.\n- [ ] WAL replay and WAL range reads use the verified record type.\n- [ ] Tests cover header/body mismatch and seq0 rejection.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768516700787,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768516700787,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768516700787,0]}
{"id":"bd-9e1s","created_at":[1769032879591,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fix canonical CBOR fixtures and lock key ordering","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769033020527,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769033020527,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769033020527,0]}
{"id":"bd-9nf","created_at":[1766127786530,0],"created_by":"darin@darinsmcstudio2.lan","title":"Boundary ID/slug type tightening","description":"**Problem**\nSome boundary layers still accept raw strings for IDs/slugs, risking invalid values slipping through.\n\n**Design**\nAudit CLI/IPC entrypoints and replace raw string handling with strong types (BeadId/BeadSlug/ActorId) as early as possible. Add validation helpers for common parse paths and remove fallible unwraps.\n\n**Acceptance**\n- [ ] Parsing/validation centralized\n- [ ] No new unwraps\n- [ ] Tests cover invalid inputs\n\n**Files:** src/cli/*, src/daemon/ipc.rs, src/core/identity.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768441818318,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768441818318,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768441818318,0]}
{"id":"bd-9ns","created_at":[1768494740628,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tests for CLI read gating parsing and propagation","description":"**Problem**\nRead gating is easy to regress; we need tests that lock the JSON parsing and ensure read consistency propagation.\n\n**Design**\nAdd focused unit tests for parsing require_min_seen JSON and for Ctx::read_consistency propagating require_min_seen + wait_timeout_ms. Keep tests in src/cli/mod.rs where other CLI parsing tests live.\n\n**Files**\n- src/cli/mod.rs","acceptance_criteria":"- [ ] Test for valid require_min_seen JSON parsing\n- [ ] Test for invalid JSON returns ValidationFailed\n- [ ] Test for Ctx::read_consistency includes require_min_seen and wait_timeout_ms","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768495110370,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768495110370,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768495110370,0]}
{"id":"bd-9qv0","created_at":[1768503815996,0],"created_by":"darin@darinsmcstudio2.lan","title":"Make head-knownness explicit in watermarks","description":"**Problem**\nWatermark allows HeadStatus::Unknown for seq>0 (core/watermark.rs). Plan §0.12 says head sha must be known for seq>0. Today this invariant is enforced ad hoc (gap_buffer drain returns PrevUnknown), which is brittle and forces runtime checks across the replication path.\n\n**Files:** src/core/watermark.rs, src/daemon/store_runtime.rs, src/daemon/repl/session.rs, src/daemon/repl/gap_buffer.rs, src/daemon/repl/runtime.rs","design":"**Design**\n- Introduce a head-known watermark type (e.g., Watermark<K, HeadKnown>) or split Watermark into Known/Maybe variants.\n- Restrict contiguity-critical APIs (advance_contiguous, gap buffer drain) to require head-known watermarks.\n- Decide how to handle peers that omit head hashes: either reject at protocol boundary or store them in a separate \"unknown head\" map until upgraded.\n- Update load_watermarks to reject/flag seq>0 without head unless in a compatibility mode.","acceptance_criteria":"- [ ] It is impossible to represent seq>0 with unknown head in the durable/applied watermarks used for contiguity.\n- [ ] Gap buffer/drain paths no longer need PrevUnknown runtime checks for durable head.\n- [ ] Tests cover head-known enforcement and any compatibility behavior.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768512153800,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768512153800,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768512153800,0]}
{"id":"bd-a0s","created_at":[1768252042894,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL replay mid-file corruption should fail fast","description":"**Problem**\nWAL replay truncates on any corruption, including mid-file CRC/record decode errors, because scan_segment doesn't distinguish tail vs mid-file. This violates REALTIME_PLAN.md 5.2 (online vs offline boundary), which requires fail-fast on mid-file corruption and only tail truncation repairs.\n\n**Design**\nIn src/daemon/wal/replay.rs scan_segment, detect tail vs mid-file:\n- tail: remaining < FRAME_HEADER_LEN, frame_len > remaining, or crc mismatch where offset+frame_len == file_len.\n- mid-file: return explicit WalReplayError (new variant) with path+offset; do not truncate.\nOnly truncate in tail cases when repair_tail=true. Surface operator action to run bd store fsck.\nAdd tests for mid-file corruption (expect error) and tail corruption (truncate) using WAL fixtures.\n\n**Acceptance**\n- [ ] Mid-file corruption during replay returns error and does not truncate.\n- [ ] Tail corruption still truncates and continues.\n- [ ] Tests cover mid-file vs tail behavior; cargo test passes.\n\n**Files:** src/daemon/wal/replay.rs, tests/phase3_wal.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768254941652,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768254941652,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768254941652,0]}
{"id":"bd-a5v","created_at":[1765744933723,0],"created_by":"darin@darinsmcstudio2.lan","title":"Blocking freshness loads stall entire daemon","description":"**Problem**\n`ensure_repo_fresh()` does a blocking `GitOp::Load` roundtrip on the state thread. Any slow fetch = every client request pauses. OK-ish for small repos, but a design footgun.\n\n**Design**\nMake refresh async:\n- If repo is clean and refresh TTL hit, kick off background load\n- Serve current cached state meanwhile\n- Apply refreshed state when it arrives (maybe invalidate caches)\n- Optionally: let queries request `fresh=true` when they really need it\n\n**Acceptance**\n- [ ] Slow git fetch doesnt block unrelated client requests\n- [ ] Stale reads are bounded (TTL still respected eventually)\n- [ ] Fresh flag available for queries that need it\n\n**Files:** src/daemon/mod.rs, src/daemon/query_executor.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765832381187,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765832381187,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765832381187,0]}
{"id":"bd-a6k","created_at":[1766127744362,0],"created_by":"darin@darinsmcstudio2.lan","title":"CRDT join property tests (commutative/associative/idempotent)","description":"**Problem**\nWe don’t have property tests proving CRDT join algebra and invariants hold across random states. A subtle regression could cause silent data loss.\n\n**Design**\nAdd proptest generators for CanonicalState (beads + tombstones + deps) and assert:\n- join(a,b) == join(b,a)\n- join(a, join(b,c)) == join(join(a,b), c)\n- join(a,a) == a\n- invariants hold after join (live ∩ tombstones = ∅, dep indexes consistent)\nUse minimal valid field generation (safe ActorId/BeadId) and keep sizes small for speed.\n\n**Acceptance**\n- [ ] Property tests added and deterministic\n- [ ] No panics; invariants checked\n- [ ] Tests run in CI\n\n**Files:** src/core/state.rs, src/core/dep.rs, Cargo.toml","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768426245227,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768426245227,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768426245227,0]}
{"id":"bd-a7k","created_at":[1768252084827,0],"created_by":"darin@darinsmcstudio2.lan","title":"Track sealed WAL segments + final_len invariant","description":"**Problem**\nwal.sqlite segment rows are always sealed=false and final_len=None; replay does not enforce sealed segment file_len == final_len. REALTIME_PLAN.md 5.2 requires sealed segment invariants and fail-fast on mismatch.\n\n**Design**\nWhen rotating segments, mark the previous segment sealed with final_len (bytes_written). Persist sealed/final_len in wal.sqlite segments table. On startup/replay, if a sealed segment exists and file_len != final_len, return WalReplayError and surface operator action. Add fsck check to flag sealed length mismatch.\n\n**Acceptance**\n- [ ] Segment rotation updates wal.sqlite segments with sealed=true and final_len.\n- [ ] Replay errors on sealed segment length mismatch.\n- [ ] Fsck reports sealed length mismatch.\n- [ ] Tests cover sealed invariant enforcement; cargo test passes.\n\n**Files:** src/daemon/wal/segment.rs, src/daemon/wal/index.rs, src/daemon/wal/replay.rs, src/daemon/wal/fsck.rs, tests/phase3_index.rs","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768257024330,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768257024330,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ae2z","created_at":[1768509347274,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fixtures: centralize WAL frame/segment constants","description":"**Problem**\\n- tests/integration/fixtures/wal.rs hardcodes WAL_FORMAT_VERSION, SEGMENT_HEADER_PREFIX_LEN, FRAME_HEADER_LEN.\\n- tests/integration/fixtures/wal_corrupt.rs hardcodes FRAME_CRC_OFFSET/FRAME_HEADER_LEN.\\n- These constants encode the WAL wire format; if production changes, fixtures drift or encode invalid assumptions.\\n\\n**Files**\\n- tests/integration/fixtures/wal.rs\\n- tests/integration/fixtures/wal_corrupt.rs\\n- src/daemon/wal/* (source of truth)","design":"Expose canonical constants (or accessors) from WAL modules (e.g., frame header len/CRC offset, segment header prefix len, current WAL format version) as pub(crate) or pub for tests. Replace the fixture constants with imports. If no single const exists yet, add them where the format is defined and re-export as needed (tie into bd-rfit if versions are centralized).","acceptance_criteria":"- [ ] No hardcoded WAL format constants remain in test fixtures.\\n- [ ] Fixtures compile using shared constants.\\n- [ ] cargo test --test integration passes.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768526585846,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768526585846,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768526585846,0]}
{"id":"bd-al7","created_at":[1768503245771,0],"created_by":"darin@darinsmcstudio2.lan","title":"Repl gap buffer reject reasons should be typed","description":"**Problem**\n`IngestDecision::Reject { code: String }` in `src/daemon/repl/gap_buffer.rs` uses ad-hoc string codes (\"prev_unknown\", \"gap_timeout\", \"gap_buffer_overflow\", etc.) and the session layer forwards them into `SubscriberLagged` errors. This is brittle and makes it easy to add new reasons without updating error handling.\n\n**Files**\n- src/daemon/repl/gap_buffer.rs\n- src/daemon/repl/session.rs\n- src/core/error/details.rs (if adding structured reason)","design":"Replace string codes with a typed enum (e.g., `ReplRejectReason`). Map that enum to error payloads (and, if needed, add a structured detail field for the reason). Update gap buffer + session logic and tests accordingly.","acceptance_criteria":"- [ ] `Reject` carries a typed reason, not a string.\n- [ ] Error payloads include the mapped reason consistently.\n- [ ] Gap buffer/session tests updated.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768522037086,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768522037086,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768522037086,0]}
{"id":"bd-am6","created_at":[1765949734336,0],"created_by":"darin@darinsmcstudio2.lan","title":"Sync fails when migrating from beads-go in PR branch with existing store","description":"**Problem**\nWhen migrating from beads-go to beads-rs in a PR branch, the sync doesn't work properly. Beads appear not to exist after migration.\n\n**Root Cause**\nThe `migrate from-go` command bypasses the daemon entirely - it directly writes to `refs/heads/beads/store` using `SyncProcess` (src/cli/commands/migrate.rs:71-74). But the daemon caches state in memory per-remote in `RepoState`. After migration completes:\n1. Git ref has the migrated state\n2. Daemon still has empty/old cached state\n3. CLI queries go through daemon, return stale data\n\n**Design**\nAdd a `Request::Refresh` IPC command that tells the daemon to reload state from the git ref for a given repo. The migrate command should call this after successful migration.\n\nAlternatively, migrate could go through the daemon IPC entirely, but that's more invasive.\n\n**Acceptance**\n- [ ] After `bd migrate from-go`, `bd list` shows the migrated beads\n- [ ] Works even if daemon was already running before migration\n- [ ] Test: migrate in a fresh clone, verify state is visible\n\n**Files:** src/daemon/ipc.rs, src/cli/commands/migrate.rs, src/daemon/core.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Fixed: added Request::Refresh and notify daemon after migration","_at":[1765949974228,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765949974228,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-amk","created_at":[1765676815639,0],"created_by":"darin@darinsmcstudio2.lan","title":"Write migration guide for beads-go to beads-rs","description":"Document the migration path for users of the Go version to switch to Rust. Cover:\n\n- Data format changes (if any)\n- CLI differences\n- New features in beads-rs\n- How to migrate existing beads data\n\nThis helps adoption and shows the project is mature enough to replace the Go version.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765677749539,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765677749539,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765677749539,0]}
{"id":"bd-ap9","created_at":[1768268763811,0],"created_by":"darin@darinsmcstudio2.lan","title":"Phase 4: add dep/delete ops to TxnDelta + apply","description":"MutationEngine currently rejects parent/dependency updates and delete because TxnDeltaV1 + apply_event only cover bead_upsert/note_append. Implement bead_delete + dep_upsert/dep_delete in core wire/event/apply, update CBOR encoding/decoding, and wire mutation planning to support create-with-deps, add/remove dep, set parent, delete.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768275871857,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768275871857,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768275871857,0]}
{"id":"bd-ar4","created_at":[1766116454284,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL write failure must abort mutation + preserve state","description":"**Problem**\nMutations can succeed even when WAL writes fail. In `src/daemon/core.rs` `mark_dirty_and_schedule` logs a warning and proceeds, so a crash can lose acknowledged data. There is no rollback of in-memory state when WAL writes fail.\n\n**Design**\nIntroduce a transactional mutation path that applies changes to a cloned `CanonicalState`, writes the WAL entry first, and only commits the new state + dirty flag on success. Add a dedicated OpError (e.g., `WalError`/`DurabilityError`) surfaced via IPC. Ensure WAL sequence only advances on successful write. Add a unit test that forces WAL write failure and verifies no state change + error return.\n\n**Acceptance**\n- [ ] WAL write failures return an error and do not modify repo state\n- [ ] WAL sequence/dirty flags remain unchanged on WAL failure\n- [ ] Successful WAL writes still schedule sync\n- [ ] Tests cover WAL failure path\n- [ ] Tests pass\n\n**Files:** src/daemon/core.rs, src/daemon/executor.rs, src/daemon/ops.rs, src/daemon/wal.rs","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766124451834,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766124451834,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766124451834,0]}
{"id":"bd-atsg","created_at":[1770579261378,0],"created_by":"darin@darinsmcstudio2.lan","title":"Finish full CLI ownership move from beads-rs to beads-cli","description":"**Problem**\nThe CLI/daemon split is still in a hybrid state in the working copy: part of the command surface has moved to `beads-cli`, while substantial parse/dispatch/handler ownership remains in `beads-rs`. This increases maintenance cost and makes crate boundaries harder to reason about.\n\n**Goal**\nComplete the move so `beads-cli` owns the full CLI command surface and `beads-rs` remains a thin orchestration/compat layer only.\n\n**Files**\n- crates/beads-cli/**\n- crates/beads-rs/src/cli/**\n- crates/beads-rs/src/bin/main.rs\n- crates/beads-rs/src/lib.rs\n- crates/beads-rs/tests/**\n- docs/architecture/**\n- docs/CRATE_DAG.md","design":"1. Inventory remaining command handlers and top-level CLI wiring still owned by `beads-rs`.\n2. Move pure IPC/read-only command paths first to minimize risk.\n3. For host-coupled commands (e.g. migrate/store/upgrade), expose typed backend seams and migrate without introducing `beads-cli -> beads-rs` or `beads-cli -> beads-daemon` forbidden edges.\n4. Move top-level parse/dispatch/runtime wiring into `beads-cli`, then keep `beads-rs` entrypoint as thin call-through shim.\n5. Rewire integration tests/fixtures to assert behavior parity (output shape, exit codes, daemon interactions).\n6. Keep boundary policy enforced with `just dylint` and update closeout docs.","acceptance_criteria":"- [ ] `beads-cli` owns full CLI command parse/dispatch/handler implementation.\n- [ ] `crates/beads-rs/src/cli/commands/*` is removed or reduced to explicit compat shims with a removal plan.\n- [ ] `bd` behavior is preserved: existing critical-path/integration tests pass without output or semantic regressions.\n- [ ] Dependency DAG policy in `docs/CRATE_DAG.md` remains satisfied (no forbidden edges introduced).\n- [ ] Verification gate passes: `cargo fmt --all`, `just dylint`, `cargo clippy --all-features -- -D warnings`, `cargo test`, `cargo test --features slow-tests`.\n- [ ] Architecture closeout doc captures final ownership map and migration deltas.","priority":1,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770618072005,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770618072005,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770618072005,0]}
{"id":"bd-atsg.1","created_at":[1770611167712,0],"created_by":"darin@darinsmcstudio2.lan","title":"Migrate create/show/update command handlers to beads-cli","description":"**Problem**\n`create`, `show`, and `update` still live in `crates/beads-rs/src/cli/commands`, even though adjacent read/write command handlers have moved to `beads-cli`. This keeps core CRUD ownership split and increases regression surface during future command work.\n\n**Design**\nMove the handler implementations and argument types for `create`, `show`, and `update` into `crates/beads-cli/src/commands/`. Keep `beads-rs` modules as thin compatibility shims that call through to `beads-cli`.\n\n**Acceptance**\n- [ ] `crates/beads-cli/src/commands/{create,show,update}.rs` exist and own handler logic.\n- [ ] `crates/beads-rs/src/cli/commands/{create,show,update}.rs` are compatibility shims only.\n- [ ] Existing output semantics (human + `--json`) are unchanged.\n- [ ] Integration coverage exercises create/show/update critical paths.\n- [ ] `cargo fmt --all`, `just dylint`, `cargo clippy --all-features -- -D warnings`, `cargo test`, and `cargo test --features slow-tests` pass.\n\n**Files**\n- crates/beads-cli/src/commands/create.rs\n- crates/beads-cli/src/commands/show.rs\n- crates/beads-cli/src/commands/update.rs\n- crates/beads-rs/src/cli/commands/create.rs\n- crates/beads-rs/src/cli/commands/show.rs\n- crates/beads-rs/src/cli/commands/update.rs","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770612479888,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770612479888,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770612479888,0]}
{"id":"bd-atsg.2","created_at":[1770611167962,0],"created_by":"darin@darinsmcstudio2.lan","title":"Migrate comments/dep/label/epic/deleted/subscribe handlers to beads-cli","description":"**Problem**\nGraph/metadata command families are still split across legacy `beads-rs` handlers (`comments`, `dep`, `label`, `epic`, `deleted`, `subscribe`), which blocks a clean ownership boundary for CLI behavior.\n\n**Design**\nPort these command handlers into `crates/beads-cli/src/commands/` in one tranche focused on behavior parity and shared render/helper reuse. Leave explicit shims in `beads-rs` until the full epic closes.\n\n**Acceptance**\n- [ ] `comments`, `dep`, `label`, `epic`, `deleted`, and `subscribe` handlers are owned by `beads-cli`.\n- [ ] Legacy handlers in `beads-rs` are reduced to call-through shims.\n- [ ] Subcommand name mapping and aliases remain stable.\n- [ ] Regression tests cover dep tree/cycles, comment add/list, label add/rm/list, epic status, and deleted/subscription flows.\n- [ ] Full verification gate passes (`fmt`, `dylint`, `clippy`, `test`, `slow-tests`).\n\n**Files**\n- crates/beads-cli/src/commands/comments.rs\n- crates/beads-cli/src/commands/dep.rs\n- crates/beads-cli/src/commands/label.rs\n- crates/beads-cli/src/commands/epic.rs\n- crates/beads-cli/src/commands/deleted.rs\n- crates/beads-cli/src/commands/subscribe.rs\n- crates/beads-rs/src/cli/commands/{comments,dep,label,epic,deleted,subscribe}.rs","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770614068426,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770614068426,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770614068426,0]}
{"id":"bd-atsg.3","created_at":[1770611168264,0],"created_by":"darin@darinsmcstudio2.lan","title":"Migrate admin/store/upgrade/migrate handlers behind beads-cli backend seams","description":"**Problem**\nHost-coupled commands (`admin`, `store`, `upgrade`, `migrate`) remain anchored in `beads-rs` due backend/runtime coupling. This is the main blocker for finishing CLI ownership transfer.\n\n**Design**\nDefine typed backend seams in `beads-cli` for host-coupled operations, then migrate command handlers into `beads-cli` while preserving crate DAG boundaries (`beads-cli` must not depend on forbidden layers).\n\n**Acceptance**\n- [ ] `admin`, `store`, `upgrade`, and `migrate` command handling logic is moved to `beads-cli`.\n- [ ] Backend trait boundaries are explicit and enforced by compile-time types.\n- [ ] No forbidden dependency edges are introduced (validated with `just dylint` and crate DAG checks).\n- [ ] Existing admin/store/upgrade behavior and output are preserved.\n- [ ] Full verification gate passes (`fmt`, `dylint`, `clippy`, `test`, `slow-tests`).\n\n**Files**\n- crates/beads-cli/src/commands/admin.rs\n- crates/beads-cli/src/commands/store.rs\n- crates/beads-cli/src/commands/upgrade.rs\n- crates/beads-cli/src/commands/migrate.rs\n- crates/beads-rs/src/cli/backend.rs\n- crates/beads-rs/src/cli/commands/{admin,store,upgrade,migrate}.rs","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770615880012,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770615880012,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770615880012,0]}
{"id":"bd-atsg.4","created_at":[1770611168570,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move top-level CLI parse/dispatch ownership into beads-cli","description":"**Problem**\nTop-level parse/dispatch and command-name wiring still lives primarily in `crates/beads-rs/src/cli/mod.rs` and `crates/beads-rs/src/cli/commands/mod.rs`, even as handler logic migrates. This keeps ownership ambiguous and adds duplication risk.\n\n**Design**\nMove command parse/dispatch ownership into `beads-cli` (or a dedicated `beads-cli` entry surface), keeping `beads-rs` as a minimal orchestration shell that delegates execution.\n\n**Acceptance**\n- [ ] Primary dispatch table and command-name mapping are owned by `beads-cli`.\n- [ ] `beads-rs` entrypoint remains a thin wrapper with explicit compatibility behavior.\n- [ ] CLI flags and aliases remain backward compatible.\n- [ ] Integration tests confirm unchanged behavior for major command families.\n- [ ] Verification gate passes (`fmt`, `dylint`, `clippy`, `test`, `slow-tests`).\n\n**Files**\n- crates/beads-cli/src/**\n- crates/beads-rs/src/cli/mod.rs\n- crates/beads-rs/src/cli/commands/mod.rs\n- crates/beads-rs/src/bin/main.rs","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmcstudio2.lan","_at":[1770617270055,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770617270055,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770617270055,0]}
{"id":"bd-atsg.5","created_at":[1770611168871,0],"created_by":"darin@darinsmcstudio2.lan","title":"CLI migration closeout: shim cleanup, docs, and parity verification","description":"**Problem**\nAfter migration tranches land, compatibility shims/documentation/test mapping can drift, leaving unclear final ownership and hidden behavior gaps.\n\n**Design**\nPerform closeout cleanup: collapse stale shims, update architecture/docs, and run parity-focused regression checks to finalize `bd-atsg` with an explicit ownership map.\n\n**Acceptance**\n- [ ] `crates/beads-rs/src/cli/commands/*` contains only intentional compat stubs or fully migrated call-throughs with a removal note.\n- [ ] Ownership map is documented in architecture docs.\n- [ ] CLI parity checks (output + exit semantics) pass on critical paths.\n- [ ] `bd-atsg` acceptance checklist can be marked complete.\n- [ ] Verification gate passes (`fmt`, `dylint`, `clippy`, `test`, `slow-tests`).\n\n**Files**\n- crates/beads-rs/src/cli/**\n- crates/beads-cli/src/**\n- docs/architecture/**\n- docs/CRATE_DAG.md\n- crates/beads-rs/tests/**","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmcstudio2.lan","_at":[1770618053146,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770618053146,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770618053146,0]}
{"id":"bd-ay2","created_at":[1768245268042,0],"created_by":"darin@darinsmcstudio2.lan","title":"Crash recovery","description":"","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"duplicate stub - no description","_at":[1768253578193,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768253578193,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ayl","created_at":[1768444207021,0],"created_by":"darin@darinsmcstudio2.lan","title":"BroadcastEvent should not require canonical bytes (type-state leak)","description":"**Problem**\n`BroadcastEvent` requires `EventBytes<Canonical>`, but replication ingest accepts `EventBytes<Opaque>` and may forward non‑canonical CBOR bytes (allowed in v0.5). In `ingest_remote_batch` we wrap opaque bytes as canonical, so the type lies about the invariant.\n\n**Signals / Evidence**\n- `BroadcastEvent.bytes: EventBytes<Canonical>` (`src/daemon/broadcast.rs`).\n- Remote ingest constructs `BroadcastEvent` by wrapping `EventBytes<Opaque>` into `EventBytes<Canonical>` (`src/daemon/core.rs`).\n- `EventBytes<Canonical>::new` is public, so any caller can claim canonicality without validation.\n\n**Why this hurts velocity**\nThis is a classic “types lying” case. It makes it impossible to reason about whether bytes are canonical and forces reviewers to audit every call site instead of trusting the type.","design":"**Design**\n- Change `BroadcastEvent` to carry `EventBytes<Opaque>` (or add an enum/marker for `Canonical | Opaque`).\n- Only label bytes as canonical when produced by the canonical encoder.\n- Restrict `EventBytes<Canonical>::new` to `pub(crate)` and expose a constructor that actually enforces canonical encoding (or rename to `new_unchecked` with clear semantics).\n- Update replication broadcast/hot‑cache to use opaque bytes and avoid implicit canonical claims.","acceptance_criteria":"- [ ] Broadcast/hot‑cache can hold opaque bytes without type lies.\n- [ ] Canonical bytes are only constructed via canonical encoder (or via an explicit `*_unchecked`).\n- [ ] No `EventBytes<Canonical>` created from opaque remote bytes.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768474444255,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768474444255,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768474444255,0]}
{"id":"bd-azss","created_at":[1768856403938,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL segment rotation ignores wal_segment_max_bytes config in integration tests","description":"**Problem**\n\nWAL segments don't rotate when `wal_segment_max_bytes` is exceeded in integration tests, even though the config is written correctly.\n\n**Evidence**\n\nThe `repl_daemon_stress_wal_rotation_roundtrip` test:\n1. Sets `wal_segment_max_bytes = 8192` (8KB) in the config\n2. Creates enough events to exceed 8KB\n3. Expects `segment_count > 1`\n4. Fails with `segment_count = 1` and `total_bytes = 17098` (17KB)\n\nThe config file at `node-0/config/beads-rs/config.toml` clearly shows:\n```toml\n[limits]\nwal_segment_max_bytes = 8192\n```\n\nBut the WAL file grows to 17KB without rotating:\n```\nsegment-1768855941320-d358b60c-1a29-4065-d89d-d98ae85e5e95.wal  17098 bytes\n```\n\n**Debugging performed**\n\n1. Verified config is written correctly to `$XDG_CONFIG_HOME/beads-rs/config.toml`\n2. Verified daemon starts with `XDG_CONFIG_HOME` pointing to the right directory\n3. Confirmed unit test `segment_rotates_on_size` passes - rotation logic itself works\n4. Confirmed config merge tests pass - `merge_layers_respects_precedence` works\n5. Traced config loading path:\n   - `load_or_init()` → `load_for_repo()` → `load_user_config()` → parses as `ConfigLayer`\n   - `merge_layers(user, repo)` applies `LimitsOverride` to `Config::default()`\n   - `apply_env_overrides()` applies `BD_TEST_FAST` overrides (doesn't touch `wal_segment_max_bytes`)\n   - `Daemon::new_with_config()` stores `config.limits`\n   - `StoreRuntime::open()` receives `daemon.limits()`\n   - `EventWal::new()` creates `SegmentConfig::from_limits(limits)`\n\n**Hypothesis**\n\nThe config loading path looks correct, but something is preventing the limits from being applied. Possibilities:\n1. Store is opened before config is fully loaded (unlikely - daemon is created with config)\n2. Serialization/deserialization mismatch between `Config` and `ConfigLayer`\n3. The daemon isn't reading from `XDG_CONFIG_HOME` for some reason\n4. There's a code path that creates the store with default limits\n\n**Affected tests**\n\n- `repl_daemon_stress_wal_rotation_roundtrip` - expects WAL rotation after exceeding 8KB\n- `repl_checkpoint_bootstrap_under_churn` - expects WAL segments to reach 2 after 400 churned requests with 64KB limit\n\n**Files involved**\n\n- `tests/integration/fixtures/repl_rig.rs` - writes config via `write_replication_user_config()`\n- `src/daemon/run.rs:74` - `load_or_init()` loads config\n- `src/config/load.rs` - `load_user_config()` parses as `ConfigLayer`\n- `src/config/merge.rs` - `merge_layers()` applies overrides\n- `src/daemon/wal/segment.rs:388` - `should_rotate()` checks `max_segment_bytes`\n- `src/daemon/store/runtime.rs:185` - `EventWal::new()` created with limits","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768858715044,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768858715044,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768858715044,0]}
{"id":"bd-b54o","created_at":[1768777674711,0],"created_by":"darin@darinsmcstudio2.lan","title":"StatusCollector collect_for uses fixed sleep; sample on watermark changes","description":"tests/integration/fixtures/admin_status.rs collect_for sleeps at fixed intervals. Use ReadConsistency require_min_seen + wait_timeout_ms to block until watermarks advance (or expose a wait-for-status helper) so sampling isn’t busy-waiting. Update admin_status tests accordingly.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768798540012,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768798540012,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768798540012,0]}
{"id":"bd-b6x","created_at":[1765690392795,0],"created_by":"darin@darinsmcstudio2.lan","title":"Persist root slug in meta.json; default new IDs to repo-name","description":"## What's Wrong\nBead IDs now support `<slug>-<suffix>` to match beads-go (repo-name slug), but new repos still default to `bd` because slug selection is inferred from existing state.\n\n## Where\n- src/daemon/executor.rs: preferred_bead_slug(...) falls back to \"bd\" when store is empty\n- src/git/wire.rs: meta.json only stores format_version; no place to persist root slug\n\n## Why It Matters\n- Fresh repos should default to the repo-name slug (beads-go parity) or at least allow configuring it.\n- Inferring slug from existing IDs fails for empty stores and is an implicit heuristic.\n\n## Suggested Fix\n- Add `root_slug` to `meta.json` (WireMeta + core Meta), and set it on init (derive from repo dir name or remote URL basename; sanitize).\n- Use persisted `root_slug` for new ID generation.\n- Decide compatibility strategy (format_version bump if needed; ensure old readers ignore unknown fields or gate by version).\n\n## Acceptance\n- After `bd init` in a repo named `foo`, new IDs default to `foo-...` (or a clearly documented rule).\n- `bd create` in an empty store uses `meta.root_slug`, not a heuristic.","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1765785395172,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765785395172,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-bfb7","created_at":[1769555663242,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fix flaky test mutation_span_includes_realtime_context missing store_id","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769558530919,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769558530919,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769558530919,0]}
{"id":"bd-bfbr","created_at":[1769287943804,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add replication-ready barrier for tailnet tests","description":"","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769771803087,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769771803087,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769771803087,0]}
{"id":"bd-bhj0","created_at":[1768636593980,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replication stress + WAL rotation e2e","description":"**Problem**\nNo long-running/high-volume replication test exists, so WAL rotation/backpressure under load is unproven.","design":"**Design**\n- Add a slow e2e that lowers wal_segment_max_bytes in config, floods mutations across nodes, and asserts WAL segment rotation and replication catch-up.\n- Verify watermarks/head convergence and no permanent backpressure stalls.","acceptance_criteria":"- [ ] Stress test triggers WAL rotation and still converges.\n- [ ] Backpressure does not deadlock replication.\n- [ ] Tests write only under ./tmp.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768641572663,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768641572663,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768641572663,0]}
{"id":"bd-bk2","created_at":[1766127735338,0],"created_by":"darin@darinsmcstudio2.lan","title":"Crash recovery integration test (kill -9 WAL replay)","description":"**Problem**\nWe still lack an integration test that proves WAL recovery works after an unclean daemon crash. Data loss here would be catastrophic.\n\n**Design**\nAdd an integration test that:\n1) creates a repo with a bare remote\n2) starts the daemon (via bd create --json) and captures PID via IPC Ping\n3) performs a mutation (bd create) and verifies WAL file exists\n4) SIGKILL the daemon immediately (kill -9) before sync finishes\n5) restart via any bd command (autostart)\n6) assert the bead is present (bd list/show) and can be synced to remote\nUse per-test XDG_RUNTIME_DIR + BD_WAL_DIR temp dirs to avoid cross-test leakage.\n\n**Acceptance**\n- [ ] Test passes reliably\n- [ ] WAL replay is asserted (data present after restart)\n- [ ] No flakiness in CI\n\n**Files:** tests/critical_path.rs (or new tests/robustness.rs), src/daemon/ipc.rs (if needed)","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768426332260,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768426332260,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768426332260,0]}
{"id":"bd-bobi","created_at":[1770673155834,0],"created_by":"darin@darinsmcstudio2.lan","title":"Restore human daemon info rendering in beads-cli print_ok","description":"","priority":3,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmcstudio2.lan","_at":[1770673649994,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770673649994,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770673649994,0]}
{"id":"bd-bpo6","created_at":[1768701673166,0],"created_by":"darin@darinsmcstudio2.lan","title":"Flaky mutation span test misses store_id (src/daemon/executor.rs:1367)","description":" intermittently fails with missing store_id in span. Failed in cargo test run, passed on re-run. Investigate span propagation / test isolation to make deterministic.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768704519285,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768704519285,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-br62","created_at":[1768592950103,0],"created_by":"darin@darinsmcstudio2.lan","title":"Test harness tailnet profile + deterministic clock","description":"Add deterministic daemon clock injection in test harness, seedable tailnet-style network faults (loss/dup/reorder/latency), and convergence helpers; update e2e to cover tailnet profile.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768627728894,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768627728894,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768627728894,0]}
{"id":"bd-buyc","created_at":[1768776927766,0],"created_by":"darin@darinsmcstudio2.lan","title":"Observability: structured metrics logs (no SQLite)","description":"**Problem**\nWe want local‑first performance visibility without SQLite. Metrics are already emitted via tracing, but there’s no explicit structured‑log contract for offline analysis.\n\n**Design**\n- Define a metrics log schema (fields + targets) and ensure JSON logging captures it (metric name, value, labels).\n- For daemon runs, keep file logging JSON by default and include span data (current span + span list).\n- Add a small doc (or comment in telemetry) describing the schema so tools can parse logs without guesswork.\n- Verify metrics log output is preserved even when general verbosity is low (coordinate with metrics config bead).\n\n**Acceptance**\n- [ ] Metrics log schema documented (field names + examples).\n- [ ] JSON file logs include metrics fields + span context.\n- [ ] Tests or fixtures validate at least one metrics event shape.\n\n**Files:** src/telemetry.rs, src/daemon/metrics.rs, docs/* (if we add a doc)","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768815730766,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768815730766,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768815730766,0]}
{"id":"bd-bv15","created_at":[1768779166365,0],"created_by":"darin@darinsmcstudio2.lan","title":"Subscribe integration tests: replace sleep loops with read gating","description":"tests/integration/daemon/subscribe.rs uses manual polling + 30s MAX_WAIT. Use ReadConsistency require_min_seen + wait_timeout_ms tied to expected seqs (from receipts) so tests block deterministically without repeated sleep/reconnect loops.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768803014488,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768803014488,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768803014488,0]}
{"id":"bd-bzxc","created_at":[1768508733099,0],"created_by":"darin@darinsmcstudio2.lan","title":"Query/API boundary: internal models + edge conversion","description":"**Problem**\n- `src/daemon/query.rs` and `src/daemon/query_executor.rs` return `crate::api` view types directly.\n- This couples internal query logic to external schemas and makes refactors harder.\n\n**Files:**\n- src/daemon/query.rs\n- src/daemon/query_executor.rs\n- src/api/mod.rs\n- src/daemon/ipc.rs (response assembly)","design":"- Introduce internal query view types (e.g., `daemon/query_model.rs`) that are independent of `api`.\n- Update query executor to return internal types.\n- Add `From` conversions in `src/api` (or a dedicated `api/convert.rs`) to build API output at the IPC boundary.\n- Ensure CLI rendering still uses API types.","acceptance_criteria":"- [ ] `query.rs` and `query_executor.rs` no longer import `crate::api`.\n- [ ] API conversions happen at the edge (IPC response assembly).\n- [ ] Behavior unchanged; tests pass.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768533158463,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768533158463,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768533158463,0]}
{"id":"bd-c1a","created_at":[1768427184513,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace fixed test sleeps with readiness checks","description":"Remaining integration tests still use fixed sleeps (daemon_lifecycle.rs, fixtures/daemon_runtime.rs, phase7_admin_status.rs collect_for). Convert to readiness polling or channel-based waits to reduce wall time and flakiness.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768428279484,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768428279484,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768428279484,0]}
{"id":"bd-c2r","created_at":[1768444169778,0],"created_by":"darin@darinsmcstudio2.lan","title":"Enforce HLC invariants: event_time_ms must match hlc_max.physical_ms","description":"**Problem**\n`event_time_ms` and `hlc_max.physical_ms` can diverge, but we never validate their equality. `apply_event` derives the write stamp from `event_time_ms` + `hlc_max.logical`, so a mismatched `event_time_ms` silently produces a stamp that doesn’t match the event’s stated HLC. This violates the spec invariant that `event_time_ms` equals the physical time used for stamps.\n\n**Signals / Evidence**\n- `apply_event` uses `WriteStamp::new(body.event_time_ms, hlc_max.logical)` (`src/core/apply.rs`).\n- `decode_event_body` only checks that `hlc_max` exists for TxnV1, not that it agrees with `event_time_ms` (`src/core/event.rs`).\n- Mutation planning sets both from the same clock, but remote events could be malformed and still be accepted.\n\n**Why this hurts velocity**\nThis is a silent invariant violation: if we ever need to reason about stamp ordering across replicas or debug clock issues, we can’t trust the stored data. It’s a latent correctness and observability trap.","design":"**Design**\n- Add validation during decode/verify: if `hlc_max` is present, require `hlc_max.physical_ms == event_time_ms`.\n- On mismatch, return a structured `DecodeError::InvalidField` (or a dedicated error) so it maps to `invalid_request`/`corruption` per policy.\n- Add tests for mismatch rejection and match acceptance.","acceptance_criteria":"- [ ] Mismatch between `event_time_ms` and `hlc_max.physical_ms` is rejected at decode/verify.\n- [ ] Tests cover mismatch and success cases.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768457113410,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768457113410,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768457113410,0]}
{"id":"bd-c5h","created_at":[1768493910635,0],"created_by":"darin@darinsmcstudio2.lan","title":"Spec-guard realtime error codes against REALTIME_ERRORS.md","description":"**Problem**\nREALTIME_ERRORS.md is the authoritative list of realtime error codes, but we do not currently guard against drift in ErrorCode mappings. A missing code would silently break IPC compatibility.\n\n**Design**\nAdd a test that parses REALTIME_ERRORS.md and asserts every documented code parses to a concrete ErrorCode (not Unknown). Keep parsing lightweight (table rows) and deterministic.\n\n**Files**\n- src/core/error.rs (tests) or tests/realtime_errors.rs","acceptance_criteria":"- [ ] Test fails if any REALTIME_ERRORS.md code is not recognized by ErrorCode::parse\n- [ ] Test passes without introducing new error codes or touching runtime logic","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768494044027,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768494044027,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768494044027,0]}
{"id":"bd-c72","created_at":[1766136147408,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add sync soak harness script (force-push, crash recovery, multi-daemon)","description":"","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766137452937,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766137452937,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766137452937,0]}
{"id":"bd-c8j","created_at":[1765781550193,0],"created_by":"darin@darinsmcstudio2.lan","title":"Refactor query_executor.rs to use require_live helpers","description":"query_executor.rs has instances of the check-then-unwrap pattern that should use the new require_live helpers added in bd-ieo.\n\nFiles: src/daemon/query_executor.rs","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Refactored query_executor.rs to use require_live with MapLiveError trait for query_show, query_dep_tree, and query_deps.","_at":[1765787093751,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765787093751,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ca2d","created_at":[1768503840422,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove unused request_sha256 from WalIndex::record_event","description":"**Problem**\nWalIndexTxn::record_event accepts request_sha256 but immediately discards it (let _ = request_sha256). Callers still pass a value, implying it is stored. This hides information loss and is confusing (error_design principle: preserve info until an explicit boundary).\n\n**Files:** src/daemon/wal/index.rs, src/daemon/executor.rs, src/daemon/core.rs","design":"**Design**\n- Remove request_sha256 from the WalIndex trait method signature and all call sites, OR store it in the events table if it is truly needed.\n- Prefer removal (spec says request_sha256 belongs to client_requests; event index is for WAL offsets).\n- Update tests and any documentation/comments accordingly.","acceptance_criteria":"- [ ] WalIndex::record_event does not accept an unused request_sha256 parameter.\n- [ ] Call sites and tests updated; no unused variables remain.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768535059025,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768535059025,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768535059025,0]}
{"id":"bd-cbx","created_at":[1766269140280,0],"created_by":"darin@darinsmcstudio2.lan","title":"bd update should accept --reason when closing","description":"CLI update rejects --reason; update should map reason to closure when --status=closed.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Completed: update --reason now supported on bd update","_at":[1766269321820,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766269321820,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ccs1","created_at":[1768824022644,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace repl rig durability expected bool with enum","description":"tests/integration/fixtures/repl_rig.rs wait_for_durability_eligible takes expected: bool. Replace with a typed enum to encode expected eligibility state and update call sites.","acceptance_criteria":"- expected bool replaced by enum\\n- call sites updated\\n- cargo check, cargo clippy -D warnings, cargo test pass","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768824239016,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768824239016,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768824239016,0]}
{"id":"bd-cd8","created_at":[1767991120724,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright examples still use timeout_duration/command (0.31 API) in watermarks_machine.rs; update to Checker::timeout + spawn/report","description":"","priority":3,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767994522309,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767994522309,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767994522309,0]}
{"id":"bd-cfqx","created_at":[1768680764190,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright repl core via ActorModel + production ingest","description":"**Problem**\n`repl_core_machine` is a hand-written state machine that bypasses Stateright’s actor/network semantics and reimplements contiguity/gap/ACK logic. It doesn’t use production code paths.\n\n**Goal**\nCreate a production-backed replication-core model using Stateright’s ActorModel. The actor logic should call real Beads ingest functions and only model nondeterministic delivery via Stateright’s network.","design":"**Design**\n1) Replace `beads_stateright_models/examples/repl_core_machine.rs` with an ActorModel-based model.\n2) Define a `ReplActor` that:\n   - On `on_msg`, decodes a `ReplMessage::Events` (or a simplified `ReplMsg` used in the model) and uses production `verify_event_frame` + `GapBufferByNsOrigin` + `Watermark` updates to ingest.\n   - Uses production `IngestDecision` semantics (buffer, forward, reject).\n   - Tracks applied/durable watermarks via production `Watermark` types.\n3) Use Stateright network semantics instead of custom action scheduling:\n   - `Network::UnorderedDuplicating` for worst-case correctness.\n   - Optional `Network::Ordered` for quick sanity checks.\n4) Use `record_msg_in`/`record_msg_out` to collect message history for invariants.\n5) Keep model state hashable by storing summaries (watermarks, counts, digest of applied event ids).\n\n**References**\n- Stateright ActorModel + network semantics:\n  - `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor.rs`\n  - `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor/model.rs`\n  - `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor/network.rs`\n- Beads prod ingest logic:\n  - `src/core/event.rs` (`verify_event_frame`)\n  - `src/daemon/repl/gap_buffer.rs` (`GapBufferByNsOrigin`, `IngestDecision`)\n  - `src/core/watermark.rs` (watermark invariants)","acceptance_criteria":"**Acceptance**\n- [ ] `repl_core_machine` uses ActorModel and Stateright network semantics (no manual action scheduling).\n- [ ] All ingest decisions call production functions; no copy of gap/contiguity logic remains.\n- [ ] Model properties cover: no-gap ACK, monotonicity, equivocation hard-close, idempotence.\n- [ ] Model runs with at least one lossy/duplicating network setting and one ordered setting.","priority":0,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768683234434,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768683234434,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768683234434,0]}
{"id":"bd-cg3","created_at":[1766136153713,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move more CLI validation into core types (parse helpers)","description":"","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766137460946,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766137460946,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766137460946,0]}
{"id":"bd-crxg","created_at":[1770617253602,0],"created_by":"darin@darinsmcstudio2.lan","title":"Flaky repl crash/restart e2e: status can fail with gap_detected in slow-tests","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1770617253602,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-cv8","created_at":[1768488084764,0],"created_by":"darin@darinsmcstudio2.lan","title":"cli/mod.rs: --actor flag validated but never applied","description":"The global --actor flag is validated in cli/mod.rs but never used to set BD_ACTOR or populate MutationMeta.actor_id. Either wire it into daemon startup/env or remove flag.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768489648317,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768489648317,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768489648317,0]}
{"id":"bd-cwe","created_at":[1766136149911,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace eprintln! usage with tracing and adjust default log levels","description":"","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766137456841,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766137456841,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766137456841,0]}
{"id":"bd-cxi","created_at":[1768483737032,0],"created_by":"darin@darinsmcstudio2.lan","title":"tests/phase7_subscribe.rs:189 flaky Ipc(Disconnected) in phase7_subscribe_streams_events_in_order","description":"","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768489208115,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768489208115,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768489208115,0]}
{"id":"bd-cze","created_at":[1765744959621,0],"created_by":"darin@darinsmcstudio2.lan","title":"Unify run.rs and server.rs client handling","description":"**Problem**\n`run.rs` and `server.rs` both implement near-identical client handling. Duplication.\n\nAlso: `handle_request` has a `SyncWait` branch thats basically dead because the state loop intercepts it.\n\n**Design**\n- Extract shared client handling into single module\n- Prune dead `SyncWait` branch (or make it the single source of truth)\n- Reduce overall code duplication\n\n**Acceptance**\n- [ ] Single client handling implementation\n- [ ] Dead code removed\n- [ ] Existing behavior preserved\n\n**Files:** src/daemon/run.rs, src/daemon/server.rs","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768000108829,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768000108829,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768000108829,0]}
{"id":"bd-d2z","created_at":[1767992679576,0],"created_by":"darin@darinsmcstudio2.lan","title":"GC floor must retroactively clear applied events <= floor for order-independent convergence; add regression test around NamespaceGcMarker apply (see gc_floor_machine)","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767995059041,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767995059041,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767995059041,0]}
{"id":"bd-d37","created_at":[1765690392595,0],"created_by":"darin@darinsmcstudio2.lan","title":"Daemon: remove unwraps in query/executor; enforce invariants via types","description":"## What's Wrong\nDaemon query/executor code uses many `unwrap()` calls that rely on invariants (e.g., `repo_state(&remote).unwrap()`). If invariants are ever violated due to a bug or partial state load, the daemon can panic.\n\nMost of these unwraps aren't \"I forgot to handle an error\" - they're \"I proved X earlier, but the borrow checker made me re-fetch, so now I assert X with `unwrap()`\". The *proof* isn't represented in the types, so it gets re-stated as a panic.\n\n## Where\n- src/daemon/query_executor.rs:27 and similar (repo_state(...).unwrap())\n- src/daemon/executor.rs: numerous repo_state_mut/get_live_mut unwraps\n\n## Why It Matters\nPanics in the daemon take down the local serialization point. For swarms, this is a reliability cliff: a single unexpected state leads to a hard crash instead of a structured error.\n\n---\n\n## Type-Design Moves to Eliminate This Pattern\n\n### 1) Introduce \"proof types\" for states already established\n\n**LoadedRemote proof:** `ensure_repo_loaded()` returns `RemoteUrl`, then callers do `self.repo_state_mut(&remote).unwrap()` everywhere. Encode the postcondition:\n\n```rust\npub struct LoadedRemote(RemoteUrl);\n\nimpl Daemon {\n    pub fn ensure_repo_loaded(...) -> Result<LoadedRemote, OpError> { ... }\n    \n    fn repo_state(&self, r: &LoadedRemote) -> &RepoState {\n        self.repos.get(&r.0).expect(\"LoadedRemote guarantees presence\")\n    }\n    \n    fn repo_state_mut(&mut self, r: &LoadedRemote) -> &mut RepoState {\n        self.repos.get_mut(&r.0).expect(\"LoadedRemote guarantees presence\")\n    }\n}\n```\n\nNow all those \"invariant unwraps\" disappear from call sites, and the invariant is centralized at the boundary. If you truly want *zero panics*, make those `expect(...)` become `Result<&RepoState, OpError::Internal(...)>` instead.\n\n**LiveBeadRef/LiveBeadMut:** In `daemon/executor.rs`, pattern is: check existence (and not tombstoned), drop borrow, tick clock, then `get_live_mut(...).unwrap()`. Create core-level lookup that returns a proof:\n\n```rust\npub enum LookupLiveError {\n    NotFound,\n    Deleted, // optionally carry Tombstone/Stamp\n}\n\npub struct LiveBeadMut<'a> { bead: &'a mut Bead }\n\nimpl CanonicalState {\n    pub fn require_live_mut(&mut self, id: &BeadId) -> Result<LiveBeadMut<'_>, LookupLiveError> {\n        if self.tombstones.contains_key(id) { return Err(LookupLiveError::Deleted); }\n        self.live.get_mut(id)\n            .map(|b| LiveBeadMut { bead: b })\n            .ok_or(LookupLiveError::NotFound)\n    }\n}\n```\n\nThen daemon maps `LookupLiveError` → `OpError::{NotFound, BeadDeleted}`. No `unwrap`, and the \"is it live?\" fact becomes a value you can pass around.\n\n### 2) Transaction helper for borrow-checker forced re-fetches\n\nThe biggest reason you end up with `unwrap()` is this sequencing constraint:\n- you borrow `repo_state` to check something\n- you need `&mut self` to tick the clock\n- so you drop the borrow and later re-borrow and `unwrap()`\n\nWrap mutation in a helper that ticks before handing out the borrow:\n\n```rust\nimpl Daemon {\n    fn with_mutation<R>(\n        &mut self,\n        repo: &Path,\n        git_tx: &Sender<GitOp>,\n        f: impl FnOnce(&mut RepoState, Stamp, &RemoteUrl) -> Result<R, OpError>,\n    ) -> Result<R, OpError> {\n        let remote = self.ensure_repo_loaded(repo, git_tx)?;      // ensures entry exists\n        let write = self.clock_mut().tick();\n        let stamp = Stamp { at: write, by: self.actor().clone() };\n\n        let rs = self.repo_state_mut(&remote);                    // infallible via LoadedRemote\n        f(rs, stamp, &remote.0)\n    }\n}\n```\n\nNow `apply_update`/`apply_close`/`apply_claim` can do \"check + mutate\" in one borrow, without \"check then unwrap later\".\n\n### 3) Make invariant-breaking APIs impossible\n\n`CanonicalState` claims \"live ∩ tombstones = ∅ (enforced by construction)\", but `insert_tombstone` can violate it. Two options:\n\n**Option A: Capability-gate dangerous methods**\n\n```rust\npub struct RawStateToken(());\npub(crate) fn raw_token() -> RawStateToken { RawStateToken(()) }\n\nimpl CanonicalState {\n    pub fn insert(&mut self, bead: Bead) -> Result<(), CoreError> { ... }     // safe\n    pub fn delete(&mut self, tomb: Tombstone) { ... }                         // safe\n    pub(crate) fn insert_tombstone_raw(&mut self, _t: &RawStateToken, tomb: Tombstone) { ... }\n}\n```\n\n**Option B: Single-map representation**\n\n```rust\nenum Entry { Live(Bead), Tombstone(Tombstone) }\nentries: BTreeMap<BeadId, Entry>\n```\n\n### 4) Remove duplicated keys from values\n\n`DepKey` stored both as map key and inside `DepEdge.key`. Remove duplication to make \"key/value mismatch\" impossible.\n\n### 5) Decide invariant violation strategy\n\nReturn `OpError::Internal(\"invariant violated: ...\")` instead of panicking. Add `bd validate` for reporting/auto-repairing violations.\n\n---\n\n## Recommended Implementation Sequence\n\n1. **First:** `LoadedRemote` + `with_mutation(...)` - deletes majority of daemon unwraps\n2. **Then:** Live proofs, capability tokens, single-map entries become easier\n\n## Acceptance\n- No `unwrap()` in non-test daemon paths where failures can be caused by repo state/git IO.\n- Add a regression test that exercises a failure path and ensures daemon responds with an error, not panic.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Superseded by epic bd-2fr - broken into individual beads","_at":[1765744476427,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765744476427,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-d7g","created_at":[1768411817049,0],"created_by":"darin@darinsmcstudio2.lan","title":"tests: env var races across fixtures","description":"**Problem**\nTests that mutate global env use separate locks, so env changes are not serialized across the test suite. `tests/fixtures/realtime.rs` and `tests/fixtures/store_dir.rs` each define their own static `ENV_LOCK`, meaning concurrent tests can stomp on BD_DATA_DIR/XDG_RUNTIME_DIR and cause flakiness (especially with realtime phase tests that rely on RealtimeFixture). This also makes it unsafe to run `cargo test` with multiple threads.\n\nEvidence:\n- `tests/fixtures/realtime.rs` defines `static ENV_LOCK` (line 12) and sets XDG_RUNTIME_DIR/BD_DATA_DIR globally.\n- `tests/fixtures/store_dir.rs` defines a separate `static ENV_LOCK` (line 9) and sets BD_DATA_DIR globally.\n\n**Design**\n- Introduce a single global env guard (e.g., `tests/fixtures/env_guard.rs`) and have all fixtures that mutate env acquire it.\n- Alternatively, avoid global env mutation by using `paths::set_data_dir_for_tests` / `lock_data_dir_for_tests` for in-process tests and passing env per Command for CLI tests.\n- Remove duplicated ENV_LOCKs once the shared guard is in place.\n\n**Acceptance**\n- [ ] All tests that change env use the same global guard.\n- [ ] No duplicate `static ENV_LOCK` definitions remain in fixtures.\n- [ ] Running `cargo test -- --test-threads=8` does not show env-related flakiness.\n\n**Files:**\n- tests/fixtures/realtime.rs\n- tests/fixtures/store_dir.rs\n- tests/fixtures/mod.rs (or new tests/fixtures/env_guard.rs)\n- src/paths.rs (if using test-only override helpers)","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768416307751,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768416307751,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768416307751,0]}
{"id":"bd-d98g","created_at":[1768503824837,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove double-apply in replication ingest","description":"**Problem**\nDaemon::ingest_remote_batch clones namespace state (get_or_default) and applies the entire batch to preview_state before WAL append, then applies again after WAL append. This is O(state size) per batch, doubles apply cost, and introduces another place for divergence if apply semantics change.\n\n**Files:** src/daemon/core.rs, src/core/apply.rs, src/daemon/repl/session.rs","design":"**Design**\n- Remove the preview_state clone/apply pass.\n- Rely on prior validation (verify_event_frame + deterministic apply_event) to make apply failures exceptional; if apply fails post-append, treat as corruption and surface a clear ErrorPayload (and potentially enter maintenance mode).\n- If a preflight is still desired, replace it with a lightweight validation pass that does not clone the full state (e.g., validate_event_body_limits + dependency existence checks already enforced upstream).\n- Update tests that currently rely on preview-state behavior.","acceptance_criteria":"- [ ] Replication ingest applies each event at most once to real state.\n- [ ] No full-state clone is performed in the hot replication path.\n- [ ] Apply failures after WAL append are surfaced as corruption with actionable details.\n- [ ] Tests updated to match the new behavior.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768522307802,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768522307802,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768522307802,0]}
{"id":"bd-de5","created_at":[1768443851032,0],"created_by":"darin@darinsmcstudio2.lan","title":"Namespace boundary not encoded in state (StoreState migration)","description":"**Problem**\nEventBody carries `namespace`, watermarks are namespace-scoped, but daemon state is still a single `CanonicalState`. `apply_event` ignores namespace and `CheckpointSnapshot` rejects any namespace other than core. This makes namespaces a runtime convention instead of a type-level boundary, allows ID collisions across namespaces, and spreads conditional logic across the codebase.\n\n**Signals / Evidence**\n- `RepoState.state` is `CanonicalState` (no namespace) (`src/daemon/repo.rs`).\n- `apply_event(&mut CanonicalState, &EventBody)` ignores `EventBody.namespace` (`src/core/apply.rs`).\n- `checkpoint` snapshot builder rejects non-core namespaces (`src/git/checkpoint/export.rs`).\n- Namespace-aware types exist (`StoreState`, `NamespaceId`) but are not wired through daemon state.\n\n**Why this hurts velocity**\nWe keep adding namespace-aware code (watermarks, policies, repl), but the core state remains global. Every new feature needs bespoke checks, and any future multi-namespace work becomes a large invasive refactor.","design":"**Design**\n1. Promote `RepoState.state` to `StoreState` and make namespace the primary boundary.\n2. Add a thin helper `apply_event_to_namespace(store_state, body)` that routes to `StoreState::ensure_namespace(body.namespace)` and calls existing `apply_event` on the selected `CanonicalState`.\n3. Update mutation + repl ingest paths to use the namespace-scoped state.\n4. Update checkpoint snapshot/builders to accept `StoreState` and remove the core-only restriction.\n5. Audit query paths to require/propagate namespace (most are already in `NormalizedReadConsistency`).\n6. Add cross-namespace isolation tests (same BeadId in different namespaces does not conflict).\n\n**Design Notes**\nKeep `CanonicalState` unchanged; `StoreState` should be the only place that holds per-namespace maps. This keeps CRDT algebra stable while encoding the boundary in types.","acceptance_criteria":"- [ ] `RepoState.state` is `StoreState`, not `CanonicalState`.\n- [ ] `apply_event` is only called on the `CanonicalState` for the event’s namespace.\n- [ ] Checkpoint snapshot/export supports non-core namespaces (no hard error for non-core).\n- [ ] Queries and IPC handlers require namespace explicitly or use a single defaulting rule.\n- [ ] Tests cover same BeadId in different namespaces without collision.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"duplicate of bd-3m5.81","_at":[1768448823112,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768448823112,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-dhv2","created_at":[1769481360002,0],"created_by":"darin@darinsmcstudio2.lan","title":"Unify CLI filter args + filter building","description":"**Problem**\n`crates/beads-rs/src/cli/commands/list.rs` and `crates/beads-rs/src/cli/commands/count.rs` each re-implement a large chunk of filter parsing and `Filters` population (status/type/priority/assignee/labels/time windows/etc.). This is easy to drift when adding a new filter or fixing parsing logic. `search` is a smaller subset but follows the same pattern.\n\n**Design**\nCreate a single reusable filter args struct and an `apply()` method that fills `Filters` consistently for all commands.\n\n1) Add a shared args struct (location: `crates/beads-rs/src/cli/commands/mod.rs` or new `crates/beads-rs/src/cli/filters.rs`):\n```rs\n#[derive(Args, Debug, Clone)]\npub struct CommonFilterArgs { /* shared flags */ }\nimpl CommonFilterArgs {\n    pub fn apply(&self, filters: &mut Filters) -> Result<()> { /* parsing + validation */ }\n}\n```\nShared fields should include:\n- `status`, `priority`, `priority_min`, `priority_max`\n- `bead_type`, `assignee`\n- `labels`, `labels_any`\n- `title_contains`, `desc_contains`, `notes_contains`\n- `created_after/before`, `updated_after/before`, `closed_after/before`\n- `empty_description`, `no_assignee`, `no_labels`\n\n2) Use `#[command(flatten)]` to embed `CommonFilterArgs`:\n- `ListArgs { common: CommonFilterArgs, ... }`\n- `CountArgs { common: CommonFilterArgs, ... }`\n(Ensure the flags/aliases remain the same as today.)\n\n3) Update handlers:\n- `list.rs`: initialize `Filters::default()`, call `args.common.apply(&mut filters)?`, then apply list-specific fields (limit/search/parent/sort).\n- `count.rs`: same, then apply count-specific fields (`title`, `id`, `--by-*` groupings).\n- (Optional) `search.rs`: keep as-is or use the shared struct if we want `--label` etc for search in the future. Don’t change user-facing behavior in this bead.\n\n4) Consolidate helpers:\n- `apply_common_filters` in `crates/beads-rs/src/cli/mod.rs` can be removed or reduced to a private helper used by `CommonFilterArgs::apply`.\n- Use existing `parse_time_ms_opt`, `parse_priority`, `parse_bead_type`, and `normalize_bead_id_for` for consistency.\n\n**Design Notes**\n- Keep help text and CLI flags **unchanged**.\n- Preserve current quirks (e.g., empty string filtering, label-any semantics) to avoid behavior changes.\n- Prefer minimal surface changes in handlers; the goal is to eliminate duplication, not change logic.\n\n**Files**\n- `crates/beads-rs/src/cli/commands/list.rs`\n- `crates/beads-rs/src/cli/commands/count.rs`\n- `crates/beads-rs/src/cli/commands/mod.rs` (or new `crates/beads-rs/src/cli/filters.rs`)\n- `crates/beads-rs/src/cli/mod.rs` (if helper is moved/removed)","acceptance_criteria":"- [ ] Shared `CommonFilterArgs` (or equivalent) exists with an `apply()` method that fills `Filters`.\n- [ ] `bd list` and `bd count` use the shared args via `#[command(flatten)]` and no longer duplicate filter parsing logic.\n- [ ] CLI flags, defaults, and help text remain unchanged for list/count.\n- [ ] `cargo test` passes.","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769512885656,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769512885656,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769512885656,0]}
{"id":"bd-di1","created_at":[1765744422313,0],"created_by":"darin@darinsmcstudio2.lan","title":"Collapse live/tombstones into single BeadEntry map","description":"**Problem**\nThe invariant \"live ∩ tombstones = ∅\" is enforced by careful method design:\n```rust\npub struct CanonicalState {\n    live: BTreeMap<BeadId, Bead>,\n    tombstones: BTreeMap<BeadId, Tombstone>,\n    // ...\n}\n```\n\nThis relies on `insert`/`delete` being correct. A bug could violate the invariant.\n\n**Design**\nMake the invariant structurally impossible:\n```rust\npub enum BeadEntry {\n    Live(Bead),\n    Tombstone(Tombstone),\n}\n\npub struct CanonicalState {\n    beads: BTreeMap<BeadId, BeadEntry>,\n    deps: BTreeMap<DepKey, DepEdge>,\n}\n```\n\nNow a bead cannot be both live and tombstoned - the type system prevents it.\n\n**Design Notes**\n- Bigger refactor than the other type improvements\n- Consider doing this when touching `state.rs` for other reasons\n- `get_live`/`get_tombstone` become pattern matches on entry\n- Iteration patterns change (`live.values()` → `beads.values().filter_map(...)`)\n- Wire format (`src/git/wire.rs`) may need adjustment\n\n**Acceptance**\n- [ ] `BeadEntry` enum in `src/core/state.rs`\n- [ ] `CanonicalState` uses single `beads: BTreeMap<BeadId, BeadEntry>`\n- [ ] All accessors (`get_live`, `get_tombstone`, iteration) updated\n- [ ] Wire format handles the change\n- [ ] Invariant comment updated to note its now structural\n- [ ] Tests pass\n\n**Files:** src/core/state.rs, src/git/wire.rs","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768492134064,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768492134064,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768492134064,0]}
{"id":"bd-doms","created_at":[1768508732062,0],"created_by":"darin@darinsmcstudio2.lan","title":"Refactor daemon store subsystem extraction","description":"**Problem**\n- `src/daemon/core.rs` owns store discovery, lock acquisition, namespace policy load, WAL/index open, and `StoreRuntime` wiring.\n- Store lifecycle logic is spread across `src/daemon/core.rs`, `src/daemon/store_runtime.rs`, `src/daemon/store_lock.rs`, `src/daemon/remote.rs`, and `src/paths.rs`.\n- This mixes storage concerns with request routing and makes store open/close hard to test in isolation.\n\n**Files:**\n- src/daemon/core.rs\n- src/daemon/store_runtime.rs\n- src/daemon/store_lock.rs\n- src/daemon/remote.rs\n- src/paths.rs\n- src/daemon/mod.rs","design":"- Introduce `src/daemon/store/` with submodules like `discovery.rs`, `open.rs`, `runtime.rs`, `lock.rs` (names can vary).\n- Move store-id resolution, path caches, and repo binding into a `StoreRegistry` or `StoreManager`.\n- Move `StoreRuntime::open` and related helpers into `store/runtime.rs`.\n- Keep `Daemon` API stable by delegating to the new store module (re-export types where needed).\n- Keep data layout and on-disk formats unchanged.","acceptance_criteria":"- [ ] Store discovery/open/lock logic lives under `src/daemon/store/`.\n- [ ] `src/daemon/core.rs` no longer contains store-id discovery or on-disk open code.\n- [ ] No behavior change: existing tests pass (`cargo test`).\n- [ ] Public exports from `crate::daemon` remain compatible.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768536342841,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768536342841,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-dqe","created_at":[1765744932476,0],"created_by":"darin@darinsmcstudio2.lan","title":"Durability gap: ops succeed before anything hits disk","description":"**Problem**\nMutations update in-memory state and schedule a sync later. If the process crashes or power dies before the debounce fires, acknowledged work is lost.\n\n**Design Options**\n\n*Option A:* Local WAL/journal\nAppend-only ops or periodic snapshot in the socket dir; replay on daemon start.\n\n*Option B:* Immediate local-only git commit  \nOn each mutation, write a local-only beads commit immediately (durable), push/compact later. Adds commits but can squash in compaction pass.\n\n**Design Notes**\nUser concern: Option B adds commits. Consider squash-on-push or a separate local ref that gets force-pushed after compaction.\n\n**Acceptance**\n- [ ] Crash after acknowledged mutation doesnt lose data\n- [ ] Recovery mechanism tested (kill -9 during burst, restart, verify state)\n- [ ] Performance acceptable (write latency)\n\n**Files:** src/daemon/mod.rs, src/daemon/executor.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Implemented WAL-based durability. Replaced local git commits with atomic WAL file writes (~10x faster). Recovery on startup merges WAL with git state. Unit tests pass; full kill -9 integration test deferred.","assignee":"darin@dusk","_at":[1765835871893,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765835871893,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765835871893,0]}
{"id":"bd-drtn","created_at":[1768616041734,0],"created_by":"darin@darinsmcstudio2.lan","title":"Multi-process replication rig helper (real daemons + fault injection)","description":"**Problem**\nWe have an in-process `ReplicationRig` and a single ad-hoc daemon-to-daemon test, but no reusable harness to spin up N real daemons with consistent config, fault injection, and convergence assertions. This makes it hard to add end-to-end replication tests that exercise real sockets, IPC, store discovery, and cleanup. Tests also end up duplicating setup/teardown logic and are brittle.\n\nWe need a multi-process replication rig that:\n- Boots N real `bd` daemons in separate repos/data/runtime/config roots under `./tmp`.\n- Wires real replication connections (TCP) with optional tailnet-style fault injection.\n- Provides helpers to apply ops, poll state, and assert convergence on watermarks/heads.\n- Cleans up all daemons and proxy processes reliably.\n\n**Files:** new fixture module (tests/integration/fixtures/repl_rig.rs), updated integration tests under tests/integration/daemon/.","design":"**Design**\n- Create `tests/integration/fixtures/repl_rig.rs` with:\n  - `ReplRig::new(node_count, options)` -> builds per-node dirs in `./tmp`, sets `BD_STORE_ID`, `BD_DATA_DIR`, `XDG_RUNTIME_DIR`, `XDG_CONFIG_HOME`, `BD_NO_AUTO_UPGRADE`.\n  - `Node` helper with `bd_cmd()`, `init()`, `start_daemon()`, `shutdown()`; stores `repo_dir`, `runtime_dir`, `data_dir`, `config_dir`, `listen_addr`, `replica_id`.\n  - `bootstrap_replica()` that runs `bd init`, reads `meta.json` for replica_id (StoreMeta), then shuts down daemon before configuring peers.\n  - `write_replication_config()` to emit `beads.toml` with listen addr + peers + allowed namespaces.\n- Fault injection:\n  - Allow `ReplRig` to optionally insert a `TailnetProxy` per link (reusing `tailnet_proxy` binary) with a profile (tailnet/none or custom). Expose `options.fault_profile` and `options.seed`.\n- Provide helpers:\n  - `create_issue(node, title)` returning id\n  - `wait_for_show(node, id, timeout)`\n  - `admin_status(node)` returning JSON payload\n  - `assert_converged(namespaces)` using admin watermarks/heads across all nodes.\n- Add at least one slow integration test (e.g. 3-node tailnet profile) using the rig instead of custom wiring.\n\n**Files:** tests/integration/fixtures/repl_rig.rs, tests/integration/daemon/* (new test), tests/integration/fixtures/mod.rs","acceptance_criteria":"**Acceptance**\n- [ ] New fixture `ReplRig` can spin up N real daemons with isolated dirs under `./tmp`.\n- [ ] Rig can apply ops (create/show) and assert convergence via admin watermarks/heads.\n- [ ] Rig supports tailnet-style fault injection via proxies (delay/drop/dup/reorder).\n- [ ] New slow integration test uses the rig and passes locally.\n- [ ] Cleanup reliably shuts down daemons and proxy processes; no orphaned sockets.\n- [ ] Tests run without writing outside `./tmp`.","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768632611383,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768632611383,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768632611383,0]}
{"id":"bd-dsvq","created_at":[1768508732683,0],"created_by":"darin@darinsmcstudio2.lan","title":"Extract subscription/backfill planning from server","description":"**Problem**\n- `src/daemon/server.rs` mixes transport (socket handling) with subscription/backfill planning, WAL reads, and broadcast error mapping.\n- This obscures boundaries and makes subscription behavior harder to test.\n\n**Files:**\n- src/daemon/server.rs\n- src/daemon/repl/runtime.rs\n- src/daemon/broadcast.rs\n- src/daemon/repl/want.rs (if needed)","design":"- Create a `subscription` module (`src/daemon/subscription.rs` or `src/daemon/repl/subscription.rs`).\n- Move `BackfillPlan`, `build_backfill_plan`, `WalRangeRead`, and subscriber limit helpers into that module.\n- Expose a function like `prepare_subscription(...) -> SubscribeReply` used by `server.rs`.\n- Add unit tests for backfill planning behavior in the new module.","acceptance_criteria":"- [ ] `server.rs` contains only transport loops and delegates subscription work to the new module.\n- [ ] Backfill planning is testable in isolation.\n- [ ] No behavior change; `phase7_subscribe` tests still pass.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768526386421,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768526386421,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768526386421,0]}
{"id":"bd-dxmk","created_at":[1768616058276,0],"created_by":"darin@darinsmcstudio2.lan","title":"Implement in-memory Event WAL backend (no filesystem)","description":"**Problem**\n`NodeOptions::in_memory()` still uses the on-disk Event WAL (with `SegmentSyncMode::None`) and only swaps the index to memory. This means tests still hit the filesystem, depend on WAL directory layout, and can’t run as fully in-memory deterministic simulations. It also makes it harder to test failure cases or performance without disk variability.\n\nWe need a true in-memory Event WAL backend that uses the same logical paths as the production WAL but stores segments/frames in memory (no fsync, no disk IO). This should integrate cleanly with the existing apply/replay/index pipeline and keep error handling parity with the disk WAL.\n\n**Files:** new in-memory WAL module, updates to WAL plumbing and test harness.","design":"**Design**\n- Introduce an Event WAL abstraction (e.g. `EventWalHandle` enum or `EventWalBackend` trait) that covers the methods used by daemon code: `append`, `flush`, `active_segment`, segment snapshot, etc.\n- Implement `MemoryEventWal`:\n  - Store per-namespace segments in memory (Vec<u8> frames), track SegmentHeader/SegmentId, last offsets, sealed/rotation state.\n  - Reuse existing frame/record encoding (`encode_frame`, `SegmentHeader`) so replay logic can be shared.\n  - Generate SegmentRow metadata identically to disk WAL to keep index updates identical.\n  - Provide read helpers for replay/catch-up (either adapt `rebuild_index`/`catch_up_index` to accept a segment source trait, or add `rebuild_index_from_memory` used in tests).\n- Wiring:\n  - Allow StoreRuntime/test harness to swap in memory WAL + memory index for in-memory nodes.\n  - Ensure no WAL files are created on disk for `NodeOptions::in_memory()`.\n- Error parity:\n  - Use the same `EventWalError` variants for corrupt frames/headers so callers get the same error payloads.\n\n**Files:** src/daemon/wal/event_wal.rs (abstraction), src/daemon/wal/memory_wal.rs (new), src/daemon/store/runtime.rs, src/test_harness/mod.rs, tests/e2e.rs or new integration tests.","acceptance_criteria":"**Acceptance**\n- [ ] `NodeOptions::in_memory()` runs with no WAL files written on disk.\n- [ ] In-memory WAL supports append/flush/rotation and index rebuild paths used in production.\n- [ ] Error handling matches disk WAL semantics (same EventWalError variants).\n- [ ] Add/extend tests: in-memory WAL roundtrip and replication convergence.\n- [ ] All existing tests continue to pass; no regression in disk WAL behavior.","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768619188872,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768619188872,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768619188872,0]}
{"id":"bd-ebhh","created_at":[1769480252695,0],"created_by":"darin@darinsmcstudio2.lan","title":"IPC ctx+payload refactor (no behavior change)","description":"**Problem**\nThe IPC request shapes are duplicated across beads-surface, CLI, and daemon. The daemon also re-declares a wire-shaped MutationRequest, leading to drift when fields are added. This creates high maintenance cost and risk of behavioral divergence.\n\n**Design**\nImplement the refactor in REFACTORING_PLAN.md with strict behavior preservation:\n- Keep wire format identical (serde defaults/renames unchanged).\n- Keep request hashing/idempotency semantics identical.\n- Keep Claim defaults and normalization rules identical.\nBreak the work into small, self-contained beads with explicit dependencies (surface types → CLI/daemon routing → mutation engine refactor → tests/fixtures updates).\n\n**Design Notes**\nThis epic is about restructuring types and call paths, not changing behavior. Any behavioral change is out of scope.\n\n**Acceptance**\n- [ ] All child beads completed and closed.\n- [ ] IPC JSON wire format unchanged for all ops.\n- [ ] Idempotency hash semantics unchanged.\n- [ ] Unit + integration tests updated and passing.\n\n**Files:**\n- REFACTORING_PLAN.md\n- crates/beads-surface/src/ipc/*\n- crates/beads-rs/src/cli/*\n- crates/beads-rs/src/daemon/*\n- crates/beads-rs/tests/**","design":"Follow REFACTORING_PLAN.md. The epic owns sequencing and dependencies only; each child bead has a crisp scope and acceptance criteria.","acceptance_criteria":"- [ ] All dependent beads closed.\n- [ ] `cargo test` green.","priority":2,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1769484628766,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769484628766,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ebhh.1","created_at":[1769480286540,0],"created_by":"darin@darinsmcstudio2.lan","title":"beads-surface: add ctx/payload modules and refactor Request (wire-compat)","description":"**Problem**\nIPC request shapes are duplicated and flat. We need shared ctx/payload types in beads-surface and a `Request` enum refactor without changing the wire format or defaults.\n\n**Design**\nImplement Phase 1 + Phase 2 of REFACTORING_PLAN.md in `crates/beads-surface` only:\n- Add `ipc/ctx.rs` with RepoCtx/MutationCtx/ReadCtx and constructors.\n- Add `ipc/payload.rs` with payload structs grouped by shape.\n- Move `default_lease_secs()` from `ipc/types.rs` into `ipc/mod.rs` as `pub(crate)`; import it in `payload.rs` for `ClaimPayload`.\n- Refactor `Request` enum variants to `{ ctx, payload }` with `#[serde(flatten)]` and keep all field names/renames/defaults identical.\n- Re-export ctx/payload from `ipc/types.rs` (and module wiring in `ipc/mod.rs`).\n- Update IPC unit tests in `ipc/types.rs` to new shape and add:\n  - Claim default lease (deserialize without lease_secs → 3600).\n  - ExtendClaim requires lease (missing lease_secs → error).\n  - RepoCtx rename (serialized JSON has \"repo\" not \"path\").\n\n**Design Notes**\n- Non‑negotiable behavior: serde defaults/renames must remain identical; Claim vs ExtendClaim defaults must not change.\n- Do not add new `skip_serializing_if` or change `#[serde(default)]` locations.\n\n**Acceptance**\n- [ ] `Request` JSON fields are unchanged for existing ops.\n- [ ] Claim defaults to 3600s when lease_secs is omitted; ExtendClaim still requires lease_secs.\n- [ ] `cargo test -p beads-surface ipc::types` passes.\n\n**Files:**\n- crates/beads-surface/src/ipc/ctx.rs\n- crates/beads-surface/src/ipc/payload.rs\n- crates/beads-surface/src/ipc/types.rs\n- crates/beads-surface/src/ipc/mod.rs","design":"Follow REFACTORING_PLAN.md Phases 1–2 exactly. Keep wire format identical; move default_lease_secs to ipc/mod.rs for shared use.","acceptance_criteria":"- [ ] All new ctx/payload types compile and are exported.\n- [ ] Request enum refactor keeps JSON wire format stable.\n- [ ] Added IPC tests for Claim default and ExtendClaim required lease.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769481353588,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769481353588,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769481353588,0]}
{"id":"bd-ebhh.2","created_at":[1769480295733,0],"created_by":"darin@darinsmcstudio2.lan","title":"CLI: switch Request construction to ctx/payload + helpers","description":"**Problem**\nCLI command handlers construct `Request` using the old flat shape. After the Request refactor, these calls must be updated in a consistent, ergonomic way.\n\n**Design**\n- Add `mutation_ctx()`, `read_ctx()`, `repo_ctx()` helpers on CLI `Ctx` (as in REFACTORING_PLAN.md Phase 3).\n- Update all CLI command files to construct `Request::{… { ctx, payload } }` using shared payload structs.\n- Keep all fields and defaults identical to prior behavior (especially Claim default lease).\n- Update any CLI unit tests that construct `Request` directly (search `Request::` in `crates/beads-rs/src/cli`).\n\n**Acceptance**\n- [ ] All CLI commands compile against new Request shape.\n- [ ] No behavior changes in CLI options/flags.\n- [ ] `cargo test -p beads-rs cli::mod` (and any affected CLI tests) passes.\n\n**Files:**\n- crates/beads-rs/src/cli/mod.rs\n- crates/beads-rs/src/cli/commands/*.rs","design":"Use the new ctx/payload types; prefer small helpers to avoid repetition. Preserve existing flag → field mappings verbatim.","acceptance_criteria":"- [ ] All CLI Request constructors are converted to ctx/payload.\n- [ ] CLI tests updated where they build Request directly.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769484614847,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769484614847,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769484614847,0]}
{"id":"bd-ebhh.3","created_at":[1769480308365,0],"created_by":"darin@darinsmcstudio2.lan","title":"Daemon mutation path: remove MutationRequest, parse payloads directly","description":"**Problem**\n`daemon::mutation_engine::MutationRequest` duplicates wire shapes and must be deleted. The mutation pipeline should parse directly from shared payloads while preserving all validation and idempotency behavior.\n\n**Design**\n- Delete `MutationRequest` enum in `daemon/mutation_engine.rs`.\n- Replace `ParsedMutationRequest::parse(MutationRequest, …)` with per‑payload parse fns (e.g., `parse_create(payload, actor)`), carrying over all normalization logic verbatim:\n  - trim‑to‑None for optional strings\n  - assignee `\"me\"/\"self\"` normalization\n  - invalid ID mapping to `OpError::InvalidId` vs `ValidationFailed`\n  - label/dep parsing behavior\n- Update executor mutation handling to accept payload structs instead of MutationRequest:\n  - `apply_*` signatures accept `payload: …` and pass into `ParsedMutationRequest::parse_*`.\n  - Preserve idempotency hash semantics: keep `request_sha256` based on `CanonicalMutation { namespace, actor_id, client_request_id, op }`.\n- Update `daemon/mutation_engine.rs` unit tests to use payloads + new parse fns.\n- Update `daemon/executor.rs` tests (idempotency, op_result_from_delta) that referenced MutationRequest.\n\n**Acceptance**\n- [ ] `MutationRequest` removed with no behavior changes.\n- [ ] All parsing/normalization semantics preserved.\n- [ ] Idempotency hash semantics unchanged.\n- [ ] `cargo test -p beads-rs daemon::mutation_engine` and `daemon::executor` pass.\n\n**Files:**\n- crates/beads-rs/src/daemon/mutation_engine.rs\n- crates/beads-rs/src/daemon/executor.rs","design":"Follow Phase 5 in REFACTORING_PLAN.md. Keep hash behavior identical and reuse existing normalization helpers.","acceptance_criteria":"- [ ] Per‑op parse fns replace ParsedMutationRequest::parse.\n- [ ] Executor mutation flow updated to use payloads directly.\n- [ ] Existing mutation engine tests updated for new parse API.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769484603890,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769484603890,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769484603890,0]}
{"id":"bd-ebhh.4","created_at":[1769480318089,0],"created_by":"darin@darinsmcstudio2.lan","title":"Daemon routing: update coord/server to ctx+payload","description":"**Problem**\nDaemon request routing (`coord.rs`, `server.rs`) matches on the old Request shape. After refactor, it must destructure `{ ctx, payload }` and pass repo/meta/read correctly.\n\n**Design**\n- Update `daemon/coord.rs` `handle_request` match arms to `{ ctx, payload }` and pass:\n  - `ctx.repo.path` for repo\n  - `ctx.meta` or `ctx.read` for meta/read\n  - payload struct directly to mutation/query handlers\n- Update `daemon/server.rs` RequestContext extraction, read gate request building, and any request‑type detection to use ctx/payload.\n- Keep RequestContext fields identical (repo, namespace, actor_id, client_request_id, read_consistency tags).\n- Update `daemon/server.rs` tests that construct Request variants.\n\n**Acceptance**\n- [ ] All daemon request routing compiles with ctx/payload Request.\n- [ ] RequestContext tests still validate the same extracted fields.\n- [ ] `cargo test -p beads-rs daemon::server` passes.\n\n**Files:**\n- crates/beads-rs/src/daemon/coord.rs\n- crates/beads-rs/src/daemon/server.rs","design":"Follow Phase 4 in REFACTORING_PLAN.md. Focus on mechanical destructuring and keep behavior stable.","acceptance_criteria":"- [ ] All match arms updated to ctx/payload.\n- [ ] RequestContext extraction tests updated and green.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769484609473,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769484609473,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769484609473,0]}
{"id":"bd-ebhh.5","created_at":[1769480327211,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tests/fixtures: update Request builders to ctx+payload","description":"**Problem**\nIntegration fixtures, test harness, and e2e tests construct Request/MutationRequest using the old flat shape. They must be updated to the new ctx/payload shape to keep coverage and ensure wire format stability.\n\n**Design**\n- Update `crates/beads-rs/src/test_harness/mod.rs` to build `Request::Create { ctx, payload }`.\n- Sweep `crates/beads-rs/tests/` for `Request::` and update all constructors to use ctx/payload.\n- Update `crates/beads-rs/tests/integration/fixtures/mutation.rs` to use payload structs and new parse fns (no MutationRequest).\n- Keep all JSON assertions and test semantics identical.\n\n**Acceptance**\n- [ ] `cargo test -p beads-rs --tests` passes.\n- [ ] No coverage gaps introduced (fixtures still exercise all ops and subscription paths).\n\n**Files:**\n- crates/beads-rs/src/test_harness/mod.rs\n- crates/beads-rs/tests/e2e.rs\n- crates/beads-rs/tests/integration/**","design":"Use a grep sweep for `Request::` and `MutationRequest::` in tests. Update each occurrence mechanically to ctx/payload; preserve all asserted JSON strings and expected results.","acceptance_criteria":"- [ ] All test fixtures updated to new Request shape.\n- [ ] Mutation fixtures updated to payload parse fns.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769484620472,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769484620472,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769484620472,0]}
{"id":"bd-efx","created_at":[1765780960927,0],"created_by":"darin@darinsmcstudio2.lan","title":"bd ready: sort by priority (P0 first, P4 last)","description":"Currently bd ready shows issues in some order but should be sorted by priority so that P0 issues appear first and P4 issues appear last. This helps agents pick the most important work first.","priority":3,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767995408322,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767995408322,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767995408322,0]}
{"id":"bd-eh6a","created_at":[1769233063269,0],"created_by":"darin@darinsmcstudio2.lan","title":"Label/note data leaks across bead ID collisions - LabelStore/NoteStore merge before collision resolution, losing lineage data visible on winner","description":"","priority":3,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769777313676,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769777313676,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769777313676,0]}
{"id":"bd-enq","created_at":[1768448973468,0],"created_by":"darin@darinsmcstudio2.lan","title":"Symlink rejection missing for WAL/index paths","description":"**Problem**\nFilesystem safety rules in REALTIME_PLAN require rejecting symlinks for wal.sqlite and wal/<namespace> directories. Current implementation only checks meta.json for symlinks; WAL/index paths can be symlinks, allowing writes outside store_dir.\n\n**Evidence**\n- src/daemon/wal/index.rs: SqliteWalIndex::open() creates/opens index/wal.sqlite with no symlink check.\n- src/daemon/wal/segment.rs: SegmentWriter::open() create_dir_all(wal/<namespace>) and create_segment() without rejecting symlinks.\n- src/daemon/wal/replay.rs: list_namespaces/list_segments iterate wal/ without symlink rejection.\n- REALTIME_PLAN §15.1 mandates symlink rejection for meta.json, index/wal.sqlite, and wal/<namespace>/.\n\n**Why this hurts**\nSymlinked WAL/index paths defeat store_dir confinement and can lead to writes outside the intended store, violating safety assumptions.","design":"**Design**\n1) Add a small helper (e.g., ensure_no_symlink(path)) and use it before opening wal.sqlite and before using wal/<namespace> paths.\n2) In SqliteWalIndex::open(), reject if wal.sqlite is a symlink (or its parent index dir is a symlink).\n3) In SegmentWriter::open()/create_segment(), reject if wal/<namespace> path is a symlink (or resolve symlink metadata).\n4) In replay_index (list_namespaces/list_segments), reject symlinked wal dirs with a clear error.\n5) Map errors to PathSymlinkRejected in IPC.\n\nAdd tests with tempdir + symlink that confirm rejection.","acceptance_criteria":"- [ ] Opening wal.sqlite rejects symlinked files/dirs.\n- [ ] Opening wal/<namespace> rejects symlinked dirs.\n- [ ] Replay/fsck path traversal rejects symlinked wal dirs.\n- [ ] Tests cover rejection paths.\n\n**Files:** src/daemon/wal/index.rs, src/daemon/wal/segment.rs, src/daemon/wal/replay.rs, src/daemon/store_runtime.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768471459759,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768471459759,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768471459759,0]}
{"id":"bd-eqi","created_at":[1766122273851,0],"created_by":"darin@darinsmcstudio2.lan","title":"Clock skew can break LWW ordering","description":"**Problem**\\nHLC relies on wall clock time. If a machine clock jumps backward or is far ahead, its stamps can dominate LWW merges and effectively overwrite other actors' updates. This can look like data loss.\\n\\n**Design**\\nPersist the last-seen WriteStamp (per-repo) and clamp local wall_ms to >= last_seen.wall_ms. If local time moves backwards, advance logical counter instead of wall time. Add skew detection (warn if now << last_seen or now >> last_seen by threshold). Consider storing max observed stamp in meta or WAL to survive restarts.\\n\\n**Acceptance**\\n- [ ] Stamps remain monotonic across restarts and backward clock jumps.\\n- [ ] Skew detection is surfaced (status/log).\\n- [ ] Tests simulate backward/forward jumps and verify monotonicity + merge ordering.\\n\\n**Files:** src/daemon/clock.rs, src/core/time.rs, src/daemon/core.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766124427491,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766124427491,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766124427491,0]}
{"id":"bd-eqn","created_at":[1768503775259,0],"created_by":"darin@darinsmcstudio2.lan","title":"Decouple mutation planning from origin_seq allocation","description":"**Problem**\nMutationEngine::plan takes origin_seq and returns fully-encoded EventBody bytes. Executor pre-allocates origin_seq via WalIndex and passes it into planning (src/daemon/executor.rs). This leaks WAL sequencing into the planner, forces long-lived SQLite txns during planning/encoding, and violates REALTIME_PLAN §0.5/§5.6 (origin_seq allocated inside WAL append). It is easy to misuse for batching/retries and makes the \"event id not assigned yet\" invariant impossible to encode in types.\n\n**Files:** src/daemon/mutation_engine.rs, src/daemon/executor.rs, src/daemon/wal/event_wal.rs, src/daemon/wal/index.rs, src/core/event.rs","design":"**Design**\n- Introduce an unsequenced event draft type (e.g., EventDraft without origin_seq/bytes) that carries delta + stamps + request_sha256.\n- Move origin_seq allocation into the WAL append path (append_local) using WalIndexTxn::next_origin_seq and durable head lookup, then build EventBody with the assigned seq and encode canonical bytes inside append.\n- Replace direct next_origin_seq calls in executor with append_local results (EventId + bytes + sha + prev_sha).\n- Keep request_sha256 computed from canonicalized mutation request; do not include origin_seq in that digest.\n- Update tests to cover seq allocation boundaries and idempotent retries.","acceptance_criteria":"- [ ] MutationEngine::plan no longer accepts origin_seq or returns pre-encoded bytes tied to a seq.\n- [ ] WAL append path is the only place that allocates origin_seq for local mutations.\n- [ ] Executor no longer holds a WAL index txn open during mutation planning/encoding.\n- [ ] Existing mutation and WAL tests pass or are updated to the new flow.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768527608416,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768527608416,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768527608416,0]}
{"id":"bd-er0e","created_at":[1768681902170,0],"created_by":"darin@darinsmcstudio2.lan","title":"Reduce repl e2e per-issue waits to speed slow-tests","description":"","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768682229894,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768682229894,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768682229894,0]}
{"id":"bd-ero6","created_at":[1768777659442,0],"created_by":"darin@darinsmcstudio2.lan","title":"ReplRig create_issue spawns bd CLI; switch to IpcClient","description":"tests/integration/fixtures/repl_rig.rs create_issue runs bd via assert_cmd for every write. Use IpcClient + Request::Create, parse ResponsePayload, and reuse client per node to avoid process spawn overhead. Speeds repl_e2e + wal rotation stress.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768799554182,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768799554182,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768799554182,0]}
{"id":"bd-eti","created_at":[1766136134236,0],"created_by":"darin@darinsmcstudio2.lan","title":"Disable tombstone GC to prevent resurrection/data loss edge cases","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766137439028,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766137439028,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766137439028,0]}
{"id":"bd-f22e","created_at":[1768610568027,0],"created_by":"darin@darinsmcstudio2.lan","title":"In-memory WAL/index backend for tests","description":"Provide in-memory WalIndex (no sqlite) and test-harness wiring for deterministic, no-fsync test stores.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768727938031,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768727938031,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768727938031,0]}
{"id":"bd-fkg","created_at":[1766127752358,0],"created_by":"darin@darinsmcstudio2.lan","title":"Wire format roundtrip + fuzz tests","description":"**Problem**\nWire serialization/parsing lacks property-level coverage. Corrupted or unexpected data could silently lose fields.\n\n**Design**\nAdd proptest-based roundtrip tests:\n- serialize_state/parse_state\n- serialize_tombstones/parse_tombstones\n- serialize_deps/parse_deps\n- serialize_meta/parse_meta (including last_write_stamp optional)\nAdditionally test tolerant parsing of legacy/extra fields (if applicable).\n\n**Acceptance**\n- [ ] Roundtrip property tests added\n- [ ] Meta last_write_stamp preserved\n- [ ] Tests run fast in CI\n\n**Files:** src/git/wire.rs, Cargo.toml","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768426227863,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768426227863,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768426227863,0]}
{"id":"bd-fn5l","created_at":[1769573201177,0],"created_by":"darin@darinsmcstudio2.lan","title":"Centralize mutation validation in core","description":"**Problem**\nMutation planning and validation are split across crates:\n- `crates/beads-rs/src/daemon/mutation_engine.rs` constructs mutations and performs partial validation.\n- `crates/beads-core/src/event.rs` performs patch validation when building event bodies.\n\nA reader must cross crates to know whether a mutation is valid. Invariants live \"somewhere else\" and are not encoded as a single validated command type.\n\n**Files:**\n- `crates/beads-rs/src/daemon/mutation_engine.rs`\n- `crates/beads-core/src/event.rs`\n- `crates/beads-core/src/wire_bead.rs`\n- `crates/beads-surface/src/ops.rs`","design":"**Design**\nCreate a validated mutation/command type in `beads-core` and require the daemon to construct only validated commands.\n\nConcrete plan:\n1) Introduce a `ValidatedMutationCommand` (or similar) in `beads-core` representing all mutation operations (create, update, close, add dep, set parent, etc.).\n2) Provide constructors that validate semantic invariants (required fields, workflow/claim rules, dep constraints, etc.).\n3) Update `mutation_engine` to build these validated commands rather than raw wire patches/ops.\n4) Update event generation to accept only validated commands and then mechanically map them to event/wire representations.\n5) Remove duplicate validation in daemon and event paths once the validated command is the sole input.\n\n**Design Notes**\n- This is a type-level boundary: once you have a `ValidatedMutationCommand`, it should be safe to apply.\n- Keep parsing and validation responsibilities clear: surface input -> parsed -> validated command -> apply/encode.","acceptance_criteria":"**Acceptance**\n- [ ] A validated mutation command type exists in `beads-core` with constructors enforcing invariants.\n- [ ] `mutation_engine` only emits validated commands (no raw unvalidated patch ops).\n- [ ] Event generation maps validated commands to wire/event representation without additional validation.\n- [ ] Duplicate validations in daemon/event paths are removed or reduced to normalization.\n- [ ] Tests cover invalid commands rejected at construction and valid commands producing events.","priority":2,"type":"chore","labels":{"entries":{"scatter":[{"replica":"b1cf9808-1b93-ce99-6aa4-46e20e14e46a","counter":6582769231331402909}],"tech-debt":[{"replica":"f0c01634-a84f-3e30-3954-73c868e2671a","counter":3470888321659076830}],"validation":[{"replica":"ae693b73-8e87-fe1b-f63a-a0ba4e593150","counter":6148553881263840510}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-fn5l-1","content":"Rendering stays in command files; avoid moving output logic into shared render modules for this work.","author":"darin@darins-Mac-Studio-2.local","at":[1769594432634,0]},{"id":"legacy-notes","content":"Rendering stays in command files; avoid moving output logic into shared render modules for this work.","author":"darin@darinsmcstudio2.lan","at":[1769595404044,0]}],"_at":[1769595404044,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769595404044,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769595404044,0]}
{"id":"bd-fpa7","created_at":[1770952695462,0],"created_by":"darin@darinsmcstudio2.lan","title":"Provide test-only metrics reset/scope API to avoid cross-test interference","description":"**Problem**\\nMetrics snapshot state is process-global, which makes strict counter/histogram assertions in concurrently running tests brittle.\\n\\n**Design**\\nAdd a test-only metrics reset/scope helper so unit tests can assert exact deltas deterministically without depending on process-global accumulation.\\n\\n**Acceptance**\\n- [ ] Test-only reset/scope API available under cfg(test)\\n- [ ] Existing sync/daemon metrics tests use deterministic local baselines\\n- [ ] No production behavior changes\\n\\n**Files:** crates/beads-daemon/src/metrics.rs, crates/beads-rs/src/git/sync.rs","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1770952695462,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-g1c","created_at":[1765744958180,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add derived indexes to avoid full dep scans","description":"Many queries do repeated full scans of deps (`deps_from`, `compute_blocked_by`, cycle detection, validation). Fine at 200 issues, painful at 20k.\n\n**Files:** src/core/state.rs, src/daemon/query_executor.rs, src/daemon/executor.rs","design":"**In-memory only** — indexes live in `RepoState`, never persisted to deps.jsonl.\n\n**Rebuild on load:** When daemon starts or merges from git, iterate deps once to build:\n```rust\nstruct DepIndexes {\n    out_edges: BTreeMap<BeadId, Vec<(BeadId, DepKind)>>,  // from -> [(to, kind)]\n    in_edges: BTreeMap<BeadId, Vec<(BeadId, DepKind)>>,   // to -> [(from, kind)]\n}\n```\n\n**Incremental update:** In `apply_add_dep` / `apply_remove_dep`, push/remove from both maps.\n\n**Functions to change:**\n- `deps_from()` (state.rs:300) → lookup `out_edges[id]`\n- `deps_to()` (state.rs:309) → lookup `in_edges[id]`  \n- `compute_blocked_by()` (query_executor.rs:707) → iterate `in_edges` filtered by kind\n- `would_create_cycle()` (executor.rs:1073) → BFS uses `out_edges` directly\n\nComplexity drops from O(all deps) to O(neighbors per hop).","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765836331910,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765836331910,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765836331910,0]}
{"id":"bd-gc3e","created_at":[1768509356085,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fixtures: consolidate identity builders","description":"**Problem**\\n- tests/integration/fixtures/identity.rs defines store_id/store_identity/replica_id helpers.\\n- tests/integration/fixtures/repl_frames.rs and repl_peer.rs redefine store_identity.\\n- tests/integration/fixtures/wal.rs builds its own StoreId/ReplicaId/StoreMeta inline.\\nThis duplication can drift (epoch/version mismatches) and makes fixtures inconsistent.\\n\\n**Files**\\n- tests/integration/fixtures/identity.rs\\n- tests/integration/fixtures/repl_frames.rs\\n- tests/integration/fixtures/repl_peer.rs\\n- tests/integration/fixtures/wal.rs","design":"Add any missing helpers to fixtures::identity (store_identity/store_meta with caller-provided seed/epoch), then replace local duplicates with imports. Once bd-rfit lands, have store_meta default to current version constants so fixtures track real formats.","acceptance_criteria":"- [ ] Only fixtures::identity owns StoreId/ReplicaId/StoreIdentity/StoreMeta builders.\\n- [ ] repl_frames/repl_peer/wal fixtures call shared helpers.\\n- [ ] cargo test --test integration passes.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768541599399,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768541599399,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768541599399,0]}
{"id":"bd-ge9f","created_at":[1768672354545,0],"created_by":"darin@darinsmcstudio2.lan","title":"Realtime: tracing + file logging defaults","description":"**Problem**\nWe lack end-to-end observability guarantees for realtime: tracing context is incomplete, and file logging defaults are not validated for daemon runs vs tests. Debugging real tailnet failures remains brittle.","design":"**Design**\n- Define a tracer/logger interface (or consistent tracing setup) that always includes critical context: store_id, store_epoch, replica_id, namespace, txn_id, client_request_id, origin_replica_id, origin_seq.\n- Enable file logging by default for daemon runs, and disable it during tests (BD_TESTING).\n- Add integration tests/assertions that context fields are present for key spans and that file logging is not enabled in tests.","acceptance_criteria":"**Acceptance**\n- [ ] File logging is enabled by default for `bd daemon run` and disabled under tests.\n- [ ] Core realtime spans/metrics include the required context fields.\n- [ ] Tests validate logging/tracing configuration and context propagation.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768677501159,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768677501159,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768677501159,0]}
{"id":"bd-gfu3","created_at":[1768779044417,0],"created_by":"darin@darinsmcstudio2.lan","title":"Use libgit2 for test repo setup to avoid spawning git","description":"Many fixtures spawn git init/config/remote for temp repos (critical_path, migration, daemon fixtures, repl_rig). Consider a shared helper that uses git2 APIs to init repo, set config, and add remote without process spawn. Should speed test setup and reduce dependency on git binary.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768814617770,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768814617770,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768814617770,0]}
{"id":"bd-gkz","created_at":[1768449027537,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replication ignores negotiated max_frame_bytes","description":"**Problem**\nHandshake negotiates an effective max_frame_bytes, but outbound writers continue using the local limit. This can emit frames larger than the peer accepts.\n\n**Evidence**\n- src/daemon/repl/session.rs: SessionPeer.max_frame_bytes is set to min(local, peer).\n- src/daemon/repl/manager.rs and src/daemon/repl/server.rs: FrameWriter is created once with limits.max_frame_bytes (local) and never updated after handshake.\n- send_payload/send_events do not clamp payload size to session.peer().max_frame_bytes.\n\n**Why this hurts**\nPeers with smaller frame limits will reject frames or disconnect even though we negotiated a smaller effective limit.","design":"**Design**\nOption A: Re-create FrameWriter after handshake with max_frame_bytes = peer.max_frame_bytes, and use it for all subsequent sends.\nOption B: Keep FrameWriter but add a size check in send_payload/send_events that enforces the peer limit (clamp batches accordingly, return FrameTooLarge if exceeded).\n\nEither way, ensure events and error payloads respect the negotiated max.","acceptance_criteria":"- [ ] Outbound payloads never exceed session.peer().max_frame_bytes.\n- [ ] send_events batches respect the peer frame limit (not just local limits).\n- [ ] Tests cover a peer with smaller max_frame_bytes.\n\n**Files:** src/daemon/repl/session.rs, src/daemon/repl/manager.rs, src/daemon/repl/server.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768454809145,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768454809145,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-gna","created_at":[1768273170014,0],"created_by":"darin@darinsmcstudio2.lan","title":"Test daemons not cleaned up: 50+ orphan bd daemon processes","description":"**Problem**\nRunning cargo test spawns daemon processes in temp directories that don't get cleaned up.\n\n```bash\npgrep -fl 'bd daemon run' | wc -l\n# Returns 50+\n```\n\nMost are from test temp dirs like:\n- /var/folders/.../beads-test-runtime-*/daemon.sock\n- /var/folders/.../.tmpXXXX/daemon.sock\n\n**Design**\n- Test fixtures should kill daemon processes on drop\n- Or use daemon shutdown request in test teardown\n- Consider `atexit` handler or test wrapper\n\n**Acceptance**\n- [ ] Daemon count doesn't grow after running cargo test\n- [ ] Test cleanup kills spawned daemons","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768428842957,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768428842957,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-gom1","created_at":[1769035051623,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fix config path override init ordering and runtime env fallback","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769040196424,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769040196424,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769040196424,0]}
{"id":"bd-gue7","created_at":[1769581967979,0],"created_by":"darin@darinsmcstudio2.lan","title":"Make state hash algorithms explicit (StateDigest)","description":"**Problem**\n“State hash” concepts are scattered and ambiguous:\n- `StoreChecksums` in `crates/beads-rs/src/git/wire.rs` hashes JSONL blobs.\n- `canonical_state_sha` in `crates/beads-rs/src/model/digest.rs` hashes canonical JSON for `CanonicalState`.\n- Checkpoint `content_hash` hashes a canonical JSON preimage in `crates/beads-rs/src/git/checkpoint/meta.rs`.\n\nThese are different algorithms over different representations, but the naming doesn’t make the distinctions explicit. This is drift risk: readers and future code can easily compare or reuse the wrong digest.\n\n**Files:**\n- `crates/beads-rs/src/git/wire.rs`\n- `crates/beads-rs/src/model/digest.rs`\n- `crates/beads-rs/src/git/checkpoint/meta.rs`\n- `crates/beads-core/src/identity.rs` (ContentHash)","design":"**Design**\nMake state digests explicit by algorithm/representation and centralize helpers.\n\nConcrete plan:\n1) Introduce a `StateDigest` enum in `beads-core` with variants like `JsonlSha256`, `CanonicalJsonSha256`, `CheckpointContentSha256`.\n2) Provide constructors that name the exact input representation, with clear function names (e.g., `digest_state_jsonl`, `digest_state_canon_json`).\n3) Replace ambiguous helpers (`canonical_state_sha`) or rename them to include representation in the name.\n4) Ensure comparisons are only done between compatible digest variants.\n\n**Design Notes**\n- Keep `ContentHash` for generic hashes, but use `StateDigest` when semantics matter.\n- This makes incorrect comparisons a compile-time error.","acceptance_criteria":"**Acceptance**\n- [ ] State digest helpers are centralized with explicit representation naming.\n- [ ] Ambiguous helpers are removed or renamed to include representation.\n- [ ] Comparisons between digests of different representations are prevented by types.\n- [ ] Tests cover each digest constructor and verify stable outputs.","priority":2,"type":"chore","labels":{"entries":{"consistency":[{"replica":"c7b8bb9a-1a86-f4b5-d2c6-5627597b5543","counter":6202662529864946871}],"drift":[{"replica":"6074ca55-a072-bdd8-a4be-46f1fefe911f","counter":11219092536443062155}],"types":[{"replica":"7f94bf78-23f1-9bfd-9d79-041712c1fd29","counter":15908889637573640793}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769771267789,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769771267789,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769771267789,0]}
{"id":"bd-gxnl","created_at":[1768672341296,0],"created_by":"darin@darinsmcstudio2.lan","title":"Realtime: WAL retention/GC guardrails","description":"**Problem**\nWAL retention/pruning is deferred, so long-running deployments can grow without bound and we have no guardrails or operator visibility.","design":"**Design**\n- Decide on a minimal retention/GC strategy consistent with REALTIME_PLAN.md; if full pruning remains deferred, add explicit guardrails instead.\n- Guardrails: surface WAL size/segment counts + growth rate in admin status/metrics, emit warnings when thresholds are exceeded, and document the operational limits in REALTIME_PLAN.md.","acceptance_criteria":"**Acceptance**\n- [ ] Either a retention/GC mechanism is implemented and tested, OR explicit guardrails are added (metrics + warnings + docs) with thresholds configurable.\n- [ ] Admin status exposes WAL size/segment growth signals.\n- [ ] Tests cover the warning/threshold behavior (deterministic, slow-test if needed).","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768722955157,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768722955157,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768722955157,0]}
{"id":"bd-h672","created_at":[1769502724207,0],"created_by":"darin@darinsmcstudio2.lan","title":"Client-request idempotency rows must store a typed, ordered event set","description":"**Problem**\n`ClientRequestRow.event_ids` is a raw `Vec<EventId>`. There is no type-level guarantee that it is:\n- non-empty\n- all in the same `(namespace, origin)`\n- ordered by `origin_seq` (or even unique)\n\nThese invariants are currently enforced ad hoc in `try_reuse_idempotent_response` (runtime checks). If a bug or bad WAL decode writes an empty/mixed list, we can emit the wrong cached response or compute an incorrect durability receipt.\n\n**Impact**\n- Idempotency safety violations: wrong result/receipt for a reused client_request_id.\n- Ordering bugs: receipts and ACK coordination rely on max seq; unordered vectors can hide the true max.\n\n**Files**\n- `crates/beads-rs/src/daemon/wal/index.rs` (ClientRequestRow + encode/decode)\n- `crates/beads-rs/src/daemon/wal/memory_index.rs`\n- `crates/beads-rs/src/daemon/executor.rs` (idempotent reuse path)\n- `crates/beads-rs/src/daemon/wal/replay.rs`","design":"**Design**\nIntroduce a typed wrapper that makes illegal states unrepresentable and preserves ordering:\n\n- New type: `ClientRequestEventIds`\n  - Fields: `namespace: NamespaceId`, `origin: ReplicaId`, `seqs: NonEmptyVec<Seq1>`\n  - Invariant: all event ids are `(namespace, origin)`; `seqs` strictly increasing.\n  - Provide `fn new(event_ids: Vec<EventId>) -> Result<Self, ClientRequestIdsError>` that:\n    - rejects empty\n    - rejects mixed namespace/origin\n    - sorts or validates strict ordering\n    - optionally de-duplicates or rejects duplicates (prefer reject)\n  - Provide `fn event_ids(&self) -> Vec<EventId>` (or iterator) that yields canonical ordering.\n\n- Replace `ClientRequestRow.event_ids: Vec<EventId>` with `event_ids: ClientRequestEventIds`.\n- Update WAL encode/decode to use the new type:\n  - `encode_event_ids` should emit canonical ordering.\n  - `decode_event_ids` should validate and return `ClientRequestEventIds`.\n- Update call sites:\n  - `upsert_client_request` signature should accept `ClientRequestEventIds`.\n  - `lookup_client_request` returns typed row; `try_reuse_idempotent_response` no longer needs to check for empty/mixed origins.\n\n**Ordering / invariants preserved**\n- Canonical ordering is by `origin_seq` ascending and preserved through encode/decode.\n- If a caller supplies out-of-order ids, constructor sorts or rejects (decide explicitly; prefer reject for truthy types).","acceptance_criteria":"- [ ] `ClientRequestEventIds::new` rejects empty or mixed-origin/namespace inputs.\n- [ ] Ordering is canonical and preserved across WAL encode/decode.\n- [ ] `ClientRequestRow` and all WAL index APIs use the typed wrapper.\n- [ ] Idempotent reuse path no longer needs to revalidate event_ids ordering/non-empty.\n- [ ] Tests cover: empty list, mixed origin, out-of-order list, and roundtrip ordering.\n- [ ] `cargo test` passes.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769551057512,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769551057512,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769551057512,0]}
{"id":"bd-haz","created_at":[1768503210143,0],"created_by":"darin@darinsmcstudio2.lan","title":"MutationRequest: add typed ParsedMutationRequest","description":"**Problem**\n`MutationRequest` in `src/daemon/mutation_engine.rs` uses `String` for bead ids, dep ids, note ids, and label values. Parsing happens in multiple branches with inconsistent error handling. This is unergonomic and allows invalid ids to flow deep into realtime planning.\n\n**Files**\n- src/daemon/mutation_engine.rs\n- src/daemon/ipc.rs\n- src/daemon/ops.rs","design":"Add a `ParsedMutationRequest` (or similar) that carries typed identifiers (`BeadId`, `NoteId`, `DepKey`, `Label`, `BeadSlug`, etc.). Parse/validate once at IPC boundary (or at the daemon core entrypoint) and pass typed requests into the mutation engine. Keep the external JSON schema unchanged but centralize conversion + error mapping.","acceptance_criteria":"- [ ] Mutation engine accepts typed requests; no parsing of IDs from strings inside planning logic.\n- [ ] Invalid IDs/labels are rejected once, at the conversion boundary.\n- [ ] Tests cover invalid ID parsing paths.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768520433456,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768520433456,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768520433456,0]}
{"id":"bd-heh","created_at":[1768173802780,0],"created_by":"darin@darinsmcstudio2.lan","title":"session_coordinator_boundary model hits counterexample for pending ingest property","description":"**Problem**\n`session_coordinator_boundary` model reports a counterexample for the property \"pending ingest starts at next expected\" when running `cargo run --example session_coordinator_boundary -- check`. This indicates either the property is too strict for v0.5 semantics (buffered/out-of-order ingest) or the model logic is wrong.\n\n**Design**\nRe-run the model and capture the counterexample path. Decide whether the property should be relaxed (e.g., allow pending ingest to start earlier) or the model should be fixed to align with v0.5 gap buffering/prev deferral rules. Update the property or ingest logic accordingly and rerun the model to confirm no counterexample.\n\n**Acceptance**\n- [ ] Reproduce the counterexample path from the model output.\n- [ ] Decide whether the property or model logic is wrong and update accordingly.\n- [ ] `cargo run --example session_coordinator_boundary -- check` completes with no counterexample for that property.\n\n**Files:** `beads_stateright_models/examples/session_coordinator_boundary.rs`","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"fixed","assignee":"darin@darinsmacstudio.lan","_at":[1768176637617,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768176637617,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768176637617,0]}
{"id":"bd-hf5d","created_at":[1770940064926,0],"created_by":"darin@darinsmcstudio2.lan","title":"Investigate label add/remove write tail-latency spikes in hotpath benchmark","description":"**Problem**\nIn hotpath benchmark runs, label mutation workflow (`label add` + `label remove`) shows significant tail latency spikes (example: mean ~43ms, max ~82ms) while most other write workflows are materially lower and tighter.\n\n**Design**\nProfile label mutation path under daemon metrics + traces to identify whether spikes are due to WAL fsync contention, checkpoint scheduling overlap, or extra query/render fanout. Add instrumentation if needed to separate queueing vs execution time.\n\n**Acceptance**\n- [ ] Repro script captures label mutation p50/p95/max with stable methodology\n- [ ] Root cause identified with evidence (metrics/logs)\n- [ ] Targeted fix reduces tail latency variance without correctness regressions\n- [ ] Regression check added to perf harness/docs\n\n**Files**\n- scripts/profile-hotpaths.sh\n- crates/beads-rs/src/daemon/*\n- crates/beads-cli/src/commands/label.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Reduced label add/remove tail latency via server loop hotpath changes (no inline WAL checkpoint on request/repl/git branches) and added p95/p99 benchmark + guardrail evidence in tmp/perf/hotpaths-20260212-161756.","assignee":"darin@darinsmcstudio2.lan","assignee_expires":1770945305567,"_at":[1770941907831,0],"_by":"darin@darinsmcstudio2.lan","_v":{"acceptance_criteria":[[1770940064926,0],"darin@darinsmcstudio2.lan"],"claim":[[1770941705567,0],"darin@darinsmcstudio2.lan"],"description":[[1770940080345,0],"darin@darinsmcstudio2.lan"],"design":[[1770940064926,0],"darin@darinsmcstudio2.lan"],"estimated_minutes":[[1770940064926,0],"darin@darinsmcstudio2.lan"],"external_ref":[[1770940064926,0],"darin@darinsmcstudio2.lan"],"labels":[[1770940080345,0],"darin@darinsmcstudio2.lan"],"priority":[[1770940064926,0],"darin@darinsmcstudio2.lan"],"source_repo":[[1770940064926,0],"darin@darinsmcstudio2.lan"],"title":[[1770940064926,0],"darin@darinsmcstudio2.lan"],"type":[[1770940064926,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770941907831,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770941705567,0]}
{"id":"bd-hips","created_at":[1768952743443,0],"created_by":"darin@darinsmcstudio2.lan","title":"Adapt bd-4rhy span propagation for PR #2 accept loop rewrite","description":"**Problem**\nPR #2 (perf-optimizations) rewrites src/daemon/run.rs accept loop from non-blocking polling to blocking accept + signal wake pattern. bd-4rhy adds span propagation to spawned threads, but targets the old structure.\n\n**Design**\nAfter PR #2 merges:\n1. Keep state_handle and git_handle span propagation (unchanged)\n2. Move client handler span propagation into the new accept_handle's loop\n3. Add span propagation to the new accept_handle thread itself\n\nThe new accept_handle structure:\n```rust\nlet accept_span = tracing::Span::current();\nlet accept_handle = std::thread::spawn(move || {\n    accept_span.in_scope(|| {\n        loop {\n            // ... accept logic ...\n            let client_span = tracing::Span::current();\n            std::thread::spawn(move || {\n                client_span.in_scope(|| handle_client(...));\n            });\n        }\n    });\n});\n```\n\n**Acceptance**\n- [ ] state_handle has span propagation\n- [ ] git_handle has span propagation  \n- [ ] accept_handle has span propagation\n- [ ] client handler threads have span propagation\n- [ ] cargo test passes\n- [ ] Traces show proper parent-child relationships across threads\n\n**Files:** src/daemon/run.rs\n**Depends on:** PR #2 merge","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769553515194,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769553515194,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769553515194,0]}
{"id":"bd-hjm","created_at":[1767984543055,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright state machine modeling for realtime Beads","description":"**Problem**\nWe need a tracked epic for the Stateright state machine model suite described in REALTIME_PLAN.md and beads_stateright_models/todo.md. Without it, modeling work is ad hoc and the sequence of invariants and model boundaries is not managed.\n\n**Design Notes**\nUse multiple small models at the seams: replication core, durability, idempotency, checkpoint lane, GC floor, identity and epoch guards, resource bounds, crash recovery. Each model should map counterexamples to integration tests.\n\n**Files:** REALTIME_PLAN.md, beads_stateright_models/todo.md, beads_stateright_models/src, beads_stateright_models/examples","design":"**Design**\nBuild a model portfolio, ordered for maximum early signal, matching the todo list:\n1) Realtime replication core: EVENTS, WANT, ACK, gaps, equivocation, monotonic seen map.\n2) Durability semantics: applied vs durable watermarks, ReplicatedFsync(k) coordinator.\n3) Idempotency and receipts: client_request_id mapping, PENDING vs COMMITTED, retry behavior, crash cut points.\n4) Checkpoint lane: snapshot inclusion, included_heads, multi writer retry loop, truthful included watermarks.\n5) GC markers and floors: ignore old events but advance contiguity and ACK.\n6) Store identity and epoch mismatch guards across replication and checkpoint import.\n7) Resource bounds and fairness: bounded buffers, round robin per namespace origin.\n8) WAL crash recovery cut points: no origin_seq reuse, durable means survives crash.\n9) Deterministic encoding and hashing: canonical CBOR and checkpoint hashing via property tests or tiny models.\n\nEach model should live in beads_stateright_models/src or examples, keep state minimal, and reference matching sections in REALTIME_PLAN.md so counterexamples map to implementation changes.","acceptance_criteria":"- [ ] Epic decomposed into per model beads with dependencies and priorities\n- [ ] Each model in beads_stateright_models/todo.md is implemented or explicitly scoped to non Stateright tests with rationale\n- [ ] Each model asserts the invariants listed in todo.md and references REALTIME_PLAN.md sections\n- [ ] Every model counterexample that maps to a product bug is translated into a deterministic regression test in the main codebase\n- [ ] Documentation exists in beads_stateright_models (README.md or similar) explaining how to run each model and interpret counterexamples","priority":2,"type":"epic","labels":{"entries":{"modeling":[{"replica":"1c35f30f-7e43-bfa4-c75f-665dbd76dc97","counter":14649477593514722683}],"realtime":[{"replica":"31ec4c94-4418-fb9c-842b-2f7339b3dba3","counter":8106486938905790905}],"stateright":[{"replica":"417b96b8-e28a-30ae-8ce4-2e49ffe1d066","counter":3031288444764710681}]},"cc":{"max":{}}},"status":"closed","_at":[1767993609274,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767993609274,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-hjm.1","created_at":[1767985279630,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright: replication core (gaps/WANT/ACK/seen_map)","description":"**Problem**\nThe current Stateright examples split core replication invariants across multiple tiny models (gap_want, equivocation, watermarks). We need one integrated replication-core model that matches REALTIME_PLAN.md §9.4/§9.5/§9.6/§9.8 and §0.12 so counterexamples map directly to the actual ingest rules.\n\n**Design Notes**\nUse existing toy pieces as seeds: beads_stateright_models/examples/gap_want_machine.rs, beads_stateright_models/examples/equivocation_machine.rs, beads_stateright_models/examples/watermarks_machine.rs, and the shared types in beads_stateright_models/src/spec.rs or realtime_types_sketch.rs.","design":"**Design**\nCreate an integrated Stateright model for the replication core: multi-namespace (core, wf), multi-origin (>=2), unordered delivery, duplication allowed. Implement the Plan §9.4/§9.5 rules: contiguity-only advancement, bounded gap buffering, WANT emission, ACK monotonicity, and equivocation detection. The model should treat the event payload as a token + sha (Plan §0.6) and maintain a small state digest set to enforce idempotence.\n\nTie the model to plan language explicitly in comments: Plan §9.4 EVENTS ordering + contiguity, §9.5 ACK monotonicity, §9.6 WANT semantics, §9.8 gap bounds, §0.12 applied vs durable seen maps (even if durable==applied in this first model). Reuse OriginStreamState-like logic (realtime_types_sketch.rs) or port minimal versions into the model to avoid drift.","acceptance_criteria":"- [ ] New model file exists (e.g., beads_stateright_models/examples/repl_core_machine.rs) and compiles\n- [ ] Properties cover todo.md Model #1 invariants: no-gap ACK, idempotence, equivocation detection, monotonicity, origin ordering, and reachability\n- [ ] Model explicitly references REALTIME_PLAN.md §9.4/§9.5/§9.6/§9.8 and §0.12 in doc comments\n- [ ] Model runs via cargo run --example repl_core_machine (or equivalent) within reasonable timeout","priority":1,"type":"feature","labels":{"entries":{"modeling":[{"replica":"5e5c50dd-8216-8dff-c3cd-072ff3c5a3aa","counter":1589913608189293226}],"realtime":[{"replica":"2c76324a-ebec-ff3b-39c1-3acc5fac3710","counter":8440291938502121092}],"stateright":[{"replica":"0d17a603-3640-a942-ba3a-06b2e25c8749","counter":17579497586890207659}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767991016023,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767991016023,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767991016023,0]}
{"id":"bd-hjm.10","created_at":[1767985369638,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright: admission + overload shedding priorities","description":"**Problem**\nThe plan defines admission priority and overload shedding (REALTIME_PLAN.md §0.19). There is no model to validate that local IPC mutations are prioritized over replication ingest and background work.\n\n**Design Notes**\nThis is a lightweight model of a priority queue with bounded capacity.","design":"**Design**\nAdd a Stateright model that simulates an AdmissionController with prioritized queues: IPC mutations > replication ingest > WANT servicing > checkpoint/scrub (Plan §0.19). Model bounded queue capacity and drop/close behavior when overloaded.\n\nProperties: local IPC is not starved by background work; replication is the first to shed under overload; no unbounded queues. Tie these to the plan invariants.","acceptance_criteria":"- [ ] New model file exists (e.g., beads_stateright_models/examples/admission_overload_machine.rs) and compiles\n- [ ] Properties cover priority ordering and overload shedding per REALTIME_PLAN.md §0.19\n- [ ] Example runs via cargo run --example admission_overload_machine (or equivalent)","priority":3,"type":"feature","labels":{"entries":{"modeling":[{"replica":"ce0d883a-aca6-bedd-edb1-16b926d3407d","counter":6520889389803509903}],"realtime":[{"replica":"d9d8d1f7-8439-a15e-f451-d72e39c343a8","counter":2165677623884005540}],"stateright":[{"replica":"36341366-8917-ade2-dacd-7a0f29bd689e","counter":13372902835658129148}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767993463416,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767993463416,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767993463416,0]}
{"id":"bd-hjm.11","created_at":[1767985377496,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright: require_min_seen read gating + timeouts","description":"**Problem**\nRead gating semantics (require_min_seen + wait_timeout_ms) are specified in REALTIME_PLAN.md §16.1 but not modeled. Without a model, it is easy to return stale reads or mis-handle retryable timeouts.\n\n**Design Notes**\nModel reads against applied watermarks and a bounded wait timer.","design":"**Design**\nCreate a Stateright model for read gating that uses applied watermarks as the truth (Plan §16.1). Include read requests with require_min_seen and wait_timeout_ms, and allow nondeterministic apply progress. Model should return: success if applied >= required, wait up to timeout, else return retryable error with current applied watermark.\n\nProperties: no read is returned with applied < require_min_seen; timeout responses are retryable and include the current watermark snapshot.","acceptance_criteria":"- [ ] New model file exists (e.g., beads_stateright_models/examples/read_gating_machine.rs) and compiles\n- [ ] Properties cover correct gating and timeout semantics per REALTIME_PLAN.md §16.1\n- [ ] Example runs via cargo run --example read_gating_machine (or equivalent)","priority":3,"type":"feature","labels":{"entries":{"modeling":[{"replica":"a40c0e1d-c70d-328c-120f-51afd29ab862","counter":17600893606934670700}],"realtime":[{"replica":"2c5f9be0-c59b-931b-013f-8edfceac9a7c","counter":13204635967680667723}],"stateright":[{"replica":"6eba5db3-2465-48dc-b6a8-96e8d377bcc2","counter":17427102999151873277}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767993540504,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767993540504,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767993540504,0]}
{"id":"bd-hjm.12","created_at":[1767985457381,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fix stateright dependency path for modeling crate","description":"**Problem**\nbeads_stateright_models depends on a local path stateright = { path = \"../stateright/stateright-master\" }, but that directory does not exist. cargo fetch fails, so models cannot be built or run.\n\n**Design Notes**\nPick one source of truth for Stateright and make it reproducible for all contributors.","design":"**Design**\nDecide on one of:\n- Add the stateright repo as a submodule under stateright/stateright-master, or\n- Switch dependency to a crates.io version or a git dependency with a fixed revision.\nUpdate beads_stateright_models/Cargo.toml accordingly and document the choice in beads_stateright_models/README.md (or similar).\n\nIf using a submodule, add setup instructions and ensure path is correct relative to repo root.","acceptance_criteria":"- [ ] cargo fetch succeeds in beads_stateright_models\n- [ ] Stateright source is pinned and reproducible (submodule or git rev or crates.io version)\n- [ ] README or docs explain how to build/run the models\n- [ ] No path dependency points to a non-existent directory","priority":1,"type":"chore","labels":{"entries":{"build":[{"replica":"e8601ed0-b6d1-e1e5-7610-5f83c97be2d6","counter":14320273262825244247}],"modeling":[{"replica":"758aca14-c651-4c85-cbf2-2ce5ce65331a","counter":10242363120617981250}],"stateright":[{"replica":"da5607ee-4768-d68f-b836-68e42516951b","counter":11383720414103967503}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767993582785,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767993582785,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767993582785,0]}
{"id":"bd-hjm.2","created_at":[1767985289433,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright: durability semantics + ReplicatedFsync(k)","description":"**Problem**\nWe need a durability coordinator model that matches REALTIME_PLAN.md §10 and §0.12. Existing watermarks_machine.rs only models monotonic counters and does not exercise ReplicatedFsync(k), eligible replica selection, or timeout semantics.\n\n**Design Notes**\nThis should align with Plan §10.1-§10.5 and the applied vs durable watermark distinction in §0.12.","design":"**Design**\nBuild a Stateright model that separates applied vs durable watermarks and explicitly models persistence as a boolean per event. Add a coordinator that waits for ReplicatedFsync(k), using an eligibility roster (Plan §10.2) and rejecting ineligible replicas. Include timeout behavior that returns retryable errors with receipts (Plan §10.5 + §0.11).\n\nLeverage the existing watermarks_machine.rs for structure but extend to include: multiple replicas, a quorum counter, and ACK-driven durable advancement. Ensure ACKs cannot advance durable beyond locally persisted events (Plan §9.5 + §0.12).","acceptance_criteria":"- [ ] New model file exists (e.g., beads_stateright_models/examples/durability_quorum_machine.rs) and compiles\n- [ ] Properties enforce: no false durability, quorum correctness for k, no counting ineligible replicas, and honest timeout receipts (todo.md Model #2)\n- [ ] Model doc comments reference REALTIME_PLAN.md §10, §0.12, and §0.11\n- [ ] Example runs via cargo run --example durability_quorum_machine (or equivalent)","priority":1,"type":"feature","labels":{"entries":{"modeling":[{"replica":"795ddba2-1131-fbd0-b1bd-72a1e25e430b","counter":556570083957757761}],"realtime":[{"replica":"ab56c7a7-1da1-09f1-bfda-00d3d0e26ad6","counter":175663632081681690}],"stateright":[{"replica":"0ef1c03f-8a69-36db-4adf-d3aa2f85c8e8","counter":6531753168502953956}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767991683829,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767991683829,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767991683829,0]}
{"id":"bd-hjm.3","created_at":[1767985300995,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright: idempotency + receipts with crash cut points","description":"**Problem**\nIdempotency and receipts are correctness-critical (REALTIME_PLAN.md §0.11, §8.2, §6.5). There is no model today that covers client_request_id reuse, PENDING vs COMMITTED receipts, or crash-window retries.\n\n**Design Notes**\nModel the receipt state machine and crash cut points so retries are deterministic and do not mint new txn_id or stamps.","design":"**Design**\nCreate a Stateright model with a client_request_id key, request_sha256 guard, and PENDING/COMMITTED receipt states. Include crash cut points aligned to Plan §6.5 ordering (append, fsync, index commit, apply, receipt finalize, reply). Allow retries at any point and ensure the model returns the original receipt without minting new identifiers (Plan §0.11, §8.2).\n\nUse small integers for stamps/txn_id but enforce the invariant that retries reuse the same values. Add explicit mismatch handling when the same client_request_id arrives with a different request digest (Plan §0.11).","acceptance_criteria":"- [ ] New model file exists (e.g., beads_stateright_models/examples/idempotency_receipt_machine.rs) and compiles\n- [ ] Properties cover: at-most-once per client_request_id, retry returns original receipt, no stamp remint, and request digest mismatch rejection (todo.md Model #3)\n- [ ] Crash/restart scenarios are modeled for the cut points in REALTIME_PLAN.md §6.5\n- [ ] Model doc comments reference §0.11, §8.2, and §6.5","priority":1,"type":"feature","labels":{"entries":{"modeling":[{"replica":"dd55d583-da56-9121-c05e-c65a7b27b9bb","counter":13303579372635729072}],"realtime":[{"replica":"8f8704be-e1f2-a406-8d9a-57bbafbed060","counter":14768718878948176106}],"stateright":[{"replica":"79178dea-bb9e-899a-5ee1-a5ebff67a80d","counter":14873742063769662553}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767992070512,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767992070512,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767992070512,0]}
{"id":"bd-hjm.4","created_at":[1767985311211,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright: checkpoint lane correctness + multi-writer","description":"**Problem**\nWe need a model for checkpoint correctness and convergence that reflects REALTIME_PLAN.md §13 and §0.12.1. There is no Stateright model covering included watermarks, included_heads, or multi-writer retry logic.\n\n**Design Notes**\nKeep the checkpoint data abstract (state_digest + included watermarks) but model the writer loop and import rules.","design":"**Design**\nBuild a Stateright model of the checkpoint lane: a register representing the checkpoint ref per group, multiple writers with non-FF failures, and import + merge logic. Represent each checkpoint as (state_digest, included watermarks, included_heads, store_epoch). Enforce Plan §13.9 import rules: durable watermarks advance to at least meta.included and included_heads seed head_sha (Plan §0.12.1).\n\nModel the multi-writer retry loop (Plan §13.10): fetch, import+merge, re-export, retry until push succeeds. Reject epoch mismatch (Plan §2.1 + §13.9.1).\n\nKeep JSONL/manifest/tar out of scope; this model focuses on semantic correctness (Plan §13.3-§13.9).","acceptance_criteria":"- [ ] New model file exists (e.g., beads_stateright_models/examples/checkpoint_lane_machine.rs) and compiles\n- [ ] Properties cover: truthful inclusion, import advances durable >= included, multi-writer convergence, and no cross-epoch merge (todo.md Model #4)\n- [ ] Model doc comments reference REALTIME_PLAN.md §13 and §0.12.1\n- [ ] Example runs via cargo run --example checkpoint_lane_machine (or equivalent)","priority":2,"type":"feature","labels":{"entries":{"modeling":[{"replica":"157e597f-a1fd-9acb-90ce-4afd2d209ecd","counter":16889135746198541417}],"realtime":[{"replica":"2afd0341-5da5-65b2-2fe7-2596a8404a4e","counter":9722930878531069402}],"stateright":[{"replica":"eae24f2b-3d3a-e4a0-3ef5-5ba7d17c57b3","counter":9919912524913751886}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767992356270,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767992356270,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767992356270,0]}
{"id":"bd-hjm.5","created_at":[1767985320945,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright: GC markers + floor semantics","description":"**Problem**\nGC floor enforcement is correctness-sensitive but currently unmodeled. We need a Stateright model that matches REALTIME_PLAN.md §2.4 (NamespaceGcMarker) and the GC floor rules described in todo.md Model #5 so we do not accidentally stall contiguity or resurrect old state.\n\n**Design Notes**\nThe model should separate state mutation from contiguity/ACK advancement.","design":"**Design**\nCreate a model that introduces NamespaceGcMarker events, tracks gc_floor_ms per namespace, and enforces the rule: events with event_time_ms <= gc_floor are ignored as state mutations but still advance contiguity and ACK (Plan §2.4 + §9.4). Use a tiny state digest (e.g., set of applied event_ids) to test resurrection behavior.\n\nAllow nondeterministic emission of GC markers by the authority replica and ensure floor monotonicity (todo.md Model #5).\n\nReference the apply logic seam in realtime_types_sketch.rs or a small local helper to keep plan alignment.","acceptance_criteria":"- [ ] New model file exists (e.g., beads_stateright_models/examples/gc_floor_machine.rs) and compiles\n- [ ] Properties cover: floor monotonicity, old events do not mutate state, old events still advance contiguity/ACK, and deterministic convergence (todo.md Model #5)\n- [ ] Model doc comments reference REALTIME_PLAN.md §2.4 and §9.4\n- [ ] Example runs via cargo run --example gc_floor_machine (or equivalent)","priority":2,"type":"feature","labels":{"entries":{"modeling":[{"replica":"2f1f2236-69ec-51b5-73e3-679cd3bde3e0","counter":9148099286657671107}],"realtime":[{"replica":"79b0c253-3888-9464-1a85-1746182a1e14","counter":12172777823378883667}],"stateright":[{"replica":"1469fba7-9ea3-5279-9c24-01c47d55d177","counter":1273907525516143466}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767992684012,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767992684012,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767992684012,0]}
{"id":"bd-hjm.6","created_at":[1767985331288,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright: store identity + epoch guardrails across lanes","description":"**Problem**\nIdentity and epoch mismatch rules must be enforced consistently across replication, checkpoint import, and WAL header validation (REALTIME_PLAN.md §0.1, §2.1, §9.3, §9.10). The current identity_handshake model only covers the replication handshake path.\n\n**Design Notes**\nWe need one model or a paired model set that proves the same guardrails apply in all lanes.","design":"**Design**\nExtend or add a Stateright model that covers store_id and store_epoch gating across: (1) replication HELLO/WELCOME, (2) checkpoint import, and (3) WAL segment header validation. Model mismatches and assert hard-close or reject semantics in all lanes (Plan §9.10 error handling).\n\nReuse or build on beads_stateright_models/examples/identity_handshake.rs, but add explicit actions for checkpoint import and WAL header accept/reject. Ensure the same validation function is referenced in comments to map to the plan.","acceptance_criteria":"- [ ] identity_handshake model is extended or a new cross-lane model added (e.g., beads_stateright_models/examples/identity_epoch_machine.rs)\n- [ ] Properties cover: no cross-store merge, no cross-epoch merge, and consistent rejection across replication/checkpoint/WAL paths (todo.md Model #6)\n- [ ] Model doc comments reference REALTIME_PLAN.md §0.1, §2.1, §9.3, and §9.10\n- [ ] Example runs via cargo run --example identity_epoch_machine (or equivalent)","priority":2,"type":"feature","labels":{"entries":{"modeling":[{"replica":"41ccd08a-99d0-74d6-06c2-123150dfbe2d","counter":7864455774641749864}],"realtime":[{"replica":"50147b59-cadd-6b3f-0c34-e76f6ff1da1f","counter":16450275880473201191}],"stateright":[{"replica":"58a0ee78-75be-6538-1536-172a35fd5954","counter":15338259604251052376}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767992854703,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767992854703,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767992854703,0]}
{"id":"bd-hjm.7","created_at":[1767985341005,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright: resource bounds + fairness across namespaces","description":"**Problem**\nThe plan mandates bounds (MAX_FRAME_BYTES, MAX_EVENT_BATCH_BYTES, gap buffer caps) and fairness across namespaces/origins (REALTIME_PLAN.md §0.19, §9.8). There is no model that checks starvation and bounded queues.\n\n**Design Notes**\nModel cost as small integers; focus on fairness and bounded buffers rather than exact byte sizes.","design":"**Design**\nBuild a Stateright model for bounded buffers and fair scheduling across namespaces/origins. The model should include: bounded gap buffer per origin, in-flight event limits, and a round-robin scheduler that selects per-(ns, origin) batches with caps (Plan §9.8).\n\nProperties: buffers never exceed configured bounds (Plan §0.19), and no starvation for core when wf is high churn (todo.md Model #7).\n\nThe model can reuse limits constants from realtime_types_sketch.rs or define tiny constants in the example.","acceptance_criteria":"- [ ] New model file exists (e.g., beads_stateright_models/examples/fairness_bounds_machine.rs) and compiles\n- [ ] Properties cover bounded queues and no starvation for core under sustained wf churn (todo.md Model #7)\n- [ ] Model doc comments reference REALTIME_PLAN.md §0.19 and §9.8\n- [ ] Example runs via cargo run --example fairness_bounds_machine (or equivalent)","priority":2,"type":"feature","labels":{"entries":{"modeling":[{"replica":"c804cd31-ce48-56e7-7d77-02a84bb35ab4","counter":18414178269261525469}],"realtime":[{"replica":"6754632e-c9e4-a34d-7e36-a7dd50c366ed","counter":3089061322524959751}],"stateright":[{"replica":"62c65438-e9b6-4a60-8517-2fa7da20a288","counter":7323072469460752563}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767992950308,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767992950308,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767992950308,0]}
{"id":"bd-hjm.8","created_at":[1767985350339,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright: WAL crash recovery cut points","description":"**Problem**\nCrash consistency and origin_seq uniqueness must hold across the append/fsync/index/apply/receipt pipeline (REALTIME_PLAN.md §6.5). There is no model that explores crash cut points and recovery behavior.\n\n**Design Notes**\nThis is an abstract model of ordering, not a full WAL implementation.","design":"**Design**\nCreate a Stateright model that encodes the durability ordering from Plan §6.5: allocate seq, write record, fsync, index commit, apply, receipt finalize, reply. Allow a crash at each cut point and a recovery step that replays durable records and reconciles PENDING receipts (Plan §0.11).\n\nProperties: no origin_seq reuse after recovery, LocalFsync receipts imply event survives crash, and recovery finds durable-but-unindexed events (todo.md Model #8).\n\nKeep the state small (counters + flags) but align the cut points to the plan language.","acceptance_criteria":"- [ ] New model file exists (e.g., beads_stateright_models/examples/wal_crash_recovery_machine.rs) and compiles\n- [ ] Properties cover no origin_seq reuse, receipt honesty, and recovery catch-up (todo.md Model #8)\n- [ ] Model doc comments reference REALTIME_PLAN.md §6.5 and §0.11\n- [ ] Example runs via cargo run --example wal_crash_recovery_machine (or equivalent)","priority":2,"type":"feature","labels":{"entries":{"modeling":[{"replica":"8908338a-106a-a28d-bb7f-172d6f7205b7","counter":578818584251418463}],"realtime":[{"replica":"8863a426-4d1c-7cbd-2ad9-fd8e3ec740fc","counter":7762292334208004488}],"stateright":[{"replica":"a7a96c71-33cf-8c4e-a97c-fed149bd27bf","counter":8334774333147728962}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767993159522,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767993159522,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767993159522,0]}
{"id":"bd-hjm.9","created_at":[1767985361788,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright: canonical hash/prev gating + unknown-key rules","description":"**Problem**\nThe hash/prev continuity and canonical CBOR rules (REALTIME_PLAN.md §0.6, §0.6.1, §0.12.1, §9.4) are foundational. We have hash_prev_machine.rs, but it does not cover unknown-key preservation or the out-of-order buffering vs prev-check policy implied by §9.4.\n\n**Design Notes**\nThis model should clarify how verification interacts with gaps and how canonicalness is enforced before WAL append.","design":"**Design**\nExtend hash_prev_machine.rs or create a new model that adds: (a) a canonical/ non-canonical flag for incoming bytes, (b) unknown-key preservation as a requirement for hash verification, and (c) explicit policy for out-of-order events (buffered until prev is known vs immediate rejection). Tie that policy to Plan §9.4 and §0.12.1 in comments and pick the interpretation the plan intends.\n\nModel invariants: wrong store => reject, sha mismatch => reject, non-canonical => reject, prev mismatch => reject, equivocation => reject. Ensure contiguity is only advanced after successful verification and (if buffered) after gaps are filled.","acceptance_criteria":"- [ ] hash_prev_machine.rs updated or a new model added (e.g., canonical_hash_machine.rs) and compiles\n- [ ] Properties cover: canonical-only acceptance, unknown-key preservation for hash validity, prev continuity per §0.12.1, and defined behavior for out-of-order events\n- [ ] Model doc comments reference REALTIME_PLAN.md §0.6, §0.6.1, §0.12.1, and §9.4\n- [ ] Example runs via cargo run --example canonical_hash_machine (or equivalent)","priority":2,"type":"feature","labels":{"entries":{"modeling":[{"replica":"db9a18cf-8955-6c4e-41cb-b907dd389c87","counter":5216526302262082596}],"realtime":[{"replica":"a6e632ab-7b8f-a917-dfca-8cc8577b72d6","counter":14425708773074605133}],"stateright":[{"replica":"5496546e-0927-8956-7d53-bcd3e2a91621","counter":14558518687260823237}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767993328922,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767993328922,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767993328922,0]}
{"id":"bd-hljv","created_at":[1768774749470,0],"created_by":"darin@darinsmcstudio2.lan","title":"Observability: per-IPC request span with request metadata","description":"**Problem**\nIPC request handling has no per-request span, so errors and downstream logs (handle_request, read gates, durability waits) lack request context (repo, request type, namespace, actor, client_request_id).\n\n**Design**\n- Add a small RequestContext extractor in `src/daemon/server.rs` that derives request_type + key fields.\n- Create a `tracing::info_span!(\"ipc_request\", ...)` in `process_request_message` and execute `daemon.handle_request` + follow-on handling inside it.\n- For durability waiters, carry the span so the eventual response/logs are in the same span.\n- Keep fields low‑cardinality (request_type, repo, namespace, actor_id, client_request_id, read_consistency).\n\n**Acceptance**\n- [ ] Request handling logs include an `ipc_request` span with the fields above.\n- [ ] Durability wait responses/logs are emitted within the same span.\n- [ ] Unit test (or focused helper test) verifies RequestContext extraction for at least Create + Show.\n\n**Files:** src/daemon/server.rs, src/daemon/ipc/types.rs (if helper added), src/daemon/executor.rs (if needed)","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768816715171,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768816715171,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768816715171,0]}
{"id":"bd-hovg","created_at":[1768823430256,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace LoadConfig autostart bool with typed enum","description":"LoadConfig in tests/integration/fixtures/load_gen.rs uses an autostart bool flag, which is easy to misread. Replace with a small enum (Autostart::{Enabled, Disabled}) and update callers that set the flag.","design":"Introduce Autostart enum in load_gen fixture; replace LoadConfig.autostart bool with Autostart. Provide helper method to convert to bool for IpcClient::with_autostart. Update tests that set autostart to use the enum.","acceptance_criteria":"- [ ] LoadConfig has no autostart bool flag\\n- [ ] Callers use Autostart enum\\n- [ ] Tests compile and pass","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768823796304,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768823796304,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768823796304,0]}
{"id":"bd-ht74","created_at":[1768722967287,0],"created_by":"darin@darinsmcstudio2.lan","title":"Clippy: resolve -D warnings across tests + core","description":"cargo clippy --all-targets -- -D warnings currently fails on multiple existing warnings: large_enum_variant/result_large_err in tests/integration/fixtures/{admin_status,ipc_stream}.rs; field_reassign_with_default in src/cli/mod.rs, src/config/{load,merge}.rs, src/core/event.rs, src/daemon/* tests; items_after_test_module in src/daemon/store/runtime.rs; cloned_ref_to_slice_refs in src/daemon/wal/index.rs and tests; plus misc (collapsible_if, module_inception, cmp_owned, manual_div_ceil).","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768760608696,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768760608696,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768760608696,0]}
{"id":"bd-i0sq","created_at":[1769502708689,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replica liveness eligibility must be encoded in the type","description":"**Problem**\n`ReplicaLivenessRow` stores `role: ReplicaRole` and `durability_eligible: bool` independently. This allows illegal states (e.g., `Observer + durability_eligible=true`) to be constructed anywhere (runtime, tests, WAL decode). The compiler cannot prevent this, and a bad row can be persisted and replayed.\n\nThis violates the durability contract: if an ineligible replica is marked eligible, `PeerAckTable` / `DurabilityCoordinator` can count the wrong replicas and report durability that never happened.\n\n**Impact**\n- False durability acknowledgements (safety violation).\n- Hard-to-debug divergence between roster policy and observed liveness.\n\n**Files**\n- `crates/beads-rs/src/daemon/wal/index.rs` (ReplicaLivenessRow definition + sqlite load/save)\n- `crates/beads-rs/src/daemon/wal/memory_index.rs`\n- `crates/beads-rs/src/daemon/repl/runtime.rs` (upsert)\n- `crates/beads-rs/src/daemon/repl/server.rs` / `manager.rs` (role/eligibility derivation)","design":"**Design**\nMake the illegal combinations unrepresentable by type:\n\nOption A (preferred):\n- Introduce a new type that encodes role + durability eligibility together.\n  - Example:\n    - `enum ReplicaDurabilityRole { Anchor { eligible: bool }, Peer { eligible: bool }, Observer }`\n  - Derive `durability_eligible()` from the enum; remove raw bool from public surfaces.\n- Replace `ReplicaLivenessRow { role: ReplicaRole, durability_eligible: bool }` with `ReplicaLivenessRow { role: ReplicaDurabilityRole }`.\n- Provide fallible conversion for decode: `impl TryFrom<(ReplicaRole, bool)> for ReplicaDurabilityRole`.\n  - Reject Observer+eligible at decode time (fail fast and surface corruption).\n\nOption B (acceptable):\n- Keep `ReplicaRole`, but replace bool with a newtype that enforces constraints:\n  - `struct DurabilityEligible(NonObserverRole)` where `NonObserverRole = Anchor | Peer`.\n  - `ReplicaLivenessRow` holds `role: ReplicaRole` and `eligibility: Option<DurabilityEligible>` where `None` implies ineligible and `Some` implies non-observer.\n\nEnsure the type exposes a single canonical encoding/decoding path so ordering and serialization are stable.\n\n**Ordering / invariants preserved**\n- Preserve deterministic ordering of `replica_liveness` rows (still keyed by `replica_id`).\n- Preserve on-disk schema: if stored as role + bool, encode from the new type; decoding remains stable but rejects illegal combos.","acceptance_criteria":"- [ ] It is impossible to construct `Observer + eligible` at compile time.\n- [ ] WAL decode fails (clear error) if an on-disk row encodes Observer+eligible.\n- [ ] All call sites use the new typed constructor or conversion.\n- [ ] Unit tests cover conversion success/failure and ensure serialization preserves current ordering.\n- [ ] `cargo test` passes.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769510328182,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769510328182,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769510328182,0]}
{"id":"bd-i3n","created_at":[1768245589766,0],"created_by":"darin@darinsmcstudio2.lan","title":"Crash recovery","description":"","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"empty stub - no description","_at":[1768254389672,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768254389672,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-i43y","created_at":[1768679264080,0],"created_by":"darin@darinsmcstudio2.lan","title":"Realtime: production-backed Stateright models (no drift)","description":"**Problem**\nStateright models in `beads_stateright_models` re-implement core realtime logic (spec types, hashing, contiguity rules), so they can silently drift from production. This violates the requirement in bd-lzhq: invariants must be checked against the actual implementation. We need a hard guarantee that model transitions use production code paths and compile break when prod changes.\n\n**Scope**\nThis is about syncing models with production: replication ingest, gap buffering, watermarks, durability quorum, idempotency/receipts, and apply semantics. The goal is no duplicated logic in the model crate.","design":"**Design**\n1) Make `beads_stateright_models` depend on the main crate (path dep) and use production APIs directly.\n   - Add a dedicated model harness module in `beads-rs` (e.g. `src/model/*` behind a `model-testing` feature) exposing *pure* adapters for Stateright:\n     - Event generation helpers (canonical EventBody + EventFrameV1 encoding)\n     - `verify_event_frame` from `src/core/event.rs`\n     - `GapBufferByNsOrigin` from `src/daemon/repl/gap_buffer.rs`\n     - `apply_event` from `src/core/apply.rs`\n     - `PeerAckTable` + `DurabilityCoordinator::poll_replicated`\n     - Memory WAL/index and `TestClock` from `src/daemon/wal/*` + `src/test_harness/mod.rs`\n2) Replace toy types and logic in `beads_stateright_models/src/spec.rs`, `realtime_types_sketch.rs`, and `toy_codec.rs` with production types or thin adapters. If anything must remain toy, it must be isolated and explicitly justified.\n3) Update at least repl_core, durability_quorum, and idempotency_receipt models to call production functions for transitions and validation.\n4) Enforce “no drift” at build time:\n   - CI/slow-tests runs `cargo check -p beads_stateright_models` (or equivalent) so production changes break models.\n   - Add a small compile-time contract test (feature-gated) that imports all production types used by models so signature changes fail fast.\n5) Use Stateright ActorModel for the replication seam so the network semantics come from Stateright, not custom model code.\n   - Consult Stateright source for actor + network hooks:\n     - `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor.rs`\n     - `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor/model.rs`\n     - `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor/network.rs`\n     - `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor/ordered_reliable_link.rs`\n     - Example: `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/examples/linearizable-register.rs`\n   - Model should select network semantics (`Network::Ordered` vs `Network::UnorderedDuplicating`, `LossyNetwork` toggles) instead of ad hoc action scheduling.\n   - Use `record_msg_in` / `record_msg_out` + `within_boundary` to track invariants and keep state space bounded.\n6) Consider Stateright’s built-in consistency testers for read/receipt semantics:\n   - `src/semantics/linearizability.rs`\n   - `src/semantics/sequential_consistency.rs`\n   - `src/semantics/register.rs` or `write_once_register.rs` when we model read/write histories.\n\n**Notes**\nIf Stateright state can’t hold non-Hash types, store minimal summaries (watermark maps, event ids, digests) and rebuild production structs inside transitions. Prefer ActorModel (message-level) for repl seam; keep other seams as smaller models or ActorModel subsystems to avoid state explosion.","acceptance_criteria":"**Acceptance**\n- [ ] Stateright models compile against production APIs; no re-implemented replicas of realtime types/hashing/contiguity logic remain in the model crate.\n- [ ] repl_core + durability_quorum + idempotency_receipt models use production functions for state transitions.\n- [ ] CI/slow-tests (or a documented command) runs a model build that fails on production API drift.\n- [ ] README in `beads_stateright_models` states the no-drift rule and how to run the production-backed models.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"split into bd-0863 bd-cfqx bd-1bs5 bd-5xvc bd-np77 bd-3fsg","_at":[1768680829687,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768680829687,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ieo","created_at":[1765744419494,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add require_live helper to eliminate bead lookup boilerplate","description":"**Problem**\nCommon pattern of \"check exists, check not deleted, then unwrap later\":\n```rust\nif repo_state.state.get_live(id).is_none() {\n    if repo_state.state.get_tombstone(id).is_some() {\n        return Response::err(OpError::BeadDeleted(id.clone()));\n    }\n    return Response::err(OpError::NotFound(id.clone()));\n}\n// ... later ...\nlet bead = repo_state.state.get_live_mut(id).unwrap();\n```\n\n**Design**\nAdd a combined lookup that returns the appropriate error:\n```rust\npub enum LiveLookupError {\n    NotFound,\n    Deleted,\n}\n\nimpl CanonicalState {\n    pub fn require_live(&self, id: &BeadId) -> Result<&Bead, LiveLookupError> {\n        if let Some(b) = self.get_live(id) {\n            return Ok(b);\n        }\n        if self.get_tombstone(id).is_some() {\n            return Err(LiveLookupError::Deleted);\n        }\n        Err(LiveLookupError::NotFound)\n    }\n\n    pub fn require_live_mut(&mut self, id: &BeadId) -> Result<&mut Bead, LiveLookupError> {\n        // Same logic for mutable access\n    }\n}\n```\n\nDaemon maps `LiveLookupError` → `OpError::{NotFound, BeadDeleted}`.\n\n**Acceptance**\n- [ ] `LiveLookupError` enum in `src/core/state.rs`\n- [ ] `require_live` and `require_live_mut` methods on `CanonicalState`\n- [ ] Executor/query code uses these instead of check-then-unwrap pattern\n- [ ] Tests for NotFound vs Deleted cases\n\n**Files:** src/core/state.rs, src/daemon/executor.rs, src/daemon/query_executor.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765781499657,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765781499657,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765781499657,0]}
{"id":"bd-igzs","created_at":[1769573227843,0],"created_by":"darin@darinsmcstudio2.lan","title":"Gate store/checkpoint meta on supported versions","description":"**Problem**\nFormat/version gating is optional across sync/checkpoint layers:\n- Git store `parse_meta` returns `format_version` but callers do not enforce it (e.g., `crates/beads-rs/src/git/sync.rs`).\n- Checkpoint import does not check `checkpoint_format_version` at all in `crates/beads-rs/src/git/checkpoint/import.rs`.\n\nThis is a global invariant that is enforced ad-hoc, creating drift risk and silent incompatibilities.\n\n**Files:**\n- `crates/beads-rs/src/git/wire.rs`\n- `crates/beads-rs/src/git/sync.rs`\n- `crates/beads-rs/src/git/checkpoint/import.rs`\n- `crates/beads-rs/src/git/checkpoint/meta.rs`\n- `crates/beads-rs/src/git/checkpoint/publish.rs`","design":"**Design**\nIntroduce typed \"supported meta\" gates so anything past parsing is guaranteed to be on a supported version.\n\nConcrete plan:\n1) Add `SupportedStoreMeta` and `SupportedCheckpointMeta` types with constructors that validate format versions against constants.\n2) Change `parse_meta` to either return `SupportedStoreMeta` or provide `parse_supported_meta` used everywhere.\n3) Add version gating to checkpoint import (both disk-based and in-memory export) using `SupportedCheckpointMeta`.\n4) Make all downstream code accept only the supported meta types so version checks are impossible to skip.\n\n**Design Notes**\n- Keep error messages explicit about expected vs actual versions.\n- When new versions are introduced, add the gate once in the supported meta constructors.","acceptance_criteria":"**Acceptance**\n- [ ] Git store meta parsing gates on `format_version` via a supported-meta type.\n- [ ] Checkpoint import rejects unsupported `checkpoint_format_version` for both file and export paths.\n- [ ] Downstream code accepts only supported-meta types (no raw version fields).\n- [ ] Tests cover unsupported version rejection and supported version acceptance.","priority":1,"type":"chore","labels":{"entries":{"scatter":[{"replica":"ff73b6cb-d206-6896-fec8-2ab7d577d23e","counter":13781616577253221021}],"tech-debt":[{"replica":"054688af-7f36-d112-157d-7754a3e71d32","counter":18265375825415473693}],"validation":[{"replica":"700d256f-9d30-224b-ed88-3272c1835928","counter":11568530239624193259}]},"cc":{"max":{}}},"status":"closed","_at":[1769575701241,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769575701241,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-iorm","created_at":[1769581932200,0],"created_by":"darin@darinsmcstudio2.lan","title":"Make store identity resolution explicit and verified","description":"**Problem**\nStore identity resolution is implicit and provenance is lost:\n- `StoreCaches::resolve_store_id` tries env override, path cache, on-disk map, git meta, git refs, then remote fallback (`crates/beads-rs/src/daemon/store/discovery.rs`).\n- The caller gets only a `StoreId` with no indication of whether it was verified (git meta) or guessed (remote fallback).\n- The mapping is persisted even for fallback guesses, potentially cementing wrong identity.\n\nThis is implicit + drift risk: multiple sources can disagree, but the code does not encode which source is trusted.\n\n**Files:**\n- `crates/beads-rs/src/daemon/store/discovery.rs`\n- `crates/beads-rs/src/daemon/core.rs`\n- `crates/beads-rs/src/daemon/store/runtime.rs`","design":"**Design**\nMake store identity resolution explicit and type-checked.\n\nConcrete plan:\n1) Introduce a `StoreIdResolution` type with:\n   - `store_id`\n   - `source` (env/path/git_meta/git_refs/remote_fallback)\n   - `verified` (bool or enum: Verified / Unverified)\n2) Update `resolve_store_id` to return `StoreIdResolution` instead of raw `StoreId`.\n3) Only persist/store the mapping when `verified == true` (e.g., git meta/ref) or when explicitly confirmed by the user.\n4) Bubble resolution provenance into logs and into any state initialization that depends on identity.\n5) Add explicit error handling for mismatched sources (e.g., git meta vs git refs disagree).\n\n**Design Notes**\n- Remote fallback should be treated as provisional until confirmed by git meta.\n- This keeps identity semantics explicit and makes guessing visible in types.","acceptance_criteria":"**Acceptance**\n- [ ] Store identity resolution returns a typed `StoreIdResolution` with provenance.\n- [ ] Persisted store-id mappings are only written for verified sources (or explicit confirmation).\n- [ ] Callers can log or surface whether identity is verified vs provisional.\n- [ ] Tests cover conflicting sources and provisional fallback behavior.","priority":2,"type":"chore","labels":{"entries":{"consistency":[{"replica":"32c75fe9-f686-d5a2-bfdc-2d97956c40ab","counter":12001613734123142000}],"identity":[{"replica":"f765274a-9fc9-04bd-d99d-ed7dce956be1","counter":5287405369260036149}],"implicit":[{"replica":"f951b638-1dd7-f002-1247-f9fe8f5e8d06","counter":7051363103046783700}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769769739527,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769769739527,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769769739527,0]}
{"id":"bd-iq0","created_at":[1768503221515,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL: use Seq0/Seq1 types instead of raw u64","description":"**Problem**\nRealtime WAL code uses raw `u64` for origin sequences in multiple layers (`RecordHeader.origin_seq`, wal index APIs, wal range reader). Callers must manually convert to `Seq1` and check for zero. This weakens invariants and makes it easy to forget a check.\n\n**Files**\n- src/daemon/wal/record.rs\n- src/daemon/wal/index.rs\n- src/daemon/wal/event_wal.rs\n- src/daemon/repl/runtime.rs\n- src/daemon/executor.rs","design":"Refactor WAL APIs to use `Seq1`/`Seq0`:\n- `RecordHeader.origin_seq: Seq1` (convert to/from u64 only when encoding/decoding bytes).\n- WalIndex `next_origin_seq` returns `Seq1`; `iter_from`/`max_origin_seq` accept/return `Seq0` where appropriate.\n- `WalRangeReader::read_range` and any `from_seq_excl` parameters should be `Seq0`.\nUpdate callers and tests accordingly to remove `Seq1::from_u64` checks.","acceptance_criteria":"- [ ] No WAL-facing APIs use raw `u64` for origin sequence inside the codebase.\n- [ ] Record header encoding/decoding remains identical on the wire.\n- [ ] Executor/WAL range paths no longer need to validate `Seq1::from_u64`.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768508452669,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768508452669,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768508452669,0]}
{"id":"bd-ir5j","created_at":[1768710062452,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright repl: add equivocation coverage run","description":"**Problem**\nEquivocation paths are opt-in; it is easy to forget to exercise them in model runs.\n\n**Design**\n- Add a documented command (and optionally a CI/just target) that runs the repl model with --equivocate.\n- Keep default equivocation off to avoid inflating baseline runs.\n\n**Acceptance**\n- [ ] There is a named command/target that runs with --equivocate.\n- [ ] No change to default model behavior.\n\n**Files**\n- justfile or scripts/ (if adding a target)\n- beads_stateright_models/examples/repl_core_machine.rs (docs/help text if needed)","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768721558420,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768721558420,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768721558420,0]}
{"id":"bd-iv40","created_at":[1768778641103,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace tailnet_proxy integration tests with network sim where possible","description":"tests/integration/daemon/repl_e2e.rs uses external tailnet_proxy for tailnet/pathological profiles. Consider using in-process NetworkSimulator (test_harness) for most fault-injection coverage, keeping only a minimal tailnet_proxy smoke test to validate the binary + framing.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768819994984,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768819994984,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768819994984,0]}
{"id":"bd-ix9","created_at":[1768503805795,0],"created_by":"darin@darinsmcstudio2.lan","title":"Align realtime error codes with specific Hash/Prev/WAL/Index variants","description":"**Problem**\nSeveral realtime error paths return ErrorCode::Corruption even when more specific codes exist (HashMismatch, PrevShaMismatch, WalCorrupt, IndexCorrupt). Examples: repl/session.rs event_frame_error_payload (hash/prev mismatches), repl/runtime.rs WalRangeError mapping (index/wal), server.rs stream_event_response_from_parts. This erodes the caller's decision surface and conflicts with REALTIME_ERRORS.md.\n\n**Files:** src/daemon/repl/session.rs, src/daemon/repl/runtime.rs, src/daemon/server.rs, src/daemon/ops.rs, src/core/error.rs","design":"**Design**\n- Replace generic Corruption usage with the specific ErrorCode variants and attach the matching *Details structs (HashMismatchDetails, PrevShaMismatchDetails, WalCorruptDetails, IndexCorruptDetails).\n- Audit other realtime error mappings for similar overbroad Corruption usage.\n- Add/adjust tests to assert the precise ErrorCode and details for each path.","acceptance_criteria":"- [ ] Hash/prev mismatch errors surface ErrorCode::HashMismatch / ErrorCode::PrevShaMismatch with details.\n- [ ] WAL/index range errors surface ErrorCode::WalCorrupt / ErrorCode::IndexCorrupt with details.\n- [ ] Tests cover each mapping and no regressions in IPC/replication payloads.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768521661577,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768521661577,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768521661577,0]}
{"id":"bd-iy0c","created_at":[1768638391462,0],"created_by":"darin@darinsmcstudio2.lan","title":"Reduce enum string mapping boilerplate (as_str/parse)","description":"Enum string mapping/parsing is duplicated across core/daemon (e.g., ProtocolErrorCode, CliErrorCode, DepKind, MessageType, Effect, WorkflowStatus). This creates long match ladders and drift risk.","design":"Introduce a cross-crate solution to define string forms and parsing in one place. Options: (A) add strum + strum_macros and replace match ladders with derives + aliases, or (B) add a local enum_str! macro that defines variant->string and alias parse table. Apply to core/error.rs, core/domain.rs, daemon/repl/proto.rs, core/event.rs, core/wire_bead.rs, error.rs, cli/commands/store.rs, daemon/store/discovery.rs.","acceptance_criteria":"- [ ] Remove manual as_str/parse match ladders for the enums listed in design\n- [ ] All tests pass (cargo test)\n- [ ] No behavior change in string formats","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768759609556,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768759609556,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768759609556,0]}
{"id":"bd-izhh","created_at":[1768719776129,0],"created_by":"darin@darinsmcstudio2.lan","title":"CLI update: skip fetch for non-JSON output","description":"src/cli/commands/update.rs fetches issue after updates just to print updated id. For non-JSON output, avoid fetch and print the id from args; keep fetch only for --json.","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768757653222,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768757653222,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768757653222,0]}
{"id":"bd-j5q1","created_at":[1768777663149,0],"created_by":"darin@darinsmcstudio2.lan","title":"ReplRig convergence/peers checks poll admin_status; add wait-based IPC helper","description":"tests/integration/fixtures/repl_rig.rs assert_converged + assert_peers_seen poll admin_status in a loop. Add a wait-style IPC (or extend admin/status with wait semantics) so tests can block on watermarks/peer visibility without sleep polling. Update repl_e2e to use the wait helper.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768800003256,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768800003256,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768800003256,0]}
{"id":"bd-j9l","created_at":[1768411803728,0],"created_by":"darin@darinsmcstudio2.lan","title":"tests: critical_path/migration share runtime dir","description":"**Problem**\n`tests/critical_path.rs` and `tests/migration.rs` share a single runtime/data dir for the entire test process via `test_runtime_dir()` (OnceLock + `/tmp/beads-test-runtime-<pid>`). That means all tests in both modules share the same XDG_RUNTIME_DIR/BD_DATA_DIR and the same daemon socket. There is no cleanup of that directory, and parallel test runs can cross-talk through the shared daemon/state. This undermines realtime phase test isolation and makes failures order-dependent.\n\nEvidence:\n- `tests/critical_path.rs` lines 14-28 define `test_runtime_dir()` with OnceLock and a fixed path.\n- `tests/migration.rs` lines 11-25 define the same pattern and reuse it for BD env.\n\n**Design**\n- Replace `test_runtime_dir()` with a per-test TempDir runtime (owned by the test fixture / TestRepo).\n- Make `TestRepo` carry `runtime_dir: TempDir` and `data_dir: PathBuf`, and update `bd()` to use those paths.\n- Reuse the shared shutdown helper from the daemon teardown bead so each runtime is cleaned up on Drop.\n- Avoid shared globals so tests can run in parallel without state collisions.\n\n**Acceptance**\n- [ ] `tests/critical_path.rs` and `tests/migration.rs` no longer use OnceLock-based runtime dirs.\n- [ ] Each test uses a unique TempDir for XDG_RUNTIME_DIR/BD_DATA_DIR and it is removed on Drop.\n- [ ] Tests can run with `--test-threads=N` without sharing a daemon/socket.\n\n**Files:**\n- tests/critical_path.rs\n- tests/migration.rs\n- tests/fixtures/daemon_runtime.rs (new, shared helper)","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768416234514,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768416234514,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768416234514,0]}
{"id":"bd-ja8c","created_at":[1768509364469,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fixtures: validate git init in RealtimeFixture","description":"**Problem**\\n- tests/integration/fixtures/realtime.rs runs git commands via Command::output() but ignores exit status.\\n- If git fails (missing binary, permission), tests fail later with confusing errors.\\n\\n**Files**\\n- tests/integration/fixtures/realtime.rs","design":"Create a small helper (e.g., run_git(args, cwd) -> Result<()>) that checks status.success(), includes stderr/stdout in error, and is used for init/config/remote commands. Consider returning Result from init_git_repo and wiring RealtimeFixture::new to propagate the error (or panic with context).","acceptance_criteria":"- [ ] git commands used in RealtimeFixture fail fast with clear error messages.\\n- [ ] No silent ignore of non-zero exit status.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768541691221,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768541691221,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768541691221,0]}
{"id":"bd-jc2z","created_at":[1769309224422,0],"created_by":"darin@darinsmcstudio2.lan","title":"Extract cli/parsers.rs module for argument parsers","description":"**Problem**\n8 parser functions are scattered in src/cli/mod.rs (lines 1598-1770), mixed with unrelated code:\n\n- `parse_bead_type()` (line 1637)\n- `parse_priority()` (line 1649)\n- `parse_status()` (line 1668)\n- `parse_dep_kind()` (line 1679)\n- `parse_sort()` (line 1683)\n- `parse_time_ms_opt()` (line 1708)\n- `parse_time_ms()` (line 1723)\n- `parse_dep_edge()` (line 1750)\n\nThese are all clap value_parser functions that convert strings to domain types. Having them in mod.rs hurts discoverability and bloats the file.\n\n**Design**\n1. Create `src/cli/parsers.rs`\n2. Move all 8 parser functions there\n3. Make them `pub(crate)` \n4. Update imports in mod.rs and any command handlers that use them directly\n\n```rust\n// src/cli/parsers.rs\nuse crate::core::{BeadType, Priority, WorkflowStatus};\nuse crate::daemon::query::{DepKind, SortField};\n\npub(crate) fn parse_bead_type(s: &str) -> Result<BeadType, String> { ... }\npub(crate) fn parse_priority(s: &str) -> Result<Priority, String> { ... }\npub(crate) fn parse_status(s: &str) -> Result<WorkflowStatus, String> { ... }\npub(crate) fn parse_dep_kind(s: &str) -> Result<DepKind, String> { ... }\npub(crate) fn parse_sort(s: &str) -> Result<SortField, String> { ... }\npub(crate) fn parse_time_ms_opt(s: &str) -> Result<Option<u64>, String> { ... }\npub(crate) fn parse_time_ms(s: &str) -> Result<u64, String> { ... }\npub(crate) fn parse_dep_edge(s: &str) -> Result<(String, String), String> { ... }\n```\n\n```rust\n// src/cli/mod.rs\nmod parsers;\nuse parsers::*; // or explicit imports\n```\n\n**Acceptance**\n- [ ] src/cli/parsers.rs created with all 8 parser functions\n- [ ] src/cli/mod.rs imports from parsers module\n- [ ] No parser functions remain in mod.rs\n- [ ] All #[arg(value_parser = ...)] references still work\n- [ ] cargo clippy passes\n- [ ] cargo test passes\n\n**Files:** src/cli/mod.rs, src/cli/parsers.rs (new)","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769772131433,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769772131433,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769772131433,0]}
{"id":"bd-je6a","created_at":[1768778621458,0],"created_by":"darin@darinsmcstudio2.lan","title":"ReplRig bootstrap starts daemons twice; keep init daemon running + reload config","description":"tests/integration/fixtures/repl_rig.rs bootstrap_replica runs initialized then shuts down the daemon; later bd commands autostart again, so each node pays two startups. Keep the init daemon running, write roster/config, then call admin reload replication on each node (or otherwise reconfigure) so we avoid the second autostart. Should cut repl_e2e setup time.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768814132893,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768814132893,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768814132893,0]}
{"id":"bd-jedr","created_at":[1769501220121,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode WAL segment sealed/final_len invariants","description":"**Problem**\n`SegmentRow` in the WAL index uses `sealed: bool` + `final_len: Option<u64>`. This allows invalid states like `sealed=true` with `final_len=None`, which are only caught at replay/fsck time.\n\nKey refs:\n- `crates/beads-rs/src/daemon/wal/index.rs:198` (SegmentRow)\n- `crates/beads-rs/src/daemon/wal/replay.rs:264` (runtime error when sealed missing final_len)\n\n**Impact**\nIndex invariants are not enforced at compile time; sealed segment metadata can be corrupt without immediate detection.","design":"**Design (opinionated)**\nMake sealed‑segment invariants structural.\n\nOption A (enum row):\n```rust\nenum SegmentRow {\n  Open { /* fields */, last_indexed_offset: u64 },\n  Sealed { /* fields */, final_len: u64 },\n}\n```\n- No `Option` for final_len; sealed implies `final_len` exists.\n- Encode/decode to DB enforces the invariant when loading rows.\n\nOption B (struct + NonZero marker):\n- `final_len: FinalLen` where `FinalLen` is only constructible when sealed, but enum is cleaner.\n\nUpdate replay/index logic to accept typed rows so invalid state cannot compile.","acceptance_criteria":"**Acceptance**\n- [ ] It is impossible to represent a sealed segment without `final_len` (compile‑time enforced).\n- [ ] DB load rejects invalid rows before creating `SegmentRow`.\n- [ ] Replay/fsck no longer needs to check for sealed+None at runtime.\n- [ ] Tests cover open vs sealed row serialization and invalid DB row rejection.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769544463964,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769544463964,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769544463964,0]}
{"id":"bd-jelh","created_at":[1770688156889,0],"created_by":"darin@darinsmcstudio2.lan","title":"Dedup CLI render dispatch and remove exitful runtime paths","description":"Implement render dispatch dedup in beads-cli and replace std::process::exit usage with typed runtime error propagation in runtime/subscribe/setup.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"in_progress","assignee":"darin@darinsmcstudio2.lan","_at":[1770688165106,0],"_by":"darin@darinsmcstudio2.lan","assignee_at":[1770688165106,0]}
{"id":"bd-jgol","created_at":[1768815691646,0],"created_by":"darin@darinsmcstudio2.lan","title":"Telemetry logging defaults: replace bool mode with enum","description":"**Problem**\napply_daemon_logging_defaults_inner uses bool flags (is_test_env, has_log_file_env) that encode multiple states implicitly; this is a type_design smell and makes invalid combinations possible.\n\n**Design**\nIntroduce a small enum (e.g., LoggingDefaultsMode { TestEnv, LogFileEnv, Default }) derived from environment/context and pass that through apply_daemon_logging_defaults_inner. Remove boolean params and update tests to cover the enum branches.\n\n**Acceptance**\n- [ ] bool flags replaced with enum in src/telemetry.rs\n- [ ] tests updated for the new mode mapping\n- [ ] cargo check, cargo test pass\n\n**Files:** src/telemetry.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768815860615,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768815860615,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768815860615,0]}
{"id":"bd-jmcy","created_at":[1769287237846,0],"created_by":"darin@darinsmcstudio2.lan","title":"Set slow-tests CI timeout to 10 minutes","description":"","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769771459556,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769771459556,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769771459556,0]}
{"id":"bd-jrz","created_at":[1768494734814,0],"created_by":"darin@darinsmcstudio2.lan","title":"CLI read gating flags for queries","description":"**Problem**\nREALTIME_PLAN requires require_min_seen + wait_timeout_ms on all read/query requests. CLI only exposes these for `bd subscribe`, so read gating cannot be exercised for `bd show/list/status/ready/...`.\n\n**Design**\nAdd global CLI flags `--require-min-seen <JSON>` and `--wait-timeout-ms <MS>` and plumb them into Ctx::read_consistency for all read/query requests. Reuse the existing JSON Watermarks parser used by subscribe. Subscribe args should override global flags when provided.\n\n**Files**\n- src/cli/mod.rs\n- src/cli/commands/subscribe.rs","acceptance_criteria":"- [ ] Global flags parsed and stored in Ctx\n- [ ] All read/query requests include require_min_seen/wait_timeout when flags provided\n- [ ] Subscribe uses explicit args when given, otherwise inherits global read gating","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768495021369,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768495021369,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768495021369,0]}
{"id":"bd-jvih","created_at":[1769581943539,0],"created_by":"darin@darinsmcstudio2.lan","title":"Unify StoreState namespace representation","description":"**Problem**\nNamespaces are modeled as a special-case “core + other map” in `StoreState`, and callers must branch on `namespace.is_core()`.\n\nEvidence:\n- `StoreState` stores `core` separately from `other` (`crates/beads-core/src/namespaced_state.rs`).\n- Call sites repeatedly do `if namespace.is_core()` in daemon and checkpoint import paths.\n\nThis is translation + scatter: the domain is “map of namespace → state,” but the code forces special casing and manual branching at every use site.\n\n**Files:**\n- `crates/beads-core/src/namespaced_state.rs`\n- `crates/beads-rs/src/git/checkpoint/import.rs`\n- `crates/beads-rs/src/daemon/core.rs`\n- `crates/beads-rs/src/daemon/executor.rs`","design":"**Design**\nRepresent namespaced state uniformly as a map with an always-present core entry.\n\nConcrete plan:\n1) Replace `StoreState { core, other }` with `StoreState { by_namespace: BTreeMap<NamespaceId, CanonicalState> }`.\n2) Enforce presence of `NamespaceId::core()` on construction and ensure `core()`/`core_mut()` are just lookups.\n3) Remove `if namespace.is_core()` branches in call sites by using uniform lookup helpers.\n4) Add `NonCoreNamespaceId` APIs only at boundaries that require them (creation), not throughout the storage layer.\n\n**Design Notes**\n- This preserves the “core always exists” invariant while eliminating translation noise.\n- If performance is a concern, keep a cached pointer to core, but the public API should be uniform.","acceptance_criteria":"**Acceptance**\n- [ ] `StoreState` uses a single map keyed by `NamespaceId` with core present.\n- [ ] Call sites no longer branch on `namespace.is_core()` for state access.\n- [ ] Core namespace presence is enforced at construction (cannot be missing).\n- [ ] Tests cover: core always present; non-core namespaces behave identically.","priority":2,"type":"chore","labels":{"entries":{"consistency":[{"replica":"a311aa90-4636-2059-2f92-20adc75fe2b5","counter":9090177277684016813}],"translation":[{"replica":"3e5e1e41-cf19-71b9-c467-86e56b14f6a9","counter":10743120924843639153}],"types":[{"replica":"c5b5cf6c-29ea-7f72-4ea1-11e3828c7617","counter":9864828405016069975}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769770055609,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769770055609,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769770055609,0]}
{"id":"bd-k67","created_at":[1768444158887,0],"created_by":"darin@darinsmcstudio2.lan","title":"EventBody decode is too strict (unknown keys break forward compat)","description":"**Problem**\n`decode_event_body_map` rejects unknown keys with `InvalidField` instead of skipping them. This makes EventBody strictly closed and blocks forward-compatible changes to realtime payloads. The plan explicitly removed unknown-key *byte preservation* but did not require rejecting unknown keys; we should accept and ignore them while preserving raw bytes.\n\n**Signals / Evidence**\n- `decode_event_body_map` returns `InvalidField` on any unknown key (`src/core/event.rs`).\n- `decode_event_hlc_max` similarly errors on unknown keys inside `hlc_max`.\n- `verify_event_frame` relies on `decode_event_body`; rejection becomes `invalid_request` or `non_canonical`, making minor forward-compatible additions fatal.\n\n**Why this hurts velocity**\nAny new field in EventBody becomes a coordinated, lockstep upgrade across all replicas and clients. That’s brittle and slows rollout.","design":"**Design**\n- Change `decode_event_body_map` to `dec.skip()` unknown keys instead of error.\n- Do the same for `hlc_max` (ignore unknown keys; still require required fields).\n- Keep existing required-field checks and limits.\n- Add tests: decoding succeeds with an extra unknown key at top-level and inside `hlc_max`, and hash verification still uses the raw bytes.","acceptance_criteria":"- [ ] Unknown keys in EventBody are ignored (no `InvalidField` error).\n- [ ] Unknown keys in `hlc_max` are ignored while still requiring `actor_id`, `physical_ms`, `logical`.\n- [ ] Tests cover forward-compat decode for both top-level and `hlc_max`.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"duplicate of bd-3m5.84","_at":[1768448823211,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768448823211,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-kh1y","created_at":[1768824438235,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace repo_has_branch bool with enum","description":"tests/integration/fixtures/git.rs returns bool for branch presence. Replace with a BranchPresence enum to avoid bool ambiguity and update call sites.","acceptance_criteria":"- repo_has_branch returns BranchPresence enum\\n- call sites updated\\n- cargo check, cargo clippy -D warnings, cargo test pass","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768824584088,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768824584088,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768824584088,0]}
{"id":"bd-km0","created_at":[1768444184831,0],"created_by":"darin@darinsmcstudio2.lan","title":"Prevent WAL/index divergence when apply_event fails during replication ingest","description":"**Problem**\nRemote ingest appends events to WAL + SQLite *before* calling `apply_event`. If `apply_event` fails (missing bead, note collision, invalid dep, etc.), the event is already durable and indexed but never applied, leaving the store in a self‑inconsistent state that will fail on replay and replication.\n\n**Signals / Evidence**\n- `ingest_remote_batch` appends records + commits index, then calls `apply_event` in a loop (`src/daemon/core.rs`).\n- `apply_event` can fail for `MissingBead`, `NoteCollision`, `InvalidDependency`, etc. (`src/core/apply.rs`).\n- On failure, we return `internal` error but do not roll back WAL/index.\n\n**Why this hurts velocity**\nThis is the kind of “works until it really doesn’t” failure that makes debugging impossible: the durable log and in-memory state diverge. Every operator‑facing repair becomes bespoke.","design":"**Design**\nOption A (preferred): add a validation step that guarantees `apply_event` cannot fail for accepted events. For remote ingest, validate against current state *before* WAL append (or implement an `apply_event_checked` that computes the outcome without side effects).\nOption B: restructure ingestion so WAL append + index commit happen *after* apply, but only if apply succeeds, and treat apply failures as corruption/reject before durability.\nEither way, if an event can’t be applied, it must be rejected *before* it is appended/indexed, with a domain error (`corruption` or `invalid_request`).\n\n**Design Notes**\nIf we stick with Option A, consider a small “preflight” that checks just the known `ApplyError` preconditions (bead existence for note_append, dep key validity, creation stamp consistency), to avoid cloning state.","acceptance_criteria":"- [ ] Remote ingest never appends/indexes an event that would fail `apply_event`.\n- [ ] Apply failures map to a specific error code (not generic `internal_error`).\n- [ ] Tests cover a remote event that would currently fail apply and verify it is rejected before WAL append.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768451885428,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768451885428,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768451885428,0]}
{"id":"bd-kqse","created_at":[1768777670480,0],"created_by":"darin@darinsmcstudio2.lan","title":"Reduce WAL rotation stress test event count by computing needed writes","description":"tests/integration/daemon/repl_e2e.rs repl_daemon_stress_wal_rotation_roundtrip hardcodes 40 creates per node. Compute minimum events based on wal_segment_max_bytes and average record size (write one event, inspect segment bytes) so we only generate what’s needed to force rotation.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768800111976,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768800111976,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768800111976,0]}
{"id":"bd-kvqe","created_at":[1768776086984,0],"created_by":"darin@darinsmcstudio2.lan","title":"Observability: add cross-replica trace_id propagation","description":"**Problem**\nWe cannot trace a mutation across replicas end‑to‑end. There is no stable correlation/trace id that survives IPC → WAL → replication → apply, so distributed debugging is manual.\n\n**Design**\n- Introduce a `TraceId` (UUID or 128‑bit) in mutation context.\n- If `client_request_id` exists, derive/use it; otherwise generate a new `TraceId` at request entry.\n- Persist `trace_id` in event metadata (wire/event body or record header) and include it in repl frames.\n- Emit `trace_id` on spans/logs for mutation planning, WAL append/apply, replication send/receive, and checkpoint/apply paths.\n- Ensure backward‑compatible decoding (missing trace_id ok).\n\n**Acceptance**\n- [ ] A mutation creates or carries a `trace_id` that appears in local WAL and replicated events.\n- [ ] Logs/spans for mutation + repl include `trace_id`.\n- [ ] Older events without trace_id still decode and apply.\n\n**Files:** src/core/event.rs, src/core/wire_bead.rs, src/daemon/executor.rs, src/daemon/repl/*, src/daemon/ipc/*","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768821917081,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768821917081,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768821917081,0]}
{"id":"bd-l1w9","created_at":[1768636601601,0],"created_by":"darin@darinsmcstudio2.lan","title":"Crash/restart during replication e2e","description":"**Problem**\nMulti-node crash/restart with in-flight replication is not tested; only single-node recovery exists.","design":"**Design**\n- Use ReplRig to start 3 nodes, begin replication, then hard-kill one daemon mid-stream.\n- Continue mutations on remaining nodes, restart the crashed node with the same dirs, and assert it catches up.\n- Validate convergence and no data loss.","acceptance_criteria":"- [ ] Crash/restart e2e passes and converges.\n- [ ] No orphaned processes/sockets.\n- [ ] Tests write only under ./tmp.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768637284852,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768637284852,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768637284852,0]}
{"id":"bd-l4y","created_at":[1765744323190,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encapsulate DepKey to enforce no self-loops by construction","description":"Make self-dependencies structurally impossible via validating constructor.\n\n**Problem:** `DepKey` has public fields and self-loop check is scattered in `apply_add_dep`:\n```rust\npub struct DepKey {\n    pub from: BeadId,\n    pub to: BeadId,\n    pub kind: DepKind,\n}\n```\n\n**Solution:** Make fields private with a validating constructor:\n```rust\nimpl DepKey {\n    pub fn new(from: BeadId, to: BeadId, kind: DepKind) -> Result<Self, CoreError> {\n        if from == to {\n            return Err(InvalidDependency {\n                reason: format!(\"cannot create self-dependency: {}\", from),\n            }.into());\n        }\n        Ok(Self { from, to, kind })\n    }\n\n    pub fn from(&self) -> &BeadId { &self.from }\n    pub fn to(&self) -> &BeadId { &self.to }\n    pub fn kind(&self) -> DepKind { self.kind }\n}\n```\n\nAdd serde support via proxy type for deserialization validation.\n\n**Impact:** Self-dependencies become unrepresentable, not just checked.\n\n**Files:** src/core/dep.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765781345450,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765781345450,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765781345450,0]}
{"id":"bd-l5k","created_at":[1768444195661,0],"created_by":"darin@darinsmcstudio2.lan","title":"Introduce EventWal append API + reuse segment writers","description":"**Problem**\nEvery mutation opens a fresh `SegmentWriter` and creates a new WAL segment, so we effectively write one segment per event. There is no `EventWal` type that owns per‑namespace writers and enforces the append/index/fsync ordering invariant; instead, the executor and core manually sequence these steps.\n\n**Signals / Evidence**\n- `apply_mutation_request_inner` creates a new `SegmentWriter::open` for every mutation (`src/daemon/executor.rs`).\n- `ingest_remote_batch` also opens a new `SegmentWriter` per batch (`src/daemon/core.rs`).\n- `wal/mod.rs` exposes low‑level pieces but no high‑level append API; the invariants live in call sites.\n\n**Why this hurts velocity**\nWe keep duplicating WAL/index sequencing logic, and segment rotation logic never gets a chance to do its job. Any change to WAL invariants requires editing multiple call sites and is easy to get subtly wrong.","design":"**Design**\n- Introduce an `EventWal` (or `WalAppender`) struct in `src/daemon/wal` that owns per‑namespace active `SegmentWriter`s.\n- Provide append APIs that encapsulate: (1) allocate seq, (2) write record, (3) fsync, (4) index updates, (5) watermark updates.\n- Keep a per‑namespace writer in `StoreRuntime` (or in EventWal) so segments are reused and rotation is meaningful.\n- Update mutation and replication ingest to go through this API.\n\n**Design Notes**\nThis aligns with the plan’s “EventWal::append” responsibility and moves invariants into one type instead of scattered call sites.","acceptance_criteria":"- [ ] Segment writers are reused across multiple events (not one segment per mutation).\n- [ ] A single EventWal append API owns the write + fsync + index sequencing invariant.\n- [ ] Executor and replication ingest no longer manually open SegmentWriter directly.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"duplicate of bd-3m5.82","_at":[1768448823313,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768448823313,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-lcyk","created_at":[1769563157376,0],"created_by":"darin@darinsmcstudio2.lan","title":"Repl envelope version must be validated against negotiated protocol","description":"**Problem**\n`decode_envelope` returns a `ReplEnvelope { version, message }`, but the reader loop ignores `version` for all post‑handshake messages. Only HELLO/WELCOME check `protocol_version` against the envelope. For EVENTS/ACK/WANT/PING/PONG, a peer can send a different envelope version and we still accept it.\n\nThis violates parse‑don’t‑validate and turns the negotiated protocol version into a soft convention rather than an enforced invariant. It will break badly once a v2 exists.\n\n**Impact**\n- Protocol drift: incompatible versions can be accepted silently.\n- Hard-to-debug failures when formats change; errors surface far from the boundary.\n\n**Files**\n- `crates/beads-rs/src/daemon/repl/proto.rs` (decode_envelope)\n- `crates/beads-rs/src/daemon/repl/manager.rs` / `server.rs` (reader loops)\n","design":"**Design (opinionated)**\nEnforce version at the decode boundary using a typed envelope.\n\n1) Add a versioned decode entry point:\n```rust\nfn decode_envelope_with_version(bytes: &[u8], limits: &Limits, expected: u32) -> Result<ReplEnvelope, ProtoDecodeError>\n```\n- Reject if `envelope.version != expected` for any message type.\n\n2) Thread the negotiated protocol version into reader loops.\n- Before handshake: accept any version within local range for HELLO/WELCOME parsing.\n- After handshake: call `decode_envelope_with_version` with the negotiated version.\n\n3) Optional: typestate the envelope itself:\n- `ReplEnvelopeV1` type for v1 messages.\n- Reader returns the versioned envelope so you cannot ignore it.\n\nThis makes protocol version an explicit, enforced invariant.","acceptance_criteria":"- [ ] Post‑handshake messages are rejected if envelope version != negotiated version.\n- [ ] Reader loop API requires an expected version after handshake (compile-time forcing).\n- [ ] Tests cover: mismatched version for EVENTS/ACK/WANT rejected.\n- [ ] `cargo test` passes.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-lcyk-1","content":"Rendering should remain in the command files; avoid moving rendering into shared helpers.","author":"darin@darins-Mac-Studio-2.local","at":[1769585373941,0]},{"id":"legacy-notes","content":"Rendering should remain in the command files; avoid moving rendering into shared helpers.","author":"darin@darinsmcstudio2.lan","at":[1769586008771,0]}],"_at":[1769586008771,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769586008771,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769586008771,0]}
{"id":"bd-lfxz","created_at":[1768506351431,0],"created_by":"darin@darinsmcstudio2.lan","title":"TxnId generation should include actor identity","description":"**Problem**\n`txn_id_for_stamp` (mutation engine) derives `TxnId` from `store_id` + `WriteStamp` (wall_ms, counter) only. The actor/replica identity is not included, so two actors with the same wall_ms/counter can produce identical TxnIds. This breaks the invariant that TxnIds are unique across actors and makes idempotency/debugging brittle.\n\n**Files**\n- src/daemon/mutation_engine.rs\n","design":"**Design**\n- Change `txn_id_for_stamp` to include actor identity (e.g., accept a full `Stamp` or `ActorId` and use it in the UUID v5 namespace/name).\n- Ensure the generated TxnId is stable for the same actor+stamp but distinct across actors.\n- Add a test that two different actors with the same wall_ms/counter produce different TxnIds.","acceptance_criteria":"- [ ] TxnId derivation incorporates actor identity (or full `Stamp`).\n- [ ] New test proves distinct actors produce different TxnIds for identical WriteStamp values.\n- [ ] Call sites updated accordingly.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768529304404,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768529304404,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768529304404,0]}
{"id":"bd-ljbq","created_at":[1769223994111,0],"created_by":"darin@darinsmcstudio2.lan","title":"Support jj workspaces in repository discovery","description":"**Problem**\n\n`bd` fails with `code=NotFound (-3)` when run from a jj-only workspace.\n\n**Root Cause**\n\nRepository discovery in `src/repo.rs` only looks for `.git` directories:\n\n1. `fast_repo_root()` walks up directories checking `dir.join(\".git\").exists()`\n2. Fallback `git2::Repository::discover()` also only finds `.git`\n\njj workspaces don't have `.git` - they have `.jj/repo/store/git_target` pointing to the backing git repo.\n\n**How jj Workspaces Work**\n\n```\n/main-repo/              # colocated repo (has both .git and .jj)\n├── .git/\n├── .jj/repo/store/\n│   ├── type           # contains \"git\"\n│   └── git_target     # contains \"../../../.git\" (relative)\n\n/workspace/              # jj-only workspace (no .git)\n├── .jj/repo/store/\n│   ├── type           # contains \"git\"  \n│   └── git_target     # e.g. \"../../../main-repo/.git\" (relative)\n```\n\nThe `git_target` file contains a relative path from `.jj/repo/store/` to the `.git` directory.\n\n**Design**\n\nExtend `fast_repo_root()` to also detect jj workspaces and resolve their backing git repo.\n\nAdd helper function `jj_git_repo_root()`:\n\n```rust\n/// Resolve jj workspace's backing git repo root, if this is a jj workspace.\nfn jj_git_repo_root(jj_dir: &Path) -> Option<PathBuf> {\n    let store_dir = jj_dir.join(\"repo/store\");\n\n    // Verify this is a git-backed jj repo\n    let type_file = store_dir.join(\"type\");\n    let backend_type = std::fs::read_to_string(&type_file).ok()?;\n    if backend_type.trim() != \"git\" {\n        return None;\n    }\n\n    // Read git_target (relative path to .git)\n    let git_target = store_dir.join(\"git_target\");\n    let target = std::fs::read_to_string(&git_target).ok()?;\n    let target = target.trim();\n\n    // Resolve relative path from store_dir\n    let git_path = store_dir.join(target);\n    let git_path = git_path.canonicalize().ok()?;\n\n    // git_target points to .git dir; return parent (repo root)\n    git_path.parent().map(|p| p.to_path_buf())\n}\n```\n\nModify `fast_repo_root()` to check for jj after checking for .git:\n\n```rust\nfn fast_repo_root(start: &Path) -> Option<PathBuf> {\n    let start = if start.is_absolute() {\n        start.to_path_buf()\n    } else {\n        std::env::current_dir().ok()?.join(start)\n    };\n\n    let mut current = Some(start.as_path());\n    while let Some(dir) = current {\n        // Check for .git first (standard git repo)\n        if std::fs::symlink_metadata(dir.join(\".git\")).is_ok() {\n            return Some(dir.to_path_buf());\n        }\n        // Check for .jj (jujutsu workspace)\n        let jj_dir = dir.join(\".jj\");\n        if std::fs::symlink_metadata(&jj_dir).is_ok() {\n            if let Some(git_root) = jj_git_repo_root(&jj_dir) {\n                return Some(git_root);\n            }\n        }\n        current = dir.parent();\n    }\n    None\n}\n```\n\n**Edge Cases**\n\n- Non-git jj backends (type != \"git\"): returns None, falls through to git2 discover which fails with appropriate error\n- Invalid/missing git_target: returns None\n- Colocated repos (.git and .jj both present): .git found first, works unchanged\n- Symlinked .jj directories: uses symlink_metadata, works correctly\n\n**Acceptance**\n\n- [ ] `bd list` works from jj-only workspace\n- [ ] `bd create` works from jj-only workspace\n- [ ] Colocated repos (with both .git and .jj) still work\n- [ ] Non-jj repos still work unchanged\n- [ ] Tests pass\n- [ ] clippy clean\n\n**Files:** `src/repo.rs`\n\n**Test workspace:** Created at `/Users/darin/Projects/beads-jj-fix` (jj-only, no .git)","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769371351736,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769371351736,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769371351736,0]}
{"id":"bd-lk0x","created_at":[1769580722486,0],"created_by":"darin@darinsmcstudio2.lan","title":"Canonical snapshot codec across git/checkpoint/WAL","description":"**Problem**\nThere are multiple full-state snapshot formats with separate parsers/serializers:\n- Git store JSONL (`crates/beads-rs/src/git/wire.rs`): state/tombstones/deps/notes + meta.json\n- Checkpoint shards (`crates/beads-rs/src/git/checkpoint/*`): per-namespace shards using `WireBeadFull`\n- WAL legacy snapshots (`crates/beads-rs/src/daemon/wal_legacy_snapshot.rs`): serde snapshot with custom wire adapters\n\nEach format has its own ordering rules, validation logic, and limit checks. This is root scatter: state snapshots are not a single concept, so every correctness change must be repeated.\n\n**Files:**\n- `crates/beads-rs/src/git/wire.rs`\n- `crates/beads-rs/src/git/checkpoint/export.rs`\n- `crates/beads-rs/src/git/checkpoint/import.rs`\n- `crates/beads-rs/src/daemon/wal_legacy_snapshot.rs`\n- `crates/beads-core/src/wire_bead.rs`","design":"**Design**\nDefine a canonical snapshot codec in core and route git/checkpoint/WAL through it.\n\nConcrete plan:\n1) Add `SnapshotWireV1` in `beads-core` that represents a full snapshot (beads, tombstones, deps, notes, label states) with explicit ordering rules.\n2) Provide `SnapshotCodec` helpers for serialize/parse with deterministic ordering + validation (uniqueness, monotonic keys).\n3) Update git store serialization/parsing to use the snapshot codec (thin adapters for legacy layout).\n4) Update checkpoint export/import to map shard files to/from the snapshot codec (or reuse codec per shard).\n5) Replace WAL legacy snapshot serialization with the canonical snapshot codec (keep a legacy reader during migration).\n\n**Design Notes**\n- The goal is one canonical snapshot representation, with adapters for storage layout (git vs checkpoint vs wal).\n- Limit checks should live in the codec layer so all callers share the same policy.","acceptance_criteria":"**Acceptance**\n- [ ] A canonical snapshot wire type and codec exist in `beads-core`.\n- [ ] Git store, checkpoint import/export, and WAL snapshot paths use the codec (legacy adapters isolated).\n- [ ] Ordering/uniqueness validation is enforced in one place.\n- [ ] Tests cover roundtrip serialization and invalid snapshot rejection through the codec.","priority":2,"type":"chore","labels":{"entries":{"scatter":[{"replica":"3fa645b0-ac58-dff0-7ff1-e79ce2241d1d","counter":486706750201976337}],"serialization":[{"replica":"420983bc-05b9-4189-739f-7230f436b25c","counter":2885346753812815568}],"tech-debt":[{"replica":"e801e0a7-3de0-cffc-e6bb-f8bca7a9aaa3","counter":114108186986265250}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769768658568,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769768658568,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769768658568,0]}
{"id":"bd-lrgl","created_at":[1768778077073,0],"created_by":"darin@darinsmcstudio2.lan","title":"StatusCollector/admin_status polls open new IPC connection each time","description":"StatusCollector and ReplRig admin_status open a fresh IPC connection per sample; polling loops can churn sockets. Add a persistent IpcConnection (or a test-only IPC session helper) to reuse the connection for repeated status queries.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768798478481,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768798478481,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768798478481,0]}
{"id":"bd-lvor","created_at":[1768509387475,0],"created_by":"darin@darinsmcstudio2.lan","title":"Gate realtime integration tests behind slow-tests","description":"**Problem**\\n- Some integration tests spawn the daemon, run load generators, and use time-based sleeps without being gated by the slow-tests feature (e.g., tests/integration/daemon/admin_status.rs, tests/integration/daemon/subscribe.rs).\\n- The test design guideline says slow tests should be opt-in; these can slow the default suite and introduce timing flakiness.\\n\\n**Files**\\n- tests/integration/daemon/admin_status.rs\\n- tests/integration/daemon/subscribe.rs\\n- any other realtime integration tests that start daemons or sleep","design":"Audit integration tests that spawn the daemon or rely on time-based sleeps; gate them with #[cfg(feature = \"slow-tests\")] (file-level or test-level) or split fast/slow variants. Keep a small smoke test (if needed) in the default suite that asserts basic wiring without sleeps. Ensure docs/justfile already reference slow-tests.","acceptance_criteria":"- [ ] Heavy realtime integration tests are opt-in via slow-tests.\\n- [ ] Default cargo test remains fast and deterministic.\\n- [ ] Any remaining ungated tests that spawn the daemon are intentionally justified in comments.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768526733285,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768526733285,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768526733285,0]}
{"id":"bd-lzhq","created_at":[1768672361080,0],"created_by":"darin@darinsmcstudio2.lan","title":"Realtime: stateright model coverage","description":"**Problem**\nThe stateright model exists but is not validated against production invariants. We have no model-checked coverage for realtime edge cases, which limits confidence in protocol correctness.","design":"**Design**\n- Prefer running Stateright over production code paths: reuse core realtime types/logic directly (via shared modules/feature flags) so the model is not a hand-written fork.\n- If direct reuse is impossible, add an automated sync mechanism (e.g., codegen or compile-time structure tests) that fails on drift between model and production types/state transitions.\n- Invariants should be asserted against the actual implementation of event apply/WAL/replication state, not a simplified model.","acceptance_criteria":"**Acceptance**\n- [ ] Model checker uses production code paths or an automated sync mechanism that prevents drift.\n- [ ] Invariants (watermarks monotonicity, no event loss, replay idempotency, durability receipts) are checked against the real implementation.\n- [ ] CI/slow-test target runs the model (bounded) and fails on counterexamples with actionable traces.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"superseded by bd-i43y","_at":[1768679267687,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768679267687,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-lzsu","created_at":[1768777372081,0],"created_by":"darin@darinsmcstudio2.lan","title":"Repl rig wait_for_show uses CLI polling; switch to IPC read gating","description":"tests/integration/fixtures/repl_rig.rs wait_for_show spawns bd show in a poll loop. Use IpcClient Request::Show with ReadConsistency { require_min_seen, wait_timeout_ms } based on create receipts (min_seen) to block once instead of sleep/poll. Should reduce E2E repl test time + flake risk.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768799705359,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768799705359,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768799705359,0]}
{"id":"bd-m1z","created_at":[1768367199735,0],"created_by":"darin@darinsmcstudio2.lan","title":"IPC subscribe WAL backfill for require_min_seen\n\n**Problem**\nSubscribe streams hot-cache/live events only; it does not backfill WAL ranges when require_min_seen lags current applied.\n\n**Design**\n- Compute per-origin backfill ranges from require_min_seen to current applied for the subscribed namespace.\n- Use WalRangeReader to read bounded frames (max_event_batch_bytes/events).\n- Stream backfill before live subscription; abort with explicit error if range missing/corrupt.\n\n**Acceptance**\n- [ ] Backfill frames are streamed before live events when require_min_seen is behind.\n- [ ] Backfill is bounded by max batch limits.\n- [ ] Error mapping matches REALTIME_ERRORS (corruption/bootstrap_required).\n- [ ] Tests cover backfill planning and error paths.\n\n**Files:** src/daemon/server.rs, src/daemon/repl/runtime.rs, src/daemon/ipc.rs, src/api/mod.rs","description":"","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768371765950,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768371765950,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768371765950,0]}
{"id":"bd-m26t","created_at":[1769495028406,0],"created_by":"darin@darinsmcstudio2.lan","title":"Seal OrSetValue to enforce deterministic collision bytes","description":"**Problem**\n`OrSetValue` is a public trait that requires a deterministic byte encoding for collision hashing, but nothing in the type system enforces determinism. External implementations can accidentally use non‑deterministic encodings (iteration over HashMap, randomized ordering, etc.), breaking CRDT determinism in subtle ways. This violates the “types should mirror your domain’s actual algebra” and “types tell the truth” principles.\n\nKey references:\n- `crates/beads-core/src/orset.rs:24` — `OrSetValue` is public and unconstrained.\n\nSeverity: non-deterministic merges and inconsistent CRDT state if a consumer implements `OrSetValue` incorrectly.","design":"**Design**\nSeal or constrain `OrSetValue` so only known-deterministic implementations are possible.\n\nOption A (sealed trait):\n- Add a private `sealed` module with a `Sealed` trait.\n- `pub trait OrSetValue: sealed::Sealed + Ord + Clone { ... }`.\n- Implement `Sealed` only for internal types (String, DepKey, Label, etc.) and document how to add new types internally.\n\nOption B (newtype wrapper):\n- Use `Deterministic<T>` wrapper that only exists for vetted types; `OrSetValue` is implemented for `Deterministic<T>` only.\n\nOption C (constructor-enforced bytes):\n- Replace `collision_bytes` with a canonical encoder function supplied at construction of the OR-Set, so determinism is localized.\n\nGiven repo philosophy, Option A is simplest and preserves API safety.","acceptance_criteria":"- [ ] External crates cannot implement `OrSetValue` directly.\n- [ ] All existing internal implementations continue to work.\n- [ ] Documentation/comments explain how to add new deterministic value types internally.\n- [ ] CRDT merge determinism is enforced by type boundaries, not conventions.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769516774010,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769516774010,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769516774010,0]}
{"id":"bd-m3ta","created_at":[1768508733307,0],"created_by":"darin@darinsmcstudio2.lan","title":"Separate protocol error codes from legacy CLI codes","description":"**Problem**\n- `core::ErrorCode` mixes realtime protocol codes with legacy CLI/IPC codes, obscuring stability boundaries.\n- It is unclear which codes are normative vs compatibility only.\n\n**Files:**\n- src/core/error.rs\n- REALTIME_ERRORS.md\n- CLI_SPEC.md (if needed)\n- src/daemon/ipc.rs (mapping)","design":"- Introduce `ProtocolErrorCode` (realtime/replication/IPC stable) and `LegacyErrorCode`.\n- Wrap them in `ErrorCode` or introduce `ErrorCode::Protocol/Legacy`.\n- Preserve current string values for compatibility; parsing should accept legacy names.\n- Update docs to state which codes are protocol-stable vs legacy.","acceptance_criteria":"- [ ] Protocol vs legacy codes are clearly separated in code and docs.\n- [ ] Existing serialized strings remain accepted and produced.\n- [ ] Tests cover parsing/serialization for both sets.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768534712583,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768534712583,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768534712583,0]}
{"id":"bd-m4vg","created_at":[1770580097883,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove unsafe from IPC autostart FD cleanup path without regressing flake fix","description":"**Problem**\n`beads-surface` IPC client autostart currently uses `unsafe` (`CommandExt::pre_exec` + raw fd close loop) to prevent file-descriptor leakage into daemon children. This fixed a real test-hang/flakiness class, but leaves maintainability/policy drift in a boundary crate.\n\nCurrent path:\n- `crates/beads-surface/src/ipc/client.rs`\n  - `prepare_daemon_spawn_command`\n  - `close_non_stdio_fds`\n\n**Goal**\nPreserve the FD-leak fix behavior while removing local `unsafe` from this code path (or strictly isolating it behind a dedicated, justified boundary).\n\n**Files**\n- crates/beads-surface/src/ipc/client.rs\n- crates/beads-daemon/** (if daemon-side early-close strategy is used)\n- crates/beads-rs/tests/integration/** (behavior/flakiness regression coverage)","design":"1. Evaluate safe alternatives to current `pre_exec` strategy (preferred: daemon-side early descriptor cleanup before runtime setup).\n2. Keep behavior invariant: daemon spawn must not inherit arbitrary test harness/capture pipe FDs.\n3. If daemon-side move is used, ensure cleanup runs before any long-lived background activity.\n4. Add regression coverage that would catch descriptor-leak hangs in lifecycle/concurrency tests.\n5. Document rationale and final boundary ownership in architecture notes.","acceptance_criteria":"- [ ] No ad-hoc `unsafe` blocks remain in `beads-surface/src/ipc/client.rs` for autostart FD cleanup.\n- [ ] Existing autostart/lifecycle integration tests remain green and non-flaky.\n- [ ] A regression test or stress harness demonstrates no inherited-FD hang in the covered scenario.\n- [ ] `cargo clippy --all-features -- -D warnings` passes.\n- [ ] `cargo test --all-features` passes.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770591196893,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770591196893,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770591196893,0]}
{"id":"bd-m5r","created_at":[1768426480808,0],"created_by":"darin@darinsmcstudio2.lan","title":"Sync push lockfile errors should be retryable","description":"During sync retry tests, push_update_reference returns 'failed to lock file' which is currently treated as PushRejected instead of NonFastForward. Treat lockfile failures as retryable so sync_with_retry can retry.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768427152531,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768427152531,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768427152531,0]}
{"id":"bd-m7v0","created_at":[1769481316008,0],"created_by":"darin@darinsmcstudio2.lan","title":"Centralize IPC request metadata extraction","description":"**Problem**\nIPC request metadata is extracted in multiple places with large, partially overlapping matches:\n- `crates/beads-rs/src/daemon/server.rs` has `RequestContext::from_request()` for span metadata and `read_gate_request()` for read gating.\n- `crates/beads-rs/src/daemon/coord.rs` has the big request dispatch match that re-states which ops are mutation/read/repo-only.\nThis duplication makes it easy to forget to update one path when new ops are added, causing silent drift in logging or read-gate coverage.\n\n**Design**\nAfter the ctx/payload refactor (bd-ebhh), introduce a single request metadata extraction path and route all span + read-gate logic through it.\n\n1) Add a shared metadata carrier:\n- `RequestInfo` (or `RequestExt`) with fields:\n  - `op: &'static str` (request type string for tracing)\n  - `repo: Option<&Path>`\n  - `namespace: Option<&str>`\n  - `actor_id: Option<&str>`\n  - `client_request_id: Option<&str>`\n  - `read: Option<&ReadConsistency>`\n- Implement `Request::info(&self) -> RequestInfo<'_>` using a **single match** on `Request` variants.\n  - Mutations use `MutationCtx` fields.\n  - Reads use `ReadCtx` fields.\n  - Repo-only ops use `RepoCtx` with no namespace/read.\n  - Admin flush/checkpoint read namespace from payload (not `ReadCtx`).\n  - `Ping`/`Shutdown` return `None` repo.\n\n2) Add convenience methods on `Request`:\n- `read_gate(&self) -> Option<ReadGateRequest>` built from `RequestInfo` (repo + read), to fully replace the current `read_gate_request()` match.\n- (Optional) `request_type(&self) -> &'static str` if it helps keep spans simple.\n\n3) Update server span + read gate logic:\n- Replace `RequestContext::from_request()` usage with `request.info()`.\n- Delete `RequestContext` struct entirely if no longer needed.\n- Replace `read_gate_request()` with the new `Request::read_gate()`.\n- Keep `read_consistency_tag()` and its semantics intact, but feed it from `RequestInfo.read`.\n\n4) Ensure the op names used in spans are **exactly** the current names (e.g., \"add_labels\", \"admin_reload_limits\").\n\n**Design Notes**\n- This is strictly a refactor: no wire format or behavior changes.\n- The single match should live in one place. Prefer `beads-surface` if it’s useful across crates, or a daemon-only extension (e.g., `crates/beads-rs/src/daemon/ipc/request_info.rs`) if we want to keep it internal.\n- Pay special attention to Admin ops with namespace payloads and to read-gated operations: the read gate coverage must remain identical.\n\n**Files**\n- `crates/beads-rs/src/daemon/server.rs`\n- `crates/beads-rs/src/daemon/ipc/mod.rs` (if adding extension helpers)\n- `crates/beads-surface/src/ipc/types.rs` (if implementing `Request::info` there)\n- `crates/beads-rs/src/daemon/server.rs` tests (span/read-gate coverage)","acceptance_criteria":"- [ ] `Request::info()` (or equivalent) exists and is the **only** match that maps requests → repo/namespace/actor/read/op.\n- [ ] `RequestContext::from_request()` and `read_gate_request()` are removed from `crates/beads-rs/src/daemon/server.rs`.\n- [ ] Tracing spans include the same fields/values as before for all ops.\n- [ ] Read gate behavior is unchanged for all ops.\n- [ ] `cargo test` passes.","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769511982141,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769511982141,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769511982141,0]}
{"id":"bd-mgf","created_at":[1765744424170,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove duplicate key from DepEdge","description":"**Problem**\n`DepKey` is stored both as the map key AND inside `DepEdge.key`:\n```rust\ndeps: BTreeMap<DepKey, DepEdge>\n\npub struct DepEdge {\n    pub key: DepKey,      // <-- duplicates the map key\n    pub created: Stamp,\n    pub life: Lww<DepLife>,\n}\n```\n\nThis duplication means:\n1. Wasted memory\n2. Possible key/value mismatch bugs (though unlikely)\n\n**Design**\nRemove `key` from `DepEdge`:\n```rust\npub struct DepEdge {\n    pub created: Stamp,\n    pub life: Lww<DepLife>,\n}\n```\n\nCallers that need the key get it from the map iteration:\n```rust\nfor (key, edge) in &state.deps {\n    // key is available here\n}\n```\n\n**Design Notes**\n- Wire format needs to handle this - on serialization, include key; on deserialization, reconstruct\n- `DepEdge::new` and `DepEdge::join` signatures change (no longer take/return key)\n- Check all usages of `edge.key` and ensure key is available from context\n\n**Acceptance**\n- [ ] `DepEdge` no longer contains `key` field\n- [ ] Wire format correctly serializes/deserializes (key comes from map, not struct)\n- [ ] All `edge.key` usages updated to use key from iteration context\n- [ ] `DepEdge::new`/`join` updated\n- [ ] Tests pass\n\n**Files:** src/core/dep.rs, src/git/wire.rs, src/daemon/executor.rs","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767997555263,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767997555263,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767997555263,0]}
{"id":"bd-mjpe","created_at":[1769501194082,0],"created_by":"darin@darinsmcstudio2.lan","title":"Repl session typestate + streaming gating","description":"**Problem**\nThe replication session state machine is enforced by runtime checks and shadow state outside the session. The compiler cannot prevent illegal transitions or misuse.\n\nSpecific compiler‑blind spots:\n- Session phase/role gating is runtime only (`begin_handshake`, `resend_handshake`, `handle_message`). A wrong call sequence compiles and just returns None/error.\n- Both inbound and outbound loops track `streaming` as a separate bool (and `accepted_set` out‑of‑band). Once set, it never goes false even if the session transitions to Draining/Closed. This allows sending events/hot‑cache in invalid phases without compile‑time or runtime guardrails.\n- Code that depends on negotiated peer info uses `session.peer()` at runtime and falls back to config when missing; this is a smell that the type system doesn’t model “handshake completed” as a state.\n\nKey refs:\n- `crates/beads-rs/src/daemon/repl/session.rs:226` (handshake API), `:251` (message handling)\n- `crates/beads-rs/src/daemon/repl/manager.rs:414` / `:528` (shadow `streaming` + `accepted_set`)\n- `crates/beads-rs/src/daemon/repl/server.rs:484` / `:596` (same issue inbound)\n\n**Impact**\nA single refactor or new feature can accidentally send events before handshake or after draining/close. These bugs will compile and only appear at runtime under load. This is correctness‑critical for repl.","design":"**Design (opinionated)**\nMake the session phase/role a *type boundary* and collapse shadow state into the session type.\n\n1) Introduce typestated session:\n```rust\nstruct Session<R, P> { /* fields */ }\n// R: Inbound | Outbound, P: Connecting | Handshaking | Streaming | Draining | Closed\n```\n- Each phase exposes only valid operations.\n- `begin_handshake(self) -> (Session<Outbound, Handshaking>, SessionAction)`\n- `handle_hello(self, ...) -> Session<Inbound, Streaming>` etc.\n\n2) Encode “peer known” in the type:\n- Only `Session<*, Streaming>` (or `StreamingSession` wrapper) exposes `peer()` and `negotiated_max_frame_bytes()`.\n- Remove fallbacks on config when peer is None; make it impossible to call those methods pre‑handshake.\n\n3) Remove shadow `streaming` + `accepted_set`:\n- The loop should match on the session typestate.\n- `accepted_set` is derived from `StreamingSession`’s peer data, not a separately mutated local variable.\n- Event send/hot‑cache methods accept `&StreamingSession` only.\n\n4) Phase transitions are explicit:\n- `SessionAction` can include a typed next‑state or return `(Session<NewState>, Vec<Action>)` to make transitions explicit and compiler‑checked.\n\nThis turns invalid phase usage into compile‑time errors.","acceptance_criteria":"**Acceptance**\n- [ ] All handshake/streaming operations are type‑gated (cannot compile in the wrong phase/role).\n- [ ] `session.peer()`/`negotiated_max_frame_bytes()` are only available after handshake.\n- [ ] The repl loops no longer track `streaming` or `accepted_set` separately; they derive from the session type/state.\n- [ ] It is impossible to send events or hot‑cache frames unless the session is in Streaming.\n- [ ] Tests cover legal transitions and ensure illegal transitions are unrepresentable (compile‑fail or typestate tests).","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769542157898,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769542157898,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769542157898,0]}
{"id":"bd-mmoi","created_at":[1768636580824,0],"created_by":"darin@darinsmcstudio2.lan","title":"Roster/epoch change e2e for replication","description":"**Problem**\nWe do not test dynamic replica roster changes or store_epoch bumps. These are high-risk paths for long-running deployments and upgrades.","design":"**Design**\n- Add integration helpers to update roster (and/or replication config) at runtime and trigger a reload via admin command.\n- If no admin API exists to bump store_epoch, add one (or document the intended mechanism), then simulate an epoch bump and ensure peers reconnect.\n- Add slow e2e that changes roster/epoch mid-flight and asserts continued convergence.","acceptance_criteria":"- [ ] Roster update + reload path exercised in e2e.\n- [ ] Store_epoch bump path exercised; peers reconnect without data loss.\n- [ ] Replication converges post-change.\n- [ ] Tests write only under ./tmp.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768641208664,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768641208664,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768641208664,0]}
{"id":"bd-mrbx","created_at":[1768512755367,0],"created_by":"darin@darinsmcstudio2.lan","title":"Integration test failure: subscribe require_min_seen disconnects","description":"**Problem**\nsubscribe_gates_on_require_min_seen fails in tests/integration/daemon/subscribe.rs:104 with Ipc(Disconnected) during the normal integration run (cargo test --test integration). This indicates the subscription stream closes unexpectedly during require_min_seen gating. The same test passed in a subsequent slow-tests run, suggesting a race or lifecycle issue rather than a deterministic assertion failure.\n\n**Repro**\n- cargo test --test integration (failed on 2026-01-15)\n\n**Files**\n- tests/integration/daemon/subscribe.rs\n- src/daemon/ipc/* (subscribe stream), src/daemon/core.rs (subscribe handling), broadcaster/gating logic","design":"Investigate why the IPC subscription stream closes during require_min_seen gating. Add structured logging around subscribe open/close paths and daemon lifecycle. Verify the daemon is started and the subscribe request is not racing daemon startup or shutdown. If the stream closes due to a specific error (gate timeout, overload, unexpected payload), surface that explicitly instead of a bare disconnect. Stabilize the test by ensuring the daemon is ready before subscribing or by retrying transient disconnects if the daemon is still live.","acceptance_criteria":"- [ ] subscribe_gates_on_require_min_seen passes reliably.\n- [ ] Subscribe stream failure modes return a structured error (not just disconnect) when possible.\n- [ ] Test setup avoids daemon lifecycle races if needed.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768525369990,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768525369990,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768525369990,0]}
{"id":"bd-ms6b","created_at":[1768506331516,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replication Session should encode phase/peer invariants","description":"**Problem**\n`Session` tracks `phase: SessionPhase` and `peer: Option<SessionPeer>` separately. Streaming-only handlers (e.g. `handle_events`) can still observe `peer == None` and emit an internal error (\"missing peer metadata while handling events\"). Invariants like “Streaming implies peer is set” are enforced with runtime checks and duplicated phase guards, which is brittle and easy to regress.\n\n**Files**\n- src/daemon/repl/session.rs\n","design":"**Design**\nIntroduce a state/typestate representation that encodes invariants:\n- Use `enum SessionState { Connecting{...}, Handshaking{...}, Streaming{peer: SessionPeer, ...}, Draining{peer: SessionPeer, ...}, Closed }` (or generic typestates) and move `peer` into the streaming/draining variants.\n- Refactor `handle_message` to pattern-match on state; only streaming/draining variants accept EVENTS/ACK/WANT/PING/PONG.\n- Remove the internal-error path for missing peer metadata and make it unrepresentable.","acceptance_criteria":"- [ ] `Session` can’t represent a streaming phase without peer metadata (no runtime `peer == None` checks).\n- [ ] `handle_events` no longer emits \"missing peer metadata\" internal errors.\n- [ ] Session tests updated/added to cover state transitions and invariants.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768524713212,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768524713212,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768524713212,0]}
{"id":"bd-mtw","created_at":[1770939350604,0],"created_by":"darin@darinsmcstudio2.lan","title":"Investigate rare >400ms ready outlier under hotpath benchmark","description":"Problem: ipc_request_duration histogram for ready shows rare outlier (~480ms max) despite p95 around 1ms after cache fix.\\n\\nDesign:\\n- Capture precise cause path (read-gate wait, scheduler tick, or sync/checkpoint interaction).\\n- Add targeted instrumentation around ready request lifecycle when latency > threshold.\\n\\nAcceptance:\\n- [ ] Repro scenario documented\\n- [ ] Root-cause identified with logs/metrics\\n- [ ] Mitigation landed or follow-up implementation bead filed","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Root-cause identified as benchmark startup contamination in log-derived summaries; harness now captures measured-phase log boundary after warm-up so ready outlier no longer appears in steady-state store identity summaries (artifact: tmp/perf/hotpaths-20260212-161756).","assignee":"darin@darinsmcstudio2.lan","assignee_expires":1770945305517,"_at":[1770941907849,0],"_by":"darin@darinsmcstudio2.lan","_v":{"acceptance_criteria":[[1770939350604,0],"darin@darinsmcstudio2.lan"],"claim":[[1770941705517,0],"darin@darinsmcstudio2.lan"],"description":[[1770939350604,0],"darin@darinsmcstudio2.lan"],"design":[[1770939350604,0],"darin@darinsmcstudio2.lan"],"estimated_minutes":[[1770939350604,0],"darin@darinsmcstudio2.lan"],"external_ref":[[1770939350604,0],"darin@darinsmcstudio2.lan"],"labels":[[1770939350604,0],"darin@darinsmcstudio2.lan"],"priority":[[1770939350604,0],"darin@darinsmcstudio2.lan"],"source_repo":[[1770939350604,0],"darin@darinsmcstudio2.lan"],"title":[[1770939350604,0],"darin@darinsmcstudio2.lan"],"type":[[1770939350604,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770941907849,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770941705517,0]}
{"id":"bd-mvd","created_at":[1768431984087,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove global test data dir lock by using thread-local overrides","description":"**Problem**\\nUnit tests that override data dir grab a global lock (paths::lock_data_dir_for_tests) and serialize across the suite. This blocks parallel test execution and shows up as time spent waiting.\\n\\n**Design**\\nUse thread-local DataDirOverride (paths::override_data_dir_for_tests) in unit tests instead of global set_data_dir_for_tests + lock. Update affected tests to use RAII guard. Keep lock-based API for cases that truly need cross-thread overrides.\\n\\n**Acceptance**\\n- [ ] Tests no longer use lock_data_dir_for_tests when not needed\\n- [ ] Data dir override is scoped and does not leak\\n- [ ] Tests still pass in parallel\\n\\n**Files**: src/git/checkpoint/cache.rs, src/daemon/store_runtime.rs, src/daemon/core.rs","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Switched tests to thread-local override_data_dir_for_tests; removed lock usage and added allow(dead_code) on lock APIs.","assignee":"darin@book","_at":[1768432817252,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768432817252,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768432817252,0]}
{"id":"bd-mw7","created_at":[1765675709837,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add bd binary to nix devshell","description":"The nix flake devShell should include the bd binary so hooks like 'bd prime' work inside nix develop. Currently bd is only available after building from source.","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765676230471,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765676230471,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765676230471,0]}
{"id":"bd-mzlo","created_at":[1768778636743,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move some repl_e2e coverage to in-process test_harness","description":"Use src/test_harness (ReplicationRig/TestWorld) to cover common replication scenarios (roundtrip, tailnet profile, crash/restart, durability receipts) without spawning daemons or tailnet_proxy. Keep 1-2 daemon E2E tests for IPC/real network, but shift most coverage to fast in-process tests.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768819579271,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768819579271,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768819579271,0]}
{"id":"bd-n11","created_at":[1765781522273,0],"created_by":"darin@darinsmcstudio2.lan","title":"Refactor executor.rs to use require_live helpers","description":"executor.rs has many instances of the check-then-unwrap pattern:\n```rust\nif repo_state.state.get_live(id).is_none() {\n    if repo_state.state.get_tombstone(id).is_some() {\n        return Response::err(OpError::BeadDeleted(id.clone()));\n    }\n    return Response::err(OpError::NotFound(id.clone()));\n}\n// ... later ...\nlet bead = repo_state.state.get_live_mut(id).unwrap();\n```\n\nShould use the new require_live/require_live_mut helpers added in bd-ieo.\n\nFiles: src/daemon/executor.rs","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Refactored executor.rs to use require_live/require_live_mut with MapLiveError trait. Eliminated all .unwrap() calls on bead lookups.","_at":[1765787088948,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765787088948,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-n15q","created_at":[1769815046164,0],"created_by":"darin@darinsmcstudio2.lan","title":"Parent dependency cycles not rejected - test_parent_deps_reject_cycles fails","description":"**Problem**\nParent dependencies should reject cycles (A's parent is B, B's parent is A), but currently allow them. The test `test_parent_deps_reject_cycles` expects failure with \"circular\" or \"cycle\" in stderr, but the operation succeeds.\n\nNote: Related dependencies (`--kind=related`) intentionally allow cycles, but parent dependencies should not.\n\n**Files:**\n- `crates/beads-rs/tests/integration/cli/critical_path.rs` (test at line ~1800)\n- `crates/beads-rs/src/daemon/mutation_engine.rs` (likely validation logic)\n- `crates/beads-core/src/dep.rs` (dependency validation)\n\n**Design**\nThe mutation engine or dep validation should check for cycles when adding parent deps. Likely need to traverse the parent chain and reject if adding this edge would create a cycle.\n\n**Acceptance**\n- [ ] `bd dep add A B --kind=parent` fails if B is already an ancestor of A\n- [ ] Error message contains \"circular\" or \"cycle\"\n- [ ] `test_parent_deps_reject_cycles` passes\n- [ ] Related deps still allow cycles (existing behavior)","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770590738233,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770590738233,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770590738233,0]}
{"id":"bd-naq0","created_at":[1770675758855,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove redundant clippy CI step after wildcard lint rollback","description":"","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmcstudio2.lan","_at":[1770675797322,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770675797322,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770675797322,0]}
{"id":"bd-neu","created_at":[1768503201562,0],"created_by":"darin@darinsmcstudio2.lan","title":"IPC: parse MutationMeta into typed namespace/durability/actor","description":"**Problem**\n`MutationMeta` in `src/daemon/ipc.rs` stores `namespace`, `durability`, `actor_id`, and `client_request_id` as `Option<String>`. These are parsed later (and in multiple places), which makes error handling inconsistent and keeps invalid values alive deep into the realtime pipeline.\n\n**Files**\n- src/daemon/ipc.rs\n- src/daemon/core.rs (parse_durability)\n- src/daemon/mutation_engine.rs","design":"Introduce an internal `ParsedMutationMeta` that uses `NamespaceId`, `DurabilityClass`, `ActorId`, and `ClientRequestId`. Parse/validate once at IPC boundary (or in a dedicated conversion layer) and propagate the typed struct through `MutationContext` / executor. Move `parse_durability` into a shared helper so the CLI/IPC use the same parser.","acceptance_criteria":"- [ ] Internal mutation flow uses typed `ParsedMutationMeta` (no raw strings).\n- [ ] Invalid namespace/durability/actor/client_request_id values fail at IPC boundary with clear errors.\n- [ ] Duplicate parsing logic removed.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768514087706,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768514087706,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768514087706,0]}
{"id":"bd-ngbq","created_at":[1768506359496,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL replay should use typed seq/namespace in tracker + errors","description":"**Problem**\nWAL replay code stores sequences as raw `u64` and error variants carry `namespace: String` + `seq: u64` (e.g., `WalReplayError::NonContiguousSeq`, `PrevShaMismatch`, `MissingHead`). `ReplayTracker`/`OriginReplayState` also use raw `u64`, forcing manual `seq == 0` checks and losing invariants that should be enforced by `Seq0`/`Seq1` and `NamespaceId`.\n\n**Files**\n- src/daemon/wal/replay.rs\n","design":"**Design**\n- Refactor `ReplayTracker`/`OriginReplayState` to use `Seq0`/`Seq1` types for `max_seq`/`contiguous_seq` and comparisons.\n- Update `WalReplayError` fields to use `NamespaceId` and typed seqs (`Seq0`/`Seq1`) instead of `String`/`u64`.\n- Adjust error mapping/helpers and tests accordingly.","acceptance_criteria":"- [ ] WAL replay tracker uses Seq types end-to-end (no raw u64 for seq).\n- [ ] WalReplayError variants carry `NamespaceId` + Seq types.\n- [ ] Tests updated to cover the new typed errors/invariants.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768528936494,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768528936494,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768528936494,0]}
{"id":"bd-nh0w","created_at":[1769553588622,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replica roster must make durability eligibility unrepresentable for observers","description":"**Problem**\n`ReplicaEntry` stores `role: ReplicaRole` and `durability_eligible: bool` independently. `ReplicaRoster::validate()` never checks for illegal combinations (e.g. `Observer + durability_eligible=true`). This violates parse-don’t-validate and lets invalid configs enter canonical state.\n\nThe `DurabilityCoordinator::eligible_replicas` path trusts the roster; in `ReplicateMode::P2p` an observer marked eligible is counted toward durability, which can report acks that never happened. This is a safety bug and the compiler cannot help.\n\n**Impact**\n- False durability availability (observer counted toward k) in P2P mode.\n- Bad config persists and is indistinguishable from valid at compile time.\n- Future refactors can silently reintroduce eligibility bugs since there is no typed guardrail.\n\n**Files**\n- `crates/beads-core/src/replica_roster.rs` (ReplicaEntry/ReplicaRoster parse + validate)\n- `crates/beads-rs/src/daemon/durability_coordinator.rs` (eligibility derivation)\n","design":"**Design**\nMake illegal combinations unrepresentable and validate at parse boundary. Keep TOML schema stable.\n\nOption A (preferred):\n1) Introduce a typed entry that encodes role + eligibility: \n   ```\n   enum ReplicaDurabilityRole {\n     Anchor { eligible: bool },\n     Peer { eligible: bool },\n     Observer,\n   }\n   ```\n2) Replace `ReplicaEntry { role, durability_eligible }` with `ReplicaEntry { role: ReplicaDurabilityRole, ... }`.\n3) Create a `ReplicaEntryWire` for serde (role + durability_eligible bool). Implement `TryFrom<ReplicaEntryWire> for ReplicaEntry` that rejects `Observer + eligible=true` (and any future invalid combos).\n4) Update `ReplicaRoster::from_toml_str` to parse `ReplicaEntryWire`, then convert to typed entries; errors surface as `ReplicaRosterError::InvalidRoleEligibility` (new error variant).\n5) Update `DurabilityCoordinator::eligible_replicas` to use `ReplicaDurabilityRole::eligible()` and `role_allows_policy` on the typed role.\n\nOption B (acceptable if we want to keep `ReplicaRole`):\n- Replace bool with `DurabilityEligibility` and make it only constructible for non-observers: `eligibility: Option<DurabilityEligible>` or `NonObserver { role: NonObserverRole, eligibility: DurabilityEligibility }`.\n- Provide explicit constructors `ReplicaEntry::anchor(...)`, `::peer(...)`, `::observer(...)` so call sites cannot fabricate invalid states.\n\n**Parse-don’t-validate**\n- The only public entry point should be typed constructors / `TryFrom` conversion from wire.\n- After parsing, there should be no API that exposes a raw bool.\n\n**Ordering / invariants preserved**\n- Preserve deterministic ordering of `ReplicaRoster.replicas` by current ordering semantics.\n- Keep TOML fields and on-disk/IPC compatibility unchanged (wire struct handles it).","acceptance_criteria":"- [ ] It is impossible to construct `Observer + eligible=true` at compile time.\n- [ ] `ReplicaRoster::from_toml_str` rejects invalid role/eligibility combos with a clear error.\n- [ ] `DurabilityCoordinator::eligible_replicas` uses the typed role/eligibility (no raw bool).\n- [ ] Unit tests cover: valid anchor/peer entries, observer ineligible, observer eligible rejected.\n- [ ] Ordering of `replicas` remains deterministic and unchanged.\n- [ ] `cargo test` passes.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769554717107,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769554717107,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769554717107,0]}
{"id":"bd-np77","created_at":[1768680802330,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright consistency testers for read/receipt semantics","description":"**Problem**\nWe currently hand-write invariants for read/receipt semantics. Stateright provides built-in linearizability/sequential consistency testers we’re not using.\n\n**Goal**\nUse Stateright’s consistency testers to validate read/receipt behavior against a sequential spec.","design":"**Design**\n1) Define a small sequential spec for receipts/reads (e.g., `Register` or `WriteOnceRegister`).\n2) Use `actor::register::RegisterMsg` helpers to record invocations/returns:\n   - `RegisterMsg::record_invocations`\n   - `RegisterMsg::record_returns`\n3) Build an ActorModel where client actors issue reads/writes (or receipt queries), and server actors call production code paths to produce responses.\n4) Attach `LinearizabilityTester` (or `SequentialConsistencyTester`) to history type H.\n5) Add a property that checks `history.is_consistent()`.\n\n**References**\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/semantics/consistency_tester.rs`\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/semantics/linearizability.rs`\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/semantics/sequential_consistency.rs`\n- `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/src/actor/register.rs`\n- Example: `~/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/stateright-0.31.0/examples/linearizable-register.rs`","acceptance_criteria":"**Acceptance**\n- [ ] A model exists that uses `LinearizabilityTester` or `SequentialConsistencyTester` for read/receipt semantics.\n- [ ] The model uses `RegisterMsg::record_invocations` + `record_returns` instead of custom history tracking.\n- [ ] Consistency property is asserted and passes in the bounded model.","priority":0,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768715517215,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768715517215,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768715517215,0]}
{"id":"bd-nph","created_at":[1768503193389,0],"created_by":"darin@darinsmcstudio2.lan","title":"BeadPatch.status should be typed (WorkflowStatus)","description":"**Problem**\n`src/daemon/ops.rs` defines `BeadPatch.status` as `Patch<String>`. The mutation engine parses strings into `WorkflowStatus` later, so invalid values flow deep into realtime planning and errors are ad-hoc. This keeps workflow invariants out of the type system and duplicates parsing logic.\n\n**Files**\n- src/daemon/ops.rs\n- src/daemon/mutation_engine.rs\n- src/daemon/ipc.rs","design":"Change `BeadPatch.status` to a typed patch (`Patch<WorkflowStatus>` or `Patch<Workflow>`). Provide serde mapping at the IPC boundary so JSON still uses `open|in_progress|closed`. Validate/parse in IPC and keep internal code fully typed. Update mutation engine and canonicalization to use the typed status directly; remove string matching.","acceptance_criteria":"- [ ] `BeadPatch.status` is typed, not `Patch<String>`.\n- [ ] Invalid status strings are rejected during IPC parsing with a clear validation error.\n- [ ] Mutation engine no longer matches status strings.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768529791359,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768529791359,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768529791359,0]}
{"id":"bd-nry","created_at":[1765744963972,0],"created_by":"darin@darinsmcstudio2.lan","title":"Allow cycles for Related deps, keep DAG enforcement for Blocks","description":"**Problem**\n`apply_add_dep` rejects ANY cycle regardless of dep kind. But \"related\" edges being acyclic is unnecessarily strict - related beads can absolutely reference each other cyclically.\n\n**Design**\n- `Related` and `DiscoveredFrom`: allow cycles (these are informational links)\n- `Blocks` and `Parent`: enforce DAG (these have ordering semantics)\n\n**Design Notes**\nOpen question: what about `DependsOn`? Could argue either way:\n- DAG: \"cant start A until B done\" implies ordering\n- Allow cycles: maybe you want mutual dependencies that resolve together?\n\nSuggest: enforce DAG for `DependsOn` initially (safer), can relax later.\n\n**Acceptance**\n- [ ] `bd dep add A B --kind=related` succeeds even if B->A exists\n- [ ] `bd dep add A B --kind=blocks` still rejects cycles\n- [ ] Tests for both cases\n\n**Files:** src/daemon/executor.rs (apply_add_dep), src/core/dep.rs","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765834663234,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765834663234,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765834663234,0]}
{"id":"bd-o7ee","created_at":[1769815030760,0],"created_by":"darin@darinsmcstudio2.lan","title":"Integration tests don't kill daemon processes on failure/timeout - causes hangs","description":"**Problem**\nIntegration tests that spawn daemons (e.g., `test_crash_recovery_replays_wal`, `test_sync_command`) leave orphaned daemon processes when tests fail or are interrupted. These orphans hold sockets/locks, causing subsequent test runs to hang indefinitely.\n\nObserved: Tests hung for 4+ hours locally. Found 3 stale `bd daemon run` processes after killing the test harness.\n\n**Files:**\n- `crates/beads-rs/tests/integration/cli/critical_path.rs`\n- `crates/beads-rs/tests/integration/daemon/crash_recovery.rs`\n- Test fixtures that spawn daemons\n\n**Design**\nOptions:\n1. Add cleanup hooks to test fixtures that kill daemon processes on drop (even on panic)\n2. Use process groups so killing the test process kills children\n3. Add per-test timeouts that forcibly clean up\n\n**Acceptance**\n- [ ] Tests that spawn daemons clean up on success, failure, and panic\n- [ ] No orphaned daemon processes after test run\n- [ ] Local test runs don't hang indefinitely","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1770590559798,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1770590559798,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1770590559798,0]}
{"id":"bd-o83","created_at":[1768411789433,0],"created_by":"darin@darinsmcstudio2.lan","title":"tests: realtime fixtures leak daemon processes","description":"**Problem**\nRealtime integration tests start the daemon via `bd` auto-start but do not shut it down. `RealtimeFixture` drops only restore env (no `Request::Shutdown`), and `AdminFixture` has no Drop cleanup. `tests/critical_path.rs` and `tests/migration.rs` also auto-start the daemon and never shut it down (only one test does best-effort). This leaves orphaned `bd daemon run` processes, stale sockets/locks, and makes repeated test runs flaky on developer machines and CI.\n\nEvidence:\n- `tests/fixtures/realtime.rs` Drop only restores env (lines 77-80).\n- `tests/phase7_admin.rs`, `tests/phase7_admin_status.rs`, `tests/phase7_subscribe.rs` use `RealtimeFixture::start_daemon()` and never stop it.\n- `tests/critical_path.rs`/`tests/migration.rs` use `bd` CLI without teardown.\n\n**Design**\n- Add a shared test helper `shutdown_daemon(runtime_dir: &Path)` (new `tests/fixtures/daemon_runtime.rs` or similar).\n- Implement shutdown by sending IPC `Request::Shutdown` to `beads/daemon.sock`, waiting for ack or socket removal; fall back to SIGTERM/SIGKILL if the process is still alive after a timeout.\n- Make the helper idempotent (missing socket/meta -> Ok).\n- Call this helper from Drop for `RealtimeFixture` and `AdminFixture`, and from the runtime fixture used by `critical_path`/`migration`.\n\n**Acceptance**\n- [ ] Any test that auto-starts the daemon shuts it down during Drop (socket + meta removed).\n- [ ] `cargo test` leaves no `bd daemon run` processes behind.\n- [ ] Helper is used by phase7 realtime tests and other integration tests that spawn the daemon.\n\n**Files:**\n- tests/fixtures/realtime.rs\n- tests/phase7_admin.rs\n- tests/phase7_admin_status.rs\n- tests/phase7_subscribe.rs\n- tests/critical_path.rs\n- tests/migration.rs\n- tests/fixtures/daemon_runtime.rs (new)","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768416090694,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768416090694,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768416090694,0]}
{"id":"bd-o8j9","created_at":[1768807784784,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace test env bool flags with typed enums for sync/checkpoints","description":"","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768809365276,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768809365276,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768809365276,0]}
{"id":"bd-o9qu","created_at":[1770936635696,0],"created_by":"darin@darinsmcstudio2.lan","title":"Non-JSON bd show path is measurably slower than JSON path","description":"**Problem**\nNon-JSON `bd show` is significantly slower than the JSON path in warm-daemon runs (roughly +80-100ms in local benchmark). `bd ready` is mostly fine, but interactive `show` render cost is visible and stacks with other latency sources.\n\nThis hurts the default human workflow because users mostly run non-JSON commands.","design":"Optimize non-JSON show path end-to-end:\n1. Profile CLI render pipeline and daemon query count for `bd show`.\n2. Collapse redundant IPC/queries and precompute display-oriented digest where appropriate.\n3. Avoid repeated expensive formatting steps for unchanged data.\n4. Add a non-JSON benchmark guardrail in CI/slow-tests for regressions.","acceptance_criteria":"- [ ] Warm-daemon non-JSON `bd show` regression benchmark is added.\n- [ ] Non-JSON `bd show` latency improves materially versus baseline on same dataset.\n- [ ] Optimization does not change output semantics or ordering.\n- [ ] Benchmark reports JSON vs non-JSON deltas for visibility.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1770940447440,0],"_by":"darin@darinsmcstudio2.lan","_v":{"acceptance_criteria":[[1770936635696,0],"darin@darinsmcstudio2.lan"],"claim":[[1770936635696,0],"darin@darinsmcstudio2.lan"],"description":[[1770936635696,0],"darin@darinsmcstudio2.lan"],"design":[[1770936635696,0],"darin@darinsmcstudio2.lan"],"estimated_minutes":[[1770936635696,0],"darin@darinsmcstudio2.lan"],"external_ref":[[1770936635696,0],"darin@darinsmcstudio2.lan"],"labels":[[1770936635696,0],"darin@darinsmcstudio2.lan"],"priority":[[1770936635696,0],"darin@darinsmcstudio2.lan"],"source_repo":[[1770936635696,0],"darin@darinsmcstudio2.lan"],"title":[[1770936635696,0],"darin@darinsmcstudio2.lan"],"type":[[1770936635696,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770940447440,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-oe8","created_at":[1765744960969,0],"created_by":"darin@darinsmcstudio2.lan","title":"Wire parsing does extra allocations","description":"**Problem**\n`git/wire.rs` repeatedly does `String::from_utf8(bytes.to_vec())` for blobs. Avoidable copy.\n\n**Design**\nUse `std::str::from_utf8(bytes)?` and parse from the slice, or stream JSONL via `serde_json::Deserializer`.\n\nNot a moral issue, just free perf + less churn.\n\n**Acceptance**\n- [ ] No unnecessary `.to_vec()` in blob parsing\n- [ ] Benchmark shows improvement (or at least no regression)\n\n**Files:** src/git/wire.rs","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767999215864,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767999215864,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767999215864,0]}
{"id":"bd-ogvs","created_at":[1769197292175,0],"created_by":"darin@darinsmcstudio2.lan","title":"CRDT Overhaul Code Review Audit","description":"**Purpose**\nSystematic code review of the crdt-overhaul branch (bd-3zoj) organized by logical segments.\n\n**Segments**\n1. crdt/1-foundation - OR-Set core types (bd-3zoj.1, bd-3zoj.2)\n2. crdt/2-state-model - LabelStore/DepStore/NoteStore + BeadView (bd-3zoj.3, bd-3zoj.4)\n3. crdt/3-wire-ops - Wire ops + event validation (bd-3zoj.5, bd-3zoj.6)\n4. crdt/4-git-wire - Git wire format (bd-3zoj.10)\n5. crdt/5-tests - Roundtrip + determinism tests (bd-3zoj.16, bd-3zoj.17, bd-3zoj.18, bd-3wz4)\n6. crdt/6-apply-collision - Deterministic collision handling (bd-3zoj.7)\n7. crdt/7-cleanup - Legacy removal (bd-3zoj.11, bd-3zoj.12)\n\n**Process**\nEach segment gets a child bead capturing review findings, flagged issues, and resolution status.","priority":2,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769560877535,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769560877535,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769560877535,0]}
{"id":"bd-ogvs.1","created_at":[1769197304799,0],"created_by":"darin@darinsmcstudio2.lan","title":"Segment 1: OR-Set Foundation review","description":"**Segment:** crdt/1-foundation (bd-3zoj.1, bd-3zoj.2)\n**Files:** src/core/orset.rs, src/core/store_meta.rs, src/daemon/store/runtime.rs\n**RepoPrompt chat:** or-set-review-369869\n\n---\n\n## Summary\n\nThis segment introduces a foundational **OR-Set (ORSWOT-style)** implementation in `src/core/orset.rs` with:\n\n- `Dot { replica, counter }` and `Dvv { max: Map<ReplicaId, u64> }`\n- `OrSet<V>` storing `entries: Map<V, Set<Dot>>` plus a causal context `cc: Dvv`\n- `apply_add`, `apply_remove`, and a state-based `join`/`merge`\n- deterministic dot-collision resolution (\"higher value wins\", with a hash fallback)\n- unit tests for DVV dominance, `join` commutativity/idempotence, dominance pruning, and collision resolution\n\nContext files indicate the dot-counter plumbing is also in place:\n- `StoreMeta` persists `orset_counter` (`#[serde(default)]`)\n- `StoreRuntime::next_orset_counter()` increments + writes meta and is covered by a persistence test\n\n## Critical issues (must address)\n\n### 1) **Current `Dvv`/`cc` pruning makes removals delete unrelated values (semantic break)**\nThe invariant \"no dots dominated by `cc` after ops\" is enforced via `prune_dominated()`, **but with `Dvv` implemented as only a per-replica max counter, this turns `cc` into an over-approximate tombstone**.\n\nConcretely: any remove that merges a context with `max[r] = c` makes *all dots from replica `r` with counter ≤ c* dominated and therefore pruned — including dots belonging to **other values**.\n\nMinimal failing scenario (this should be a unit test and currently fails with this implementation):\n\n```rust\n#[test]\nfn remove_does_not_remove_other_values_from_same_replica() {\n    let mut set = OrSet::new();\n    let d1 = dot(1, 1);\n    let d2 = dot(1, 2);\n\n    set.apply_add(d1, \"a\".to_string(), Sha256([0; 32]));\n    set.apply_add(d2, \"b\".to_string(), Sha256([0; 32]));\n\n    let mut ctx = Dvv::default();\n    ctx.observe(d2);\n    set.apply_remove(&\"b\".to_string(), &ctx);\n\n    assert\\!(set.contains(&\"a\".to_string())); // should hold, currently pruned\n    assert\\!(\\!set.contains(&\"b\".to_string()));\n}\n```\n\nThis is not an edge case — labels/deps will routinely have multiple values added by the same replica with increasing counters, so \"remove one label wipes earlier labels from the same author\" is catastrophic.\n\n**Design implication:** As written, the CRDT is not an OR-Set for multi-element sets; it behaves more like \"per-replica GC-floor\" for all earlier dots.\n\n#### What to do\nYou likely need to change *either* the representation *or* the merge rule:\n\n- **Option A (recommended if you truly mean ORSWOT):** make `cc` an *observed clock* (version vector) and implement the standard ORSWOT merge rule that filters dots using *the other side's clock and presence/absence*, not \"drop anything dominated by merged cc\". This avoids the \"remove b removes a\" failure because presence of `a`'s dot on the removing replica prevents it from being treated as removed.\n- **Option B (tombstone-style OR-Set):** `cc` must be able to represent **arbitrary sets of removed dots**, not just a per-replica max. That implies a \"dot cloud\" / exception set (true dotted version vectors) or explicit tombstones. A plain max-per-replica vector cannot represent \"removed dot (r,2) but keep dot (r,1) alive\".\n\nRight now, `CRDT_OVERHAUL.md` describes `Dvv` exactly as \"max per replica\" *and* describes pruning by merged cc — those two combined create the bug above. Either the spec needs adjustment, or this code needs to move to the correct ORSWOT rule.\n\n### 2) `OrSet::join` commutative/idempotent tests are insufficient given the above\nThe provided commutative/idempotent test covers only disjoint replicas/values. Because of the pruning issue, you can still satisfy commutativity/idempotence while being semantically wrong.\n\nAdd targeted tests around:\n- two values added by the same replica + remove one value\n- join across replicas where one side's `cc` is advanced by removing one element but the other element must remain\n\n### 3) \"Durable\" dot counter: meta writes aren't crash-safe\n`StoreRuntime::next_orset_counter()` persists by rewriting JSON via `fs::write`. This is:\n- not atomic (crash during write can truncate/corrupt)\n- not fsync'd (power loss can roll back the counter)\n\nGiven the design intent (\"holes OK, reuse not\"), **counter rollback risks dot reuse**, which then triggers dot collisions and data loss by deterministic collision winner.\n\nIf you need \"durable across crashes/power loss\", consider:\n- write-to-temp + `rename` atomic swap\n- directory + file fsync, or store counter in a more crash-resilient store (sqlite / WAL)\n- at minimum: atomic replace to avoid truncated JSON\n\n## Minor improvements\n\n- **Layering / dependency hygiene:** `orset.rs` depends on `super::event::Sha256` only for the `_op_hash` argument, but doesn't use it. For a \"Layer 3\" CRDT primitive, importing from `event` risks future cycles once wire/event code starts depending on OR-Set types. Consider:\n  - remove `_op_hash` until needed, or\n  - accept `[u8; 32]` directly, or a small hash type defined in a lower layer.\n- **Collision hash tie-break is effectively dead code** under correct `Ord/Eq`:\n  - dot collision means different values ⇒ `left.cmp(right) \\!= Equal`, so hash fallback won't run.\n  - If you want the spec's `(value, sha256(dot||value))` literally, it's fine, but acknowledge the hash won't matter unless `Ord` is violated.\n- **Missing accessor(s) needed by design:** the spec's remove planning needs the current dots per value. `entries` is private and there's no `dots_for(value)` / `ctx_for(value)` helper yet. That's likely needed soon.\n\n## What's done well\n\n- Clear module-level docs and a readable API surface (`apply_add`, `apply_remove`, `join`, `merge`).\n- Determinism-friendly data structures (`BTreeMap`/`BTreeSet`).\n- Explicit dot-collision resolution logic exists and is deterministic.\n- Store-side dot counter persistence is implemented with a straightforward test showing persistence to disk.\n\n## Actionable next steps\n\n1. **Resolve the core semantic issue:** decide whether this is ORSWOT (recommended) or tombstone OR-Set, then adjust `Dvv` and `OrSet::join` accordingly.\n2. Add a **unit test that removing one value does not remove other values from the same replica** (the example above).\n3. Add a **join test** that exercises the same scenario across replicas (one side removes one value; the other value must survive join).\n4. Decide whether `orset.rs` should depend on `event::Sha256`; remove or refactor `_op_hash` to avoid layer coupling.\n5. If \"durable counter\" is a hard requirement, harden `write_store_meta` to be atomic/fsync-safe to prevent counter rollback and dot reuse.\n\n---\n\n**UPDATE:** Later segments (crdt/4-git-wire+) add `dots_for()` accessor and tests for add-wins semantics (`orset_add_wins_over_remove_ctx`, `orset_join_preserves_concurrent_add`). The critical issue #1 may already be addressed - needs manual verification.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1769559413844,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769559413844,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ogvs.2","created_at":[1769198665337,0],"created_by":"darin@darinsmcstudio2.lan","title":"Segment 2: State Model review","description":"**Segment:** crdt/2-state-model (bd-3zoj.3, bd-3zoj.4)\n**Files:** src/core/state.rs, src/core/bead.rs, src/core/dep.rs, +30 others\n**RepoPrompt chat:** state-model-review-187BB8\n\n---\n\n## Summary\n\nThis patch is test-only: it adds `updated_stamp_includes_labels_and_notes` in `src/core/state.rs` to assert that `CanonicalState::updated_stamp_for()` incorporates:\n\n- the per-bead `LabelState.stamp` (after `apply_label_add`), and\n- the latest note's `(at, author)` (after inserting a `Note` into `NoteStore`),\n\nwhich matches the `CRDT_OVERHAUL.md` updated-stamp rule after labels/notes were moved out of `Bead`.\n\n## Critical issues (invariant risks to address)\n\n### 1) `LabelState.stamp` updates are not monotonic and can regress\nIn `CanonicalState::{apply_label_add, apply_label_remove}`:\n\n```rs\nif !change.is_empty() {\n    state.stamp = Some(stamp);\n}\n```\n\nProblems:\n- **No max()**: if an older event is applied later (totally plausible in distributed ingest), `stamp` can move backwards, making `updated_stamp` potentially regress and violating the intent that `updated_stamp` reflect the max across content sources.\n- **Change detection is membership-only**: `OrSetChange` is computed from membership sets only; OR-Set *internal* state can change (new dot, cc merge) without changing the visible membership set, and `stamp` won't update. If the stamp is meant to be \"last label CRDT activity\" (as `CRDT_OVERHAUL.md` suggests: \"update store stamp when OR-Set state changes\"), this is currently under-counting.\n\nWhy this matters to your stated invariants:\n- If label operations are applied out of order, `updated_stamp` may no longer be `>=` the true maximum label-related stamp that should participate in resurrection.\n\n**Suggested fix**\n- Update `LabelState.stamp` with `max(existing, stamp)` (you already have `set_label_stamp()` that does exactly this; `apply_label_*` should use it).\n- If the intended semantic is \"OR-Set state changed\" (not just membership changed), you'll likely need to extend `OrSet::{apply_add, apply_remove}` (or the returned change type) to indicate **internal mutation** as well as membership diff.\n\n### 2) Legacy dep→OR-Set bridge likely breaks \"delete then re-add\" for the same dep\nIn `CanonicalState::insert_dep` (legacy wire path), active membership uses:\n\n```rs\nlet dot = Self::legacy_dot_for_dep(&merged.created, &key);\nself.dep_store.set.apply_add(dot, key.clone(), ...)\n```\n\nBut `merged.created` is intentionally the **earliest created** stamp (stable provenance), not the \"latest active\" stamp. With OR-Set semantics, that means:\n\n- Add at `t1` ⇒ dot derived from `t1`\n- Delete at `t2` ⇒ remove observes dot(t1) and records it in cc\n- Re-add at `t3` (restore) ⇒ **tries dot(t1) again**, but cc dominates it ⇒ add is ignored ⇒ dep never comes back in `dep_store`/`dep_indexes`\n\nThis violates the \"dep_indexes reflect DepStore membership and behave correctly\" expectation in practice, and will make deps non-restorable under the current legacy apply path.\n\n**Suggested fix**\n- For \"active\" membership, derive the dot from the **active-life stamp** (`merged.life.stamp`) rather than `merged.created`, and make the same adjustment in `rebuild_dep_indexes()` (it currently derives from `edge.created`).\n- Add a regression test that covers the *real* problematic sequence: **active → deleted → active** (not just deleted→active).\n\n### 3) Current invariant checks don't actually validate `dep_indexes` against `DepStore`\nYour proptest `assert_invariants()` checks `dep_indexes` against the legacy `deps` map:\n\n```rs\nfor (key, edge) in state.deps.iter() { ... }\n```\n\n…but `dep_indexes` is explicitly derived from `dep_store` (and rebuilt from `dep_store.values()` after join). If `deps` and `dep_store` ever diverge, this invariant won't catch it.\n\n**Suggested fix**\n- Add an invariant check that:\n  - every `DepKey` in `dep_store.values()` exists in both indexes, and\n  - every edge present in indexes corresponds to a `DepKey` present in `dep_store`.\n\n## Minor improvements\n\n- The new test is good and targeted, but you could make it slightly stronger by asserting full stamp equality after the label add (not just `wall_ms`), e.g. `assert_eq!(updated, label_stamp)`.\n- Consider adding tests for:\n  - **orphan hiding**: add labels/notes/deps for a missing bead and assert `labels_for/notes_for/deps_from` don't surface them, while the internal stores retain them (`labels_for_any`, `NoteStore`, `dep_store`).\n  - **resurrection via labels/notes**: tombstone newer than fields but older than label/note activity should resurrect.\n  - **content_hash determinism**: same hash regardless of label/note insertion order and stable across join.\n- `compute_content_hash()` appears deterministic, but it likely omits at least `estimated_minutes` (and possibly other fields you intend to be part of OCC). Confirm intent and add a \"hash changes when field changes\" test if OCC depends on it.\n\n## What's done well\n\n- The added test directly encodes the `CRDT_OVERHAUL.md` updated-stamp rule and will prevent regressions as labels/notes continue moving out of `Bead`.\n- The state model separation is clean: `CanonicalState` as the owner of stores + `BeadView` for derived metadata, and deterministic ordering (BTree*, explicit sorts) for stable hashing/output.\n\n## Next steps\n\n1. Fix `LabelState.stamp` maintenance to be monotonic (`max`) and aligned with the intended \"OR-Set state changed\" semantics.\n2. Fix legacy dep dot derivation (`insert_dep` / `rebuild_dep_indexes`) to support delete→re-add.\n3. Extend invariant/test coverage to validate `dep_indexes` against **`dep_store`**, and add the missing dep restore regression test.\n4. Add deterministic/content-hash regression tests (including field coverage) if `ContentHash` is relied on for OCC.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769559883438,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769559883438,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769559883438,0]}
{"id":"bd-ogvs.3","created_at":[1769201020522,0],"created_by":"darin@darinsmcstudio2.lan","title":"Segment 3: Wire Ops + Event Validation review","description":"**Segment:** crdt/3-wire-ops (bd-3zoj.5, bd-3zoj.6)\n**Files:** src/core/wire_bead.rs, src/core/event.rs, src/daemon/mutation_engine.rs, +10 others\n**RepoPrompt chat:** crdt-wire-ops-0FBA1A\n\n---\n\n## Summary (what this segment accomplishes)\n\nThis segment completes the \"wire ops + validation\" portion of the CRDT overhaul by:\n\n- Introducing explicit OR-Set wire operations for labels/deps (`WireLabelAdd/RemoveV1`, `WireDepAdd/RemoveV1`) based on `(dot, ctx/DVV)`.\n- Making `TxnDeltaV1` canonical + duplicate-safe via `TxnOpKey` and a `BTreeMap` storage strategy, **including dot in the key for add ops** to prevent dedup collisions.\n- Extending CBOR encode/decode in `src/core/event.rs` to support these new ops and the `WireDotV1` / `WireDvvV1` payloads.\n- Adding **D1 semantic validation** that rejects workflow/claim patches that would depend on `Keep`.\n- Updating mutation planning to mint dots for add ops, build DVV contexts for removes, and to emit workflow/claim patches that always satisfy the new D1 rules—plus validating the assembled `EventBody` before encoding.\n\nOverall, the direction and shape match `CRDT_OVERHAUL.md` and the new invariants are mostly enforced consistently across planning, validation, and apply.\n\n---\n\n## Critical issues (must address)\n\n### 1) `encode_wire_tombstone` can emit invalid CBOR in release builds\n**File:** `src/core/event.rs` (`encode_wire_tombstone`)\n\nYou compute `has_lineage` as `at.is_some() || by.is_some()` and add `+2` to the encoded map length, but only emit the fields when **both** are present. If only one is set, you hit a `debug_assert\\!`—which is compiled out in release—so you will emit a map header declaring too many entries.\n\nThat's a correctness bug that can corrupt event bytes / WAL records (and potentially break replication) if a partially-filled tombstone ever reaches encoding.\n\n**Fix suggestion (runtime, not debug-only):**\n- Either compute length based on `(Some, Some)` only:\n  ```rs\n  let has_lineage = tombstone.lineage_created_at.is_some()\n      && tombstone.lineage_created_by.is_some();\n  if tombstone.lineage_created_at.is_some() ^ tombstone.lineage_created_by.is_some() {\n      return Err(EncodeError::InvalidField { ... }); // or similar\n  }\n  ```\n- Or validate the XOR invariant before encoding and error out.\n\nAlso consider adding a semantic validation hook for tombstones (same XOR check) since mutation planning now calls `validate_event_body()` but that currently only validates bead patches.\n\n---\n\n### 2) Test fixture creates D1-invalid workflow patches\n**File:** `tests/integration/fixtures/event_body.rs` (`sample_bead_patch`)\n\nThe fixture sets:\n```rs\npatch.status = Some(WorkflowStatus::Open);\n```\n…but does **not** set `closed_reason` / `closed_on_branch`, leaving them at `Keep`.\n\nWith the new validator:\n```rs\nif patch.status.is_some() && (patch.closed_reason.is_keep() || patch.closed_on_branch.is_keep()) { ... }\n```\nthis fixture is now semantically invalid.\n\nEven if current integration tests only call `apply_event()` (and don't validate), anything that goes through `verify_event_frame` / `validate_event_body` (or new mutation-engine validation) will reject these events. This is a likely \"tests start failing later\" landmine.\n\n**Fix options:**\n- Preferred for D1 coverage: keep `status: Some(Open)` but add:\n  ```rs\n  patch.closed_reason = WirePatch::Clear;\n  patch.closed_on_branch = WirePatch::Clear;\n  ```\n- Or omit `status` entirely in the fixture (leave it `None`) if the intent is \"create-like patch\".\n\n---\n\n### 3) Potential gap: claim semantic validation allows \"unclaimed but expires set\"\n**File:** `src/core/event.rs` (`validate_bead_patch_semantics`)\n\nCurrent claim rule only enforces \"no Keep asymmetry\":\n```rs\nif assignee_keep ^ expires_keep { error }\n```\n\nThis still allows **both-not-Keep** combinations like:\n- `assignee = Clear`, `assignee_expires = Set(...)` (nonsensical)\n- `assignee = Set(...)`, `assignee_expires = Clear` (might be valid if you allow non-expiring claims)\n\nIf `build_claim()` rejects some of these, then malformed-but-decodable events can pass `validate_event_body_semantics()` and later fail during apply.\n\n**Action:** confirm intended Claim domain invariants and either:\n- tighten validation to reject impossible combos (at minimum: `assignee == Clear` implies `expires == Clear`), or\n- ensure `build_claim()` is total and treats any \"weird but explicit\" combination deterministically (no error).\n\nGiven the CRDT goal (\"apply should only fail on malformed encodings/invariant violations\"), it's better to reject at validation with a clear `EventValidationError::InvalidClaimPatch`.\n\n---\n\n## Minor improvements / quality suggestions\n\n### A) Strengthen workflow validation slightly (optional but safer)\nToday you only require \"explicit closure fields if status is touched\". Two additional checks worth considering:\n\n- Reject `closed_reason` / `closed_on_branch` patches when `status` is `None` (they're ignored by apply anyway; catching them early reduces \"silent no-op\" footguns).\n- Optionally enforce that for `status \\!= Closed`, closure patches must be `Clear` (not `Set`) to avoid weird payloads.\n\n### B) Add missing roundtrip + apply coverage for new OR-Set ops\nRight now the provided integration tests focus on notes + LWW fields. Add targeted tests for:\n\n- **CBOR** encode/decode roundtrip including:\n  - multiple `LabelAdd` for same `(bead_id,label)` with different dots (proves `TxnOpKey` dot inclusion matters)\n  - `LabelRemove` and `DepRemove` DVV contexts\n- apply idempotency/commutativity for label/dep ops:\n  - apply same `LabelAdd` twice (dot idempotency)\n  - `Remove(ctx)` then concurrent `Add(dot)` not in ctx (add-wins)\n  - `plan_set_parent` producing remove+add converges and doesn't accidentally remove the new parent dot\n\n### C) Docs drift\n`CRDT_OVERHAUL.md` still describes:\n- `WireDvvV1(Vec<(ReplicaId,u64)>)` but implementation uses a `BTreeMap` and CBOR encodes it as a map.\n- `WireDotV1 { replica_id, ... }` vs encoded key `\"replica\"`.\n\nRecommend updating the doc section so wire format expectations match the actual encoder.\n\n### D) Optional: validate dot origin\nNot required by the current spec, but for robustness: consider validating that `LabelAdd.dot.replica` / `DepAdd.dot.replica` matches `EventBody.origin_replica_id`. Otherwise a buggy/malicious replica could mint dots \"as\" another replica and disrupt DVV monotonic assumptions.\n\n---\n\n## What's done particularly well\n\n- **TxnOpKey includes dot for add ops** (`LabelAdd`, `DepAdd`): this is the correct fix for dedup collisions and aligns with the spec.\n- `TxnDeltaV1` using a `BTreeMap<TxnOpKey, TxnOpV1>` provides:\n  - canonical op ordering,\n  - stable iteration for encoding,\n  - and duplicate detection in one place.\n- CBOR decode paths are careful about:\n  - unique keys (`ensure_unique_key`),\n  - per-txn op limits,\n  - and note size constraints.\n- Mutation engine changes (close/reopen/claim/unclaim/extend_claim + status normalization) are consistent with the D1 validator, and calling `validate_event_body()` before encoding is a strong \"fail fast\" defense against accidental regression.\n\n---\n\n## Next steps (actionable)\n\n1. **Fix `encode_wire_tombstone`** to enforce lineage field pairing at runtime and to keep map length consistent in release builds.\n2. **Update `sample_bead_patch` fixture** to satisfy D1 workflow semantics (explicitly clear closure fields when `status` is set, or omit `status`).\n3. Decide on **claim invariants** and either:\n   - tighten `validate_bead_patch_semantics` to reject impossible explicit claim combos, or\n   - ensure apply is total for all explicit combinations.\n4. Add **CBOR + apply tests** covering label/dep OR-set ops (roundtrip, idempotency, add-wins behavior).\n5. Update `CRDT_OVERHAUL.md` to reflect the final on-wire encoding choices (DVV map vs vec, dot field/key names).","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769560077072,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769560077072,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769560077072,0]}
{"id":"bd-ogvs.4","created_at":[1769201905536,0],"created_by":"darin@darinsmcstudio2.lan","title":"Segment 4: Git Wire Format review","description":"**Segment:** crdt/4-git-wire (bd-3zoj.10)\n**Files:** src/git/wire.rs, src/git/sync.rs, src/core/state.rs, src/core/orset.rs, src/daemon/migration.rs\n**RepoPrompt chat:** git-wire-review-451D06\n\n---\n\n## Summary\n\nThis segment keeps the Git wire format deterministic and roundtrippable while adding/using richer CRDT stores:\n\n- `deps.jsonl` supports an OR-Set encoding (`WireDepStore`) and can still parse legacy per-edge JSONL.\n- `state.jsonl` embeds per-bead OR-Set label metadata and uses the sparse `_v` mechanism for per-field stamps (SPEC §5.2.1).\n- `notes.jsonl` is serialized deterministically and included in `meta.json` checksums (optional on read for legacy commits).\n- The actual diff in this slice is a small readability refactor in `parse_deps` (using an `if ... && let Ok(...)` chain) with no intended semantic change.\n\n## Critical issues (must address)\n\n### 1) Integrity hole: `read_state_at_oid` silently ignores malformed `meta.json`\nIn `src/git/sync.rs`, meta parsing is guarded by an `if let ... && let Ok(meta) = wire::parse_meta(...)` chain. If `meta.json` exists but is corrupted/unparseable, the loader currently:\n- drops `checksums` to `None`, and\n- proceeds to load state without checksum verification.\n\nThis undermines SPEC §5.2 (\"Readers MUST verify these checksums when present\") and makes corruption harder to detect.\n\n**Action:** Treat an existing-but-unparseable `meta.json` as a hard load failure. Concretely, change the loader logic to:\n- if `meta.json` is present → require `parse_meta` succeed (or return error),\n- and if parsed checksums exist → always verify.\n\n### 2) Deterministic dep ordering may be spec-ambiguous because `DepKind` ordering is likely enum-order, not lexical\n`serialize_deps` sorts entries by `DepKey` (`entries.sort_by(|a,b| a.key.cmp(&b.key))`). `DepKey` derives `Ord`, meaning `(from, to, kind)` ordering uses `DepKind`'s `Ord`.\n\nIf `DepKind` is `#[derive(Ord)]` in variant-declaration order (common), that order may not match a lexical `\"blocks\" < \"discovered_from\" < \"parent\" < \"related\"` interpretation of SPEC §5.3's `(from,to,kind)` ascending requirement.\n\n**Action options:**\n- Make `DepKind: Ord` explicitly compare by `as_str()` (recommended for cross-impl determinism).\n- Or, keep `DepKind` as-is but **explicitly codify** in SPEC/design docs that ordering uses enum-variant order, not string order.\n\n### 3) MSRV risk: `if let` chains require a minimum Rust version\nThe diff changes to:\n\n```rust\nif non_empty.len() == 1\n    && let Ok(wire) = serde_json::from_str::<WireDepStore>(non_empty[0])\n{\n    ...\n}\n```\n\nThis relies on \"let chains\" in `if` conditions. Ensure the project's MSRV supports it; otherwise this is a build breaker.\n\n**Action:** Confirm MSRV (Cargo.toml / docs). If MSRV is below the stabilization version, revert to the nested `if` form.\n\n## Minor improvements (quality / robustness)\n\n### A) Normalize OR-Set state on parse (defensive correctness)\nBoth labels and deps rebuild OR-Set state via `OrSet::from_parts(...)`, which does **not** enforce invariants (e.g., pruning dots dominated by `cc`, resolving dot collisions). That's OK for trusted canonical commits, but it's brittle against:\n- corrupted-but-JSON-valid commits (especially if checksums are bypassed as noted above),\n- future format changes, or\n- manually edited repos.\n\n**Suggestion:** Add a `normalize()` step (or construct via `OrSet::join(&OrSet::new(), &set)`) to ensure:\n- dominated dots are pruned,\n- collisions are resolved deterministically.\n\n### B) `verify_store_checksums` should not contain an `expect(...)`\n```rust\nlet actual_notes = actual.notes.expect(\"notes checksum missing\");\n```\n\nIt's safe today because you always compute with `Some(notes_bytes)` in this function, but it's an avoidable panic path.\n\n**Suggestion:** Replace with a normal error if `actual.notes.is_none()` (or compute `actual_notes` directly in the scope where it's needed).\n\n### C) Spec/design drift: `deps.jsonl` OR-Set is a single JSON object line\nThe design doc slice suggests a JSONL shape with a `cc` line and per-edge lines. Current implementation writes a single `WireDepStore` JSON object with an `entries` array. This is still deterministic, but it:\n- makes diffs noisier (any dep change rewrites the whole blob),\n- weakens the literal interpretation of SPEC §5.3's \"deps.jsonl sorted by (from,to,kind)\" (since it's not \"one edge per line\" anymore).\n\n**Suggestion:** If the intent is to keep JSONL nice for diffs, consider switching `deps.jsonl` OR-Set encoding to multi-line canonical form (cc line + per-key lines), while preserving deterministic order.\n\n## What's done particularly well\n\n- Strong determinism posture: BTreeMap/BTreeSet use throughout, explicit sorting for IDs/keys/dots, and newline normalization for JSONL outputs.\n- Backward compatibility: labels can parse legacy arrays, deps can parse legacy edge-per-line JSONL, notes.jsonl is optional on read.\n- Roundtrip and property tests cover core determinism and the important \"OR-Set metadata persists even when membership is empty\" case (add then remove, cc-only state).\n\n## Next steps (actionable)\n\n1. **Make meta parsing strict** in `read_state_at_oid`: fail if `meta.json` exists but can't be parsed; if checksums exist, always verify.\n2. **Define dep ordering canonically**:\n   - either implement `Ord` for `DepKind` by `as_str()`, or\n   - document enum-order as canonical and add a regression test for ordering.\n3. **Confirm MSRV** supports `if let` chains; otherwise revert the refactor.\n4. (Optional but recommended) **Normalize OR-Set on parse** to prevent accepting invalid OR-Set states.\n5. Consider whether `deps.jsonl` should move to **multi-line OR-Set encoding** for better diffs and clearer compliance with SPEC §5.3 ordering language.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769560184576,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769560184576,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769560184576,0]}
{"id":"bd-ogvs.5","created_at":[1769202950304,0],"created_by":"darin@darinsmcstudio2.lan","title":"Segment 5: Tests review","description":"**Segment:** crdt/5-tests (bd-3zoj.16, bd-3zoj.17, bd-3zoj.18, bd-3wz4)\n**Files:** src/git/wire.rs, src/core/wire_bead.rs, src/daemon/query_model.rs, src/api/issues.rs, CRDT_OVERHAUL.md\n**RepoPrompt chat:** crdt-tests-review-E393FB\n\n---\n\n## Summary (what this segment accomplishes)\n\nThis segment adds/expands test coverage around four CRDT-overhaul invariants:\n\n1. **Wire encode/decode roundtrips (realtime + snapshot wire)**  \n   `src/core/wire_bead.rs` now has unit tests confirming JSON roundtrips for `WireNoteV1`, `WireBeadPatch` (incl. `WirePatch::Clear`), and `TxnDeltaV1` (incl. `WireDotV1` + `WireDvvV1` through op payloads). It also asserts **canonical op ordering** and **duplicate-key rejection**.\n\n2. **Git/checkpoint roundtrips preserving OR-Set metadata + notes**  \n   `src/git/wire.rs` tests now exercise `serialize_*` + `parse_legacy_state` end-to-end and explicitly verify that **OR-Set dots + causal context (DVV)** and **notes** survive a roundtrip.\n\n3. **Deterministic OR-Set serialization**  \n   `src/git/wire.rs` includes a \"same logical state, different insertion order\" test asserting byte-for-byte identical `state.jsonl`, `deps.jsonl`, and `notes.jsonl`.\n\n4. **`updated_at` changes when labels/notes change (no scalar field edit)**  \n   `src/core/state.rs` validates `updated_stamp` includes label/note activity, and both `src/api/issues.rs` and `src/daemon/query_model.rs` add tests showing this propagates correctly to `Issue/IssueSummary.updated_at` and `updated_by`.\n\nOverall this aligns well with **CRDT_OVERHAUL.md**'s locked invariants.\n\n---\n\n## Critical issues (should address)\n\n### 1) Determinism test does not vary label/dep stamps, so it may miss a real convergence bug\nYour determinism test (`serialize_orset_is_deterministic_across_insertion_order`) varies *operation insertion order*, but all label/dep ops share the same `Stamp` (`stamp.clone()` everywhere). That means it **won't catch** an important class of nondeterminism:\n\n- If `label_stamp` / `dep_store.stamp` are updated by **assignment** (last-applied wins) rather than **`max(existing, incoming)`**, then applying the same set of ops in different orders but with *different stamps* can yield different final metadata → different `updated_stamp` / different serialization bytes.\n\nThis matters because **CRDT_OVERHAUL.md's updated_stamp rule** implicitly assumes those stamps are stable CRDT summaries (i.e., merge/order independent).\n\n**Actionable fix (tests):**\n- Modify the insertion-order determinism test to use *different* stamps for the two label adds (and separately dep adds), then apply in opposite orders and assert serialization equality.\n- Same idea for label add vs label remove: different stamps, reversed order.\n\nIf that test fails, it indicates a real CRDT convergence issue in stamp tracking (not just a test issue).\n\n---\n\n## Minor improvements (quality + coverage)\n\n### A) Add a `WireBeadFull` JSON roundtrip test (not just conversion test)\n`wire_bead_full_preserves_stamps` validates `BeadView → WireBeadFull → Bead` conversion and `label_stamp()` behavior, but does **not** assert JSON encode/decode roundtrip for `WireBeadFull` itself.\n\n**Suggestion:**\n- Add `serde_json::to_string(&wire)` then `from_str` and assert equality.\n- Include at least two notes out-of-order to verify the note sorting determinism actually gets exercised (currently only one note).\n\n### B) Add a sparse-`_v` partial coverage test for git wire\nIn `src/git/wire.rs`, current tests hit:\n- `_v` omitted (all fields same as bead stamp), and\n- `_v` containing \"everything\" (when notes force bead-level stamp ahead of all fields).\n\nThey do not clearly hit the \"**only some fields differ**\" case (sparse `_v` correctness).\n\n**Suggestion:**\n- Construct a bead where only `title.stamp` is newer than the rest (no notes), serialize/parse/serialize, and assert byte-for-byte equality.\n- Add a case where `label_stamp == bead_stamp` so `_v.labels` is omitted and must be reconstructed from default `_at/_by`.\n\n### C) Reduce duplication between API and daemon updated_at tests\n`src/api/issues.rs` and `src/daemon/query_model.rs` test modules are essentially identical. That's fine short-term, but it's extra maintenance.\n\n**Suggestion:**\n- Factor shared helpers into a small internal test helper module (even just a `#[cfg(test)] mod test_helpers` in `core`).\n\n### D) If legacy parsing is intended to be supported, add explicit legacy-format tests\n`parse_deps` and `WireLabels` both support legacy shapes, but this segment's tests primarily validate the new OR-Set format.\n\n**Suggestion:**\n- Add a focused unit test that feeds `parse_deps` multiple legacy `WireDep` lines and asserts correct reconstructed state (or explicitly decide legacy isn't required and remove the parser paths).\n\n---\n\n## What's done particularly well\n\n- **End-to-end checksum & roundtrip assertions** in `src/git/wire.rs` are strong; byte-for-byte equality is exactly what you want for the determinism requirement.\n- The OR-Set metadata test (`roundtrip_orset_metadata_preserves_dots_and_context`) correctly asserts both:\n  - membership dots (`dots_for(...)`), and\n  - causal context (`cc()`),\n  which directly matches CRDT_OVERHAUL's \"persist dots + DVV\" invariant.\n- The **`updated_at` propagation tests** validate the full pipeline: `CanonicalState.bead_view → BeadView.updated_stamp → Issue/IssueSummary updated_at`, matching the architecture notes.\n\n---\n\n## Next steps (specific, actionable)\n\n1. **Strengthen determinism tests** by using different stamps for label/dep ops in different application orders (this is the biggest missing coverage).\n2. Add:\n   - `WireBeadFull` JSON roundtrip test (with >1 note to exercise sorting),\n   - git wire sparse `_v` partial-diff test.\n3. Optional cleanup: dedupe API + daemon updated_at tests via a shared helper module.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769560267801,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769560267801,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769560267801,0]}
{"id":"bd-ogvs.6","created_at":[1769203763780,0],"created_by":"darin@darinsmcstudio2.lan","title":"Segment 6: Apply Collision Handling review","description":"**Segment:** crdt/6-apply-collision (bd-3zoj.7)\n**Files:** src/core/apply.rs, src/core/state.rs, tests/integration/core/apply.rs\n**RepoPrompt chat:** crdt-collision-review-B904F2\n\n---\n\n## Summary (what this test change accomplishes)\n\nThis patch updates the integration test `note_collision_is_deterministic` to match the **D4 note collision winner rule** by ensuring the colliding note has the **same `(at, author)`** as the existing one, so the test actually exercises the **`sha256(content)` tie-breaker**. It also removes now-unused imports and fixes ownership by cloning `bead_id` when building the `NoteAppend`.\n\nNet effect: the test now correctly validates the \"content-hash tiebreak\" portion of deterministic note collision handling.\n\n---\n\n## Critical issues / gaps to address\n\n### 1) Integration tests still don't cover most of the collision + totality surface area\nGiven the scope of \"Apply Collision Handling\", the integration suite still lacks coverage for:\n\n- **Bead creation collisions**\n  - Two `BeadUpsert`s with the same `BeadId` but different `created` stamps\n  - Deterministic winner selection + insertion of a **lineage collision tombstone**\n  - Order-independence (`apply(A); apply(B)` vs `apply(B); apply(A)`)\n  - Suppression of subsequent ops for the losing lineage\n\n- **OR-Set dot collisions (labels + deps)**\n  - Same `Dot` used with different values; winner should be deterministic (value lexicographic, then `sha256(dot||value)`)\n  - Order-independence of applying the competing adds\n  - \"stamp updates only on real membership change\" behavior around collisions\n\n- **Orphan totality rules**\n  - `LabelAdd/Remove`, `DepAdd/Remove`, and `NoteAppend` on **missing beads** must not error\n  - Orphans should become visible after later bead creation (queries hide until bead exists)\n\nRight now, the integration file only covers: idempotency, one note collision tiebreak, and LWW ordering.\n\n### 2) Merge-path determinism remains a risk (not tested here)\nEven though this diff only touches tests, it's worth calling out: the merge side must align with apply for D4 to be \"done\".\n\n- `CanonicalState::join` currently **keeps the left bead** on `Bead::join` collision while collecting errors (non-commutative in the presence of collisions).\n- `NoteStore::join` is left-biased for same `(bead_id, note_id)`.\n\nIf collisions can exist in inputs to `join()` (e.g., from older snapshots/checkpoints, manual state construction, or partial replication paths), this violates the \"deterministic everywhere\" goal. There are no integration tests that would catch this divergence.\n\n---\n\n## Minor improvements (quality / robustness)\n\n- In `note_collision_is_deterministic`, consider asserting the intended preconditions explicitly to prevent fixture drift from accidentally changing what the test exercises:\n  - `assert_eq\\!(stored.at, expected_at)` isn't possible via `notes_for()` refs unless you also pull `note.at` and `note.author` from both versions, but you can at least assert the incoming `note.at/author` match the base fixture's values before applying.\n\n- The expected-winner computation could mirror the spec tuple ordering even though this test currently pins `(at, author)` equal. That would make the test self-documenting and resilient if `sample_note()` changes.\n\n---\n\n## What's done particularly well\n\n- **Intentionality:** Switching from a hand-constructed `WireNoteV1` (with different `at/author`) to `sample_note(2, 1)` makes it clear the test is about the **hash tie-break**, not timestamp/author precedence.\n- **Cleanliness:** Removing `WireNoteV1`/`WireStamp` imports and fixing the `bead_id` move with `bead_id.clone()` keeps the test correct and idiomatic.\n\n---\n\n## Actionable next steps\n\n1. **Add integration tests for bead ID collisions**:\n   - Apply two conflicting creations in both orders; assert same winner + lineage tombstone behavior.\n2. **Add integration tests for OR-Set dot collisions** (labels + deps):\n   - Same `Dot`, different value; ensure deterministic resolution + order-independence.\n3. **Add integration tests for orphan ops**:\n   - Apply label/dep/note ops before bead exists; ensure no error and visibility after bead creation.\n4. **Add tests around \"stamp updates only on real membership change\"**:\n   - Add a second dot for the same label/dep value (membership unchanged) and assert stamp/`updated_stamp` doesn't advance.\n5. (If D4 is meant to include merge right now) **Add merge/join collision tests** or update merge to apply the same collision comparators as apply.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769560639246,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769560639246,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769560639246,0]}
{"id":"bd-ogvs.7","created_at":[1769204890711,0],"created_by":"darin@darinsmcstudio2.lan","title":"Segment 7: Cleanup review","description":"**Segment:** crdt/7-cleanup (bd-3zoj.11, bd-3zoj.12)\n**Files:** 33 files, -880 lines net (major deletions: src/git/collision.rs, DepEdge/DepLife, NoteLog)\n**RepoPrompt chat:** crdt-cleanup-review-801B27\n\n---\n\n## Summary (what these changes accomplish)\n\n- **WAL snapshot dep serialization is now JSON-safe and deterministic**: `DepStore` is encoded as a `WalDepStore { cc, entries[], stamp }` (mirrors the checkpoint/git approach of \"entry lists\"), and legacy dep snapshots are still convertible via `dep_store_from_legacy`.\n- **Core CRDT model looks cleaned of legacy dep/note/label structures** in the provided context:\n  - Core deps are `DepKey` OR-Set membership (no core `DepEdge`/`DepLife`).\n  - Notes are in `NoteStore` (no `NoteLog` embedded in `Bead`).\n  - Labels are OR-Set state in `LabelStore` (no LWW label field in `BeadFields`).\n- **Git sync merge path is simplified**: `src/git/sync.rs` merges via `CanonicalState::join` directly; there's no collision \"remap\" module or call site shown.\n\n## Critical issues / must-address\n\n### 1) \"Collision ApplyError paths are gone\" is **not true yet**\nIn `src/core/apply.rs` the enum still includes:\n- `ApplyError::BeadCollision`\n- `ApplyError::NoteCollision`\n\nAnd at least one is still referenced:\n\n```rs\nstate\n  .insert(bead)\n  .map_err(|_| ApplyError::BeadCollision { id: id.clone() })?;\n```\n\nEven if this is \"effectively unreachable\" after the earlier collision-handling logic, it still violates the segment 7 acceptance criterion you cited (\"ApplyError/collision legacy paths are gone\").\n\n**Action**:\n- If collisions are now always resolved deterministically, **remove these variants** and refactor the remaining callsites to be infallible (or treat failures as internal invariants with `expect`/panic + metrics).\n- If there are still legitimate failure cases, document them explicitly and reconcile with the \"apply total\" constraint.\n\n### 2) WAL format change may break \"recent-but-not-ancient\" WAL snapshots\n`WalStateV2.deps` changed from `DepStore` → `WalDepStore`. With the current untagged enum:\n\n```rs\nenum WalStateRepr {\n  V2(WalStateV2),        // now expects WalDepStore\n  LegacyVecs(...),       // expects Vec<LegacyWalDep>\n  LegacyMaps(...),       // expects BTreeMap<DepKey, ...>\n}\n```\n\nA WAL written by the immediately previous code (when deps were a `DepStore` JSON object) likely won't match *any* variant, because:\n- it won't deserialize as `WalDepStore`, and\n- it won't look like the legacy vec/map shapes.\n\nGiven your global constraint (\"old local stores unsupported; wipe\"), this might be acceptable — but then keeping legacy parsing paths is a bit inconsistent.\n\n**Action** (pick one):\n- **Accept breakage** and explicitly document that WAL files from earlier builds are unsupported and should be deleted on upgrade.\n- Or add a transitional variant that can deserialize the previous `DepStore`-shaped deps (even if only for dev ergonomics).\n\n### 3) `WalDepStore::into_dep_store` inserts empty-dot entries (potentially unsafe)\nThis code:\n\n```rs\nif dots.is_empty() {\n    map.entry(entry.key).or_default();\n} else {\n    map.insert(entry.key, dots);\n}\n```\n\nRisks creating OR-Set `entries` containing keys with empty dot sets. Whether that's harmless depends on `OrSet` invariants:\n- If `OrSet::values()`/`is_empty()`/`contains()` assume \"no empty dot sets\", you can get subtle bugs (phantom values, incorrect emptiness, etc.).\n\n**Action**:\n- Prefer **skipping empty-dot entries entirely**, or normalize through an `OrSet` constructor that prunes empties.\n- If empty entries are intentionally meaningful, add an explicit comment explaining why and ensure `OrSet` APIs treat them correctly.\n\n## Minor improvements (quality/cleanup)\n\n- **DRY**: `WalDepStore` is structurally very similar to `WireDepStoreV1`/`WireDepEntryV1`. If layering allows, consider reusing the existing wire structs (or extracting a shared internal representation) to avoid divergence.\n- **`Labels::remove` returns `true` unconditionally** (`src/core/collections.rs`). That's misleading and can hide bugs at call sites. Either:\n  - return the real \"changed?\" boolean (`before_len \\!= after_len`), or\n  - make it `fn remove(&mut self, label: &str)` without a return value.\n\n## What's done particularly well\n\n- **The WAL deps change is targeted and solves a real problem**: serializing `BTreeMap<DepKey, ...>` to JSON is not viable (non-string keys), and the new entry-list format aligns with the checkpoint/git dep encoding.\n- **Git sync is now cleanly CRDT-based**: merge uses `CanonicalState::join` with no sign of ID remap collision hacks, which is exactly the desired direction.\n- **Core model cleanup appears consistent**: DepKey-only deps, OR-Set labels, NoteStore notes, and no bead-embedded NoteLog in the shown files.\n\n## Specific next steps\n\n1. **Remove collision error variants** (`ApplyError::BeadCollision`, `ApplyError::NoteCollision`) and any remaining call sites that can surface them, or justify them with explicit invariants/docs.\n2. **Decide on WAL backward-compat stance**:\n   - If \"wipe is fine\", add a comment and possibly a more explicit error message instructing deletion.\n   - If not, add a transitional deserialization branch for the previous `DepStore` JSON shape.\n3. **Prune empty-dot handling** in `WalDepStore::into_dep_store` unless you can prove `OrSet` tolerates it.\n4. Run a final grep-based audit (or CI check) for the explicit delete list tokens:\n   - `NoteLog`, `DepLife`, core `DepEdge`, `WireDepV1`, `WireDepDeleteV1`, `WireBeadPatch.labels`, `git::collision`/remap callsites, and the collision ApplyError variants.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769560826154,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769560826154,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769560826154,0]}
{"id":"bd-oi9","created_at":[1765744523302,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add --parent flag to bd update command","description":"**Problem**\nCannot reparent a bead after creation. Beads created independently cannot be linked to an epic as children later.\n\nCurrently `--parent` only works at create time:\n```\nbd create \"subtask\" --parent=bd-epic\n```\n\n**Solution**\nAdd `--parent` flag to `bd update`:\n```\nbd update bd-xyz --parent=bd-epic\n```\n\n**Design Notes**\n- Should validate parent exists and is not deleted\n- Should prevent circular parent relationships\n- Consider `--parent=\"\"` or `--no-parent` to unparent a bead\n- Parent changes should be LWW like other fields\n- ID format: beads created with --parent get hierarchical IDs (bd-abc.1). Reparenting existing beads probably keeps their original ID rather than renumbering.\n\n**Acceptance**\n- [ ] `bd update <id> --parent <epic-id>` works\n- [ ] Invalid/deleted parent rejected with clear error\n- [ ] Circular parent reference rejected\n- [ ] Can unparent a bead (remove from epic)\n- [ ] `bd show` reflects new parent\n- [ ] `bd epic status` includes reparented beads","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765775468839,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765775468839,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765775468839,0]}
{"id":"bd-ojex","created_at":[1768822541066,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace AdminFixture checkpoints_enabled bool with typed enum","description":"AdminFixture in tests/integration/daemon/admin.rs uses a checkpoints_enabled bool to control env setup. Align with type_design.md by replacing it with a small enum (Enabled/Disabled) or similar typed mode.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768823628764,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768823628764,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768823628764,0]}
{"id":"bd-omw","created_at":[1767916438346,0],"created_by":"darin@darinsmcstudio2.lan","title":"Cleanup: simplify CLI/daemon reasoning","description":"**Problem**\nSimplification work is scattered across CLI/daemon and lacks a single epic to track dependencies and progress.\n\n**Design**\nGroup simplification beads under this epic so we can track progress and sequence work.\n\n**Acceptance**\n- [ ] All child beads are completed.\n\n**Files:** n/a","priority":2,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1767920152435,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767920152435,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-omw.1","created_at":[1767916489266,0],"created_by":"darin@darinsmcstudio2.lan","title":"Centralize dependency spec parsing","description":"**Problem**\nDependency spec parsing is duplicated in `src/cli/mod.rs` (`normalize_dep_specs`) and `src/daemon/executor.rs` (`parse_dep_specs`). The two implementations can drift (string format, DepKind parsing, error messages), which makes CLI validation diverge from daemon validation and complicates reasoning about dependency formats.\n\n**Design**\nAdd a shared parser in core and use it from both CLI and daemon:\n- Introduce a `DepSpec` type in `src/core/dep.rs` (or a small `dep_spec` module) with `{ kind: DepKind, id: BeadId }`.\n- Implement `DepSpec::parse_list(raw: &[String]) -> Result<Vec<DepSpec>, CoreError>` that handles comma-separated lists and optional `kind:id` prefixes.\n- Implement `DepSpec::to_spec_string()` for canonical formatting (`blocks:bd-123` or `bd-123` for default).\n- Update `src/cli/mod.rs` to replace `normalize_dep_specs` with core parsing + `to_spec_string()` for normalized request strings.\n- Update `src/daemon/executor.rs` to replace its local `parse_dep_specs` with core parsing and map errors to `OpError::ValidationFailed`.\n\n**Design Notes**\nKeep the current user-facing behavior (comma-separated specs, optional `kind:` prefix) and preserve existing error messages as much as possible. Use `DepKind::parse` and `BeadId::parse` in one place so the spec grammar is canonical.\n\n**Acceptance**\n- [ ] CLI and daemon both rely on the core parser for dependency specs.\n- [ ] Canonical formatting is unchanged for default `blocks` dependencies.\n- [ ] Error messages remain user-friendly and point to the `deps` field.\n- [ ] Run `codex review --uncommitted` (timeout 10m) and address findings.\n- [ ] Tests pass.\n\n**Files:** `src/core/dep.rs`, `src/cli/mod.rs`, `src/daemon/executor.rs`","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767918613652,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767918613652,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767918613652,0]}
{"id":"bd-omw.2","created_at":[1767916497452,0],"created_by":"darin@darinsmcstudio2.lan","title":"Unify CLI description/body normalization","description":"**Problem**\n`resolve_description` is duplicated in `src/cli/commands/create.rs` and `src/cli/commands/update.rs`. The duplicated logic increases drift risk (different error messages or behavior) and makes it harder to reason about CLI validation.\n\n**Design**\nExtract a shared helper into `src/cli/mod.rs` (or `src/cli/commands/mod.rs`) that resolves `--description` and `--body`:\n- Add `fn resolve_description(description: Option<String>, body: Option<String>) -> Result<Option<String>>` returning the same validation error as today.\n- Replace both call sites in create/update with the shared helper.\n- Keep error messages identical and ensure the helper stays CLI-only (no daemon changes).\n\n**Design Notes**\nThis is a pure refactor: no behavior changes, just a single source of truth for the validation error and normalization.\n\n**Acceptance**\n- [ ] `create` and `update` use the shared helper; duplicate implementations removed.\n- [ ] Error messages and behavior are unchanged from the current CLI.\n- [ ] Run `codex review --uncommitted` (timeout 10m) and address findings.\n- [ ] Tests pass.\n\n**Files:** `src/cli/mod.rs`, `src/cli/commands/create.rs`, `src/cli/commands/update.rs`","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767919576880,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767919576880,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767919576880,0]}
{"id":"bd-omw.3","created_at":[1767916519416,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move label/parent updates into daemon ops","description":"**Problem**\nCLI handlers perform read-modify-write for labels and parent relationships. `src/cli/commands/label.rs` fetches each issue then sends a full `Update` patch, and `src/cli/commands/update.rs` queries deps then removes/adds parent edges. This makes changes non-atomic, adds round trips, and splits core behavior across CLI and daemon.\n\n**Design**\nAdd daemon-side ops for label and parent mutations and switch CLI to use them:\n- Extend IPC `Request` with `AddLabels { repo, id, labels: Vec<String> }` and `RemoveLabels { repo, id, labels: Vec<String> }`, or a single `UpdateLabels { add, remove }` request.\n- Add `SetParent { repo, id, parent: Option<String> }` that replaces existing parent edges in one mutation.\n- Implement handlers in `src/daemon/executor.rs` that apply the changes atomically in a single WAL mutation, validating label formats and parent existence.\n- Update CLI `label` commands to call the new label ops; update `update` to call `SetParent` when `--parent/--no-parent` is provided.\n- Keep response payloads consistent (use `OpResult::Updated` or add a small label/parent result if needed for clarity).\n\n**Design Notes**\nThis keeps CLI thin and centralizes behavior in the daemon. It also avoids subtle races (labels changed between fetch and update) and makes parent updates atomic.\n\n**Acceptance**\n- [ ] CLI label add/remove no longer fetches issues; daemon applies label changes atomically.\n- [ ] Parent updates are handled by a dedicated daemon op; CLI no longer manipulates deps directly.\n- [ ] Label validation errors and missing parent errors remain user-friendly.\n- [ ] Run `codex review --uncommitted` (timeout 10m) and address findings.\n- [ ] Tests pass.\n\n**Files:** `src/daemon/ipc.rs`, `src/daemon/ops.rs`, `src/daemon/executor.rs`, `src/cli/commands/label.rs`, `src/cli/commands/update.rs`, `src/api/mod.rs`","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767919327281,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767919327281,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767919327281,0]}
{"id":"bd-omw.4","created_at":[1767916527694,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move BeadPatch application into BeadPatch helper","description":"**Problem**\n`Daemon::apply_update` applies `BeadPatch` field-by-field inline in `src/daemon/executor.rs`. The patch semantics live in `src/daemon/ops.rs`, but the actual application logic lives elsewhere, so adding or changing fields requires touching multiple places and is easy to miss.\n\n**Design**\nAdd a helper on `BeadPatch` to apply patches directly to `BeadFields`:\n- Implement `BeadPatch::apply_to_fields(&self, fields: &mut BeadFields, stamp: &Stamp) -> Result<(), OpError>` in `src/daemon/ops.rs`.\n- Move the current field-application logic (including label parsing and status -> workflow transition) into this helper.\n- Update `Daemon::apply_update` to call the helper inside the WAL mutation.\n\n**Design Notes**\nKeep behavior identical: required fields cannot be cleared, label parsing stays strict, and status strings map to the same workflows with the same validation errors.\n\n**Acceptance**\n- [ ] `Daemon::apply_update` delegates patch application to `BeadPatch::apply_to_fields`.\n- [ ] Label validation and workflow transitions behave exactly as before.\n- [ ] Run `codex review --uncommitted` (timeout 10m) and address findings.\n- [ ] Tests pass.\n\n**Files:** `src/daemon/ops.rs`, `src/daemon/executor.rs`","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767919459457,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767919459457,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767919459457,0]}
{"id":"bd-omw.5","created_at":[1767916535975,0],"created_by":"darin@darinsmcstudio2.lan","title":"Consolidate CLI Filters building","description":"**Problem**\n`handle_list` and `handle_count` both build `Filters` manually with overlapping fields and similar trimming logic. The duplication makes it easy for behavior to drift (e.g., title/label handling) and adds cognitive overhead when updating filter semantics.\n\n**Design**\nIntroduce a small CLI helper to construct `Filters`:\n- Add a helper (e.g., `filters_from_list_args`, `filters_from_count_args`, or a `FiltersBuilder`) in `src/cli/mod.rs` or a new `src/cli/filters.rs`.\n- Move common normalization (status, priority, bead_type, assignee, labels, search text, parent) into shared code.\n- Keep command-specific fields (e.g., time ranges for count) in their respective handlers.\n\n**Design Notes**\nThis is a refactor only; do not change behavior. Preserve exact parsing and validation error messages.\n\n**Acceptance**\n- [ ] `handle_list` and `handle_count` use shared `Filters` construction for common fields.\n- [ ] CLI filter behavior remains unchanged.\n- [ ] Run `codex review --uncommitted` (timeout 10m) and address findings.\n- [ ] Tests pass.\n\n**Files:** `src/cli/mod.rs`, `src/cli/commands/list.rs`, `src/cli/commands/count.rs`","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767919809675,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767919809675,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767919809675,0]}
{"id":"bd-omw.6","created_at":[1767916544774,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove unused BeadOp / Request::to_op duplication","description":"**Problem**\n`BeadOp` and `Request::to_op`/`to_query` duplicate the IPC field definitions but are not used by the runtime path (`Daemon::handle_request` does its own parsing). This duplication adds surface area without benefit and makes it harder to reason about which path is authoritative.\n\n**Design**\nSimplify the IPC/ops surface by removing unused conversion helpers:\n- Audit call sites to confirm `BeadOp` and `Request::to_op`/`to_query` are unused outside tests.\n- Remove `Request::to_op`/`to_query` and the `BeadOp` type if unused; update tests accordingly.\n- If external API concerns exist, replace with a small internal helper or mark the methods `#[deprecated]` and keep a single authoritative path (`handle_request`).\n\n**Design Notes**\nGoal is to reduce duplication and keep one clear entry point for validation and parsing.\n\n**Acceptance**\n- [ ] Unused `BeadOp`/`Request::to_op`/`to_query` code is removed or deprecated with no functional change.\n- [ ] IPC request handling continues to use a single authoritative parsing path.\n- [ ] Run `codex review --uncommitted` (timeout 10m) and address findings.\n- [ ] Tests pass.\n\n**Files:** `src/daemon/ipc.rs`, `src/daemon/ops.rs`, `src/daemon/core.rs`","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767920141478,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767920141478,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767920141478,0]}
{"id":"bd-oybi","created_at":[1769573146615,0],"created_by":"darin@darinsmcstudio2.lan","title":"Type root slug and checkpoint paths","description":"**Problem**\nCore identifiers and checkpoint paths are stringly-typed across crates:\n- `root_slug: Option<String>` in `crates/beads-core/src/meta.rs`, `crates/beads-rs/src/git/sync.rs`, `crates/beads-rs/src/daemon/mutation_engine.rs`, and migration code\n- Checkpoint shard paths are raw `String` in `crates/beads-rs/src/git/checkpoint/layout.rs` and `crates/beads-rs/src/git/checkpoint/types.rs`\n\nThis forces repeated parsing/normalization and makes it easy to forget validation in new call paths. The same rules are re-implemented in multiple places (scatter + translation).\n\n**Files:**\n- `crates/beads-core/src/meta.rs`\n- `crates/beads-core/src/identity.rs`\n- `crates/beads-rs/src/git/sync.rs`\n- `crates/beads-rs/src/daemon/mutation_engine.rs`\n- `crates/beads-rs/src/git/checkpoint/layout.rs`\n- `crates/beads-rs/src/git/checkpoint/types.rs`\n- `crates/beads-rs/src/cli/mod.rs`","design":"**Design**\nIntroduce validated newtypes for root slug and checkpoint paths, and make them the only constructors used across crates.\n\nConcrete plan:\n1) Add a `RootSlug` (or reuse `BeadSlug`) newtype in `beads-core` for root slug. Provide `parse` and `as_str` helpers, and implement `Serialize`/`Deserialize` to preserve JSON compatibility.\n2) Replace `Option<String>` root_slug fields with `Option<RootSlug>` (or `Option<BeadSlug>`) in core meta and git sync structs. Provide explicit conversion points where raw strings enter (CLI flags, migration import).\n3) For checkpoint paths, add:\n   - `CheckpointShardName` (validates `xx.jsonl` hex format)\n   - `CheckpointRelPath` / `CheckpointShardPath` as a validated wrapper around the current string-based path\n   - Methods to render to string when writing to disk\n4) Update checkpoint snapshot payload (`CheckpointShardPayload`/`CheckpointSnapshot`) to use validated path types.\n5) Update parsing helpers (`parse_shard_path`) to return the new types and move path validation into their constructors.\n\n**Design Notes**\n- Keep JSON compatibility by serializing newtypes as strings.\n- Keep the raw-string constructors private to ensure no new call path bypasses validation.\n- Where multiple crates need the type, place it in `beads-core` (or a small shared module under `beads-rs` if truly checkpoint-specific).","acceptance_criteria":"**Acceptance**\n- [ ] `root_slug` uses a validated newtype (or `BeadSlug`) end-to-end; no `Option<String>` remains in sync/mutation/meta paths.\n- [ ] All raw slug inputs are validated exactly once at the boundary (CLI/migration/import).\n- [ ] Checkpoint path types are validated and used in snapshot payloads instead of raw `String`.\n- [ ] `parse_shard_path` returns a validated path type; path validation logic is centralized.\n- [ ] JSON serialization remains stable (strings on the wire).\n- [ ] Tests cover invalid slug/path rejection and roundtrip serialization.","priority":2,"type":"chore","labels":{"entries":{"scatter":[{"replica":"6f316bb8-ea0e-ab2a-d87f-e90d22752386","counter":10343354840535972593}],"tech-debt":[{"replica":"5a06d3fc-6f6d-07fa-d087-7ebe04d2004c","counter":3757700608173678545}],"types":[{"replica":"d3bd6222-d771-f22f-ec24-29a78e5bbdf9","counter":7431944384248101420}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-oybi-1","content":"Rendering should stay in command files; avoid centralizing output rendering in shared helpers.","author":"darin@darins-Mac-Studio-2.local","at":[1769589301774,0]},{"id":"legacy-notes","content":"Rendering should stay in command files; avoid centralizing output rendering in shared helpers.","author":"darin@darinsmcstudio2.lan","at":[1769590164941,0]}],"_at":[1769590164941,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769590164941,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769590164941,0]}
{"id":"bd-p4tv","created_at":[1770940679832,0],"created_by":"darin@darinsmcstudio2.lan","title":"Rebase and land PR #42 absorb optimization onto current main","description":"**Problem**\nOpen PR #42 (in-place `absorb` optimization) is currently not directly mergeable against current main and its historical CI checks are stale/cancelled.\n\n**Design**\n- Rebase/cherry-pick PR #42 changes onto current main.\n- Resolve conflicts in CRDT merge paths (`state.rs`, `orset.rs`, `bead.rs`, `git_worker.rs`).\n- Re-run full validation and benchmark hotpaths before merge.\n\n**Acceptance**\n- [ ] PR #42 logic is applied on top of current main without semantic regressions\n- [ ] `cargo clippy --all-features -- -D warnings` and `cargo test --all-features` pass\n- [ ] Benchmark compare artifact saved showing impact on key hotpaths\n\n**Refs**\n- https://github.com/delightful-ai/beads-rs/pull/42","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1770940679832,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-p72a","created_at":[1769483948024,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode event/patch invariants in types (validated EventBody/TxnDelta)","description":"**Problem**\nCore mutation accepts raw wire/event types that can represent invalid states. `apply_event` takes `EventBody` (raw) and `TxnOpV1`/`WireBeadPatch` without a validated type boundary. We rely on runtime validators (`validate_event_body_semantics`, `workflow_patch_from_wire`, `claim_patch_from_wire`, partial checks in `apply_event`) and on call sites remembering to run them. That is a compiler blind spot: a new ingestion path, refactor, or test helper can bypass validation and still mutate CanonicalState.\n\nExamples of illegal states that compile today:\n- `WireBeadPatch`: `status=Closed` with `closed_reason=Keep` or `closed_on_branch=Keep`.\n- Claim patch where `assignee`/`assignee_expires` are mismatched or partially set.\n- `created_at` set without `created_by` (or vice versa).\n- Self-dependencies in `DepAdd`/`DepRemove`.\n- Tombstone lineage fields partially set or invalid.\n\nThis violates “types should tell the truth” and “parse, don’t validate”. Invalid states are representable *after* parsing and can flow into core logic.\n\nKey refs:\n- `crates/beads-core/src/apply.rs:51` — `apply_event` accepts raw `EventBody`.\n- `crates/beads-core/src/event.rs:2353` — runtime semantic validation.\n- `crates/beads-core/src/event.rs:2418` — `ValidatedBeadPatch` exists but isn’t the boundary.\n\n**Impact**\nDeterministic corruption of canonical state from unvalidated events. This is a P0 correctness risk because it weakens the CRDT safety boundary and makes refactors dangerous.","design":"**Design (opinionated)**\nMake validation a *type boundary*, not a convention.\n\n1) Split raw vs validated types:\n- Rename current `EventBody` to `EventBodyRaw` (private to module) or wrap it in `EventBody<Unvalidated>`.\n- Define `EventBody<Validated>` (or `ValidatedEventBody`) that is the only type accepted by core apply.\n- Mirror this for `TxnDelta` and `TxnOpV1` if needed, or wrap `TxnDeltaV1` inside a validated event type.\n\n2) Make validation constructors explicit:\n- `impl TryFrom<EventBodyRaw> for EventBody<Validated>` runs *all* semantic + limits validation.\n- `ValidatedBeadPatch` should be the only patch type that reaches `apply_bead_upsert`.\n- Add `ValidatedDepAdd`, `ValidatedDepRemove`, `ValidatedTombstone` wrappers if needed to encode per-op invariants.\n\n3) Narrow core API surface:\n- Change `apply_event(state, body)` to accept only `EventBody<Validated>`.\n- Make `apply_bead_upsert` accept `ValidatedBeadPatch` (not `WireBeadPatch`).\n- Provide a single validation boundary in ingestion, e.g. `verify_event_frame` returns `VerifiedEvent<Validated>`.\n\n4) Parse-don’t-validate rule:\n- Public decode APIs should return validated types or error (no raw types escaping).\n- Raw/unchecked constructors are `pub(crate)` or private.\n\n5) Migration plan:\n- Add new types and conversions, then update all call sites.\n- Temporarily keep deprecated wrappers that call validation; remove them once all callers are migrated.\n\nThis makes “forgetting to validate” a compile error.","acceptance_criteria":"**Acceptance**\n- [ ] `apply_event` only accepts a validated event type; raw `EventBody` cannot compile at call sites.\n- [ ] `apply_bead_upsert`/dep operations require validated patch/op wrappers, not raw wire structs.\n- [ ] There is exactly one public validation boundary from wire bytes to validated events; raw decode types do not escape the module.\n- [ ] All existing callers are migrated; no `validate_event_body_*` calls remain outside the boundary.\n- [ ] Tests: at least one compile‑fail or trybuild test demonstrating that invalid patches cannot reach core apply; runtime tests still reject invalid events at the boundary.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769505294393,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769505294393,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769505294393,0]}
{"id":"bd-pdje","created_at":[1768710056437,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright repl: add --timeout-secs for repeatable baselines","description":"**Problem**\nModel runs use a fixed 60s timeout; baselines are harder to compare and re-run at known limits.\n\n**Design**\n- Add a --timeout-secs <u64> flag to repl_core_machine.\n- Print timeout in the config line.\n- Thread the value into checker().timeout(Duration::from_secs(...)).\n\n**Acceptance**\n- [ ] Timeout defaults to current 60s.\n- [ ] Passing --timeout-secs overrides both check + explore.\n- [ ] Example run documented in output or README comment.\n\n**Files**\n- beads_stateright_models/examples/repl_core_machine.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768721474879,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768721474879,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768721474879,0]}
{"id":"bd-pkcb","created_at":[1768503831170,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remove dead RepoState.wal_sequence","description":"**Problem**\nRepoState.wal_sequence is never read or written outside struct initialization (src/daemon/repo.rs). It is a legacy snapshot-WAL counter and no longer reflects the realtime event WAL sequencing (per-namespace origin_seq). Keeping it is misleading and dead.\n\n**Files:** src/daemon/repo.rs","design":"**Design**\n- Remove wal_sequence from RepoState and its initializers.\n- Scan for any remaining uses; if any are discovered, either delete or replace with the correct event-WAL sequencing concept.","acceptance_criteria":"- [ ] RepoState has no wal_sequence field.\n- [ ] No references remain in code or tests.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768535261373,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768535261373,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768535261373,0]}
{"id":"bd-ppd1","created_at":[1770936635642,0],"created_by":"darin@darinsmcstudio2.lan","title":"Checkpoint label decode incompatibility spams warnings and risks state gaps","description":"**Problem**\nDaemon checkpoint import repeatedly logs decode failures for label state (`invalid length 0, expected struct WireLabelStateV1 with 2 elements`). This indicates wire-compat mismatch or invalid fallback handling in checkpoint decode.\n\nRisk: noisy logs, extra recovery work, and possible state omission if decode fallback is incomplete.","design":"Make checkpoint decoding robust and explicitly versioned:\n1. Audit wire schema/version negotiation for label state.\n2. Add backwards-compatible decode path(s) for historical payload shapes.\n3. Fail soft with typed diagnostics and targeted fallback instead of repeated generic warnings.\n4. Add roundtrip and fixture tests across old/new checkpoint payloads.","acceptance_criteria":"- [ ] Existing checkpoints import without repeated `WireLabelStateV1` decode warnings.\n- [ ] Label state parity is preserved after import (no silent drop/regression).\n- [ ] Version compatibility tests cover old and new encodings.\n- [ ] Logs include actionable error context when an unknown future wire version is encountered.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1770936635642,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ps02","created_at":[1768719782830,0],"created_by":"darin@darinsmcstudio2.lan","title":"CLI IPC: reuse daemon connection per command","description":"Multiple commands call send() repeatedly (show/update/label/delete/create --file), each opening a Unix socket and version ping. Add a small client wrapper to reuse one connection per command and verify version once.","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768758390512,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768758390512,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768758390512,0]}
{"id":"bd-pt2x","created_at":[1768778987654,0],"created_by":"darin@darinsmcstudio2.lan","title":"Speed up test repo setup: avoid per-repo git config","description":"Many fixtures run  per temp repo. Use env (GIT_AUTHOR_NAME/EMAIL + GIT_COMMITTER_NAME/EMAIL or GIT_CONFIG_GLOBAL to a temp file) in test helpers so repo setup skips two git config invocations per repo. Apply in fixtures: realtime.rs, repl_rig.rs, daemon/*, cli/*","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768805118193,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768805118193,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768805118193,0]}
{"id":"bd-q4z","created_at":[1768444217587,0],"created_by":"darin@darinsmcstudio2.lan","title":"Deprecate legacy snapshot WAL and remove from runtime path","description":"**Problem**\nLegacy snapshot WAL (`wal_legacy_snapshot`) and `apply_wal_mutation` are still wired into the daemon runtime even though realtime WAL + replication are in place. The legacy WAL is initialized on daemon start and the code path remains in `Daemon` despite not being used by the new mutation pipeline. This keeps two durability systems alive, increases cognitive load, and makes future changes riskier.\n\n**Signals / Evidence**\n- Daemon still constructs legacy `Wal` in `run_daemon` (`src/daemon/run.rs`).\n- `Daemon` stores `wal: Arc<Wal>` and exposes `apply_wal_mutation` even though new mutations use event WAL (`src/daemon/core.rs`).\n- `apply_wal_mutation` is only referenced in tests (`src/daemon/core.rs`).\n\n**Why this hurts velocity**\nTwo durability paths mean double mental model and duplicated invariants. It’s easy to accidentally keep legacy behavior alive or regress realtime expectations.","design":"**Design**\n- Gate legacy WAL behind a feature flag or explicit migration mode.\n- Remove `apply_wal_mutation` from the main execution path (keep only for legacy migration tests if needed).\n- If realtime is stable, remove the legacy WAL from daemon startup entirely and leave migration in a separate tool/module.\n- Document the deprecation timeline and add a kill switch if we need emergency fallback.","acceptance_criteria":"- [ ] Legacy snapshot WAL is not initialized in the normal runtime path.\n- [ ] `apply_wal_mutation` is removed or clearly isolated to legacy/migration mode.\n- [ ] No production code depends on legacy WAL once realtime is verified.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768485481523,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768485481523,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768485481523,0]}
{"id":"bd-qcz","created_at":[1766116454563,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL read/merge failures must not be ignored","description":"**Problem**\n`ensure_repo_loaded` ignores WAL read errors and WAL merge errors (`if let Ok(Some(wal_entry))` + warn on `join` failure). Corrupted WAL or merge conflicts can silently drop unsynced data.\n\n**Design**\nTreat WAL read/merge failures as fatal for load: return an OpError that surfaces the WAL issue, keep the WAL file intact, and avoid overwriting state with stale git data. Add a test that injects a corrupted WAL and asserts load returns an error.\n\n**Acceptance**\n- [ ] WAL read errors are returned to the caller (no silent ignore)\n- [ ] WAL merge conflicts return a structured error\n- [ ] WAL file is preserved on error\n- [ ] Tests cover corrupted WAL and merge failure paths\n- [ ] Tests pass\n\n**Files:** src/daemon/core.rs, src/daemon/wal.rs, src/daemon/ops.rs","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766124452035,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766124452035,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766124452035,0]}
{"id":"bd-qn3o","created_at":[1769483948227,0],"created_by":"darin@darinsmcstudio2.lan","title":"Make dependency ops carry non-self DepKey in wire types","description":"**Problem**\nDependency self-edges are only prevented by runtime validation (`validate_event_body_semantics` checks `from == to`). Yet the domain already has `DepKey::new` which makes self-deps impossible. Wire ops (`WireDepAddV1`/`WireDepRemoveV1`) still carry raw `from/to/kind`, so invalid states are representable until runtime. This makes it easy for new codepaths to forget validation and introduce self-deps, and it violates the “information holds its shape” / “types tell the truth” principles.\n\nKey references:\n- `crates/beads-core/src/dep.rs:52` — `DepKey::new` enforces non-self.\n- `crates/beads-core/src/event.rs:2371` — runtime self-dep check.\n- `crates/beads-core/src/wire_bead.rs:683` — wire dep ops store raw `from/to/kind`.\n\nSeverity: Self-deps are logically invalid and can cause cycle detection/path logic to misbehave. Relying on runtime checks here is fragile and non-local.","design":"**Design**\nRepresent dependency operations in terms of `DepKey` (or a `NonSelfDepKey` newtype) so self-deps are unrepresentable.\n\n1) Introduce `NonSelfDepKey(DepKey)` (or reuse `DepKey` directly) with serde that preserves the existing wire shape `{from,to,kind}`.\n2) Update `WireDepAddV1`/`WireDepRemoveV1` to store `key: NonSelfDepKey` and expose accessors for `from/to/kind`.\n3) Provide serde impls that encode/decode to the same JSON layout to maintain compatibility.\n4) Update `TxnOpV1::key()` and any dep handling to use the new key field.\n5) Remove the self-dep check in `validate_event_body_semantics` once it’s structurally impossible, leaving only the tombstone lineage validation.\n\nMigration notes:\n- If serde compatibility is risky, add `#[serde(flatten)]` with a custom proxy to preserve wire form.\n- Add a small conversion layer for old tests/fixtures if needed.","acceptance_criteria":"- [ ] It is impossible to construct a dep add/remove op with `from == to` without a fallible conversion.\n- [ ] Wire serialization remains backward-compatible (same JSON fields).\n- [ ] `validate_event_body_semantics` no longer needs a self-dep check.\n- [ ] Existing dep-related tests pass; add at least one compile-time or conversion test for self-dep rejection.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769502647044,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769502647044,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769502647044,0]}
{"id":"bd-qon","created_at":[1768492584564,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add daemon DepCycles query","description":"**Problem**\nCLI needs a structured dep cycles query; current Validate only returns free-form warnings.\n\n**Design**\nAdd an IPC Request variant and QueryResult variant that returns dependency cycles as lists of BeadId strings. Use the CanonicalState helper for detection.\n\n**Acceptance**\n- [ ] New Request/Response types in src/daemon/ipc.rs\n- [ ] QueryExecutor handles DepCycles and returns structured cycles\n- [ ] Tests for query serialization + a simple cycle","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768493117299,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768493117299,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768493117299,0]}
{"id":"bd-qrjo","created_at":[1769495940597,0],"created_by":"darin@darinsmcstudio2.lan","title":"Enforce protocol range invariants in type","description":"**Problem**\n`ProtocolRange::new(min, max)` does not enforce `min <= max`. This allows constructing invalid ranges that only fail later at negotiation. It’s a typestate gap: the type claims to be a range but permits impossible states.\n\nKey references:\n- `crates/beads-rs/src/daemon/repl/session.rs:44` — `ProtocolRange` + `new`.\n- `crates/beads-rs/src/daemon/repl/session.rs:71` — `SessionConfig::new` constructs ranges.\n\n**Design**\nEncode the invariant in the type.\n\n- Make `ProtocolRange::new` return `Result<Self, ProtocolRangeError>` and validate `min <= max`.\n- Add helpers: `ProtocolRange::exact(v)` and `ProtocolRange::range(min, max)`.\n- Consider `NonZeroU32` for versions if 0 is invalid.\n- Update session config construction and any tests to use the validated constructor.\n\n**Acceptance**\n- [ ] It is impossible to construct a `ProtocolRange` with `min > max`.\n- [ ] All call sites use `ProtocolRange::exact` or validated `new`.\n- [ ] Tests cover invalid ranges (min>max) and valid exact-range negotiation.\n\n**Files**\n- `crates/beads-rs/src/daemon/repl/session.rs`","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769583834758,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769583834758,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769583834758,0]}
{"id":"bd-qrlt","created_at":[1768508733928,0],"created_by":"darin@darinsmcstudio2.lan","title":"Reorganize integration tests by feature","description":"**Problem**\n- Integration tests are phase-based (`tests/phase*`) which makes it hard to find feature coverage.\n- New contributors must know implementation phases to find tests.\n\n**Files:**\n- tests/phase*.rs\n- tests/fixtures/*","design":"- Rename/move phase tests into feature-based files (`tests/wal_*`, `tests/repl_*`, `tests/checkpoint_*`, `tests/admin_*`, etc).\n- Keep test contents unchanged; only file names/organization change.\n- Update any references in docs if needed.","acceptance_criteria":"- [ ] Integration tests are grouped by feature.\n- [ ] `cargo test` passes with the same coverage.\n- [ ] No change to fixture behavior.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768542583816,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768542583816,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768542583816,0]}
{"id":"bd-qsk","created_at":[1768010129816,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright model: pending ingest contiguity counterexample","description":"**Problem**\nRunning `cargo run --example session_coordinator_boundary -- check` reports a counterexample for the property \"pending ingest starts at next expected\". The trace shows pending ingest can start ahead of the next expected seq:\n- DeliverEvent(3)\n- DeliverEvent(2)\n- DeliverEvent(1)\n- CoordinatorIngest\n- DeliverEvent(1)\n- DeliverEvent(2)\n- DeliverAck\n\nThis indicates either the model invariant is wrong or the coordinator boundary logic allows a gap to slip through.\n\n**Design**\nInspect `beads_stateright_models/examples/session_coordinator_boundary.rs` and the underlying boundary logic. Confirm the intended rule (pending ingest should start at next expected, not beyond). If the rule is intended, adjust the model and/or coordinator state machine so it enforces contiguity when ingesting pending events. Add a regression test in the beads runtime to mirror the counterexample trace once the implementation exists (or add a model-only regression property if implementation work is not yet wired).\n\n**Acceptance**\n- [ ] Model check passes without the \"pending ingest starts at next expected\" counterexample.\n- [ ] If rule is intended, coordinator boundary enforces contiguity (no ingest beyond next expected).\n- [ ] Regression test added for the counterexample trace (model or implementation).\n\n**Files:** beads_stateright_models/examples/session_coordinator_boundary.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768490241017,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768490241017,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768490241017,0]}
{"id":"bd-qw1v","created_at":[1768510073390,0],"created_by":"darin@darinsmcstudio2.lan","title":"Integration test admin_status_monotonic_under_load can time out at 3s","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"fixed by bd-zl6d timeout scaling","assignee":"darin@book","_at":[1768525607619,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768525607619,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768525607619,0]}
{"id":"bd-qz97","created_at":[1769209711470,0],"created_by":"darin@darinsmcstudio2.lan","title":"CRDT Overhaul audit fixes + verification","description":"**Problem**\\nPost-audit fixes and verification work for CRDT overhaul issues identified in bd-ogvs.*.\\n\\n**Scope**\\nCore OR-Set semantics, event validation, git/WAL integrity, merge determinism, and missing test coverage.\\n\\n**Files**: src/core, src/git, src/daemon, tests/*, CRDT_OVERHAUL.md","design":"**Design**\\nTrack individual fixes and verification tasks as child beads so audit beads remain intact.\\n\\n**Notes**\\nSome fixes include typestate upgrades to make invalid states unrepresentable.","acceptance_criteria":"- [ ] All child beads closed\\n- [ ] CRDT_OVERHAUL.md updated where behavior/spec changes","priority":1,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769510452648,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769510452648,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769510452648,0]}
{"id":"bd-qz97.1","created_at":[1769209799358,0],"created_by":"darin@darinsmcstudio2.lan","title":"OR-Set DVV pruning removes unrelated values (fix ORSWOT semantics)","description":"**Problem**\\nOrSet uses Dvv as max-per-replica and prunes any dot dominated by cc. A remove of one value advances cc and incorrectly removes unrelated values added earlier by the same replica. This breaks labels/deps semantics (remove one label can erase others).\\n\\n**Files**: src/core/orset.rs, src/core/state.rs, src/core/event.rs, src/git/wire.rs, src/daemon/wal_legacy_snapshot.rs","design":"**Design**\\nImplement correct ORSWOT removal semantics by making Dvv a dotted version vector (max + dot exceptions) or equivalent tombstone mechanism so removal can target specific dots without wiping earlier dots from the same replica.\\n\\nImplementation sketch:\\n- Extend Dvv to include an explicit dot set (exception set).\\n- dominates(dot) returns true if dot.counter <= max[replica] OR dot in dots.\\n- merge/join merges max and dot sets and compacts dots covered by max.\\n- apply_remove(value, ctx) removes dots for that value dominated by ctx and merges ctx into cc (without over-approximating unrelated dots).\\n- Update encode/decode for DVV if representation changes (wire + git + WAL).\\n- Add normalization to drop empty entries and resolve collisions deterministically after join.\\n\\nTesting should focus on remove targeting only intended dots and add-wins behavior under concurrency.","acceptance_criteria":"- [ ] Unit test: same replica adds two values, remove one -> other survives.\\n- [ ] Unit test: apply_remove with ctx containing dot for value A does NOT remove value B from same replica.\\n- [ ] Join test: a has value A, b removes B and advances ctx; join preserves A.\\n- [ ] Join test: concurrent add vs remove (ctx not covering new dot) is add-wins.\\n- [ ] Serialization roundtrip preserves DVV semantics (encode/decode for DVV if format changed).","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769217756691,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769217756691,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769217756691,0]}
{"id":"bd-qz97.10","created_at":[1769209801215,0],"created_by":"darin@darinsmcstudio2.lan","title":"WAL snapshot format transition: decide compat vs explicit failure","description":"**Problem**\\nRecent WAL snapshots may not deserialize after WalDepStore format change. The current untagged enum will fail without a clear remediation path.\\n\\n**Files**: src/daemon/wal_legacy_snapshot.rs","design":"**Design**\\nPick and implement one strategy:\\nA) Add a transitional legacy variant that can parse the previous DepStore-shaped WAL JSON and convert to DepStore.\\nB) If backward compatibility is explicitly unsupported, detect the shape and return a clear error instructing users to delete old WAL files.\\n\\nInclude tests for the chosen strategy using a handcrafted JSON sample of the prior format (or a simulated struct) to ensure behavior stays locked.","acceptance_criteria":"- [ ] Test: legacy WAL sample either deserializes correctly (compat path) or fails with explicit wipe guidance (non-compat path).\\n- [ ] Test: current WalEntry still roundtrips.","priority":3,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769225042433,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769225042433,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769225042433,0]}
{"id":"bd-qz97.11","created_at":[1769209801424,0],"created_by":"darin@darinsmcstudio2.lan","title":"Deterministic merge for bead/note collisions in CanonicalState::join","description":"**Problem**\\nCanonicalState::join and NoteStore::join are left-biased for collisions, so merges can be non-commutative when collisions exist. This violates the D4 deterministic convergence goal.\\n\\n**Files**: src/core/state.rs, src/core/bead.rs, src/core/apply.rs, tests/integration/core/apply.rs","design":"**Design**\\nImplement collision resolution in join using the same comparator as apply:\\n- Bead collision winner: (created_stamp, content_hash) per CRDT_OVERHAUL.md. Insert lineage tombstone for loser.\\n- Note collision winner: (note.at, note.author, sha256(content)).\\nUpdate NoteStore::join to choose winner deterministically, not left-biased.\\nEnsure join is commutative and idempotent even with collisions in inputs.","acceptance_criteria":"- [ ] Unit/integration test: two bead creations with same id in different orders yield same winner + lineage tombstone.\\n- [ ] Unit test: NoteStore::join resolves collisions deterministically, order-independent.\\n- [ ] Property test: join is commutative for states with collisions.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769220341326,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769220341326,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769220341326,0]}
{"id":"bd-qz97.12","created_at":[1769209837721,0],"created_by":"darin@darinsmcstudio2.lan","title":"Determinism tests: vary label/dep stamps across insertion order","description":"**Problem**\\nCurrent determinism tests use identical stamps; they may miss order-dependent stamp regressions.\\n\\n**Files**: src/git/wire.rs, src/core/state.rs","design":"**Design**\\nExtend determinism tests to use different stamps for label/dep ops and apply them in opposite orders, asserting identical serialized output and updated_stamp behavior.","acceptance_criteria":"- [ ] Test: label ops with different stamps applied in reversed order serialize identically.\\n- [ ] Test: dep ops with different stamps applied in reversed order serialize identically.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769215570717,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769215570717,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769215570717,0]}
{"id":"bd-qz97.13","created_at":[1769209837920,0],"created_by":"darin@darinsmcstudio2.lan","title":"Apply totality: orphan label/dep/note ops before bead exists","description":"**Problem**\\nApply should be total for label/dep/note ops even when the bead is missing; current coverage does not lock this down.\\n\\n**Files**: src/core/apply.rs, tests/integration/core/apply.rs","design":"**Design**\\nAdd integration tests that apply LabelAdd/Remove, DepAdd/Remove, and NoteAppend to missing beads, then create the bead and verify the ops become visible.","acceptance_criteria":"- [ ] Tests: orphan label/dep/note ops do not error on apply.\\n- [ ] Tests: after later bead creation, labels/notes/deps become visible via queries.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769216272427,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769216272427,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769216272427,0]}
{"id":"bd-qz97.14","created_at":[1769209838121,0],"created_by":"darin@darinsmcstudio2.lan","title":"DepStore invariants: dep_indexes parity + delete/re-add regression","description":"**Problem**\\nInvariant checks do not validate dep_indexes against dep_store, and there is no regression test for delete-then-readd of the same dependency.\\n\\n**Files**: src/core/state.rs, tests/integration/core/apply.rs","design":"**Design**\\n- Add invariant assertion that dep_indexes exactly reflect dep_store values.\\n- Add regression test: dep add -> remove -> re-add results in membership and indexes reflecting the re-added edge.\\n- Include dependency-specific tests as requested.","acceptance_criteria":"- [ ] Invariant test: dep_indexes contains exactly dep_store.values().\\n- [ ] Regression test: delete then re-add a dep restores membership and indexes.\\n- [ ] Dependency tests cover both outgoing and incoming index paths.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769214728374,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769214728374,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769214728374,0]}
{"id":"bd-qz97.15","created_at":[1769209838334,0],"created_by":"darin@darinsmcstudio2.lan","title":"CBOR roundtrip tests for label/dep OR-Set ops","description":"**Problem**\\nNo explicit CBOR roundtrip tests for new label/dep ops; regressions could break WAL/replication.\\n\\n**Files**: src/core/event.rs, tests/integration/fixtures/event_body.rs","design":"**Design**\\nAdd tests that encode EventBody with LabelAdd/LabelRemove and DepAdd/DepRemove, then decode and re-encode to assert byte-for-byte equivalence and semantic equality.\\nInclude multiple LabelAdd ops with same label but different dots to ensure TxnOpKey dot inclusion is preserved.","acceptance_criteria":"- [ ] CBOR encode/decode roundtrip test for LabelAdd/LabelRemove.\\n- [ ] CBOR encode/decode roundtrip test for DepAdd/DepRemove.\\n- [ ] Test: multiple LabelAdd with same (bead_id,label) but different dots are preserved.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769214221069,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769214221069,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769214221069,0]}
{"id":"bd-qz97.16","created_at":[1769209838539,0],"created_by":"darin@darinsmcstudio2.lan","title":"Legacy deps parsing tests (git wire)","description":"**Problem**\\nLegacy dep parsing paths exist but are not explicitly tested.\\n\\n**Files**: src/git/wire.rs","design":"**Design**\\nAdd unit tests that feed legacy dep JSONL lines (per-edge) into parse_deps/parse_legacy_state and assert correct DepStore reconstruction and ordering.","acceptance_criteria":"- [ ] Test: legacy deps JSONL parses into expected DepStore values.\\n- [ ] Test: ordering and determinism preserved after parse -> serialize.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769215079275,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769215079275,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769215079275,0]}
{"id":"bd-qz97.17","created_at":[1769209838751,0],"created_by":"darin@darinsmcstudio2.lan","title":"OR-Set dot collision tests for labels/deps","description":"**Problem**\\nNo integration-level tests assert deterministic resolution when the same dot is used for different label/dep values.\\n\\n**Files**: src/core/orset.rs, src/core/state.rs, tests/integration/core/apply.rs","design":"**Design**\\nAdd tests for label/dep dot collisions using identical dots but different values, assert deterministic winner (lexicographic then hash tie-break) and order-independence.","acceptance_criteria":"- [ ] Test: label dot collision resolved deterministically, order-independent.\\n- [ ] Test: dep dot collision resolved deterministically, order-independent.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769215459038,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769215459038,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769215459038,0]}
{"id":"bd-qz97.18","created_at":[1769209838951,0],"created_by":"darin@darinsmcstudio2.lan","title":"Dependency behavior test suite (add/remove/indexes/order)","description":"**Problem**\\nDependency behavior lacks a focused test suite covering add/remove semantics, index parity, and ordering expectations.\\n\\n**Files**: src/core/state.rs, src/git/wire.rs, tests/integration/core/apply.rs","design":"**Design**\\nAdd a dedicated dependency-focused test module that covers:\\n- add/remove idempotency for deps\\n- dep_indexes parity with dep_store\\n- ordering of DepKind in serialization (if lexical)\\n- delete->readd behavior across different kinds","acceptance_criteria":"- [ ] Tests cover dep add/remove idempotency.\\n- [ ] Tests cover dep_indexes parity with dep_store.\\n- [ ] Tests cover DepKind ordering for serialization.\\n- [ ] Tests cover delete->readd across multiple DepKind variants.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769216674628,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769216674628,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769216674628,0]}
{"id":"bd-qz97.19","created_at":[1769210188036,0],"created_by":"darin@darinsmcstudio2.lan","title":"Cleanup: remove/justify ApplyError collision variants","description":"**Problem**\\nApplyError still contains BeadCollision/NoteCollision variants even though collisions are now meant to be deterministic and total. This contradicts the CRDT overhaul goal and leaves dead/error paths.\\n\\n**Files**: src/core/apply.rs, src/core/state.rs","design":"**Design**\\nAudit remaining call sites for BeadCollision/NoteCollision. If collisions are fully handled deterministically, remove the variants and refactor callers to be infallible (or treat as internal invariants). If still needed, document why and align with CRDT_OVERHAUL.md.","acceptance_criteria":"- [ ] No reachable code path returns ApplyError::{BeadCollision, NoteCollision} OR clear docs justify remaining use.\\n- [ ] Tests updated to match the chosen approach.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769223184476,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769223184476,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769223184476,0]}
{"id":"bd-qz97.2","created_at":[1769209799557,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tombstone lineage pairing: make invalid lineage state unrepresentable","description":"**Problem**\\nencode_wire_tombstone can emit invalid CBOR if exactly one lineage field is set; debug_assert is skipped in release. This risks corrupt WAL/replication frames.\\n\\n**Files**: src/core/event.rs, src/core/wire_bead.rs, src/git/checkpoint/*","design":"**Design**\\nMake tombstone lineage pairing a typestate invariant. Replace the two Option fields with a single Option<LineageStamp> (struct containing at+by). Encode only when lineage is Some. Add runtime validation that rejects partial lineage in decode or construction paths.\\n\\nAlso add a semantic validator hook for tombstones so invalid lineage can never reach encoding.\\n\\nUpdate wire conversion helpers (checkpoint import/export) to use the new lineage representation.","acceptance_criteria":"- [ ] Unit test: encoding a tombstone with lineage=None produces correct map length.\\n- [ ] Unit test: decoding a tombstone with only one lineage field returns a validation error.\\n- [ ] Roundtrip test: tombstone with lineage Some(at,by) encodes and decodes identically.\\n- [ ] Regression test: validate_event_body rejects tombstone with partial lineage before encoding.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769219167693,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769219167693,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769219167693,0]}
{"id":"bd-qz97.20","created_at":[1769210188242,0],"created_by":"darin@darinsmcstudio2.lan","title":"Cleanup: remove orset.rs dependency on event::Sha256","description":"**Problem**\\norset.rs depends on event::Sha256 even though it only uses a placeholder op_hash arg. This is a layer violation risk as event depends on OR-Set elsewhere.\\n\\n**Files**: src/core/orset.rs","design":"**Design**\\nRemove the dependency by either: (a) dropping the unused op_hash parameter, (b) accepting raw [u8;32], or (c) defining a lower-layer hash type. Ensure no cyclic dependency is created.","acceptance_criteria":"- [ ] orset.rs no longer imports event::Sha256.\\n- [ ] Public API remains stable or is migrated cleanly with tests updated.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769223018144,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769223018144,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769223018144,0]}
{"id":"bd-qz97.21","created_at":[1769210188450,0],"created_by":"darin@darinsmcstudio2.lan","title":"Cleanup: update CRDT_OVERHAUL.md wire format details","description":"**Problem**\\nCRDT_OVERHAUL.md describes DVV and dot encoding shapes that differ from the current implementation (map vs vec, field names).\\n\\n**Files**: CRDT_OVERHAUL.md","design":"**Design**\\nUpdate docs to match actual on-wire encoding (CBOR/json) for WireDvvV1/WireDotV1 and any other drift discovered. Keep spec statements aligned with code to avoid future mismatches.","acceptance_criteria":"- [ ] CRDT_OVERHAUL.md updated to reflect current wire encoding.\\n- [ ] Docs explicitly call out map vs vec and field names used in CBOR.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769222183680,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769222183680,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769222183680,0]}
{"id":"bd-qz97.22","created_at":[1769210188658,0],"created_by":"darin@darinsmcstudio2.lan","title":"Cleanup: Labels::remove return value should reflect change","description":"**Problem**\\nLabels::remove returns true unconditionally, which can hide bugs at call sites and mislead tests.\\n\\n**Files**: src/core/collections.rs","design":"**Design**\\nEither return a real changed flag (before_len != after_len) or change the API to return () and update call sites. Pick whichever matches usage patterns best.","acceptance_criteria":"- [ ] Labels::remove no longer returns a misleading unconditional true.\\n- [ ] Call sites updated to the chosen API.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769222402180,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769222402180,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769222402180,0]}
{"id":"bd-qz97.23","created_at":[1769210188869,0],"created_by":"darin@darinsmcstudio2.lan","title":"Cleanup: DRY WalDepStore vs WireDepStoreV1","description":"**Problem**\\nWalDepStore duplicates the structure of WireDepStoreV1, increasing maintenance burden and risk of drift.\\n\\n**Files**: src/daemon/wal_legacy_snapshot.rs, src/core/wire_bead.rs (or shared module)","design":"**Design**\\nConsider sharing a common internal dep-store struct or reusing WireDepStoreV1 if layering allows. Ensure serialization remains stable and test coverage stays intact.","acceptance_criteria":"- [ ] WalDepStore and wire dep store use shared representation or documented reasons for divergence.\\n- [ ] Tests cover WAL dep serialization after refactor.","priority":4,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769225328532,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769225328532,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769225328532,0]}
{"id":"bd-qz97.24","created_at":[1769221346002,0],"created_by":"darin@darinsmcstudio2.lan","title":"Resolve note collision policy mismatch (REALTIME_PLAN vs CRDT_OVERHAUL)","description":"**Problem**\\nREALTIME_PLAN.md says note-id collisions with different content are corruption (not LWW), but CRDT_OVERHAUL.md and current code resolve note collisions deterministically. This spec mismatch can confuse future changes and tests.\\n\\n**Design**\\nPick the authoritative policy and align docs/tests accordingly:\\n- If corruption: update validation/apply to reject note-id collisions and adjust tests.\\n- If deterministic: update REALTIME_PLAN.md wording to match CRDT_OVERHAUL.md and keep tests.\\n\\n**Acceptance**\\n- [ ] Spec text is consistent across REALTIME_PLAN.md and CRDT_OVERHAUL.md.\\n- [ ] Tests match the chosen policy.\\n\\n**Files**\\n- REALTIME_PLAN.md\\n- CRDT_OVERHAUL.md\\n- docs/CRDT_AUDIT.md (if referenced)","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769221788626,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769221788626,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769221788626,0]}
{"id":"bd-qz97.3","created_at":[1769209799770,0],"created_by":"darin@darinsmcstudio2.lan","title":"Label/dep stamp monotonicity + stamp on internal OR-Set change","description":"**Problem**\\nLabelState.stamp (and DepStore.stamp) is assigned directly on membership change; out-of-order apply can regress stamps and updated_stamp. Also, OR-Set internal changes (new dot, cc merge) can occur without membership change but currently do not update stamps.\\n\\n**Files**: src/core/state.rs, src/core/orset.rs, src/core/bead.rs, src/git/wire.rs","design":"**Design**\\n- Use max(existing, incoming) for stamp updates to enforce monotonicity.\\n- Extend OrSetChange to indicate internal state mutation (not only membership diff).\\n- Update apply_label_add/remove and apply_dep_add/remove to update stamps when internal OR-Set state changes, not just membership diff.\\n\\nKeep updated_stamp behavior aligned with CRDT_OVERHAUL.md (labels/notes/fields max).","acceptance_criteria":"- [ ] Unit test: apply two label ops out of order; label stamp remains max.\\n- [ ] Unit test: adding a new dot for an existing label updates label stamp even if membership unchanged.\\n- [ ] Determinism test: apply same label/dep ops in different orders with different stamps => identical serialized state.\\n- [ ] Dep stamp behavior mirrors label stamp behavior in tests.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769213597875,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769213597875,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769213597875,0]}
{"id":"bd-qz97.4","created_at":[1769209799974,0],"created_by":"darin@darinsmcstudio2.lan","title":"Meta.json corruption must fail load + checksum verification","description":"**Problem**\\nread_state_at_oid ignores meta.json if parsing fails, silently skipping checksum verification even though meta.json exists. This violates spec and masks corruption.\\n\\n**Files**: src/git/sync.rs, src/git/wire.rs","design":"**Design**\\n- If meta.json exists and parse_meta fails, return a SyncError (do not load state).\\n- If parse_meta succeeds and checksums are present, always verify.\\n- Preserve existing behavior only when meta.json is absent.\\n\\nAdd focused tests in sync to cover corrupted meta.json and checksum mismatch behavior.","acceptance_criteria":"- [ ] Test: meta.json present but invalid -> read_state_at_oid returns error.\\n- [ ] Test: meta.json present with checksums -> checksum mismatch returns error.\\n- [ ] Test: meta.json absent -> load succeeds (legacy behavior).","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769211599242,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769211599242,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769211599242,0]}
{"id":"bd-qz97.5","created_at":[1769209800177,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fix sample_bead_patch fixture to satisfy D1 workflow rules","description":"**Problem**\\nsample_bead_patch sets status=Open but leaves closed_reason/closed_on_branch as Keep, which violates D1 validation and will fail any path that validates events.\\n\\n**Files**: tests/integration/fixtures/event_body.rs","design":"**Design**\\nUpdate fixture to explicitly Clear closed_reason and closed_on_branch when status is set, or omit status entirely depending on intent. Add a small fixture validation test that validate_event_body accepts the generated sample event.","acceptance_criteria":"- [ ] Fixture uses explicit closure fields when status is set (or status omitted).\\n- [ ] New test: validate_event_body accepts sample_event_body.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769212397955,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769212397955,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769212397955,0]}
{"id":"bd-qz97.6","created_at":[1769209800383,0],"created_by":"darin@darinsmcstudio2.lan","title":"WalDepStore conversion must not create empty-dot entries","description":"**Problem**\\nWalDepStore::into_dep_store inserts entries with empty dot sets, which violates OrSet invariants and can create phantom membership.\\n\\n**Files**: src/daemon/wal_legacy_snapshot.rs, src/core/orset.rs","design":"**Design**\\nSkip entries with empty dot sets during conversion, or normalize through OrSet constructor that prunes empties. Ensure resulting DepStore contains only keys with non-empty dot sets. Add a regression test with empty-dot entries.","acceptance_criteria":"- [ ] Unit test: WalDepStore with empty dots produces DepStore with no values.\\n- [ ] Unit test: WalDepStore with mixed empty/non-empty dots preserves only non-empty entries.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769211764333,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769211764333,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769211764333,0]}
{"id":"bd-qz97.7","created_at":[1769209800591,0],"created_by":"darin@darinsmcstudio2.lan","title":"Claim/workflow patch validation: tighten rules + typestate patch types","description":"**Problem**\\nClaim validation only checks Keep mismatch; it allows explicit but nonsensical combos (e.g., assignee Clear with expires Set). Workflow/claim patches can be constructed in invalid states, then only fail at apply or produce odd semantics.\\n\\n**Files**: src/core/event.rs, src/core/apply.rs, src/core/wire_bead.rs, src/daemon/mutation_engine.rs","design":"**Design**\\nIntroduce explicit patch enums to make invalid states unrepresentable (typestate):\\n- WorkflowPatch::{NoChange, SetStatus{status, closed_reason, closed_on_branch}}\\n- ClaimPatch::{NoChange, Clear, Set{assignee, expires}}\\nConvert WireBeadPatch to carry these in a backward-compatible way or add validated newtypes (ValidatedBeadPatch) used by encoder/mutation_engine.\\n\\nUpdate validate_bead_patch_semantics to reject impossible explicit claim combos if full typestate is too invasive. Ensure apply remains total for all explicit combinations allowed by validator.","acceptance_criteria":"- [ ] Tests: invalid claim combos (Clear+Set, Set+Clear where disallowed) are rejected by validation.\\n- [ ] Tests: valid claim combos are accepted and apply deterministically.\\n- [ ] Tests: workflow status set requires explicit closure fields (already validated).\\n- [ ] Encoder/mutation_engine only accepts validated patch types.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769221304333,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769221304333,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769221304333,0]}
{"id":"bd-qz97.8","created_at":[1769209800798,0],"created_by":"darin@darinsmcstudio2.lan","title":"DepKind canonical ordering for deterministic deps.jsonl","description":"**Problem**\\nDepKind derives Ord by enum order. If spec expects lexical ordering, deps.jsonl sort order may be ambiguous or inconsistent across implementations.\\n\\n**Files**: src/core/domain.rs, src/git/wire.rs, CRDT_OVERHAUL.md","design":"**Design**\\nChoose one canonical ordering and enforce it:\\n- Preferred: implement Ord for DepKind by as_str() lexical order.\\n- Alternatively: document enum order as canonical and add tests to lock it.\\nUpdate docs accordingly.","acceptance_criteria":"- [ ] Unit test: DepKind ordering matches chosen canonical order.\\n- [ ] Git wire test: serialized deps.jsonl order is stable and matches canonical order.\\n- [ ] CRDT_OVERHAUL.md updated if spec language changes.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1769212590237,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769212590237,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769212590237,0]}
{"id":"bd-qz97.9","created_at":[1769209801009,0],"created_by":"darin@darinsmcstudio2.lan","title":"MSRV guard: enforce compiler support for let-chains","description":"**Problem**\\nCode uses if-let chains; lowering MSRV below their stabilization would break builds without clear failure mode.\\n\\n**Files**: Cargo.toml, tests/* (new test module)","design":"**Design**\\nAdd a small compile-time guard using rustversion (dev-dependency):\\n- In a test module, add #[rustversion::before(1.64)] compile_error!(\"MSRV must be >= 1.64 for let-chains\").\\nThis makes any MSRV regression fail immediately. Keep Cargo.toml rust-version in sync.","acceptance_criteria":"- [ ] Test/compile guard exists and fails on compilers < 1.64.\\n- [ ] rust-version in Cargo.toml remains >= 1.64 (currently 1.91).","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Paused per request before starting work","assignee":"darin@book","_at":[1769222444555,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769222444555,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769222444555,0]}
{"id":"bd-r0rk","created_at":[1769516758309,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fix failing test mutation_span_includes_realtime_context missing store_id","description":"","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769552514187,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769552514187,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769552514187,0]}
{"id":"bd-r13r","created_at":[1769494177983,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode known/unknown head state in Watermark types","description":"**Problem**\n`HeadStatus::Unknown` exists in core and can be constructed for any watermark, yet several runtime paths treat it as impossible and `unreachable!()` if it appears. This means the type admits a state the system claims cannot happen. It violates “types tell the truth” and creates latent panics if a future refactor or new codepath produces Unknown.\n\nKey references:\n- `crates/beads-core/src/watermark.rs:118` — `HeadStatus` includes `Unknown`.\n- `crates/beads-rs/src/daemon/repl/session.rs:727` — `unreachable!(\"unknown head should never reach session state\")`.\n- `crates/beads-rs/src/daemon/repl/gap_buffer.rs:287` — same assumption.\n- `crates/beads-rs/src/daemon/executor.rs:840` — “durable watermark head should be known”.\n\nSeverity: latent panic in WAL/repl and mutation pipelines; correctness depends on a convention rather than an enforced invariant.","design":"**Design**\nEncode “known head” vs “unknown head” in types rather than runtime branches.\n\nOption A (split enum):\n- `enum HeadKnown { Genesis, Known([u8;32]) }`\n- `enum HeadMaybe { Genesis, Known([u8;32]), Unknown }`\n- `Watermark<K, H>` where H is `HeadKnown` or `HeadMaybe`.\n- Functions that require known heads (durable/applied in repl/gap buffer) only accept `Watermark<_, HeadKnown>`.\n\nOption B (newtypes):\n- `struct DurableHead(HeadStatus)` with `TryFrom<HeadStatus>` enforcing `Genesis|Known`.\n- `Watermark<K>` uses `HeadKnown` for durable/applied; only snapshot inputs use `HeadMaybe` and must be validated to `HeadKnown` before entering session state.\n\nMigration:\n- Update watermark parsing and session snapshot ingestion to return `Result<Watermark<_, HeadKnown>, WatermarkError>` instead of allowing Unknown.\n- Remove `unreachable!` branches; they should become impossible to compile.\n- CLI/admin rendering can still show Unknown by using a distinct “maybe head” type if needed.\n\nThis follows “types should make time/causality explicit” and “the controversial type is probably the right type.”","acceptance_criteria":"- [ ] No `unreachable!` or panics for Unknown heads in repl/gap buffer/executor paths.\n- [ ] Types distinguish known vs unknown head states; durable/applied paths only accept known.\n- [ ] Snapshot ingestion/decoding validates head presence explicitly.\n- [ ] All existing tests updated; add one compile-time or conversion test to ensure Unknown cannot reach session state.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769513422110,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769513422110,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769513422110,0]}
{"id":"bd-r1a","created_at":[1768080574909,0],"created_by":"darin@darinsmcstudio2.lan","title":"Clarify prev_sha validation vs gap buffering in v0.5 replication","description":"**Problem**\nREALTIME_PLAN.md v0.5 says receivers must verify `prev_sha256` matches the current head before buffering/appending, but also mandates buffering out-of-order events and issuing WANT. For seq > durable+1, `prev_sha256` references seq-1 which is unknown until the gap fills, so the rule is ambiguous.\n\n**Design**\nClarify the intended rule:\n- Option A: allow buffering even if prev_sha is not yet verifiable; validate when the prefix arrives.\n- Option B: require prev_sha to match the durable head (no buffering of future events).\nUpdate plan text to remove ambiguity and align the replication/model implementations.\n\n**Acceptance**\n- [ ] Spec text explicitly states when prev_sha must be validated for buffered events.\n- [ ] Model/implementation updated to match clarified rule.\n\n**Files:**\n- REALTIME_PLAN.md\n- beads_stateright_models/examples/canonical_hash_machine.rs\n- beads_stateright_models/examples/repl_core_machine.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1768168713860,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768168713860,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768168713860,0]}
{"id":"bd-r330","created_at":[1768774750085,0],"created_by":"darin@darinsmcstudio2.lan","title":"Observability: make metrics emission configurable","description":"**Problem**\nMetrics are emitted as `tracing::info!` events and are filtered out unless global log level enables INFO. There is no configuration to enable/disable or tune metric emission.\n\n**Design**\n- Introduce `metrics` config (e.g., `metrics.enabled`, `metrics.level`, optional `metrics.target`).\n- Add env overrides (e.g., `BD_METRICS`, `BD_METRICS_LEVEL`).\n- Update `daemon::metrics` to respect config (no‑op when disabled, emit at configured level/target).\n\n**Acceptance**\n- [ ] Metrics emission can be toggled and leveled via config/env.\n- [ ] Default behavior matches current output for daemon with INFO logging.\n- [ ] Tests cover config/env overrides and disabled mode.\n\n**Files:** src/config/schema.rs, src/config/merge.rs, src/telemetry.rs (if needed), src/daemon/metrics.rs","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768778040828,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768778040828,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768778040828,0]}
{"id":"bd-rcu","created_at":[1768493917602,0],"created_by":"darin@darinsmcstudio2.lan","title":"Show applied/durable watermarks in admin status CLI output","description":"**Problem**\nAdmin status human output omits applied/durable watermarks, which are core realtime visibility signals when diagnosing lag. The data exists in API but is hidden in CLI.\n\n**Design**\nExtend render_admin_status in src/cli/render.rs to print applied/durable watermarks per namespace/origin in a deterministic order. Keep formatting concise (namespace -> origin -> seq, head state optional). Add a focused unit test for the new formatting.\n\n**Files**\n- src/cli/render.rs","acceptance_criteria":"- [ ] Human output includes applied + durable watermarks grouped by namespace\n- [ ] Output order is deterministic (namespace, then origin)\n- [ ] Unit test covers the new formatting","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768494422744,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768494422744,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768494422744,0]}
{"id":"bd-rfit","created_at":[1768506341917,0],"created_by":"darin@darinsmcstudio2.lan","title":"Validate StoreMeta versions + centralize format constants","description":"**Problem**\n`StoreRuntime::open` accepts existing `StoreMeta` without validating `store_format_version`, `wal_format_version`, `checkpoint_format_version`, `replication_protocol_version`, or `index_schema_version`. This means a daemon can silently run against an unsupported store layout. Also, format/version constants are duplicated across modules (`store_runtime.rs`, `wal/segment.rs`, `wal/index.rs`, `repl/proto.rs`), which is brittle and can drift.\n\n**Files**\n- src/daemon/store_runtime.rs\n- src/core/store_meta.rs\n- src/daemon/wal/segment.rs\n- src/daemon/wal/index.rs\n- src/daemon/repl/proto.rs\n","design":"**Design**\n- Add a single source of truth for format/protocol versions (e.g., `core::versions` or `StoreMetaVersions::current()` with associated consts).\n- In `StoreRuntime::open`, validate existing `StoreMeta` against the current versions and return a dedicated error (e.g., `StoreRuntimeError::UnsupportedVersion { expected, got }`) on mismatch.\n- Update WAL/index/proto modules to import the shared constants instead of redefining their own.\n- Add tests to cover mismatch handling and ensure constants are used consistently.","acceptance_criteria":"- [ ] `StoreRuntime::open` rejects incompatible `StoreMeta` versions with a structured error.\n- [ ] Only one canonical set of format/protocol constants exists.\n- [ ] Tests cover version mismatch and regression on constant drift.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768528250108,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768528250108,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768528250108,0]}
{"id":"bd-ri7b","created_at":[1769501232627,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode WAL index watermark invariants","description":"**Problem**\nWAL index `WatermarkRow` stores seqs and head hashes as independent fields (`applied_seq`, `applied_head_sha`, `durable_seq`, `durable_head_sha`). This makes illegal combinations representable (seq>0 with head=None; seq=0 with head=Some). The invariant is only enforced later (or not at all).\n\nKey refs:\n- `crates/beads-rs/src/daemon/wal/index.rs:210` (WatermarkRow)\n- `crates/beads-rs/src/daemon/wal/index.rs:821` (loading rows without invariant checks)\n\n**Impact**\nIndex can hold inconsistent watermarks, which can break replication and durability checks. Compiler cannot enforce the invariant.","design":"**Design (opinionated)**\nRepresent watermarks as typed `Watermark<K>` (or a `WireWatermark { seq, head }`) in the index row.\n\n- Replace the four raw fields with:\n```rust\nstruct WatermarkRow {\n  namespace: NamespaceId,\n  origin: ReplicaId,\n  applied: Watermark<Applied>,\n  durable: Watermark<Durable>,\n}\n```\n- DB decode builds `Watermark<Applied>`/`Watermark<Durable>` via `Watermark::new`, so invalid seq/head combos fail immediately.\n- DB encode decomposes the typed watermark into columns.\n\nThis enforces seq/head correctness at the type boundary.","acceptance_criteria":"**Acceptance**\n- [ ] `WatermarkRow` cannot be constructed with invalid seq/head combinations.\n- [ ] DB load rejects invalid rows before they reach runtime logic.\n- [ ] All index users operate on typed watermarks (no raw seq/head pairs).\n- [ ] Tests cover row round‑trip and invalid row rejection.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769546140963,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769546140963,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769546140963,0]}
{"id":"bd-riqc","created_at":[1768776087190,0],"created_by":"darin@darinsmcstudio2.lan","title":"Observability: local metrics store (SQLite)","description":"**Problem**\nWe need local‑first performance visibility without relying on a centralized service. Current metrics are only in-memory snapshots + tracing events.\n\n**Design**\n- Add a local observability store (SQLite) for metrics time‑series (and optionally log metadata) under `<data_dir>/obs/obs.db`.\n- Record metrics events with timestamp + labels; expose an admin query to fetch ranges.\n- Keep storage bounded (retention by time or max rows).\n- Optional: store log index/metadata (not full messages) for quick filtering.\n\n**Acceptance**\n- [ ] Metrics time‑series are persisted locally and queryable via admin API/CLI.\n- [ ] Storage is bounded via retention config.\n- [ ] Works offline; no external service required.\n\n**Files:** src/daemon/metrics.rs, src/daemon/admin.rs, src/api/admin.rs, src/cli/commands/admin.rs, src/paths.rs","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Too much complexity for now; prefer structured logs","_at":[1768776917515,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768776917515,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-rjn","created_at":[1768503796003,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace GapBuffer string codes with structured errors","description":"**Problem**\nGapBuffer rejects use stringly-typed codes (gap_timeout, gap_buffer_overflow, etc) via IngestDecision::Reject { code: String } in src/daemon/repl/gap_buffer.rs. This bypasses ErrorCode/REALTIME_ERRORS, loses structured details, and makes it easy for codes to drift silently.\n\n**Files:** src/daemon/repl/gap_buffer.rs, src/daemon/repl/session.rs, src/core/error.rs","design":"**Design**\n- Introduce a GapReject/GAP error enum that carries ErrorCode plus typed details (e.g., OverloadedDetails or GapDetectedDetails).\n- Change IngestDecision::Reject to carry this typed error instead of a String.\n- Map the typed error to ErrorPayload in Session (or at the boundary) using canonical ErrorCode values.\n- Add tests asserting the payload codes/details for each rejection reason.","acceptance_criteria":"- [ ] No string literals are used to represent gap rejection codes.\n- [ ] All gap rejections map to canonical ErrorCode values with details.\n- [ ] Tests cover the mapping for timeout/overflow cases.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"duplicate of bd-al7","_at":[1768505186094,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768505186094,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-roy","created_at":[1765744417943,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add LoadedRemote proof type to eliminate repo_state unwraps","description":"**Problem**\nAfter `ensure_repo_loaded()`, we \"know\" the repo exists, but the type does not prove it:\n```rust\nlet remote = self.ensure_repo_loaded(repo, git_tx)?;\n// ... later ...\nlet repo_state = self.repo_state_mut(&remote).unwrap(); // \"I know it is there\"\n```\n\n**Design**\nCreate a proof type that can only be constructed by loading:\n```rust\n/// Proof that a repo is loaded. Only created by Daemon::ensure_repo_loaded.\npub struct LoadedRemote(RemoteUrl);\n\nimpl LoadedRemote {\n    pub fn remote(&self) -> &RemoteUrl { &self.0 }\n}\n\nimpl Daemon {\n    pub fn ensure_repo_loaded(&mut self, repo: &Path, git_tx: &Sender<GitOp>) \n        -> Result<LoadedRemote, OpError> \n    {\n        let remote = self.resolve_remote(repo)?;\n        // ... loading logic ...\n        Ok(LoadedRemote(remote))\n    }\n\n    /// Infallible because LoadedRemote proves existence\n    pub fn repo_state(&self, proof: &LoadedRemote) -> &RepoState {\n        self.repos.get(proof.remote())\n            .expect(\"LoadedRemote guarantees repo exists\")\n    }\n\n    pub fn repo_state_mut(&mut self, proof: &LoadedRemote) -> &mut RepoState {\n        self.repos.get_mut(proof.remote())\n            .expect(\"LoadedRemote guarantees repo exists\")\n    }\n}\n```\n\nThe `expect` is now documentation of a proven invariant, not a latent bug.\n\n**Acceptance**\n- [ ] `LoadedRemote` type exists in `src/daemon/mod.rs` or `src/daemon/state.rs`\n- [ ] `ensure_repo_loaded` returns `LoadedRemote`\n- [ ] `repo_state`/`repo_state_mut` take `&LoadedRemote` parameter\n- [ ] All `.unwrap()` calls on repo_state lookups in executor/query code are removed\n- [ ] Tests pass\n\n**Files:** src/daemon/mod.rs, src/daemon/executor.rs, src/daemon/query_executor.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Added LoadedRemote proof type. ensure_repo_loaded/fresh return LoadedRemote, repo_state/repo_state_mut take &LoadedRemote and are infallible. All .unwrap() calls on repo_state lookups removed.","assignee":"darin@dusk","_at":[1765786356990,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765786356990,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765786356990,0]}
{"id":"bd-rptz","created_at":[1769288486747,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add admin reload-limits to apply config limits at runtime","description":"","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769562239090,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769562239090,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769562239090,0]}
{"id":"bd-rqsg","created_at":[1770939380708,0],"created_by":"darin@darinsmcstudio2.lan","title":"Handle stale refs/beads/backup/*.lock in sync backup ref maintenance","description":"Problem: stale backup ref lockfiles can wedge sync/prune loops and cause repeated background refresh failures.\\n\\nDesign:\\n- In backup ref create/prune paths, detect locked ref errors, remove stale lockfile, retry once.\\n- Keep behavior idempotent and safe for concurrent daemon work.\\n\\nAcceptance:\\n- [ ] Repro with pre-created stale lockfile no longer wedges sync\\n- [ ] Regression test covers stale lockfile cleanup+retry\\n- [ ] No correctness regression in backup ref retention/prune behavior","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1770940447396,0],"_by":"darin@darinsmcstudio2.lan","_v":{"acceptance_criteria":[[1770939380708,0],"darin@darinsmcstudio2.lan"],"claim":[[1770939380708,0],"darin@darinsmcstudio2.lan"],"description":[[1770939380708,0],"darin@darinsmcstudio2.lan"],"design":[[1770939380708,0],"darin@darinsmcstudio2.lan"],"estimated_minutes":[[1770939380708,0],"darin@darinsmcstudio2.lan"],"external_ref":[[1770939380708,0],"darin@darinsmcstudio2.lan"],"priority":[[1770939380708,0],"darin@darinsmcstudio2.lan"],"source_repo":[[1770939380708,0],"darin@darinsmcstudio2.lan"],"title":[[1770939380708,0],"darin@darinsmcstudio2.lan"],"type":[[1770939380708,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770940447396,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-rraj","created_at":[1768719790402,0],"created_by":"darin@darinsmcstudio2.lan","title":"CLI JSON output: stream to stdout to cut allocations","description":"JSON paths build large strings via to_string_pretty (print_ok in src/cli/mod.rs and command-specific JSON outputs). Use serde_json::to_writer_pretty on a stdout lock and append newline.","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768758758478,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768758758478,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768758758478,0]}
{"id":"bd-rzh4","created_at":[1769563141180,0],"created_by":"darin@darinsmcstudio2.lan","title":"Repl FrameReader must enforce negotiated max_frame_bytes","description":"**Problem**\nWe construct `FrameReader` with `limits.max_frame_bytes` and never update it after handshake. This means we accept inbound frames larger than the negotiated `peer.max_frame_bytes` (as long as they are below the local max). That violates the handshake contract and makes the negotiated frame limit a lie.\n\nThis is an implicit invariant: code assumes the negotiated limit is enforced, but the type does not encode it and the reader keeps the pre-handshake limit forever.\n\n**Impact**\n- Protocol correctness: peers can send frames larger than agreed without being rejected.\n- Resource safety: negotiated limit is ignored, enabling larger-than-expected frames.\n- Hard-to-see bug because the limit looks enforced elsewhere (`SessionWire::frame_limit`), but only for *sending*.\n\n**Files**\n- `crates/beads-rs/src/daemon/repl/frame.rs` (FrameReader)\n- `crates/beads-rs/src/daemon/repl/manager.rs` (run_reader_loop outbound)\n- `crates/beads-rs/src/daemon/repl/server.rs` (run_reader_loop inbound)\n","design":"**Design (opinionated)**\nMake the negotiated frame limit a type boundary, not a runtime convention.\n\n1) Introduce typestated reader limits:\n```rust\nstruct Unnegotiated;\nstruct Negotiated { max_frame_bytes: usize }\nstruct FrameReader<R, L> { reader: R, limit: L }\n```\n- `FrameReader<R, Unnegotiated>` is only valid before handshake.\n- After handshake, transition to `FrameReader<R, Negotiated>` using the negotiated max.\n\n2) Split reader loop helpers:\n- `run_reader_loop_unnegotiated(reader, ...)` for the initial HELLO.\n- `run_reader_loop_negotiated(reader, negotiated_max, ...)` for steady-state.\n\n3) Alternatively, if typestate feels heavy, add a `FrameLimit` newtype and make `run_reader_loop` require it; only the handshake produces a `FrameLimit` for use.\n\n4) Enforce `min(local_max, peer_max)` as the negotiated limit; reject larger frames with `FrameTooLarge`.\n\nThis removes scatter: the negotiated limit is enforced where frames are read, not assumed.","acceptance_criteria":"- [ ] After handshake, inbound/outbound reader loops enforce the negotiated `max_frame_bytes`.\n- [ ] A peer sending frames larger than negotiated is rejected with `FrameTooLarge`.\n- [ ] The negotiated limit is produced by the handshake and required by the reader API (compile-time gating).\n- [ ] Tests cover: negotiated limit < local max; oversized frame rejected.\n- [ ] `cargo test` passes.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-rzh4-1","content":"Implemented via FrameLimitState (Arc<AtomicUsize>) with NegotiatedFrameLimit newtype; reader loops apply negotiated limit after handshake so FrameReader enforces it per frame.","author":"darin@darins-Mac-Studio-2.local","at":[1769569095172,0]},{"id":"legacy-notes","content":"Implemented via FrameLimitState (Arc<AtomicUsize>) with NegotiatedFrameLimit newtype; reader loops apply negotiated limit after handshake so FrameReader enforces it per frame.","author":"darin@darinsmcstudio2.lan","at":[1769569161254,0]}],"_at":[1769569161254,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769569161254,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769569161254,0]}
{"id":"bd-s2x","created_at":[1765676880084,0],"created_by":"darin@darinsmcstudio2.lan","title":"Smart commit message threshold (5) is hardcoded","description":"## What's Wrong\nThe threshold for switching from detailed to count-based commit messages is hardcoded to 5 in to_commit_message().\n\n## Where\n- src/git/sync.rs:92 (`if !self.details.is_empty() && total <= 5`)\n\n## Why It Matters\nMinor - the magic number 5 isn't configurable or documented. Fine for now, but if users want different behavior they can't change it.\n\n## Suggested Fix\nEither document why 5, or make it a const at module level.","priority":4,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765677875351,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765677875351,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765677875351,0]}
{"id":"bd-si5m","created_at":[1769554076661,0],"created_by":"darin@darinsmcstudio2.lan","title":"Repl ACKs must be validated against negotiated namespaces","description":"**Problem**\nACK messages are accepted and forwarded to `PeerAckTable` without validating that their namespaces were negotiated in the handshake. `handle_ack` returns the raw `Ack`, and `update_peer_ack` blindly updates state. A peer can send ACKs for namespaces it never accepted (or was never offered), and we will count those toward durability. This violates parse-don’t-validate and makes durability safety depend on peer honesty.\n\n**Impact**\n- False durability success: `DurabilityCoordinator` may count a peer for a namespace it never replicated.\n- Compiler cannot prevent misuse; a refactor can accidentally pass raw ACKs further without guards.\n\n**Files**\n- `crates/beads-rs/src/daemon/repl/session.rs` (message handling + handshake state)\n- `crates/beads-rs/src/daemon/repl/server.rs` / `crates/beads-rs/src/daemon/repl/manager.rs` (`update_peer_ack`)\n- `crates/beads-rs/src/daemon/repl/peer_acks.rs` (ack table)\n","design":"**Design (opinionated)**\nValidate ACKs at the session boundary and make invalid ACKs unrepresentable downstream.\n\n1) Introduce a validated ACK type tied to negotiated namespaces:\n```rust\nstruct ValidatedAck {\n  durable: WatermarkState<Durable>,\n  applied: Option<WatermarkState<Applied>>,\n}\nstruct AllowedNamespaces(BTreeSet<NamespaceId>);\n```\n`AllowedNamespaces` is created from the negotiated `SessionPeer.accepted_namespaces`.\n\n2) In `Session<*, Streaming>::handle_ack`, validate: every namespace in `Ack` is in `AllowedNamespaces`.\n- If any namespace is not allowed, return `InvalidRequest` / `NamespacePolicyViolation` and transition to `Draining` (fail fast).\n- Otherwise, build `ValidatedAck` (optionally filter empty maps) and emit `SessionAction::PeerAck(ValidatedAck)`.\n\n3) Change `SessionAction::PeerAck` to carry `ValidatedAck` (not raw `Ack`).\n- Update `update_peer_ack` to accept `ValidatedAck`.\n- This makes it impossible to update `PeerAckTable` without negotiated-namespace validation.\n\n4) Preserve ordering/determinism by keeping `BTreeMap` ordering; validation should not reorder.\n\n**Why this is parse-don’t-validate**\nWire ACKs are decoded -> validated immediately -> only validated type flows further. No later runtime checks.","acceptance_criteria":"- [ ] ACKs containing any namespace outside negotiated `accepted_namespaces` are rejected with a clear error.\n- [ ] `SessionAction::PeerAck` carries only a validated type (no raw `Ack` in the repl loops).\n- [ ] `update_peer_ack` cannot be called without a validated ACK.\n- [ ] Ordering of watermark maps remains deterministic (BTreeMap order preserved).\n- [ ] Tests cover: allowed ACK, disallowed namespace ACK, mixed allowed+disallowed, and applied=None cases.\n- [ ] `cargo test` passes.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769555684276,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769555684276,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769555684276,0]}
{"id":"bd-stdu","created_at":[1769560249236,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add git wire sparse _v and WireBeadFull JSON roundtrip tests","description":"","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769585084102,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769585084102,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769585084102,0]}
{"id":"bd-sz4","created_at":[1766116456966,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add integrity checksum for store blobs","description":"**Problem**\nState blobs are trusted JSON; corruption is only detected if JSON parsing fails. Silent corruption could lead to inconsistent state or data loss.\n\n**Design**\nInclude a checksum (e.g., SHA256) in `meta.json` for state/tombstones/deps blobs and verify on read. On mismatch, surface a clear error and avoid overwriting state.\n\n**Acceptance**\n- [ ] Checksums written on commit\n- [ ] Checksums verified on load\n- [ ] Corruption returns a structured error\n\n**Files:** src/git/wire.rs, src/git/sync.rs, src/api/mod.rs, SPEC.md","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768443354139,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768443354139,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768443354139,0]}
{"id":"bd-t268","created_at":[1768778631082,0],"created_by":"darin@darinsmcstudio2.lan","title":"Allow WAL sync mode override for tests (skip fsync)","description":"Expose SegmentSyncMode override via config/env (test-only) so integration tests that don’t validate fsync can run with sync_mode=None. Use when BD_TEST_FAST or explicit env (e.g., BD_WAL_SYNC_MODE=none). Reduces disk I/O in realtime/repl tests.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768802668649,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768802668649,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768802668649,0]}
{"id":"bd-t3nb","created_at":[1770941907857,0],"created_by":"darin@darinsmcstudio2.lan","title":"Admin metrics include startup warm-up outliers in hotpath runs","description":"Problem: admin-metrics snapshot is cumulative across daemon lifetime, so request histogram maxima include startup/warm-up operations and can mislead steady-state comparisons (e.g., ready max).\n\nDesign: add a daemon metrics reset/snapshot-since capability (or benchmark-side daemon restart before measured phase) so steady-state histograms can be isolated without manual parsing.\n\nAcceptance:\n- [ ] Benchmark can report steady-state admin histograms without startup contamination\n- [ ] docs/PERF_HOTPATHS.md documents expected behavior and workflow\n- [ ] regression test or scripted check validates boundary behavior","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1770941907857,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-t7tz","created_at":[1768625370615,0],"created_by":"darin@darinsmcstudio2.lan","title":"Telemetry: logger/tracer interfaces + log retention + trace context","description":"Add logging/tracing configuration with file retention + pluggable logger/tracer interfaces. Ensure realtime spans include store/replica/namespace/txn context.","priority":1,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768626943686,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768626943686,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768626943686,0]}
{"id":"bd-t835","created_at":[1769563918176,0],"created_by":"darin@darinsmcstudio2.lan","title":"git store JSONL: enforce canonical ordering + uniqueness","description":"Problem\n- wire::parse_state_full and friends accept any order and silently overwrite duplicate IDs (state) or duplicate dep keys.\n- That means corrupted or hand-edited store files can silently drop data depending on line order.\n- The canonical ordering invariants (sorted by BeadId / TombstoneKey / DepKey / NoteId) are not enforced at the parse boundary.\n\nImpact\n- Data loss can go unnoticed.\n- Violates parse-don't-validate and the \"ordering is a stability invariant\" we rely on for deterministic diffs.\n","design":"Design\n- Add a canonical JSONL parser for the git store that enforces strictly increasing order and uniqueness per file.\n  - state.jsonl: BeadId strictly increasing, no duplicates.\n  - tombstones.jsonl: BeadId (or TombstoneKey) strictly increasing, no duplicates.\n  - notes.jsonl: (bead_id, note_id) strictly increasing, no duplicates.\n  - deps.jsonl: DepKey entries strictly increasing, no duplicates.\n- Return WireError::InvalidValue with file + line context on violations.\n- Keep serialization order exactly matching these rules so roundtrip is deterministic.\n\nScatter fit\n- Enforce ordering in one parser per file type; eliminate implicit reliance on serialize_* ordering.\n\nFiles\n- crates/beads-rs/src/git/wire.rs\n- crates/beads-rs/src/git/sync.rs (error reporting context)","acceptance_criteria":"Acceptance\n- Parsing files with duplicates or out-of-order entries fails with a specific WireError.\n- Roundtrip tests verify canonical ordering and strict parsing.\n- Existing valid stores continue to parse without changes.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769578536087,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769578536087,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769578536087,0]}
{"id":"bd-t9xz","created_at":[1769573160970,0],"created_by":"darin@darinsmcstudio2.lan","title":"Separate parent edges from generic deps","description":"**Problem**\nParent relationships are represented as a generic dependency kind (`DepKind::Parent`) and are enforced by convention in mutation paths (`SetParent` vs `AddDep`). This means the single-parent invariant is not encoded in types, and any new generic dep path can violate it.\n\n**Files:**\n- `crates/beads-core/src/domain.rs`\n- `crates/beads-core/src/dep.rs`\n- `crates/beads-rs/src/daemon/mutation_engine.rs`\n- `crates/beads-rs/src/daemon/query_executor.rs`\n- `crates/beads-rs/src/compat/go_schema.rs`","design":"**Design**\nSplit parent edges from general dependency edges at the type level and disallow `DepKind::Parent` in generic dep ops.\n\nConcrete plan:\n1) Introduce a distinct `ParentEdge` (or `ParentLink`) type in `beads-core` with explicit `child` and `parent` fields.\n2) Update dependency types so `DepKey`/`DepKind` only represent non-parent deps (e.g., Blocks/Related). If `DepKind::Parent` must remain for compatibility, make it unreachable from public constructors.\n3) Add dedicated ops: `SetParent`, `ClearParent`, `ParentAdd` (if needed), and remove the ability to add/remove parent edges via generic `DepAdd`/`DepRemove`.\n4) Update mutation planning: `SetParent` path constructs parent ops only; generic dep add path rejects parent kind at type level (compile time) or with explicit runtime error.\n5) Update validation paths and wire formats so parent edges have a single representation and invariant enforcement.\n\n**Design Notes**\n- If removing `DepKind::Parent` is too invasive, keep it for legacy parsing but map it immediately into parent-specific types.\n- Make parent edges DAG-safe by construction and remove ad-hoc runtime checks where possible.","acceptance_criteria":"**Acceptance**\n- [ ] Parent edges are represented by a distinct type, not `DepKey` + `DepKind::Parent`.\n- [ ] Generic dep add/remove APIs cannot represent parent edges.\n- [ ] Mutation engine uses only parent-specific ops for parent changes.\n- [ ] Event validation rejects parent edges in generic dep operations (or the type system prevents them).\n- [ ] Tests cover: single-parent invariant, parent edge add/remove, and rejection of parent via generic deps.","priority":2,"type":"chore","labels":{"entries":{"scatter":[{"replica":"7b9928ee-b787-3c08-2811-817afc36d5ce","counter":16657498115539209288}],"tech-debt":[{"replica":"2327902c-7bd5-5649-8474-67df1052b6a9","counter":5468007523263720890}],"types":[{"replica":"34a32b01-6fa4-4c78-0755-14bcce256832","counter":6491874434171015920}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-t9xz-1","content":"Reminder: keep rendering in the command files themselves; avoid moving rendering into shared layers.","author":"darin@darins-Mac-Studio-2.local","at":[1769590759150,0]},{"id":"legacy-notes","content":"Reminder: keep rendering in the command files themselves; avoid moving rendering into shared layers.","author":"darin@darinsmcstudio2.lan","at":[1769593331247,0]}],"_at":[1769593331247,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769593331247,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769593331247,0]}
{"id":"bd-tjbb","created_at":[1769578525789,0],"created_by":"darin@darinsmcstudio2.lan","title":"parse_legacy_state double-inserts label_store for state entries in git/wire.rs","description":"","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769589200382,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769589200382,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769589200382,0]}
{"id":"bd-txrl","created_at":[1769565888376,0],"created_by":"darin@darinsmcstudio2.lan","title":"mutation: stamp must be derived from actor context","description":"Problem\n- MutationEngine::plan accepts a Stamp separate from MutationContext.actor_id and never verifies they match.\n- A caller can pass mismatched actor/HLc stamp, yielding events whose HLC actor differs from the request actor.\n- This violates causality invariants and is not caught by the compiler.\n\nImpact\n- Incorrect event authorship and HLC ordering; difficult-to-debug replication issues.\n- Violates \"types should tell the truth\"; the API implies any Stamp is valid.\n","design":"Design\n- Introduce a StampedContext type that can only be constructed from MutationContext + Stamp after verifying stamp.by == ctx.actor_id.\n- Change plan signature to accept StampedContext (or accept a stamp builder that derives from ctx).\n- Option: have plan compute stamp from ctx + wall clock, and only accept the wall clock inputs, not a raw Stamp.\n- Add a debug assertion or validation error if mismatch is detected in legacy call sites.\n\nScatter fit\n- Make the mismatch unrepresentable; no call site can pass a mismatched stamp.\n\nFiles\n- crates/beads-rs/src/daemon/mutation_engine.rs\n- crates/beads-rs/src/daemon/executor.rs (callers)\n- crates/beads-rs/src/daemon/core.rs (callers)","acceptance_criteria":"Acceptance\n- plan cannot be called without a validated StampedContext (compile-time change).\n- Mismatched actor/stamp is impossible to represent or yields a clear OpError at construction.\n- Tests cover mismatch rejection and valid stamping.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769575175967,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769575175967,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769575175967,0]}
{"id":"bd-tzkw","created_at":[1769483948649,0],"created_by":"darin@darinsmcstudio2.lan","title":"Make LoadedStore a real proof via borrowed handle/typestate","description":"**Problem**\n`LoadedStore` is a marker type that claims a store is loaded, yet the docs state accessors can still return Internal if the invariant is violated. This is exactly the kind of “type that lies” that causes unsafe refactors and hidden runtime failure modes. It violates the principles in `docs/philosophy/type_design.md`.\n\nKey references:\n- `crates/beads-rs/src/daemon/core.rs:54` — `LoadedStore` comment says invariant can still be violated.\n\nSeverity: This is the primary gateway to daemon state. Any misuse can lead to internal errors despite “proof” types, making correctness non-local and brittle.","design":"**Design**\nMake “loaded store” a real proof by tying it to actual entries in the daemon state via borrowing or a typestate.\n\nOption A (borrowed handle):\n- `struct LoadedStore<'a> { store_id: StoreId, remote: RemoteUrl, runtime: &'a mut StoreRuntime, lane: &'a mut GitLaneState }`.\n- Only constructed by `Daemon::ensure_repo_loaded*` by looking up entries and borrowing them.\n- Callers that need a loaded store take `LoadedStore<'_>`; they can’t exist without the backing map entry.\n\nOption B (index token + invariants):\n- `LoadedStore` holds an internal key tied to a `StoreCaches` entry that cannot be fabricated.\n- Accessors use the key to retrieve references without `Option` or Internal errors.\n\nMigration:\n- Update `ensure_repo_loaded`/`ensure_repo_loaded_strict`/`ensure_repo_fresh` to return the borrowed handle.\n- Collapse “internal if invariant violated” branches since they become impossible.\n- Add tests for failure modes (ensure errors only occur during loading, not post-hoc access).","acceptance_criteria":"- [ ] A loaded-store handle cannot exist without a backing runtime/lane entry (enforced by borrow or token).\n- [ ] Codepaths that currently return Internal due to “missing loaded store” are eliminated.\n- [ ] All loaded-store APIs take the new handle type; no raw `store_id`+`remote` pairs used for access.\n- [ ] Tests cover missing/invalid store errors at load time only.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769509260925,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769509260925,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769509260925,0]}
{"id":"bd-u3iu","created_at":[1768779104512,0],"created_by":"darin@darinsmcstudio2.lan","title":"Speed up git fixtures with a cached template repo","description":"Many tests create a fresh git repo via Reinitialized existing Git repository in /Users/darin/Projects/beads-rs-macstudio/.git/ + config. Create a template repo once (per test process) and copy/clone it into temp dirs for each test to avoid repeated init/config overhead. Could use OnceLock + fs copy or git clone --shared.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768817008232,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768817008232,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768817008232,0]}
{"id":"bd-uakj","created_at":[1769565869849,0],"created_by":"darin@darinsmcstudio2.lan","title":"mutation: dep adds must carry DAG proof types","description":"Problem\n- plan_add_dep builds raw DepKey + ad-hoc check_no_cycle, then emits WireDepAddV1.\n- The NoCycleProof/DepAddKey types exist but aren't used here, so the compiler can't enforce that DAG checks happened.\n- A future refactor can bypass the cycle check without the type system noticing.\n\nImpact\n- Cycle invariants for Blocks/Parent depend on discipline instead of types.\n- Violates parse-don't-validate and \"types should tell the truth\".\n","design":"Design\n- Make MutationEngine add deps through DepAddKey only:\n  - Use state.check_dep_add_key(key) to return DepAddKey (Acyclic|Free).\n  - Change WireDepAddV1 (or an internal wrapper) to carry DepAddKey, or make the add path require a DepAddKey parameter.\n- Option A: introduce a ValidatedDepAdd type in core (mirrors ValidatedBeadPatch) that only constructs from DepAddKey; mutation_engine must build that.\n- Option B: split add ops in mutation engine: add_dep_acyclic requires NoCycleProof, add_dep_free does not; prohibit raw DepKey in the API.\n- Ensure all dependency adds (including create's dependency list and SetParent path) go through the same typed gate.\n\nScatter fit\n- One entry point (check_dep_add_key) owns DAG validity; call sites no longer repeat or forget checks.\n\nFiles\n- crates/beads-rs/src/daemon/mutation_engine.rs\n- crates/beads-core/src/dep.rs\n- crates/beads-core/src/state.rs\n- crates/beads-core/src/event.rs (if adding ValidatedDepAdd)","acceptance_criteria":"Acceptance\n- There is no mutation path that can add a DAG edge without a DepAddKey/NoCycleProof.\n- Compiler forces add paths to handle Acyclic vs Free keys explicitly.\n- Tests cover: cycle detection for Blocks/Parent; Related/DiscoveredFrom bypass DAG checks but still validated.\n- Existing behavior preserved for valid inputs.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769593916887,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769593916887,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769593916887,0]}
{"id":"bd-ucph","created_at":[1768778071486,0],"created_by":"darin@darinsmcstudio2.lan","title":"LoadGenerator spawns threads even for 1 worker; add fast path","description":"tests/integration/fixtures/load_gen.rs always spawns worker threads, even when workers=1 (common in tests). Add a single-thread fast path to avoid thread spawn + atomics/mutex overhead for small loads.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768798295461,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768798295461,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768798295461,0]}
{"id":"bd-ufv1","created_at":[1769562833894,0],"created_by":"darin@darinsmcstudio2.lan","title":"Repl namespace lists must be canonicalized at parse boundary","description":"**Problem**\nReplication wire decoding returns raw `Vec<NamespaceId>` for `requested_namespaces`, `offered_namespaces`, and `accepted_namespaces`. Order is preserved from the wire, not canonicalized. Later we compare vectors for equality (e.g. WELCOME replay), which can reject a peer that sends the same set in a different order.\n\nThis is a parse-don’t-validate violation (we should normalize at the boundary), and a classic scatter bug: correctness depends on every caller remembering to sort/dedup.\n\n**Impact**\n- False handshake failures due to ordering differences.\n- Hidden coupling to wire ordering; brittle and hard to reason about.\n\n**Files**\n- `crates/beads-rs/src/daemon/repl/proto.rs` (decode_namespace_list)\n- `crates/beads-rs/src/daemon/repl/session.rs` (HELLO/WELCOME replay comparison)\n","design":"**Design (opinionated)**\nMake namespace lists a canonical type, and only expose canonicalized lists internally.\n\n1) Introduce a `NamespaceSet` newtype:\n```rust\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct NamespaceSet(Vec<NamespaceId>);\nimpl NamespaceSet {\n  pub fn from_wire(mut v: Vec<NamespaceId>) -> Self { v.sort(); v.dedup(); Self(v) }\n  pub fn as_slice(&self) -> &[NamespaceId] { &self.0 }\n}\n```\n(Or use `BTreeSet` internally if you want set semantics and ordering for free.)\n\n2) `decode_namespace_list` should return `NamespaceSet` (or at least canonicalize before returning).\n3) `SessionPeer` should store `NamespaceSet` (or a canonical `NamespaceList` type) so comparisons are order-insensitive.\n4) `encode_namespace_list` should always emit canonical order from the set type.\n\nThis removes ordering‑sensitive comparisons and keeps the invariant local.","acceptance_criteria":"- [ ] Decoding a namespace list always yields canonical (sorted + deduped) order.\n- [ ] Handshake replay accepts the same set regardless of wire ordering.\n- [ ] Internal storage uses the canonical type (no raw Vec in session peer).\n- [ ] Encoding always emits canonical order.\n- [ ] Tests cover: same set different order, duplicates on wire, empty list.\n- [ ] `cargo test` passes.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769598978711,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769598978711,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769598978711,0]}
{"id":"bd-umt1","created_at":[1769502740691,0],"created_by":"darin@darinsmcstudio2.lan","title":"Repl watermark heads must be coupled to seq at parse boundary","description":"**Problem**\nReplication wire structs (`Ack`, `Hello`, `Welcome`) carry `WatermarkMap` plus optional `WatermarkHeads`. There is no type-level coupling between `seq` and `head`, so it is easy to construct invalid states (e.g., `seq>0` with no head). The compiler cannot prevent this; errors only surface later as runtime failures (`MissingHead` / divergence), and these failures are not localized to the parsing boundary.\n\nThis violates parse-don’t-validate and makes correctness depend on call-site discipline.\n\n**Impact**\n- Incorrect or missing heads can stall replication or mark peers diverged.\n- Internal code can accidentally emit invalid ACKs without compile-time feedback.\n\n**Files**\n- `crates/beads-rs/src/daemon/repl/proto.rs` (Ack/Hello/Welcome decode)\n- `crates/beads-rs/src/daemon/repl/session.rs` (watermark snapshot/seed)\n- `crates/beads-rs/src/daemon/repl/peer_acks.rs`","design":"**Design**\nIntroduce a typed, invariant-preserving watermark representation at the Repl boundary:\n\n- Create an internal type that represents *validated* watermarks (use `Watermarks<K>` or a new `WatermarkSnapshot<K>` that contains `Watermark<K>` values).\n- Keep wire format unchanged by introducing wire-only structs:\n  - `WireAck` / `WireHello` / `WireWelcome` with `WatermarkMap` + `WatermarkHeads` (serde/cbor only)\n  - `Ack` / `Hello` / `Welcome` used internally with `Watermarks<K>` (or validated snapshot type)\n- `decode_*` should parse into wire structs, then immediately validate/convert into the typed representation:\n  - Missing head for seq>0 becomes a `ProtoDecodeError::InvalidField`.\n  - Genesis (`seq=0`) must have no head (or Genesis marker), enforced by `Watermark::new`.\n- `encode_*` should accept the typed representation and derive wire maps/heads in canonical order.\n\n**Ordering / invariants preserved**\n- Maintain deterministic ordering by using `BTreeMap` during wire conversion.\n- No change to wire encoding order or shape; only validation is moved to the parse boundary.","acceptance_criteria":"- [ ] Internal repl message types cannot be constructed without valid head/seq combinations.\n- [ ] Decode rejects `seq>0` without head and `seq=0` with head (clear error).\n- [ ] Encoding preserves canonical ordering and wire compatibility.\n- [ ] Tests cover valid/invalid ACKs and HELLO/WELCOME watermark snapshots.\n- [ ] `cargo test` passes.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769542804718,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769542804718,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769542804718,0]}
{"id":"bd-uzos","created_at":[1769574026333,0],"created_by":"darin@darinsmcstudio2.lan","title":"Keep read models typed; serialize enums as strings","description":"**Problem**\nDomain enums leak into read APIs as raw strings:\n- API `IssueSummary` uses `status: String` and `issue_type: String` in `crates/beads-api/src/issues.rs`\n- Go compat schema uses strings for status/type in `crates/beads-rs/src/compat/go_schema.rs`\n\nThis forces repeated string conversion at each read surface and weakens invariants. It is translation + scatter: the domain shape is lost at the API boundary, and each view re-derives the same mapping rules.\n\n**Files:**\n- `crates/beads-api/src/issues.rs`\n- `crates/beads-rs/src/compat/go_schema.rs`\n- `crates/beads-core/src/domain.rs`\n- `crates/beads-core/src/bead.rs`","design":"**Design**\nKeep domain enums typed in the read projection, and convert to strings only at serialization boundaries.\n\nConcrete plan:\n1) Update the read projection (see `bd-y06u`) to carry typed enums for status/type/labels.\n2) Change API `Issue`/`IssueSummary` to store those enums internally (or wrap them), and implement custom serde to emit strings.\n3) Update Go compat conversion to use the typed projection and perform string conversion once in the serializer.\n4) Remove ad-hoc `.to_string()` conversions scattered in view builders.\n\n**Design Notes**\n- This keeps external JSON compatible but makes internal code trust types.\n- If full API type changes are too disruptive, add `IssueSummaryTyped` and only serialize to string form for the API layer.","acceptance_criteria":"**Acceptance**\n- [ ] Read projection carries typed enums (status/type) instead of strings.\n- [ ] API and compat serializers emit the same string values as before.\n- [ ] View builders no longer manually map enums to strings in multiple places.\n- [ ] Tests confirm JSON output unchanged and typed fields usable in code.","priority":3,"type":"chore","labels":{"entries":{"scatter":[{"replica":"a930fd44-8136-5653-9e53-45d43f4cc966","counter":9299972828716551115}],"translation":[{"replica":"d5455f86-6252-63a2-efbe-1691758ddc22","counter":9488852662554878196}],"types":[{"replica":"7db60923-0454-a2c6-6d9f-6d40ae5db6e7","counter":17025940431833190592}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769776663093,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769776663093,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769776663093,0]}
{"id":"bd-uzwo","created_at":[1769309224115,0],"created_by":"darin@darinsmcstudio2.lan","title":"Extract ValidationError helper for CLI handlers","description":"**Problem**\nCLI handlers manually construct validation errors with repetitive boilerplate:\n\n```rust\n// src/cli/commands/create.rs:17-20\nError::Op(crate::daemon::OpError::ValidationFailed {\n    field: \"create\".into(),\n    reason: \"cannot specify both title and --file flag\".into(),\n})\n\n// src/cli/commands/update.rs:26-29\nError::Op(crate::daemon::OpError::ValidationFailed {\n    field: \"reason\".into(),\n    reason: \"--reason requires --status=closed\".into(),\n})\n\n// src/cli/commands/dep.rs:9-12\nError::Op(crate::daemon::OpError::ValidationFailed {\n    field: \"dep\".into(),\n    reason: msg,\n})\n```\n\nThis pattern appears 10+ times across handlers. No helper exists despite `normalize_bead_id_for()` in mod.rs showing the pattern works.\n\n**Design**\nAdd a helper function in `src/cli/mod.rs` (near line 1351 where similar helpers exist):\n\n```rust\n/// Create a validation error for CLI argument validation\npub(crate) fn validation_error(field: impl Into<String>, reason: impl Into<String>) -> Error {\n    Error::Op(crate::daemon::OpError::ValidationFailed {\n        field: field.into(),\n        reason: reason.into(),\n    })\n}\n```\n\nThen replace all manual constructions:\n```rust\n// Before\nreturn Err(Error::Op(crate::daemon::OpError::ValidationFailed {\n    field: \"create\".into(),\n    reason: \"cannot specify both title and --file flag\".into(),\n}));\n\n// After\nreturn Err(validation_error(\"create\", \"cannot specify both title and --file flag\"));\n```\n\n**Acceptance**\n- [ ] `validation_error()` helper added to src/cli/mod.rs\n- [ ] All `Error::Op(OpError::ValidationFailed { ... })` patterns in src/cli/commands/ replaced\n- [ ] Helper is pub(crate) so command modules can use it\n- [ ] cargo clippy passes\n- [ ] cargo test passes\n\n**Files:** src/cli/mod.rs, src/cli/commands/create.rs, src/cli/commands/update.rs, src/cli/commands/dep.rs, src/cli/commands/label.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-uzwo-1","content":"Rendering stays in command files; helper should only reduce validation error boilerplate.","author":"darin@darins-Mac-Studio-2.local","at":[1769579440594,0]},{"id":"legacy-notes","content":"Rendering stays in command files; helper should only reduce validation error boilerplate.","author":"darin@darinsmcstudio2.lan","at":[1769579564772,0]}],"_at":[1769579564772,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769579564772,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769579564772,0]}
{"id":"bd-v1xr","created_at":[1769501256172,0],"created_by":"darin@darinsmcstudio2.lan","title":"IPC update patch must not allow Closed status","description":"**Problem**\nThe IPC update patch schema allows setting `status=Closed` via `BeadPatch.status`, without requiring `closed_reason`/`closed_on_branch`. This violates the workflow invariant (closed must carry closure data), and relies on downstream runtime validation to reject invalid updates.\n\nKey refs:\n- `crates/beads-surface/src/ops.rs:82` — `BeadPatch.status: Patch<WorkflowStatus>`.\n- `crates/beads-surface/src/ipc/payload.rs:51` — Update payload uses `BeadPatch`.\n\n**Impact**\nIPC schema can represent illegal states; compiler can’t prevent accidental Close‑via‑Update.","design":"**Design (opinionated)**\nMake “Close” a dedicated operation only; updates must not encode the Closed state.\n\nOptions:\n- Replace `BeadPatch.status: Patch<WorkflowStatus>` with `Patch<OpenInProgress>` where:\n```rust\nenum OpenInProgress { Open, InProgress }\n```\n- Alternatively, remove `status` from `BeadPatch` entirely and require `Close`/`Reopen` IPC ops for status transitions.\n\nThis forces correct closure semantics and makes illegal updates unrepresentable at the schema level.","acceptance_criteria":"**Acceptance**\n- [ ] IPC update patch cannot encode `Closed` (compile‑time enforced).\n- [ ] Closing a bead is only possible via the `Close` IPC operation with explicit reason/branch data.\n- [ ] Attempts to send `status=closed` in Update payload fail at decode time.\n- [ ] Tests cover Update payload rejecting closed status and Close op still working.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-v1xr-1","content":"Constraint: keep rendering logic in the command files themselves; do not move rendering out of command files.","author":"darin@darins-Mac-Studio-2.local","at":[1769583969449,0]},{"id":"legacy-notes","content":"Constraint: keep rendering logic in the command files themselves; do not move rendering out of command files.","author":"darin@darinsmcstudio2.lan","at":[1769584529017,0]}],"_at":[1769584529017,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769584529017,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769584529017,0]}
{"id":"bd-v9i","created_at":[1766116455765,0],"created_by":"darin@darinsmcstudio2.lan","title":"Git fetch should use explicit refspec + surface errors","description":"**Problem**\n`remote.fetch(&[\"refs/heads/beads/store\"], ...)` relies on libgit2 refspec defaults; it may only update FETCH_HEAD and leave `refs/remotes/origin/beads/store` stale. Fetch errors are also ignored, so the daemon can sync against stale remote state without any signal.\n\n**Design**\nUse an explicit refspec (`refs/heads/beads/store:refs/remotes/origin/beads/store`) and return/propagate fetch errors (or at least surface them in status/IPC). Keep a best-effort path for offline reads but make failures visible.\n\n**Acceptance**\n- [ ] Fetch updates `refs/remotes/origin/beads/store`\n- [ ] Fetch errors are surfaced (status/IPC/logs)\n- [ ] Tests cover refspec + fetch failure behavior\n\n**Files:** src/git/sync.rs, src/daemon/git_worker.rs","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766124419956,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766124419956,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766124419956,0]}
{"id":"bd-vb0","created_at":[1766116455465,0],"created_by":"darin@darinsmcstudio2.lan","title":"init_beads_ref must not overwrite existing local ref","description":"**Problem**\n`init_beads_ref` fetches and force-updates `refs/heads/beads/store` to remote even if a local ref already exists. If local has data, this can overwrite it.\n\n**Design**\nIf local ref exists, treat init as a no-op (already initialized). Only fast-forward local when it does not exist. Never force-update without preserving local history. Add a test that ensures init does not modify an existing local ref.\n\n**Acceptance**\n- [ ] init is a no-op when local ref exists\n- [ ] No forced updates on existing local refs\n- [ ] Tests cover init with existing local ref\n- [ ] Tests pass\n\n**Files:** src/git/sync.rs","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1766124452636,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766124452636,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766124452636,0]}
{"id":"bd-vz9z","created_at":[1768713481528,0],"created_by":"darin@darinsmcstudio2.lan","title":"Stateright regression test for durability idempotency model","description":"**Problem**\nDurability/idempotency model fixes are not covered by the normal test suite, so regressions (e.g. non-monotonic client-observed receipts) can slip in.\n\n**Design**\n- Add a regression test under beads_stateright_models/tests that executes the durability idempotency ActorModel to completion and asserts all properties.\n- Expose the example's build_model() so the test can call it without duplicating logic.\n- Keep the test deterministic (single thread) and fail fast if model checking does not complete.\n\n**Acceptance**\n- [ ] Test added in beads_stateright_models/tests that runs the durability idempotency model and asserts properties.\n- [ ] Example exposes a callable build_model() for the test.\n- [ ] cargo test in beads_stateright_models passes.\n\n**Files:** beads_stateright_models/examples/durability_idempotency_machine.rs, beads_stateright_models/tests/","priority":0,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768713845968,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768713845968,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768713845968,0]}
{"id":"bd-w22","created_at":[1768495457653,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tests for namespace propagation in issue summaries","description":"**Problem**\nNamespace propagation is easy to regress once added; we need a focused test to lock it down.\n\n**Design**\nAdd a unit test in src/daemon/query_executor.rs to assert IssueSummary built from a bead includes the expected namespace. Update existing helper to include namespace field.\n\n**Files**\n- src/daemon/query_executor.rs","acceptance_criteria":"- [ ] Test asserts IssueSummary.namespace == read namespace\n- [ ] Existing tests updated for new field","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768496261325,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768496261325,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768496261325,0]}
{"id":"bd-w36","created_at":[1765744931340,0],"created_by":"darin@darinsmcstudio2.lan","title":"Scheduler spawns unbounded threads on reschedule (threadpocalypse)","description":"**Problem**\n`src/daemon/scheduler.rs` spawns a new thread on every schedule call, and reschedules do not cancel old sleepers. Under bursty ops, this devolves into \"death by a thousand sleeping threads\".\n\n**Design**\nSingle timer mechanism:\n- Keep a min-heap of `(deadline, remote)`\n- State loop computes next deadline and uses `crossbeam::channel::after(next - now)` (or one dedicated timer thread)\n- When rescheduling, update the heap entry (or push and ignore stale entries by checking current deadline in a map)\n\nThis makes the daemon \"boring\" which is good.\n\n**Acceptance**\n- [ ] At most 1 timer thread (or zero with channel-based approach)\n- [ ] Rapid reschedules dont accumulate sleeping threads\n- [ ] Stress test: 1000 rapid mutations, verify thread count stays bounded\n- [ ] Existing sync behavior preserved (debounce still works)\n\n**Files:** src/daemon/scheduler.rs","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765772953094,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765772953094,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765772953094,0]}
{"id":"bd-w4a","created_at":[1768444235281,0],"created_by":"darin@darinsmcstudio2.lan","title":"Default namespace policies are incomplete (missing sys/wf/tmp)","description":"**Problem**\nWhen `namespaces.toml` is missing, we default to only `core` instead of the spec default set (`core`, `sys`, `wf`, `tmp`). This makes new installs diverge from the realtime plan and forces callers to handle “missing namespace” errors that shouldn’t exist by default.\n\n**Signals / Evidence**\n- `default_policies()` returns only `core` (`src/daemon/store_runtime.rs`).\n- Spec defaults for `sys`, `wf`, `tmp` are documented in REALTIME_PLAN.md (0.4).\n\n**Why this hurts velocity**\nWe keep tripping over missing namespaces when adding features that expect them (policy checks, replication routing, GC/retention). It’s a hidden configuration requirement that should be encoded in defaults.","design":"**Design**\n- Expand `default_policies()` to include `sys_default`, `wf_default`, `tmp_default` with spec values.\n- Add a test that missing `namespaces.toml` yields all four namespaces.\n- Ensure any code that assumes only `core` is updated or guarded.","acceptance_criteria":"- [ ] Default policies include `core`, `sys`, `wf`, and `tmp`.\n- [ ] Test covers default policy set when `namespaces.toml` is absent.","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"duplicate of bd-3m5.91","_at":[1768448823524,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768448823524,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-w9og","created_at":[1768704221218,0],"created_by":"darin@darinsmcstudio2.lan","title":"Flaky critical_path tests test_dependencies/test_reopen_closed","description":"Full cargo test run failed in tests/critical_path.rs for test_dependencies and test_reopen_closed (unexpected stdout), but both pass when run individually. Investigate shared state or ordering issues in critical_path harness.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768704520098,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768704520098,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-wbb","created_at":[1768439548764,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fuzzing on macOS picks MacPorts zlib; make cargo fuzz work without LIBZ_SYS_STATIC env","description":"","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768490437702,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768490437702,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768490437702,0]}
{"id":"bd-wlh","created_at":[1768483169469,0],"created_by":"darin@darinsmcstudio2.lan","title":"src/daemon/server.rs:1164 TestEnv.store_id unused triggers cargo test warnings","description":"","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768489720581,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768489720581,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768489720581,0]}
{"id":"bd-wm65","created_at":[1768774749880,0],"created_by":"darin@darinsmcstudio2.lan","title":"Observability: configurable log filter/level","description":"**Problem**\nLog level/filter is only controlled by `LOG` env or `-v`, so daemon log verbosity is not persistently configurable.\n\n**Design**\n- Add `logging.filter` (string) to config schema for `tracing_subscriber::EnvFilter` directives.\n- Add env override `BD_LOG_FILTER` (string). Precedence: LOG env > BD_LOG_FILTER > config.logging.filter > verbosity.\n- Update `telemetry::init` to build an EnvFilter that merges the chosen source.\n\n**Acceptance**\n- [ ] Config accepts `logging.filter = \"beads_rs=debug,metrics=info\"`.\n- [ ] `BD_LOG_FILTER` overrides config, `LOG` overrides both.\n- [ ] Tests updated or added for parsing/precedence.\n\n**Files:** src/config/schema.rs, src/config/merge.rs, src/telemetry.rs, src/bin/main.rs","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768777313215,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768777313215,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768777313215,0]}
{"id":"bd-wni5","created_at":[1769494178189,0],"created_by":"darin@darinsmcstudio2.lan","title":"Bind WAL VerifiedRecord to canonical event bytes/body","description":"**Problem**\n`VerifiedRecord` is “verified” only relative to a provided `EventBody`, but it doesn’t carry that body or ensure its payload bytes are the canonical encoding of that body. Callers can accidentally pair a header/payload with the wrong decoded body (or a non-canonical body encoding) while still constructing `VerifiedRecord`. This undermines the WAL’s trust boundary and violates the “information holds its shape” principle.\n\nKey references:\n- `crates/beads-rs/src/daemon/wal/record.rs:330` — verification uses `EventBody` passed from outside.\n- `crates/beads-core/src/event.rs:32` — `EventBytes<Canonical>` type exists but is not used in WAL record types.\n\nSeverity: a class of subtle integrity bugs where WAL frames are “verified” without actually binding bytes to semantic content.","design":"**Design**\nMake `VerifiedRecord` carry a canonical event representation that binds body ↔ bytes ↔ hash.\n\nOption A (canonical event wrapper):\n- Introduce `CanonicalEvent { body: EventBody<Validated>, bytes: EventBytes<Canonical>, sha256: Sha256 }`.\n- `VerifiedRecord` stores `CanonicalEvent` (or at least `EventBytes<Canonical>` + `sha256`), eliminating mismatched pairs.\n\nOption B (generic record state):\n- `Record<State>` where `State = Verified<Canonical>` includes `EventBytes<Canonical>` and `EventBody<Validated>`.\n- `verify_with_event_body` replaced by `verify_with_canonical(bytes: EventBytes<Canonical>, body: EventBody<Validated>)`.\n\nMigration:\n- Update WAL write APIs to require `CanonicalEvent` or `EventBytes<Canonical>`.\n- Update replay/ingest to decode bytes into canonical event (already enforced in core decode) and thread that through.\n\nNotes:\n- This should dovetail with the existing P0 bead to add `EventBody<Validated>`.","acceptance_criteria":"- [ ] `VerifiedRecord` cannot be constructed without canonical bytes bound to the exact event body.\n- [ ] WAL append APIs require canonical event bytes (or a canonical event wrapper).\n- [ ] Existing replay/ingest code updated; no ad‑hoc pairing of body + payload remains.\n- [ ] Tests updated or added to ensure mismatched body/payload cannot compile or fails at conversion boundary.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769514960846,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769514960846,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769514960846,0]}
{"id":"bd-wos","created_at":[1768281970823,0],"created_by":"darin@darinsmcstudio2.lan","title":"Clock anomaly record missing in admin status/doctor (REALTIME_PLAN §2.8)","description":"**Problem**\nForward-jump clamping only logs; no structured clock anomaly info is surfaced in status/doctor.\n\n**Design**\nRecord last clock anomaly in daemon/repo state (timestamp, delta, kind) and expose via status/doctor outputs.\n\n**Acceptance**\n- [ ] Forward-jump clamp updates clock anomaly record\n- [ ] Status/doctor includes last anomaly fields\n- [ ] Tests cover update + serialization","priority":2,"type":"task","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768399139812,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768399139812,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768399139812,0]}
{"id":"bd-woz","created_at":[1767914938111,0],"created_by":"darin@darinsmcstudio2.lan","title":"**Problem**\n`Daemon::apply_update` applies `BeadPatch` field-by-field inline. The patch semantics live in `src/daemon/ops.rs`, but the actual application logic lives in `src/daemon/executor.rs`, so adding or changing fields requires touching both places and is easy to miss.\n\n**Design**\nAdd a helper on `BeadPatch` (e.g., `apply_to_fields(&self, fields: &mut BeadFields, stamp: &Stamp) -> Result<(), OpError>`) in `src/daemon/ops.rs`. Move the current field-application logic (including label parsing and status→workflow transition) into this helper. Update `Daemon::apply_update` to call the helper inside `apply_wal_mutation`.\n\n**Design Notes**\nKeep behavior identical: ignore `Patch::Clear` for required fields (title/description) and for labels (no-op), preserve current status validation and error messages.\n\n**Acceptance**\n- [ ] `Daemon::apply_update` delegates patch application to `BeadPatch::apply_to_fields`.\n- [ ] Label validation and workflow transitions behave exactly as before.\n- [ ] Tests pass.\n\n**Files:** `src/daemon/ops.rs`, `src/daemon/executor.rs`","description":"","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darinsmacstudio.lan","_at":[1767999708289,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1767999708289,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1767999708289,0]}
{"id":"bd-ws6v","created_at":[1768778081415,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tailnet proxy readiness uses bind polling; add ready-file/handshake","description":"tests/integration/fixtures/tailnet_proxy.rs waits for listen by polling bind+sleep. Add a readiness signal to tailnet_proxy (e.g., --ready-file) and wait on that instead to reduce polling and tighten timeouts.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768802314240,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768802314240,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768802314240,0]}
{"id":"bd-wte","created_at":[1765689969486,0],"created_by":"darin@darinsmcstudio2.lan","title":"rustfmt.toml uses unstable options on stable","description":"## What's Wrong\ncargo fmt prints warnings because rustfmt.toml sets unstable_features=true and group_imports=StdExternalCrate, which require nightly rustfmt.\n\n## Where\n- rustfmt.toml\n\n## Why It Matters\nNoisy output in CI/local workflows (for example, just release-patch runs cargo fmt -- --check). It can also cause formatting drift if contributors have different toolchains.\n\n## Options\n1. Remove unstable settings and rely on stable rustfmt defaults.\n2. Pin nightly rustfmt in dev shell/CI to support the config.\n\n---\nDiscovered while: running cargo fmt during migration slug work.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765775547196,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765775547196,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765775547196,0]}
{"id":"bd-wxaq","created_at":[1769563839480,0],"created_by":"darin@darinsmcstudio2.lan","title":"git store meta parse should be versioned + verified","description":"Problem\n- wire::parse_meta exposes format_version but no caller enforces it; read_state_at_oid always treats store as legacy/v1.\n- meta.json can omit checksums; we silently skip verification and still accept blobs.\n- root_slug is Option<String> and not validated at the parse boundary; invalid slugs propagate until mutation_engine rejects them at runtime.\n\nImpact\n- We can accept incompatible future formats or corrupt data without a clear error.\n- The type system can't tell us whether meta was verified or even compatible.\n- Violates parse-don't-validate and Scatter (callers must remember what is safe).\n","design":"Design\n- Replace ParsedMeta with a versioned enum, e.g. StoreMeta::Legacy | StoreMeta::V1 { root_slug: Option<BeadSlug>, last_write_stamp: Option<WriteStamp>, checksums: StoreChecksums }.\n- parse_meta validates format_version == 1; unknown versions return WireError::InvalidValue (or a new UnsupportedVersion variant).\n- For v1 meta, require all checksum fields; treat partial checksum sets as hard errors.\n- Validate root_slug via BeadSlug::parse at parse time; store as Option<BeadSlug> so invalid slugs are unrepresentable.\n- read_state_at_oid returns a typed LoadedStore that carries verification state explicitly (e.g. LoadedStore { meta: StoreMeta, state }). Callers must handle Legacy vs V1 (no silent fallthrough).\n\nScatter fit\n- Put all version + checksum validation in wire.rs; callers should not need to re-check.\n- Remove ad-hoc Option<String> plumbing for root_slug; let the type tell the truth.\n\nFiles\n- crates/beads-rs/src/git/wire.rs\n- crates/beads-rs/src/git/sync.rs\n- crates/beads-rs/src/daemon/git_worker.rs\n- crates/beads-rs/src/daemon/migration.rs\n- crates/beads-rs/src/daemon/core.rs","acceptance_criteria":"Acceptance\n- parse_meta rejects unsupported format_version with a clear error.\n- v1 meta without full checksum set fails to parse.\n- root_slug is validated on load and stored as BeadSlug (invalid slug cannot reach mutation_engine).\n- read_state_at_oid exposes meta verification state via types (Legacy vs V1) and callers compile-fail until they handle it.\n- Add tests for unsupported version, missing checksums, invalid root_slug, and a happy-path v1 meta with checksums.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-wxaq-1","content":"Rendering should stay in the command files themselves; do not move rendering into shared helpers.","author":"darin@darins-Mac-Studio-2.local","at":[1769570923199,0]},{"id":"legacy-notes","content":"Rendering should stay in the command files themselves; do not move rendering into shared helpers.","author":"darin@darinsmcstudio2.lan","at":[1769571514034,0]}],"_at":[1769571514034,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769571514034,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769571514034,0]}
{"id":"bd-wy1","created_at":[1768444225712,0],"created_by":"darin@darinsmcstudio2.lan","title":"Store lock heartbeat is never updated","description":"**Problem**\nStore lock metadata includes `last_heartbeat_ms`, but the daemon never updates it. That makes the lock look stale even when the daemon is healthy, and it undermines the intended recovery UX.\n\n**Signals / Evidence**\n- `StoreLockMeta` contains `last_heartbeat_ms` (`src/daemon/store_lock.rs`).\n- `StoreLock::update_heartbeat` exists but is never called (no references).\n\n**Why this hurts velocity**\nOperators will get misleading diagnostics and may delete live locks. It’s also a sign of unexercised code paths.","design":"**Design**\n- Add a small periodic heartbeat in the daemon loop (e.g., every 10s) that calls `StoreLock::update_heartbeat`.\n- If we don’t want heartbeats, remove the field + method entirely to avoid lying metadata.","acceptance_criteria":"- [ ] `last_heartbeat_ms` is regularly updated while the daemon holds the lock, or the field is removed.\n- [ ] Tests or logs demonstrate the heartbeat behavior.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"duplicate of bd-3m5.87","_at":[1768448823419,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768448823419,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-x0go","created_at":[1768778626426,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add BD_TEST_FAST to shorten debounces/backoffs/keepalives for tests","description":"Introduce a test-only config override (e.g., BD_TEST_FAST=1) to reduce sync debounce (500ms), checkpoint debounce/max-interval, replication backoff/keepalive, and other long waits when BD_TESTING. Apply in config merge or daemon defaults so integration tests don’t pay production timers.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768811732562,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768811732562,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768811732562,0]}
{"id":"bd-x1z","created_at":[1766116456666,0],"created_by":"darin@darinsmcstudio2.lan","title":"Remote URL normalization should canonicalize ssh/https variants","description":"**Problem**\nState sharing keys by normalized remote URL, but normalization is currently minimal (trim slash + parse). ssh/https variants (e.g., `git@github.com:org/repo` vs `https://github.com/org/repo`) can create split state.\n\n**Design**\nCanonicalize host + path across ssh/https/file URLs. Consider using `git2::Remote::url()` parsing or a dedicated normalizer with test cases.\n\n**Acceptance**\n- [ ] ssh/https URLs normalize to same key\n- [ ] Test coverage for common URL variants\n\n**Files:** src/daemon/remote.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1766129877018,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766129877018,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-x2tt","created_at":[1770952695438,0],"created_by":"darin@darinsmcstudio2.lan","title":"Backup ref stale-lock cleanup fallback when PID/age checks are unavailable","description":"**Problem**\\nBackup ref lock cleanup is policy-gated by age and PID liveness. When lock metadata cannot be read or PID liveness is unknown repeatedly, stale lock files can survive and keep backup create/delete in best-effort skip mode.\\n\\n**Design**\\nAdd a bounded fallback strategy for long-lived unknown locks (for example: retry budget + age ceiling + explicit telemetry) that preserves correctness while preventing indefinite stale-lock accumulation.\\n\\n**Acceptance**\\n- [ ] Unknown/metadata-failed lockfiles eventually become recoverable under a bounded, auditable policy\\n- [ ] No corruption or active-lock clobbering in tests\\n- [ ] Metrics distinguish normal stale cleanup vs fallback path\\n\\n**Files:** crates/beads-rs/src/git/sync.rs, crates/beads-daemon/src/metrics.rs","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1770952695438,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-x4f","created_at":[1766121917662,0],"created_by":"darin@darinsmcstudio2.lan","title":"Persist WAL in durable data dir","description":"**Problem**\\nWAL files are stored under the daemon socket dir (often XDG_RUNTIME_DIR). Those locations are ephemeral and can be cleared on reboot/cleanup. If sync hasn't completed, a reboot can drop WAL and lose acknowledged mutations.\\n\\n**Design**\\nStore WALs in a persistent data directory (XDG_DATA_HOME/beads-rs/wal). Keep socket in runtime dir but decouple WAL path. Add migration from legacy runtime WAL dir to new persistent dir on daemon startup, preserving newer WAL if both exist. Allow env override for tests.\\n\\n**Acceptance**\\n- [ ] WAL persists across daemon restarts/reboots (no runtime dir dependency).\\n- [ ] Legacy runtime WALs are migrated or preserved with a warning.\\n- [ ] Tests cover migration + legacy format.\\n- [ ] Tests pass.\\n\\n**Files:** src/daemon/wal.rs, src/daemon/run.rs, src/daemon/ipc.rs","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"persist wal in data dir","assignee":"darin@dusk","_at":[1766122193695,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1766122193695,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1766122193695,0]}
{"id":"bd-x4zj","created_at":[1769309222772,0],"created_by":"darin@darinsmcstudio2.lan","title":"Move direct println\\!() calls from CLI handlers to render.rs","description":"**Problem**\nSome CLI command handlers use direct `println\\!()` instead of going through render.rs, causing:\n- Inconsistent output formatting\n- Untestable output (no way to capture/verify)\n- Mixed patterns: some commands use `render::render_*()`, others use `print_ok()`, others raw println\n\nExamples found:\n- `src/cli/commands/close.rs:19`: `println\\!(\"✓ Closed {}: {}\", id.as_str(), reason_str);`\n- `src/cli/commands/update.rs:122`: direct println for success message\n- Similar patterns in reopen.rs, delete.rs, claim.rs, unclaim.rs\n\n**Design**\n1. Audit all command handlers in `src/cli/commands/` for direct println usage\n2. For each, either:\n   a. Add a `render_<command>()` function to render.rs, OR\n   b. Use existing `print_ok()` wrapper if output is simple \"✓ Done\" style\n3. Ensure JSON mode (`ctx.json`) is handled consistently — render functions should check this\n\nExample refactor for close.rs:\n```rust\n// Before (close.rs:19)\nprintln\\!(\"✓ Closed {}: {}\", id.as_str(), reason_str);\n\n// After (render.rs)\npub fn render_close(id: &BeadId, reason: Option<&str>) {\n    let reason_str = reason.map(|r| format\\!(\" ({})\", r)).unwrap_or_default();\n    println\\!(\"✓ Closed {}{}\", id.as_str(), reason_str);\n}\n\n// close.rs\nrender::render_close(&id, args.reason.as_deref());\n```\n\n**Acceptance**\n- [ ] No direct println\\!() in src/cli/commands/*.rs (except for --json output via print_json)\n- [ ] All human-readable output goes through render.rs functions\n- [ ] render.rs has consistent pattern: render_<command>() for each command with custom output\n- [ ] cargo clippy passes\n- [ ] cargo test passes\n\n**Files:** src/cli/commands/close.rs, src/cli/commands/update.rs, src/cli/commands/reopen.rs, src/cli/commands/delete.rs, src/cli/commands/claim.rs, src/cli/commands/unclaim.rs, src/cli/render.rs","acceptance_criteria":"- [ ] No direct println! in crates/beads-rs/src/cli/commands/*.rs (stdout via print_line/print_ok/print_json)\\n- [ ] Human-readable output stays in command files (local render_* helpers as needed)\\n- [ ] cargo clippy passes\\n- [ ] cargo test passes","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-x4zj-1","content":"Per user: keep rendering helpers in the command files; avoid central render.rs. Replace println! with local render_* helpers + print_ok/print_json.","author":"darin@darins-Mac-Studio-2.local","at":[1769562626979,0]},{"id":"go-comment-bd-x4zj-2","content":"Per user: keep rendering helpers in the command files; avoid central render.rs. Replace println! with local render_* helpers + print_ok/print_json.","author":"darin@darins-Mac-Studio-2.local","at":[1769562879544,0]},{"id":"go-comment-bd-x4zj-3","content":"Decision: keep rendering in the command files themselves; avoid moving output into render.rs or other centralized render helpers.","author":"darin@darins-Mac-Studio-2.local","at":[1769564808968,0]},{"id":"go-comment-bd-x4zj-4","content":"Reaffirmed: keep rendering in the command files; avoid central render.rs helpers.","author":"darin@darins-Mac-Studio-2.local","at":[1769577749197,0]},{"id":"legacy-notes","content":"Per user: keep rendering helpers in the command files; avoid central render.rs. Replace println! with local render_* helpers + print_ok/print_json.\n\nPer user: keep rendering helpers in the command files; avoid central render.rs. Replace println! with local render_* helpers + print_ok/print_json.\n\nDecision: keep rendering in the command files themselves; avoid moving output into render.rs or other centralized render helpers.\n\nReaffirmed: keep rendering in the command files; avoid central render.rs helpers.","author":"darin@darinsmcstudio2.lan","at":[1769577749197,0]}],"_at":[1769577749197,0],"_by":"darin@darinsmcstudio2.lan","_v":{"workflow":[[1769563302921,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1769563302921,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769577749197,0]}
{"id":"bd-x5vl","created_at":[1769573989704,0],"created_by":"darin@darinsmcstudio2.lan","title":"Canonical set types for unordered collections","description":"**Problem**\nUnordered collections are represented as raw `Vec`/`String` in multiple layers, and each call site re-sorts/dedups to get canonical order.\n\nExamples:\n- `normalize_namespaces` in `crates/beads-rs/src/git/checkpoint/export.rs`\n- `normalize_namespaces` in `crates/beads-rs/src/daemon/repl/session.rs`\n- `canonical_deps` in `crates/beads-rs/src/daemon/mutation_engine.rs`\n- `DepSpec::parse_list` returns raw `Vec<DepSpec>` in `crates/beads-core/src/dep.rs`\n\nThis is scatter + drift: the \"same\" collection can have different ordering/dup semantics depending on which normalizer you remembered to call.\n\n**Files:**\n- `crates/beads-core/src/dep.rs`\n- `crates/beads-rs/src/git/checkpoint/export.rs`\n- `crates/beads-rs/src/daemon/repl/session.rs`\n- `crates/beads-rs/src/daemon/mutation_engine.rs`\n- `crates/beads-core/src/collections.rs` (if adding set types)","design":"**Design**\nIntroduce canonical set types for frequently normalized collections and use them across boundaries.\n\nConcrete plan:\n1) Add canonical set wrappers in `beads-core`:\n   - `NamespaceSet`\n   - `DepSpecSet`\n   - `LabelSet` (if not already modeled)\n2) Construction performs sort + dedup and enforces any domain constraints.\n3) Provide stable iteration order and `Serialize`/`Deserialize` as arrays.\n4) Replace ad-hoc normalizers (`normalize_namespaces`, `canonical_deps`, etc.) with these types.\n5) Update APIs to accept/return the canonical set types, not raw vectors.\n\n**Design Notes**\n- For performance, the set can store a `Vec` plus a flag that it is already canonical.\n- Provide `from_vec_unchecked` only for trusted internal uses (tests/fixtures).","acceptance_criteria":"**Acceptance**\n- [ ] Canonical set types exist in `beads-core` and enforce ordering/dedup at construction.\n- [ ] All current normalizer helpers are removed or reduced to thin adapters to the new types.\n- [ ] Checkpoint export, repl session, and mutation engine use canonical sets instead of raw vectors.\n- [ ] Tests cover ordering/dedup stability and JSON roundtrip for at least two set types.","priority":2,"type":"chore","labels":{"entries":{"consistency":[{"replica":"da0c1333-f460-e74a-5b00-d977fa78e30c","counter":17898955235301714852}],"scatter":[{"replica":"8073d7b3-f7d3-5b03-e5cc-4864714584cc","counter":4859875972913792609}],"types":[{"replica":"70b255b2-30eb-fac0-7c5b-36191fb6964f","counter":11664029674433400982}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769761162486,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769761162486,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769761162486,0]}
{"id":"bd-xbje","created_at":[1769496015985,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode durability receipt/proof invariants in types","description":"**Problem**\n`DurabilityReceipt` allows internally inconsistent states: `DurabilityOutcome` is independent from `DurabilityProofV1`, so contradictory combinations compile. Examples:\n- `outcome=Achieved { requested: ReplicatedFsync{k}, achieved: ReplicatedFsync{k} }` while `durability_proof.replicated=None`.\n- `outcome=Achieved` with `acked_by.len() < k`.\n- `outcome=Pending { requested: LocalFsync }` (nonsensical: local fsync is immediate).\n\nBecause construction is ad‑hoc in multiple places, the compiler cannot prevent broken receipts. This can mislead clients about durability guarantees and cause incorrect retry behavior.\n\nKey refs:\n- `crates/beads-core/src/durability.rs:137` — receipt structure.\n- `crates/beads-core/src/durability.rs:126` — outcome enum (no tie to proof).\n- `crates/beads-rs/src/daemon/durability_coordinator.rs` — constructs receipts based on convention.\n\n**Impact**\nIncorrect durability reporting and client behavior; high severity for correctness and ops safety.","design":"**Design (opinionated)**\nCouple proof and outcome in the type system so inconsistent receipts are unrepresentable.\n\nOption A (preferred): split receipt by durability class.\n- `enum DurabilityReceipt { Local(LocalReceipt), Replicated(ReplicatedReceipt) }`\n- `struct LocalReceipt { proof: LocalFsyncProof, min_seen: Watermarks<Applied>, ... }`\n- `struct ReplicatedReceipt { proof: ReplicatedProof, outcome: ReplicatedOutcome, ... }`\n- `ReplicatedOutcome` is either `Pending { requested: NonZeroU32 }` or `Achieved { requested, achieved }` and always *requires* `ReplicatedProof`.\n- Enforce `acked_by.len() >= k` at construction for Achieved.\n\nOption B: make `DurabilityOutcome` carry its proof and remove the separate `durability_proof` field entirely.\n\nWhichever variant we pick, construction should be via constructors that validate invariants; all ad‑hoc struct literals should go away.","acceptance_criteria":"**Acceptance**\n- [ ] It is impossible to construct a receipt with outcome/proof mismatch (compile‑time enforced).\n- [ ] Achieved replicated receipts require `acked_by.len() >= k` by construction.\n- [ ] Pending outcomes are only possible for replicated durability (not local fsync).\n- [ ] All receipt construction sites compile using the new constructors; no raw struct literals remain.\n- [ ] Tests cover mismatch rejection and correct merge behavior with the new types.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769523799138,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769523799138,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769523799138,0]}
{"id":"bd-xert","created_at":[1768723112513,0],"created_by":"darin@darinsmcstudio2.lan","title":"Missing realtime_types_sketch.rs referenced in realtime workflow","description":"Task instructions reference beads_stateright_models/src/realtime_types_sketch.rs but file is missing in repo. Either add the type sketch file or update docs/instructions to point to the correct location.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768727115197,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768727115197,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768727115197,0]}
{"id":"bd-xhdd","created_at":[1769309222461,0],"created_by":"darin@darinsmcstudio2.lan","title":"Extract get_or_default_namespace() helper in daemon/core.rs","description":"**Problem**\nThe same 4-line state access pattern appears 50+ times across executor.rs, query_executor.rs, and other daemon modules:\n\n```rust\nlet empty_state = CanonicalState::new();\nlet state = self.store_runtime(&proof)?.state.get(&namespace).unwrap_or(&empty_state);\n```\n\nVariations include:\n- `self.store_runtime(&proof)?` (immutable)\n- `self.store_runtime_mut(&proof)?` (mutable)\n- `.state.get(&namespace).unwrap_or(&empty_state)` vs `.state.ensure_namespace(ns)`\n\nThis duplication adds ~100 lines of boilerplate and makes the access pattern inconsistent.\n\n**Design**\nAdd two helper methods to `Daemon` impl in `src/daemon/core.rs`:\n\n```rust\nimpl Daemon {\n    /// Get namespace state immutably, returning empty state if namespace does not exist\n    fn namespace_state(&self, proof: &LoadedStore, ns: &NamespaceId) -> Result<&CanonicalState, OpError> {\n        static EMPTY: CanonicalState = CanonicalState::new(); // or use OnceCell\n        Ok(self.store_runtime(proof)?\n            .state\n            .get(ns)\n            .unwrap_or(&EMPTY))\n    }\n\n    /// Get or create namespace state mutably\n    fn namespace_state_mut(&mut self, proof: &LoadedStore, ns: NamespaceId) -> Result<&mut CanonicalState, OpError> {\n        Ok(self.store_runtime_mut(proof)?\n            .state\n            .ensure_namespace(ns))\n    }\n}\n```\n\nThen replace all occurrences in:\n- `src/daemon/executor.rs` (~15 occurrences)\n- `src/daemon/query_executor.rs` (~20 occurrences)\n- `src/daemon/mutation_engine.rs` (~10 occurrences)\n\n**Acceptance**\n- [ ] Helper methods added to Daemon impl\n- [ ] All `store_runtime(&proof)?.state.get(&namespace).unwrap_or(&empty)` patterns replaced\n- [ ] All `store_runtime_mut(&proof)?.state.ensure_namespace(ns)` patterns replaced\n- [ ] cargo clippy passes\n- [ ] cargo test passes\n\n**Files:** src/daemon/core.rs, src/daemon/executor.rs, src/daemon/query_executor.rs, src/daemon/mutation_engine.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769559143502,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769559143502,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769559143502,0]}
{"id":"bd-xmr","created_at":[1765744420750,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add with_mutation helper for borrow-checker friendly mutations","description":"**Problem**\nBorrow checker forces this awkward pattern:\n1. Borrow `repo_state` to check something\n2. Need `&mut self` to tick the clock\n3. Drop borrow, re-borrow, and `unwrap()` because \"I proved it exists earlier\"\n\n**Design**\nWrap mutation in a helper that ticks before handing out the borrow:\n```rust\nimpl Daemon {\n    fn with_mutation<R>(\n        &mut self,\n        loaded: &LoadedRemote,  // or repo: &Path + git_tx\n        f: impl FnOnce(&mut RepoState, Stamp) -> Result<R, OpError>,\n    ) -> Result<R, OpError> {\n        let write = self.clock_mut().tick();\n        let stamp = Stamp { at: write, by: self.actor().clone() };\n        let rs = self.repo_state_mut(loaded);\n        f(rs, stamp)\n    }\n}\n```\n\nNow `apply_update`/`apply_close`/`apply_claim` can do \"check + mutate\" in one borrow.\n\n**Design Notes**\n- Depends on `LoadedRemote` existing (bd-xxx) OR can take repo+git_tx and call ensure_repo_loaded internally\n- Consider whether stamp should be passed in or returned for callers that need it after\n- May want variants: `with_mutation` vs `with_mutation_loaded` depending on whether repo already loaded\n\n**Acceptance**\n- [ ] `with_mutation` helper exists in `src/daemon/mod.rs`\n- [ ] At least one executor method uses it (start with simplest case like `apply_claim`)\n- [ ] Pattern eliminates the \"check, drop, tick, re-fetch, unwrap\" sequence\n- [ ] Tests pass\n\n**Files:** src/daemon/mod.rs, src/daemon/executor.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Added with_mutation helper to Daemon, refactored apply_claim to use it. Pattern eliminates the 'check, drop, tick, re-fetch, unwrap' sequence.","assignee":"darin@dusk","_at":[1765786547553,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765786547553,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765786547553,0]}
{"id":"bd-xo3o","created_at":[1769481339433,0],"created_by":"darin@darinsmcstudio2.lan","title":"DRY read preamble in daemon query executor","description":"**Problem**\n`crates/beads-rs/src/daemon/query_executor.rs` repeats the same read setup in nearly every query:\n`ensure_repo_fresh → normalize_read_consistency → check_read_gate → store_runtime/state lookup`.\nThis repetition adds risk: any change to read-gate, read consistency normalization, or state lookup must be edited in many places, and the error mapping must stay identical everywhere.\n\n**Design**\nIntroduce a single helper that performs the standard read preamble and hands a normalized context into a closure.\n\n1) Add a lightweight context struct local to `query_executor.rs`:\n```rs\nstruct ReadCtx<'a> {\n    remote: LoadedStore,\n    read: NormalizedReadConsistency,\n    store: &'a StoreRuntime,\n    state: &'a CanonicalState,\n    repo_state: Option<&'a GitLaneState>,\n}\n```\n- `repo_state` is optional to support `query_status` (only it needs git lane details). Other queries can ignore it.\n- `state` should be the namespace-selected state (fall back to `CanonicalState::new()` if missing).\n\n2) Add helper on `Daemon` in `query_executor.rs`:\n```rs\nfn with_read_ctx<F>(\n    &mut self,\n    repo: &Path,\n    read: ReadConsistency,\n    git_tx: &Sender<GitOp>,\n    want_repo_state: bool,\n    f: F,\n) -> Response\nwhere\n    F: for<'a> FnOnce(ReadCtx<'a>) -> Result<ResponsePayload, OpError>,\n```\nImplementation details:\n- Call `ensure_repo_fresh`, `normalize_read_consistency`, and `check_read_gate` in that order.\n- Pull `store_runtime` and compute `state` for `read.namespace()`.\n- If `want_repo_state` is true, fetch `git_lane_state` and include it.\n- Convert the closure’s `Result` into `Response::ok` / `Response::err_from` (preserving existing error mapping).\n\n3) Convert all `query_*` methods to use the helper:\n- `query_show`, `query_show_multiple`, `query_list`, `query_ready`, `query_dep_tree`, `query_dep_cycles`, `query_deps`, `query_notes`, `query_blocked`, `query_stale`, `query_count`, `query_deleted`, `query_epic_status`, `query_validate`.\n- `query_status` should pass `want_repo_state = true` and use `ctx.repo_state`.\n\n4) Remove duplicated preamble blocks from all queries.\n\n**Design Notes**\n- Keep behavior identical: same order of operations, same error returns.\n- Keep `CanonicalState::new()` fallback behavior for missing namespaces.\n- Avoid borrow checker pain by keeping the helper and `ReadCtx` inside `query_executor.rs` and using a closure (`for<'a>`) so `state`/`store` borrows don’t escape.\n\n**Files**\n- `crates/beads-rs/src/daemon/query_executor.rs`","acceptance_criteria":"- [ ] All query handlers in `crates/beads-rs/src/daemon/query_executor.rs` call a shared `with_read_ctx` (or equivalent) helper.\n- [ ] No query method manually repeats the full read preamble sequence.\n- [ ] Read gate behavior, error mapping, and namespace selection are unchanged.\n- [ ] `query_status` still includes repo state–derived warnings/fields and uses the helper with `want_repo_state`.\n- [ ] `cargo test` passes.","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769511605294,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769511605294,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769511605294,0]}
{"id":"bd-xw8l","created_at":[1768778972354,0],"created_by":"darin@darinsmcstudio2.lan","title":"RealtimeFixture start_daemon uses bd init; switch to IPC Init","description":"tests/integration/fixtures/realtime.rs start_daemon shells out to initialized. Replace with IpcClient::send_request(Request::Init{repo}) using autostart so we avoid a CLI process spawn in realtime tests.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768800807875,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768800807875,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768800807875,0]}
{"id":"bd-xyce","created_at":[1769495892464,0],"created_by":"darin@darinsmcstudio2.lan","title":"OrSet from_parts allows invalid CRDT state","description":"**Problem**\n`OrSet::from_parts` constructs an OR‑Set from arbitrary `entries` + `cc` with no validation or normalization. That means invalid CRDT states can enter core from untrusted decode/import paths and still pass the type checker.\n\nInvalid but representable states today:\n- Dots dominated by `cc` still present in `entries` (should be pruned).\n- The same dot appears under multiple values (collision unresolved).\n- Empty dot sets remain as live values.\n- `cc` not normalized, leaving redundant dots / inconsistent dominance.\n\nWe currently call `OrSet::from_parts` from wire + checkpoint + legacy snapshot decode paths, so malformed data can deterministically corrupt CRDT state.\n\nKey refs:\n- `crates/beads-core/src/orset.rs:208` — unchecked constructor.\n- `crates/beads-rs/src/git/wire.rs:669` — wire decode uses it.\n- `crates/beads-rs/src/git/checkpoint/import.rs:834` / `:854` — checkpoint import uses it.\n- `crates/beads-rs/src/daemon/wal_legacy_snapshot.rs:103` / `:337` — legacy snapshot uses it.\n\n**Impact**\nCore CRDT corruption from untrusted inputs. This is P0: it breaks determinism and can persist invalid state through joins/merges.","design":"**Design (opinionated)**\nMake OR‑Set construction validated/typed and remove unchecked construction from public API.\n\n1) Introduce a validated constructor:\n- `pub fn try_from_parts(entries, cc) -> Result<OrSet<Normalized>, OrSetError>`.\n- Validation steps (must be deterministic):\n  - `cc.normalize()`\n  - prune dominated dots\n  - resolve dot collisions deterministically\n  - drop empty entries\n  - optionally error if duplicate dots are found under multiple values *before* normalization (prefer strictness for network inputs)\n\n2) Typestate or wrapper:\n- `OrSet<Normalized>` vs `OrSet<Raw>` (or `OrSetParts` -> `OrSet`), so only normalized sets can enter `LabelState::from_parts` / `DepStore::from_parts`.\n- Make the unchecked `from_parts` `pub(crate)` or delete it.\n\n3) Boundary‑specific behavior:\n- For network/wire decode: reject invalid OR‑Sets with a clear error (fail fast).\n- For legacy/import paths: provide an explicit `normalize_for_import` that returns a normalized set but logs/warns (so corruption doesn’t leak silently).\n\n4) Update all decode/import call sites to use the validated constructor.\n\nThis turns “oops, forgot to normalize” into a compile error.","acceptance_criteria":"**Acceptance**\n- [ ] There is no public API that can construct an `OrSet` from raw parts without validation.\n- [ ] All decode/import paths use validated construction (wire, checkpoint import, WAL legacy snapshot).\n- [ ] Invalid OR‑Set input fails fast at the boundary (or is explicitly normalized only in migration paths).\n- [ ] Tests cover: dominated dot pruning, dot collision resolution, empty‑entry removal, and rejection of duplicate‑dot collisions.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769501517889,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769501517889,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769501517889,0]}
{"id":"bd-xyeh","created_at":[1769815094397,0],"created_by":"darin@darinsmcstudio2.lan","title":"Placeholder: ze0x epic deferred until ready","description":"","priority":4,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1769815094397,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-y06u","created_at":[1769573188480,0],"created_by":"darin@darinsmcstudio2.lan","title":"Single authoritative read projection","description":"**Problem**\nThe codebase maintains multiple parallel \"view\" shapes for bead state:\n- `BeadView` in `crates/beads-core/src/bead.rs`\n- API read models (`Issue`, `IssueSummary`) in `crates/beads-api/src/issues.rs`\n- Go-compat read model in `crates/beads-rs/src/compat/go_schema.rs`\n- Git wire view in `crates/beads-rs/src/git/wire.rs`\n- Checkpoint wire view in `crates/beads-core/src/wire_bead.rs`\n\nAny field change requires updating multiple representations and conversions, spreading domain knowledge across crates. This is translation + scatter and drives drift risk.\n\n**Files:**\n- `crates/beads-core/src/bead.rs`\n- `crates/beads-api/src/issues.rs`\n- `crates/beads-rs/src/compat/go_schema.rs`\n- `crates/beads-rs/src/git/wire.rs`\n- `crates/beads-core/src/wire_bead.rs`","design":"**Design**\nIntroduce a single authoritative read projection for beads and derive all external views from it.\n\nConcrete plan:\n1) Define `BeadProjection` (or similar) in `beads-core` with the normalized read fields needed across API/CLI/compat (id, title, status, labels, claims, timestamps, deps metadata, etc.).\n2) Add `impl From<&BeadView> for BeadProjection` (or `BeadProjection::from_view`) so projection is computed, not stored.\n3) Update API models (`Issue`, `IssueSummary`) to derive from `BeadProjection` rather than re-reading `BeadView` directly.\n4) Update Go compatibility serialization and git/checkpoint snapshot generation to use `BeadProjection` as their input.\n5) Remove ad-hoc, repeated field extraction where possible (especially where the same fields are recomputed in multiple places).\n\n**Design Notes**\n- Keep the projection focused on read surfaces; it should not become a second canonical state. It is derived, not stored.\n- Where a view needs data not in the projection (e.g., notes text concatenation), make that explicitly a local computation.","acceptance_criteria":"**Acceptance**\n- [ ] A single read projection type exists in `beads-core` and is derived from `BeadView`.\n- [ ] API `Issue` and `IssueSummary` are created from the projection, not by re-deriving fields from `BeadView`.\n- [ ] Go compat and git/checkpoint snapshot generation uses the projection as input.\n- [ ] Removed or consolidated redundant conversions across crates.\n- [ ] Tests cover projection correctness for key fields (status, claim, timestamps, labels).","priority":3,"type":"chore","labels":{"entries":{"scatter":[{"replica":"559b20a3-9581-648d-4667-ea46e152bf1f","counter":14870053164861002409}],"tech-debt":[{"replica":"325712e0-45b5-0d67-d915-462acb9fa10a","counter":4136133385536648194}],"translation":[{"replica":"bbb1fe9e-cd3c-60ea-544c-997e456a9a48","counter":6831323290834555527}]},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769775226614,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769775226614,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769775226614,0]}
{"id":"bd-y2u2","created_at":[1768672332003,0],"created_by":"darin@darinsmcstudio2.lan","title":"Realtime: multi-process replication e2e harness","description":"**Problem**\nReplication e2e uses a single-process harness. It does not exercise OS-level process isolation, socket paths, file locks, or real daemon lifecycle races, so confidence in real deployments is incomplete.","design":"**Design**\n- Build a multi-process harness that spawns separate `bd` daemons per node with isolated runtime/data/config dirs under ./tmp.\n- Drive mutations and admin/status through IPC (no in-process shortcuts).\n- Add slow e2e scenarios: concurrent startup, crash/restart, and tailnet fault injection across processes.","acceptance_criteria":"**Acceptance**\n- [ ] Multi-process harness exists and is reusable for new replication tests.\n- [ ] At least one slow e2e covers crash/restart + tailnet faults across processes.\n- [ ] Tests write only under ./tmp and pass with `cargo test --features slow-tests`.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768679877853,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768679877853,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768679877853,0]}
{"id":"bd-y5c","created_at":[1770939350580,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add perf regression guardrail using hotpath benchmark artifacts","description":"Problem: hotpath regressions are hard to catch without a standardized before/after compare in normal workflow.\\n\\nDesign:\\n- Add CI or pre-merge automation path that runs hotpath benchmark in controlled mode and reports deltas from baseline artifacts.\\n- Include thresholds for major regressions on ready/list/show/status hotpaths.\\n\\nAcceptance:\\n- [ ] Automated path runs benchmark + compare\\n- [ ] Delta report is persisted as artifact\\n- [ ] Regression threshold policy documented","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1770940602751,0],"_by":"darin@darinsmcstudio2.lan","_v":{"acceptance_criteria":[[1770939350580,0],"darin@darinsmcstudio2.lan"],"claim":[[1770939350580,0],"darin@darinsmcstudio2.lan"],"description":[[1770939350580,0],"darin@darinsmcstudio2.lan"],"design":[[1770939350580,0],"darin@darinsmcstudio2.lan"],"estimated_minutes":[[1770939350580,0],"darin@darinsmcstudio2.lan"],"external_ref":[[1770939350580,0],"darin@darinsmcstudio2.lan"],"priority":[[1770939350580,0],"darin@darinsmcstudio2.lan"],"source_repo":[[1770939350580,0],"darin@darinsmcstudio2.lan"],"title":[[1770939350580,0],"darin@darinsmcstudio2.lan"],"type":[[1770939350580,0],"darin@darinsmcstudio2.lan"]},"closed_at":[1770940602751,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-y8x","created_at":[1765744322054,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add serde boundary validation for identity types (BeadId, ActorId, NoteId, Priority)","description":"Use `#[serde(try_from, into)]` to validate at deserialization boundary instead of scattered runtime checks.\n\n**Problem:** These types use `#[serde(transparent)]` which accepts any value, then validation happens later in handlers.\n\n**Solution:** Follow the `BranchName` pattern (identity.rs:363-416):\n```rust\n#[serde(try_from = \"String\", into = \"String\")]\npub struct BeadId(String);\n\nimpl TryFrom<String> for BeadId {\n    type Error = CoreError;\n    fn try_from(s: String) -> Result<Self, Self::Error> {\n        Self::parse(&s)\n    }\n}\n\nimpl From<BeadId> for String {\n    fn from(id: BeadId) -> String { id.0 }\n}\n```\n\nApply to: BeadId, ActorId, NoteId, Priority (use `try_from = \"u8\"` for Priority).\n\n**Impact:** Invalid IDs fail at deserialization rather than scattered through handlers. Request types can use `BeadId` directly instead of `String`.\n\n**Files:** src/core/identity.rs, src/core/domain.rs","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Added serde boundary validation via try_from/into for BeadId, ActorId, NoteId, and Priority. Invalid values now fail at deserialization rather than scattered through handlers. Added 6 tests for the new validation behavior.","assignee":"darin@dusk","_at":[1765786005799,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765786005799,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765786005799,0]}
{"id":"bd-yax6","created_at":[1769495028619,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode workflow/claim snapshot invariants in WireBeadFull","description":"**Problem**\n`WireBeadFull` includes redundant workflow/claim timestamps (`closed_at/closed_by`, `assignee_at`) that can conflict with the canonical LWW stamps derived from `workflow`/`claim`. Conversions ignore these fields, which means the wire type can represent contradictory states. This violates “information holds its shape” and creates a lying API for checkpoints/snapshots.\n\nKey references:\n- `crates/beads-core/src/wire_bead.rs:303` — `WireBeadFull` fields.\n- `crates/beads-core/src/composite.rs:99` — closure/claim timestamps are derived from LWW stamps.\n\nSeverity: snapshot import/export can silently accept inconsistent data; types do not encode invariants.","design":"**Design**\nMake workflow/claim snapshot representations canonical and non‑redundant.\n\nOption A (sum types):\n- Replace `status + closed_*` with `WorkflowSnapshot`:\n  - `Open {}`\n  - `InProgress {}`\n  - `Closed { at: WireStamp, by: ActorId, reason: Option<String>, on_branch: Option<String> }`\n- Replace `assignee + assignee_at + assignee_expires` with `ClaimSnapshot`:\n  - `Unclaimed {}`\n  - `Claimed { assignee: ActorId, at: WireStamp, expires: Option<WallClock> }`\n\nOption B (derived-only):\n- Remove `closed_at/closed_by` and `assignee_at` from `WireBeadFull`; derive from stamps only.\n\nGiven compatibility needs, Option A keeps wire expressiveness while encoding invariants.\n\nMigration:\n- Adjust serde for backward compatibility (accept old fields, emit new shape).\n- Update `WireBeadFull::from_view` and `From<WireBeadFull> for Bead` accordingly.","acceptance_criteria":"- [ ] `WireBeadFull` cannot represent conflicting workflow/claim timestamps.\n- [ ] Import/export preserves canonical stamps without redundancy.\n- [ ] Backward compatibility path exists or explicit migration is documented.\n- [ ] Tests cover at least one inconsistent legacy payload being rejected or normalized.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769517753954,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769517753954,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769517753954,0]}
{"id":"bd-ycab","created_at":[1768778996787,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add BD_TEST_DISABLE_GIT_SYNC to skip git sync in tests","description":"Background git sync can be expensive in integration tests that don't assert git behavior. Add a test-only env (e.g., BD_TEST_DISABLE_GIT_SYNC=1) to bypass scheduling/starting sync unless explicitly enabled. Update realtime/daemon fixtures to set it by default; enable in git-specific tests as needed.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768806377683,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768806377683,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768806377683,0]}
{"id":"bd-ydi","created_at":[1765689969686,0],"created_by":"darin@darinsmcstudio2.lan","title":"Daemon restart on client version mismatch","description":"## What's Wrong\nIf an older `bd daemon run` process is already running, a newer `bd` CLI will connect to it and may hit confusing errors when behavior/protocol expectations change (e.g. bead ID parsing rules).\n\n## Where\n- src/daemon/ipc.rs: client connects to existing socket without verifying daemon version\n- src/daemon/run.rs: daemon is spawned from current executable only when no daemon is reachable\n\n## Why It Matters\nUpgrading `bd` can silently keep using an older daemon until the socket disappears. This can break new features (like non-`bd-` id slugs) and makes failures look like user input errors.\n\n## Suggested Fix\nAdd a lightweight handshake (e.g. Request::Ping returns daemon version/build hash). If mismatch with client, have client request shutdown + respawn, or refuse with a clear message.\n\n---\nDiscovered while: implementing beads-go migration root slug support.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765775066747,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765775066747,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765775066747,0]}
{"id":"bd-yiof","created_at":[1768506367556,0],"created_by":"darin@darinsmcstudio2.lan","title":"Deduplicate WAL record header base length constant","description":"**Problem**\n`mutation_engine.rs` defines `RECORD_HEADER_BASE_LEN = 88`, duplicating the canonical constant in `wal/record.rs`. If the WAL header layout changes, `estimated_record_bytes` will silently become wrong, causing brittle sizing logic.\n\n**Files**\n- src/daemon/mutation_engine.rs\n- src/daemon/wal/record.rs\n","design":"**Design**\n- Expose a shared constant or accessor from `wal/record.rs` (e.g., `RecordHeader::base_len()` or `RECORD_HEADER_BASE_LEN` as `pub(crate)`).\n- Replace the magic number in `mutation_engine.rs` with the shared value.","acceptance_criteria":"- [ ] No duplicate hard-coded record header length remains.\n- [ ] `estimated_record_bytes` uses the shared record header size.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768535163198,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768535163198,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768535163198,0]}
{"id":"bd-yluk","created_at":[1768778978223,0],"created_by":"darin@darinsmcstudio2.lan","title":"ReplRig Node::start_daemon uses bd status; switch to IPC ping","description":"tests/integration/fixtures/repl_rig.rs Node::start_daemon runs \nIssue Database Status\n=====================\n\nSummary:\n  Total Issues:      439\n  Open:              75\n  In Progress:       1\n  Blocked:           0\n  Closed:            363\n  Ready to Work:     76\n  Deleted:           3 (tombstones)\n\nSync:\n  dirty:             false\n  in_progress:       false\n  last_sync:         2026-01-18 23:29\n  consecutive_failures: 0 (CLI spawn) just to autostart. Use IpcClient::send_request(Request::Ping) or Request::Status to autostart + verify daemon instead.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768800663248,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768800663248,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768800663248,0]}
{"id":"bd-yoon","created_at":[1768636588528,0],"created_by":"darin@darinsmcstudio2.lan","title":"ReplicatedFsync durability e2e","description":"**Problem**\nWe have no end-to-end coverage for ReplicatedFsync durability receipts or read-gating semantics under partial failure.","design":"**Design**\n- Add an integration test that performs mutations with DurabilityClass::REPLICATED_FSYNC(k) and validates receipts (requested/achieved/min_seen) via IPC.\n- Add a failure-mode test with one peer down to ensure receipts report pending/unavailable correctly.\n- Assert min_seen/read-gating behavior across nodes.","acceptance_criteria":"- [ ] ReplicatedFsync e2e passes with k-of-n healthy.\n- [ ] Failure-mode receipt reflects insufficient eligible replicas.\n- [ ] min_seen/read-gating validated.\n- [ ] Tests write only under ./tmp.","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768638502178,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768638502178,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768638502178,0]}
{"id":"bd-yzmj","created_at":[1768508260025,0],"created_by":"darin@darinsmcstudio2.lan","title":"Reorganize integration tests into single module tree","description":"**Problem**\nIntegration tests live as many top-level crates in `tests/` and are named by phase (phase1/phase2/phase7), which obscures intent and makes it unclear where new integration tests should live. There isn't a single integration test entrypoint or hierarchy aligned with runtime boundaries.\n\n**Files**\n- tests/* (integration test files)\n- tests/fixtures/*\n","design":"**Design**\n- Create a single integration test crate at `tests/integration/mod.rs`.\n- Move existing integration tests into a module tree grouped by contract boundaries (core/apply, wal/fsck/index/seq, repl/*, checkpoint, admin, cli, upgrade, migration, crash_recovery, realtime_errors).\n- Move shared fixtures under `tests/integration/fixtures/` and re-export from the crate root for consistent use.\n- Update module paths/usages and remove per-file `mod fixtures;` declarations.\n- Rename file headers to remove “phase X” naming.","acceptance_criteria":"- [ ] No phase-named integration test files remain.\n- [ ] All integration tests compile under `tests/integration/mod.rs` as a single crate.\n- [ ] Fixtures are centralized and imported from a single module.\n- [ ] `cargo test` still discovers and runs the integration tests.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","closed_reason":"Duplicate of bd-qrlt","_at":[1768508963682,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768508963682,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-z4vo","created_at":[1768719779416,0],"created_by":"darin@darinsmcstudio2.lan","title":"CLI show: batch summaries for related issue lists","description":"src/cli/commands/show.rs calls fetch_issue_summary per id for deps/children/related. Use Request::List with Filters::ids to fetch all summaries in one IPC round-trip, then map id->summary.","priority":1,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","_at":[1768757897903,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768757897903,0],"closed_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-z5s","created_at":[1769228909727,0],"created_by":"darin@book","title":"CRDT minor suggestions from review","description":"**Problem**\nMinor suggestions from CRDT review that were deferred.\n\n**Design**\n1. **Normalize on parse** - Add prune_dominated()/normalization after OrSet::from_parts() in git/wire.rs and WAL\n2. **Remove unused variant** - Delete EventValidationError::TooManyLabels if unused\n3. **join() error handling** - Either return Self directly or actually collect errors instead of expect()\n\n**Acceptance**\n- [ ] prune_dominated() called after OrSet::from_parts()\n- [ ] TooManyLabels variant removed if unused\n- [ ] join() error handling cleaned up\n- [ ] All tests pass","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1769228918184,0],"_by":"darin@book","_v":{"acceptance_criteria":[[1769228909727,0],"darin@book"],"claim":[[1769228909727,0],"darin@book"],"design":[[1769228909727,0],"darin@book"],"estimated_minutes":[[1769228909727,0],"darin@book"],"external_ref":[[1769228909727,0],"darin@book"],"priority":[[1769228909727,0],"darin@book"],"source_repo":[[1769228909727,0],"darin@book"],"title":[[1769228909727,0],"darin@book"],"type":[[1769228909727,0],"darin@book"],"workflow":[[1769228909727,0],"darin@book"]}}
{"id":"bd-z9oc","created_at":[1768774749674,0],"created_by":"darin@darinsmcstudio2.lan","title":"Observability: CLI command span + context","description":"**Problem**\nCLI logs/errors don’t carry command context, making it hard to correlate failures with user commands or repos.\n\n**Design**\n- Wrap `cli::run` in a `tracing::info_span!(\"cli_command\", command = ..., repo = ...)` in `src/bin/main.rs` or `src/cli/mod.rs`.\n- Extract command name and repo (if present) from `cli::Args`.\n\n**Acceptance**\n- [ ] CLI errors are emitted within a `cli_command` span that includes command + repo fields.\n- [ ] No behavior change for stdout/stderr output.\n\n**Files:** src/bin/main.rs, src/cli/mod.rs","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768813798462,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768813798462,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768813798462,0]}
{"id":"bd-zd0","created_at":[1765690393195,0],"created_by":"darin@darinsmcstudio2.lan","title":"CI docs drift: xtask/coverage references but no xtask crate","description":"## What's Wrong\nRepo docs/config mention a coverage job and a `cargo xtask coverage` path, but the repo has no `xtask` crate and current workflows don't include the referenced coverage job.\n\n## Where\n- .github/AGENTS.md (mentions coverage + xtask)\n- .cargo/config.toml (defines `xtask` alias)\n- .github/workflows/ci.yml (current actual CI)\n\n## Why It Matters\nStale CI documentation misleads contributors and future agents. The `xtask` alias suggests functionality that doesn't exist.\n\n## Suggested Fix\nEither:\n1) Add an `xtask/` crate and wire a real coverage job, or\n2) Remove the alias and update .github/AGENTS.md to match reality.\n\n## Acceptance\n- CI docs accurately describe the workflows that actually run.\n- No dead `cargo xtask` alias unless backed by a crate.","priority":3,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765775640762,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765775640762,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765775640762,0]}
{"id":"bd-ze0x","created_at":[1768622238197,0],"created_by":"darin@darinsmcstudio2.lan","title":"Port Go beads features to beads-rs","description":"## Overview\nEpic for tracking features from Go beads (v0.22-v0.47+) that should be ported to beads-rs.\n\n## Purpose\nThis is a **human review queue** - beads under this epic require design review before implementation. Most are tagged `human-needed` because they involve architectural decisions about how to adapt Go patterns to Rust idioms.\n\n## Categories\n- Core types & data model extensions\n- Molecules, formulas, and workflow templates  \n- Dependencies and graph link types\n- Status states and workflow\n- CLI/UX improvements\n- Sync, storage, and maintenance\n- Design-heavy features (mail, routing)\n\n## Process\n1. Review each bead's description and design options\n2. Make architectural decisions\n3. Remove `human-needed` label when design is settled\n4. Implementation can proceed\n\n## Exclusions\n- Features that are already implemented in beads-rs\n- Features that don't make sense for the Rust rewrite\n\n---\n*Created from: changelog analysis of Go beads v0.22-v0.47*","priority":2,"type":"epic","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622238197,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.1","created_at":[1768622383738,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add molecule infrastructure to beads-rs","description":"**Problem**\nbeads-rs currently lacks the molecule system that exists in Go beads. Molecules are foundational - they're the workflow template system that enables complex agent orchestration.\n\n**What are Molecules?**\nMolecules are workflow templates (protos) that can be instantiated. They're the same as epics but with workflow semantics:\n- Proto (solid): Template epic with 'template' label\n- Mol (liquid): Poured instance → persistent, syncs to git\n- Wisp (vapor): Ephemeral instance → local only, auto-cleanup\n\n**Core Fields**\n- mol_type: enum (swarm/patrol/work)\n- bonded_from: Vec<BondRef> for compound molecules\n- Ephemeral: bool flag (wisps vs persistent mols)\n\n**Design**\nThe molecule system layers on top of existing epics/dependencies. No separate storage needed - just:\n1. Add molecule-specific fields to Issue type\n2. Add template label handling\n3. Implement instantiation logic (variable substitution)\n\n**Files to Study (Go beads)**\n- cmd/bd/mol.go - molecule commands structure\n- cmd/bd/template.go - template loading and instantiation\n- internal/types/types.go - Issue fields for molecules\n- docs/MOLECULES.md - conceptual overview\n\n**Acceptance**\n- [ ] Issue type extended with molecule fields\n- [ ] Template label recognized\n- [ ] Basic instantiation works (pour proto → mol)\n- [ ] Tests for molecule CRDT semantics\n","priority":1,"type":"epic","labels":{"entries":{"human-needed":[{"replica":"8bede988-ad34-cd1e-689c-a6cd3c458a16","counter":13251068344367108153}]},"cc":{"max":{}}},"status":"open","_at":[1768622383738,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.10","created_at":[1768622414118,0],"created_by":"darin@darinsmcstudio2.lan","title":"Defer/undefer commands with time-based scheduling","description":"**Problem**\n\nGo beads has a StatusDeferred workflow status for putting issues on ice (icebox). This is distinct from blocked status - deferred issues aren't waiting on dependencies, they're deliberately postponed for future consideration.\n\nKey features missing from beads-rs:\n- `bd defer [id]` command to set status to deferred\n- `bd undefer [id]` command to restore to open\n- `--until` flag for time-based deferral\n- `defer_until` timestamp field for auto-revealing issues\n- Snowflake (❄) display icon for deferred status\n- Exclusion from `bd ready` by default\n\n**Design**\n\nAdd StatusDeferred variant to Status enum and implement defer/undefer commands.\n\nTime-based scheduling uses the defer_until field:\n- `bd defer bd-abc --until=tomorrow` sets defer_until timestamp\n- `bd defer bd-abc --until=+1h` (relative: +6h, -1d, +2w)\n- `bd defer bd-abc --until=2025-01-20` (absolute: ISO 8601 or date-only)\n- Issues with defer_until > now are excluded from `bd ready`\n- `bd undefer` clears both status and defer_until\n\nTime parsing supports layered formats (from timeparsing/parser.go):\n1. Compact duration: +6h, -1d, +2w, 3m, 1y (regex: `[+-]?(\\d+)([hdwmy])`)\n2. Absolute formats: YYYY-MM-DD, RFC3339, ISO 8601 variants\n3. Natural language: \"tomorrow\", \"next monday\", \"in 3 days\" (using chrono crate or similar)\n\nImplementation files:\n- `src/core/workflow.rs` - Add StatusDeferred variant\n- `src/core/lww.rs` - Add defer_until field to Bead struct as Lww<Option<Timestamp>>\n- `src/cli/defer.rs` - Defer command with --until flag\n- `src/cli/undefer.rs` - Undefer command\n- `src/util/timeparse.rs` - Time parsing utilities (compact duration, NLP, absolute)\n- `src/daemon/ops.rs` - Defer/undefer operations\n- `src/cli/ready.rs` - Filter out deferred issues (status=deferred OR defer_until > now)\n\nStatusDeferred display:\n- Icon: ❄ (snowflake)\n- Color: muted/gray (see ui/styles.go line 236)\n- Format: `MutedStyle.Render(\"❄\")` in Go\n\nDeferred issues behavior:\n- Don't appear in `bd ready` by default\n- Still visible in `bd list`\n- Can be claimed if you explicitly want to work on them\n\n**Design Notes**\n\nGo beads uses olebedev/when for NLP time parsing. For Rust, consider:\n- chrono-english crate for NLP (\"tomorrow\", \"next monday\")\n- regex for compact duration parsing (+6h, -1d)\n- chrono for absolute timestamp parsing\n\nTime parsing error handling should provide helpful examples:\n```\nError: invalid --until format \"foo\". Examples: +1h, tomorrow, next monday, 2025-01-15\n```\n\nEdge cases:\n- Defer without --until just sets status=deferred (no timestamp)\n- Undefer always clears both status and defer_until\n- Setting status to anything other than deferred should clear defer_until\n- Auto-reveal happens in ready work calculation, not via background job\n\n**Acceptance**\n\n- [ ] Status enum has StatusDeferred variant\n- [ ] Bead struct has defer_until field (Lww<Option<Timestamp>>)\n- [ ] `bd defer [id]` sets status to deferred\n- [ ] `bd defer [id] --until=<time>` parses and sets defer_until timestamp\n- [ ] Time parsing supports: +6h, -1d, +2w, tomorrow, next monday, 2025-01-15\n- [ ] `bd undefer [id]` restores to open and clears defer_until\n- [ ] `bd ready` excludes issues with status=deferred OR defer_until > now\n- [ ] Deferred status displays with snowflake icon (❄) in muted color\n- [ ] Tests for time parsing (compact, NLP, absolute formats)\n- [ ] Tests for defer/undefer operations\n- [ ] Migration handles StatusDeferred from Go beads export\n\n**Files:**\n- src/core/workflow.rs\n- src/core/lww.rs\n- src/cli/defer.rs\n- src/cli/undefer.rs\n- src/util/timeparse.rs\n- src/daemon/ops.rs\n- src/cli/ready.rs","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"5ac7d3cc-7f07-4053-ec59-0ba83ed7f1ff","counter":14532607019882133948}]},"cc":{"max":{}}},"status":"open","_at":[1768622414118,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.11","created_at":[1768622420344,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add wisp system to beads-rs","description":"**Problem**\nbeads-rs needs wisps - ephemeral molecules that never sync to JSONL. Wisps are crucial for operational workflows (patrols, releases, health checks) that shouldn't clutter git history.\n\n**What are Wisps?**\nWisps are ephemeral issues with Ephemeral=true flag:\n- Created: bd mol wisp <proto> or bd create --ephemeral\n- Stored: In SQLite (.beads/beads.db) with Ephemeral=true\n- Excluded: From JSONL export (never sync to git)\n- Lifecycle: Either squash to digest OR burn without trace\n- Use cases: Patrol cycles, release workflows, health checks, diagnostics\n\n**How it Works (Go beads)**\n1. Create wisp: Sets Ephemeral=true on all spawned issues\n2. Execution: Normal bd operations work on wisp issues\n3. Export filtering: autoflush.go skips issues where Ephemeral=true\n4. Cleanup: bd mol squash <id> OR bd mol burn <id>\n5. GC: bd mol wisp gc removes orphaned old wisps\n\n**Phase Metaphor**\n- Solid (proto): Template\n- Liquid (mol): Persistent work via bd pour\n- Vapor (wisp): Ephemeral work via bd mol wisp\n\n**Design**\nThe Ephemeral flag is already in Go Issue struct. In Rust:\n1. Add ephemeral: bool to Issue (with Lww<bool>)\n2. Export filter: Skip issues where ephemeral.value == true\n3. Wisp commands: bd mol wisp create <proto>\n4. Lifecycle commands: squash, burn, gc\n\n**Files to Study (Go beads)**\n- cmd/bd/wisp.go - wisp creation and management\n- cmd/bd/autoflush.go - export filtering (line ~200: skip ephemeral)\n- cmd/bd/mol_squash.go - compress wisps to digest\n- cmd/bd/mol_burn.go - delete without trace\n- docs/MOLECULES.md - vapor phase explanation\n\n**Acceptance**\n- [ ] Issue.ephemeral field added (Lww<bool>)\n- [ ] Export skips ephemeral issues\n- [ ] bd mol wisp create command\n- [ ] bd mol wisp list command\n- [ ] bd mol wisp gc command\n- [ ] bd mol squash compresses wisps\n- [ ] bd mol burn deletes wisps\n- [ ] Tests for ephemeral lifecycle\n","priority":1,"type":"epic","labels":{"entries":{"human-needed":[{"replica":"11e94383-193a-fa15-06ed-f9d437376602","counter":12387313066889556085}]},"cc":{"max":{}}},"status":"open","_at":[1768622420344,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.12","created_at":[1768622426568,0],"created_by":"darin@darinsmcstudio2.lan","title":"bd human command - focused help menu","description":"**Problem**\nbd has 70+ commands, many for AI agents and advanced workflows. Human users need a focused menu showing only the ~15 essential commands.\n\n**Design**\nImplement `bd human` command that displays:\n- Working With Issues: create, list, show, update, close, reopen, comment\n- Finding Work: ready, search, status, stats\n- Dependencies: dep add/remove/tree, graph, blocked\n- Setup & Sync: init, sync, doctor\n- Getting Help: quickstart, help, --help\n- Quick Examples: common workflows with actual commands\n\nReference: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/human.go`\n\nOutput format:\n```\nbd - Essential Commands for Humans\nFor all 70+ commands: bd --help\n\nWorking With Issues:\n  create                Create a new issue\n  list                  List issues (filter with --status, --priority, --label)\n  ...\n\nQuick Examples:\n  # Create and track an issue\n  bd create \"Fix login bug\" --priority 1\n  bd update bd-abc123 --status in_progress\n  ...\n```\n\n**Design Notes**\n- Use ui rendering functions for consistent styling\n- Keep it under 40 lines of output\n- Focus on human workflow, not agent commands\n- Include real examples, not placeholders\n\n**Acceptance**\n- [ ] bd human shows ~15 essential commands\n- [ ] Grouped by workflow area (issues, finding work, deps, setup)\n- [ ] Quick examples section with real commands\n- [ ] Mentions full --help for all 70+ commands\n- [ ] Clean formatting with ui helpers\n\n**Files:**\n- `src/cli/human.rs` (new)\n- `src/cli/mod.rs` (register command)","priority":3,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622426568,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.13","created_at":[1768622428755,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add Convoy issue type support","description":"**Problem**\nbeads-rs lacks the Convoy issue type - a cross-project tracking primitive with reactive completion. Convoys track multiple issues (potentially across repos) and automatically close when all tracked items complete. This enables coordinated multi-project work.\n\n**What Convoys Do (from Go beads)**\nConvoy is a lightweight tracking container that uses the 'tracks' dependency relation (non-blocking). When any tracked issue closes, convoy checks if all tracked items are complete and auto-closes if so. This is reactive completion - no polling needed.\n\nUse cases:\n- Track related work across multiple repos\n- Group cross-cutting concerns (security audit, docs update, etc.)\n- Coordinate releases (track all pre-release tasks)\n- Monitor distributed swarm work\n\n**Go Implementation**\nType definition in internal/types/types.go:\n- IssueType = TypeConvoy (line 493)\n- Uses standard Issue fields (no custom fields)\n- Relies on 'tracks' dependency relation (DependencyType)\n\nDependency tracking (internal/types/types.go line 713):\n- DepTracks: convoy.issue_id tracks target.depends_on_id\n- Non-blocking (doesn't affect ready work calculation)\n- Direction: convoy → tracked issue\n\nReactive completion (internal/storage/sqlite/transaction.go lines 583-650):\nWhen any issue closes, query for convoys tracking it:\n```sql\nSELECT i.id FROM issues i\nJOIN dependencies d ON d.issue_id = i.id AND d.type = 'tracks'\nJOIN labels l ON i.id = l.issue_id AND l.label = 'gt:convoy'\nWHERE d.depends_on_id = ? AND i.status != 'closed'\n```\nFor each convoy, check if ALL tracked items are closed. If yes, auto-close convoy.\n\nNote: Uses 'gt:convoy' label instead of issue_type for Gas Town separation.\n\n**Design for Rust**\nData model (src/core/):\nNo special fields needed - convoys are regular beads with:\n- Standard Issue fields\n- 'tracks' dependencies to tracked items\n- Reactive completion logic in close handler\n\nReactive completion (src/daemon/ or src/core/):\nWhen closing any bead:\n1. Find all convoys that track this bead (traverse 'tracks' edges incoming)\n2. For each convoy, check if all tracked items are closed\n3. If yes, auto-close convoy with reason \"All tracked items complete\"\n\nCLI (src/cli/):\n- bd create --type convoy \"Track release work\"\n- bd dep add <convoy-id> <tracked-id> --type tracks\n- bd dep list <convoy-id> -t tracks (show what convoy tracks)\n- bd list --type convoy (filter convoys)\n\n**Design Notes**\n- Convoy is more about behavior (reactive close) than structure\n- 'tracks' relation must be non-blocking (doesn't affect bd ready)\n- Multi-repo tracking needs cross-repo dependency support\n- Auto-close should include metadata (which issues triggered completion)\n- Consider: Should convoy completion cascade to parent convoys?\n\n**Acceptance**\n- [ ] Convoy type constant defined\n- [ ] 'tracks' dependency type added to DependencyType enum\n- [ ] DepTracks marked as non-blocking (doesn't affect ready work)\n- [ ] Bead close handler checks for tracking convoys\n- [ ] Convoy auto-closes when all tracked items are closed\n- [ ] bd create --type convoy works\n- [ ] bd dep add supports --type tracks\n- [ ] bd dep list shows tracks relationships\n- [ ] Tests for convoy reactive completion\n- [ ] Tests for convoy with cross-repo tracked items (if multi-repo supported)\n- [ ] Migration from Go beads preserves convoy type and tracks relations\n\n**Files to study in Go beads:**\n- tmp/beads/internal/types/types.go (line 493: TypeConvoy, line 713: DepTracks)\n- tmp/beads/internal/storage/sqlite/transaction.go (lines 583-650: reactive completion)\n- tmp/beads/cmd/bd/types.go (line 26: convoy description)","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"2e3c15ae-5540-814d-4aad-3e9edd25f2d5","counter":3082487056783492846}]},"cc":{"max":{}}},"status":"open","_at":[1768622428755,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.14","created_at":[1768622429278,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add supersede command for version chain links","description":"**Problem**\nGo beads supports `bd supersede <old> --with <new>` to mark an issue as superseded by a newer version and automatically close it. Useful for design docs, specs, and evolving artifacts. beads-rs needs this.\n\n**How it works in Go beads**\n- Command: `bd supersede <old> --with <new>` (in cmd/bd/duplicate.go)\n- Uses `DepSupersedes` dependency type\n- Automatically closes the superseded issue\n- Close reason references the replacement issue\n- Stored in dependencies table (per Decision 004)\n\n**Design for Rust**\n1. Add `Supersedes` variant to `DepKind` enum in src/core/domain.rs\n2. Mark it as non-DAG-enforcing (informational chain)\n3. Add CLI command: src/cli/commands/supersede.rs\n   - `bd supersede <old> --with <new>`\n   - Validates replacement issue exists\n   - Rejects self-supersession (old == new)\n   - Creates supersedes edge\n   - Closes old issue atomically\n4. Wire through daemon IPC for atomic operation\n5. Add to CLI command tree\n\n**Design considerations**\n- Atomicity: dependency + closure must be atomic\n- Allow superseding already-closed issues? (spec updates)\n- Close reason should reference replacement ID\n- Should we build supersession chains? (A supersedes B supersedes C)\n  * Go doesn't enforce linearity\n  * Could have multiple \"next versions\" (branches)\n- Direction of edge: old -> new (Go's choice)\n\n**Design questions for human review**\n- Should supersedes be bidirectional or unidirectional?\n  * Go: unidirectional (old -> new)\n  * Allows querying \"what did this replace?\" vs \"what replaces this?\"\n- Should we prevent cycles in supersession chains?\n  * Or allow time-travel paradoxes for lols?\n- Display: show \"superseded by X\" in bd show/list?\n\n**Files to study**\n- tmp/beads/cmd/bd/duplicate.go - runSupersede function\n- tmp/beads/internal/types/types.go - DepSupersedes type\n- src/core/bead.rs - bead closure workflow\n\n**Acceptance**\n- [ ] Supersedes added to DepKind enum\n- [ ] bd supersede command creates edge and closes issue\n- [ ] Self-supersession rejected\n- [ ] Replacement issue validated to exist\n- [ ] JSON output format matches Go beads\n- [ ] Cargo fmt, clippy, test pass","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"ec276192-fc14-5b30-db63-c0ef99c8159a","counter":18188522642124036763}]},"cc":{"max":{}}},"status":"open","_at":[1768622429278,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.15","created_at":[1768622429797,0],"created_by":"darin@darinsmcstudio2.lan","title":"Implement bd repair command - Repair orphaned foreign key references with transaction safety","description":"","design":"Port the database repair feature from Go beads to beads-rs.\n\n## Problem\n\nWhen the database has orphaned foreign key references (dependencies, labels, comments, events pointing to non-existent issues), migration invariant checks fail and prevent the database from opening. This creates a chicken-and-egg problem where `bd doctor --fix` can't run because it can't open the database.\n\n## Solution\n\nA standalone repair command that opens the database DIRECTLY, bypassing migration invariant checks, and cleans orphaned references.\n\n## Implementation approach\n\n**Location**: `src/cli/repair.rs` (new file)\n\n**Command structure**:\n```rust\npub struct RepairArgs {\n    #[arg(long)]\n    dry_run: bool,\n    #[arg(long)]\n    json: bool,\n    #[arg(long)]\n    path: Option<PathBuf>,  // defaults to current dir\n}\n```\n\n**Orphaned references to detect and clean**:\n1. Dependencies where issue_id doesn't exist\n2. Dependencies where depends_on_id doesn't exist (excluding external:xxx)\n3. Labels where issue_id doesn't exist\n4. Comments where issue_id doesn't exist\n5. Events where issue_id doesn't exist\n\n**Repair process**:\n1. Find .beads directory and database path\n2. Open SQLite directly (foreign_keys=OFF, bypass migration checks)\n3. Run detection queries for each orphan type\n4. If dry-run: report what would be cleaned\n5. If not dry-run:\n   - Create backup: `beads.db.pre-repair`\n   - Start transaction\n   - Execute DELETE statements for orphans\n   - Mark affected issues as dirty (for export)\n   - Commit transaction\n   - Run WAL checkpoint\n\n**Output**:\n```json\n{\n  \"database_path\": \"/path/to/.beads/beads.db\",\n  \"dry_run\": false,\n  \"orphan_counts\": {\n    \"dependencies_issue_id\": 3,\n    \"dependencies_depends_on\": 1,\n    \"labels\": 5,\n    \"comments\": 0,\n    \"events\": 2,\n    \"total\": 11\n  },\n  \"orphan_details\": { /* arrays of specific orphans */ },\n  \"status\": \"success\",\n  \"backup_path\": \"/path/to/.beads/beads.db.pre-repair\"\n}\n```\n\n## Files to reference\n\nGo implementation: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/repair.go`\n\nKey SQL queries:\n```sql\n-- Orphaned deps (issue_id)\nSELECT d.issue_id, d.depends_on_id\nFROM dependencies d\nWHERE NOT EXISTS (SELECT 1 FROM issues WHERE id = d.issue_id)\n\n-- Orphaned deps (depends_on_id)\nSELECT d.issue_id, d.depends_on_id\nFROM dependencies d\nWHERE NOT EXISTS (SELECT 1 FROM issues WHERE id = d.depends_on_id)\n  AND d.depends_on_id NOT LIKE 'external:%'\n\n-- Similar for labels, comments, events\n```\n\n## Design notes\n\n- **Transaction safety**: All deletes in a single transaction. Rollback on any error.\n- **Backup first**: Always create backup before destructive ops. Fail fast if backup fails.\n- **Dirty tracking**: Mark parent issues dirty so exports stay consistent\n- **No migration layer**: This command bypasses the normal storage layer entirely\n- **Error recovery**: Preserve backup on error, print recovery instructions\n\n## Questions\n\n1. Should this be a daemon operation or direct SQLite access?\n   - Recommendation: Direct SQLite, daemon might not be running when repair is needed\n2. Do we need a --force flag to skip confirmation?\n3. Should we auto-run `bd doctor` after successful repair?","acceptance_criteria":"- [ ] Command opens database with foreign_keys=OFF\n- [ ] Detects all 5 types of orphaned references\n- [ ] Creates backup before making changes\n- [ ] All deletes happen in a single transaction\n- [ ] Transaction rolls back on any error\n- [ ] Dry-run mode shows what would be cleaned\n- [ ] JSON output includes all orphan details\n- [ ] Works on corrupted databases that won't open normally\n- [ ] Preserves backup file after completion","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"ffaccba2-fbaa-48c0-9cb1-ad2e2f8b25bd","counter":6125257156869369387}]},"cc":{"max":{}}},"status":"open","_at":[1768622429797,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.16","created_at":[1768622431666,0],"created_by":"darin@darinsmcstudio2.lan","title":"Prefix-based routing - Cross-rig command routing","description":"**Problem**\nIn multi-rig setups (orchestrator with multiple rigs), commands should auto-route to the correct rig based on issue ID prefix. The Go beads has routes.jsonl for prefix-to-path mapping, enabling seamless cross-rig operations.\n\n**What the Feature Does**\nAutomatic command routing based on issue ID prefix:\n- `bd show bd-abc` - Routes to rig with \"bd-\" prefix\n- `bd show gt-xyz` - Routes to rig with \"gt-\" prefix\n- `bd update bd-abc --status in_progress` - Routes to correct rig\n- No need to `cd` to correct directory - routing is transparent\n\nConfiguration via `routes.jsonl` in town root (e.g., `~/gt/.beads/routes.jsonl`):\n```jsonl\n{\"prefix\": \"bd-\", \"path\": \"beads/mayor/rig\"}\n{\"prefix\": \"gt-\", \"path\": \"gastown/mayor/rig\"}\n{\"prefix\": \"poly-\", \"path\": \"polecats/mayor/rig\"}\n```\n\nRoutes resolve:\n- Prefix to .beads directory\n- Path is relative to town root (found by walking up to `mayor/town.json`)\n- Supports symlinks (via redirect files)\n\n**Why It Needs Design Work**\n\n1. **Daemon Architecture**:\n   - Go beads: One daemon per workspace\n   - Routing opens connections to foreign databases\n   - Rust architecture: Same approach or different?\n   - Per-rig daemon vs centralized router?\n\n2. **Database Lifecycle**:\n   - Who owns the routed database connection?\n   - Do we keep connections open or open/close per operation?\n   - Cache strategy for routes.jsonl?\n   - Handle database lock contention?\n\n3. **Error Handling**:\n   - What if target rig doesn't exist?\n   - What if prefix not found in routes.jsonl?\n   - Fallback behavior?\n   - Clear error messages for users?\n\n4. **ID Resolution**:\n   - Partial ID resolution (bd-abc vs full hash)\n   - Cross-rig duplicate detection\n   - Collision prevention across rigs\n\n**Key Decisions to Make**\n\n1. **Routes File Location**:\n   - Go approach: Find town root by walking up to `mayor/town.json`\n   - Alternative: Configuration setting?\n   - Multiple routes files (rig-local + town-level)?\n   - How to handle non-orchestrator setups?\n\n2. **Connection Model**:\n   ```rust\n   // Option A: Route at API layer\n   fn show(id: &str) -> Result<Issue> {\n       let beads_dir = resolve_beads_dir_for_id(id)?;\n       let storage = Storage::open(beads_dir)?;\n       storage.get_issue(id)\n   }\n   \n   // Option B: Route at storage layer\n   impl Storage {\n       fn get_issue(&self, id: &str) -> Result<Issue> {\n           if let Some(routed) = self.routes.lookup(id) {\n               return routed.get_issue(id);\n           }\n           // fallback to local\n       }\n   }\n   ```\n\n3. **Command Coverage**:\n   - Which commands support routing? (show, update, close, comment - yes)\n   - Which don't? (create always local? or use --rig flag?)\n   - Read-only vs write operations - different rules?\n\n4. **Sync Interactions**:\n   - Does routing affect sync behavior?\n   - Do routed operations trigger sync in target rig?\n   - How to handle daemon mode with routing?\n\n**Trade-offs to Consider**\n\n1. **Complexity vs Transparency**:\n   - Pro: Seamless UX, no CD required\n   - Con: Action-at-a-distance can confuse\n   - Solution: Clear output showing which rig was used?\n\n2. **Performance**:\n   - Opening foreign databases adds latency\n   - Could cache connections but adds complexity\n   - Trade-off: Speed vs memory/file handles\n\n3. **Lock Contention**:\n   - Multiple rigs = multiple daemons\n   - Each daemon has exclusive db lock\n   - Routing from one daemon to another's db = potential conflict\n   - May need read-only mode for routed access?\n\n4. **Backward Compatibility**:\n   - Routes.jsonl is optional - works without it\n   - Non-orchestrator repos unaffected\n   - But what about existing Rust users?\n\n**Reference Files in Go Beads**\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/routing/routes.go` - Route loading/resolution\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/routing/routing.go` - Routing logic\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/docs/ROUTING.md` - Routing documentation\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/docs/MULTI_REPO_AGENTS.md` - Agent workflows\n\n**Go Implementation Details**\n- `ExtractPrefix(id)` - Gets \"bd-\" from \"bd-abc123\"\n- `LoadRoutes(beadsDir)` - Parses routes.jsonl\n- `ResolveBeadsDirForID(id, currentBeadsDir)` - Maps ID to .beads directory\n- `findTownRoot()` - Walks up to find mayor/town.json\n- `resolveRedirect()` - Follows symlink redirects\n\n**Acceptance**\n- [ ] Design document for routing architecture (daemon model, connection lifecycle)\n- [ ] Route resolution algorithm adapted to Rust\n- [ ] Error handling spec (missing routes, missing rigs, locks)\n- [ ] Command-by-command routing support plan\n- [ ] Sync interaction design\n- [ ] Performance considerations (caching, connection pooling)\n- [ ] Decision on read-only vs read-write routing","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"40030a2b-543a-2576-3660-d1f421f9a7d7","counter":1133274413160658948}]},"cc":{"max":{}}},"status":"open","_at":[1768622431666,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.17","created_at":[1768622433646,0],"created_by":"darin@darinsmcstudio2.lan","title":"Pinned status for persistent beads","description":"**Problem**\n\nGo beads has StatusPinned for marking beads that should stay open indefinitely. Pinned beads are persistent context markers, not work items that need completion.\n\nMissing from beads-rs:\n- StatusPinned workflow status\n- Pin/unpin commands\n- Display icon (📌) and color\n- Different cleanup behavior (pinned beads survive cleanup)\n\nPinned vs Deferred:\n- Pinned: Stays open permanently, won't be auto-closed\n- Deferred: Temporarily on ice, will be revisited\n\nUse cases:\n- Documentation beads that track ongoing decisions\n- Reference beads for common patterns\n- Context beads for project state\n\n**Design**\n\nAdd StatusPinned variant to Status enum.\n\nCommands:\n- `bd pin [id]` - Set status to pinned\n- `bd unpin [id]` - Restore to open\n\nStatusPinned behavior:\n- Shows in `bd list` but not `bd ready` (not actionable work)\n- Excluded from cleanup operations (unlike closed/deferred)\n- Can't be auto-closed by workflows\n- Different from deferred: deferred will be revisited, pinned stays indefinitely\n\nDisplay (from ui/styles.go):\n- Icon: 📌 (pushpin emoji)\n- Color: Purple (#d2a6ff) - special/elevated status\n- Style: `StatusPinnedStyle.Render(\"📌\")`\n\nImplementation files:\n- `src/core/workflow.rs` - Add StatusPinned variant\n- `src/cli/pin.rs` - Pin command\n- `src/cli/unpin.rs` - Unpin command (restore to open)\n- `src/daemon/ops.rs` - Pin/unpin operations\n- `src/cli/list.rs` - Display pinned beads with icon\n- `src/cli/ready.rs` - Exclude pinned from ready work\n\n**Design Notes**\n\nGo beads has a `pinned` boolean field separate from status (types.go line 81). However, the Go codebase also has StatusPinned (line 447). Need to reconcile:\n- Option 1: Status-based (StatusPinned) - simpler, no dual representation\n- Option 2: Field-based (pinned bool) + status=open - allows \"pinned in_progress\"\n- Recommendation: Use StatusPinned (status-based). Pinned beads aren't \"work in progress\", they're persistent markers.\n\nPinned beads don't expire:\n- Cleanup operations skip pinned beads\n- Can't be auto-closed by formulas/workflows\n- Manual unpin required to close\n\n**Acceptance**\n\n- [ ] Status enum has StatusPinned variant\n- [ ] `bd pin [id]` sets status to pinned\n- [ ] `bd unpin [id]` restores to open\n- [ ] `bd ready` excludes pinned beads\n- [ ] Pinned status displays with 📌 icon in purple color\n- [ ] Cleanup operations skip pinned beads\n- [ ] Tests for pin/unpin operations\n- [ ] Migration handles StatusPinned from Go beads export\n\n**Files:**\n- src/core/workflow.rs\n- src/cli/pin.rs\n- src/cli/unpin.rs\n- src/daemon/ops.rs\n- src/cli/list.rs\n- src/cli/ready.rs","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"ab2041bb-da0e-900a-52f1-9104ba24ab33","counter":5855223272650655807}]},"cc":{"max":{}}},"status":"open","_at":[1768622433646,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.18","created_at":[1768622434574,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add bd pour command to beads-rs","description":"**Problem**\nNeed bd pour command to instantiate protos as persistent molecules. Pour is the primary way to create work from templates.\n\n**What is Pour?**\nPour instantiates a proto (template) as a persistent mol:\n- Phase: Proto (solid) → Mol (liquid)\n- Storage: Creates real issues in .beads/ that sync to git\n- Variables: Substitutes {{var}} placeholders with --var flags\n- Result: Epic + children with dependencies intact\n\n**How it Works (Go beads)**\n1. Load proto (from DB OR cook formula inline)\n2. Clone subgraph with variable substitution\n3. Apply defaults from formula VarDefs\n4. Create all issues + dependencies + labels\n5. Schedule autoflush to sync to JSONL\n\n**Command Syntax**\nbd pour <proto-or-formula> [--var k=v]... [--assignee agent] [--attach other-proto]\n\n**Examples**\n- bd pour mol-feature --var name=auth\n- bd pour beads-release --var version=1.0.0\n- bd pour mol-epic --var title=\"My Epic\" --assignee claude\n\n**Design**\nImplements cloneSubgraph from template.go:\n- Variable substitution in title/description/fields\n- Preserve dependency graph topology\n- Apply formula defaults (VarDef.default)\n- Check required variables (VarDef.required)\n- Handle attachments (--attach for bonding during pour)\n\n**Files to Study (Go beads)**\n- cmd/bd/pour.go - pour command implementation\n- cmd/bd/template.go - cloneSubgraph (line ~500)\n- cmd/bd/cook.go - resolveAndCookFormula (inline cooking)\n\n**Acceptance**\n- [ ] bd pour command implemented\n- [ ] Loads proto from DB or cooks formula inline\n- [ ] Variable substitution works\n- [ ] Defaults applied from formula\n- [ ] Required variable validation\n- [ ] Creates issues + deps + labels\n- [ ] --assignee flag works\n- [ ] Tests for pour workflow\n","priority":1,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"aabe0c2c-d9ad-5cdf-37cc-b3e8877f6611","counter":11675068047917621288}]},"cc":{"max":{}}},"status":"open","_at":[1768622434574,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.19","created_at":[1768622438205,0],"created_by":"darin@darinsmcstudio2.lan","title":"bd show --short for compact output","description":"**Problem**\n`bd show` output is verbose for scripting use cases. Need a compact mode showing only essential fields.\n\n**Design**\nAdd `--short` flag to `bd show` that displays:\n- Single-line format: `ID [Priority] [Type] Status - Title`\n- For closed issues: entire line dimmed to show completion\n- Omit description, design, acceptance criteria, notes\n- JSON mode: include all fields but format compactly\n\nReference implementation in Go beads show.go:\n```go\nshortMode, _ := cmd.Flags().GetBool(\"short\")\n```\n\nExample output:\n```\nbd-abc123 [P1] [bug] in_progress - Fix authentication timeout\n```\n\nClosed issue (dimmed):\n```\nbd-def456 [P0] [feature] closed - Add OAuth support\n```\n\n**Design Notes**\n- Use `ui::RenderIssueCompact` helper for consistent formatting\n- In JSON mode, still return full object (--short only affects human output)\n- Useful for scripting and quick scans\n\n**Acceptance**\n- [ ] --short flag on bd show command\n- [ ] Single-line compact format\n- [ ] Closed issues dimmed (entire line)\n- [ ] JSON mode unaffected (full objects)\n- [ ] Works with multiple IDs (one line per ID)\n\n**Files:**\n- `src/cli/show.rs`","priority":3,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622438205,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.2","created_at":[1768622395742,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add relate/unrelate CLI commands for bidirectional graph links","description":"**Problem**\nGo beads supports `bd relate <id1> <id2>` and `bd unrelate <id1> <id2>` for creating bidirectional \\\"see also\\\" links between issues. This enables knowledge graph connections without blocking or hierarchy. beads-rs needs the same capability.\n\n**How it works in Go beads**\n- Commands: `bd relate` and `bd unrelate` (in cmd/bd/relate.go)\n- Creates bidirectional relates-to links using the dependency API\n- Uses `DepRelatesTo` dependency type (stored in dependencies table)\n- Both issues reference each other (id1 -> id2 and id2 -> id1)\n- Non-blocking relationship (doesn't affect ready work calculation)\n\n**Design for Rust**\n1. Add `RelatesTo` variant to `DepKind` enum in src/core/domain.rs\n2. Mark it as non-DAG-enforcing (like Related and DiscoveredFrom)\n3. Add CLI commands: src/cli/commands/relate.rs\n   - `bd relate <id1> <id2>` - creates both edges atomically\n   - `bd unrelate <id1> <id2>` - removes both edges atomically\n4. Wire through daemon IPC in src/daemon/ for atomic bidirectional operations\n5. Add to CLI command tree in src/cli/mod.rs\n\n**Design considerations**\n- Bidirectional atomicity: both edges created/removed in same operation\n- Prevent self-relations (id1 == id2)\n- Handle partial failures gracefully\n- JSON output shows both IDs and relation status\n\n**Files to study**\n- tmp/beads/cmd/bd/relate.go - Go implementation reference\n- tmp/beads/internal/types/types.go - DepRelatesTo type definition\n- src/core/domain.rs - where DepKind lives\n- src/cli/commands/dep.rs - similar command pattern\n\n**Acceptance**\n- [ ] RelatesTo added to DepKind enum\n- [ ] bd relate command creates bidirectional links\n- [ ] bd unrelate command removes bidirectional links\n- [ ] Self-relations rejected with clear error\n- [ ] JSON output format matches Go beads\n- [ ] Cargo fmt, clippy, test all pass","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"230b2c64-03b7-e293-f144-a90b8cb3e774","counter":10654888833020258604}]},"cc":{"max":{}}},"status":"open","_at":[1768622395742,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.20","created_at":[1768622448893,0],"created_by":"darin@darinsmcstudio2.lan","title":"bd show --children to display child issues","description":"**Problem**\nViewing child issues of an epic requires separate commands. Need inline display of children with parent details.\n\n**Design**\nAdd `--children` flag to `bd show` that:\n- Shows parent issue details first\n- Lists all child issues below (issues that depend on parent via parent-child dependency)\n- Children displayed in tree format with indentation\n- Respects --short flag for compact child display\n\nReference: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/show.go` lines 87-91\n\nExample output:\n```\nbd-abc123 [P1] [epic] open - User authentication system\n  Description: ...\n  Children:\n    bd-abc123.1 [P1] [feature] in_progress - OAuth integration\n    bd-abc123.2 [P2] [feature] open - Session management\n    bd-abc123.3 [P0] [bug] blocked - Login timeout\n```\n\n**Design Notes**\n- Query dependencies where DependsOnID = parent ID AND type = parent-child\n- Use tree characters from ui module (TreeChild, TreeIndent)\n- Combine with --short for compact child listings\n- JSON mode: include \"children\" array in parent object\n\n**Acceptance**\n- [ ] --children flag on bd show\n- [ ] Parent details shown first\n- [ ] Children listed with tree indentation\n- [ ] Works with --short for compact display\n- [ ] JSON mode includes children array\n- [ ] Handles epics with many children efficiently\n\n**Files:**\n- `src/cli/show.rs`\n- `src/core/workflow.rs` (helper to get children)","priority":3,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622448893,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.21","created_at":[1768622449305,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add waits-for dependency type for dynamic fanout gates","description":"**Problem**\nGo beads supports waits-for dependencies for dynamic fanout gates. B waits for spawner A's dynamically-bonded children to complete. This enables molecule bonding patterns where a step waits for all parallel work spawned by a previous step. beads-rs needs this.\n\n**How it works in Go beads**\n- Dependency type: `DepWaitsFor` (in internal/types/types.go)\n- Gate types: \"all-children\" (wait for all) or \"any-children\" (wait for first)\n- Metadata field `WaitsForMeta` stores gate type and optional spawner ID\n- Affects blocked cache calculation (internal/storage/sqlite/blocked_cache.go)\n- B is blocked until condition met based on gate type\n- SpawnerID identifies which step spawns the children to wait for\n  * If empty, waits for all direct children of depends_on_id\n\n**Gate semantics**\n- all-children (default): blocked while ANY child is not closed\n- any-children: blocked until ANY child is closed (first completion unblocks)\n\n**Design for Rust**\n1. Add `WaitsFor` variant to `DepKind` enum in src/core/domain.rs\n2. Mark it as DAG-enforcing (affects ready work calculation)\n3. Define WaitsForMeta structure for JSON metadata:\n   - gate: \"all-children\" | \"any-children\"\n   - spawner_id: optional BeadId\n4. Update blocked cache logic to handle waits-for:\n   - Query children of spawner\n   - Check gate condition (all vs any)\n   - Mark as blocked if condition not met\n5. Add CLI support for creating waits-for deps with metadata\n6. Add JSON serialization for metadata field\n\n**Design considerations**\n- Metadata storage: use DepEdge metadata field or separate structure?\n- Default gate type: \"all-children\" (matches Go)\n- Should we validate spawner_id exists?\n- How to query \"what is B waiting for\"? (show spawner + children)\n- Performance: waits-for gates require recursive child queries\n\n**Design questions for human review**\n- Should waits-for support timeout/deadline metadata?\n- Should we allow custom gate predicates beyond all/any?\n- How to handle orphaned waits-for (spawner deleted)?\n- Should gate type be extensible (enum vs string)?\n\n**Files to study**\n- tmp/beads/internal/types/types.go - WaitsForMeta, DepWaitsFor\n- tmp/beads/internal/storage/sqlite/blocked_cache.go - lines 182-216 (waits-for logic)\n- src/core/dep.rs - dependency edge structure\n- src/daemon/ops/blocked.rs - blocked work calculation (if exists)\n\n**Acceptance**\n- [ ] WaitsFor added to DepKind enum\n- [ ] WaitsForMeta structure defined and serializable\n- [ ] Blocked cache updated to handle waits-for gates\n- [ ] all-children gate blocks until all children closed\n- [ ] any-children gate blocks until first child closes\n- [ ] CLI can create waits-for deps with gate metadata\n- [ ] Cargo fmt, clippy, test pass","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"3aa0ea12-248f-77cf-4a78-ef21a8c909b8","counter":14212175201581814820}]},"cc":{"max":{}}},"status":"open","_at":[1768622449305,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.22","created_at":[1768622452519,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add bd mol bond command to beads-rs","description":"**Problem**\nNeed bd mol bond for dynamic molecule composition - attaching work graphs at runtime. Bond is polymorphic and handles proto+proto, proto+mol, mol+mol operands.\n\n**What is Bond?**\nBond creates dependencies between work graphs. It's polymorphic:\n- proto + proto → compound proto (reusable template)\n- proto + mol → spawn proto, attach to molecule  \n- mol + mol → join molecules with dependency\n\n**Bond Types**\n- sequential (default): B waits for A to complete\n- parallel: B runs alongside A (organizational link)\n- conditional: B runs only if A fails\n\n**Dynamic Bonding (Christmas Ornament Pattern)**\nUse --ref for custom child IDs with variable substitution:\n- bd mol bond mol-arm patrol --ref arm-{{name}} --var name=ace\n- Creates: patrol.arm-ace (readable ID instead of hash)\n\n**Phase Control**\n- Default: Follow target's phase (ephemeral target → ephemeral spawn)\n- --pour: Force persistent spawn (Ephemeral=false)\n- --ephemeral: Force ephemeral spawn (Ephemeral=true)\n\n**How it Works (Go beads)**\n1. Resolve operands (formula, proto, or mol)\n2. Cook formulas inline if needed\n3. Clone proto if attaching to mol\n4. Create dependency edge with specified bond type\n5. Handle ref substitution for custom child IDs\n\n**Command Syntax**\nbd mol bond <A> <B> [--type sequential|parallel|conditional] [--ref child-ref] [--var k=v]... [--pour|--ephemeral]\n\n**Examples**\n- bd mol bond mol-feature mol-deploy  # compound proto\n- bd mol bond mol-feature bd-abc123  # attach to molecule\n- bd mol bond bd-abc123 bd-def456  # join molecules\n- bd mol bond mol-arm patrol --ref arm-{{name}} --var name=ace  # dynamic ID\n\n**Design Considerations**\n- Polymorphic dispatch based on operand types\n- Formula inline cooking (ephemeral protos)\n- Variable substitution for --ref\n- Phase inheritance vs --pour/--ephemeral override\n- BondRef tracking in Issue.bonded_from\n\n**Files to Study (Go beads)**\n- cmd/bd/mol_bond.go - bond command (polymorphic logic)\n- cmd/bd/template.go - cloneSubgraph with CloneOptions\n- docs/MOLECULES.md - bonding patterns (line 91-116)\n\n**Acceptance**\n- [ ] bd mol bond command implemented\n- [ ] Polymorphic operand handling\n- [ ] Bond type support (sequential/parallel/conditional)\n- [ ] --ref flag for custom child IDs\n- [ ] Variable substitution in refs\n- [ ] Phase control (--pour / --ephemeral)\n- [ ] BondRef tracking\n- [ ] Tests for all bond combinations\n","priority":1,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"70613446-365e-2f5d-d74a-1e06afe8f9cc","counter":11986892603917172928}]},"cc":{"max":{}}},"status":"open","_at":[1768622452519,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.23","created_at":[1768622459363,0],"created_by":"darin@darinsmcstudio2.lan","title":"Hooked status for agent work assignment (GUPP)","description":"**Problem**\n\nGo beads has StatusHooked for tracking work that's actively assigned to an agent's hook. This is part of the GUPP (Gas Unified Polecat Protocol) agent coordination system.\n\nMissing from beads-rs:\n- StatusHooked workflow status\n- hook_bead field on Issue (0..1 cardinality)\n- Hook/unhook commands\n- Display icon and color\n\nHooked vs InProgress:\n- InProgress: Human or agent claimed the work (assignee set)\n- Hooked: Agent has work on its hook (active execution, one at a time)\n\nThis is primarily for Gas Town agent swarms but should be supported in core beads-rs for compatibility.\n\n**Design**\n\nAdd StatusHooked variant to Status enum and hook_bead field to Bead struct.\n\nFields (from types.go):\n- status: StatusHooked\n- hook_bead: string (optional) - Current work on agent's hook (0..1 cardinality)\n\nCommands:\n- `bd hook [id]` - Set status to hooked (for current agent)\n- `bd unhook [id]` - Clear hooked status, restore to in_progress or open\n\nStatusHooked behavior:\n- Shows work is actively being executed by an agent\n- Only one bead can be hooked per agent at a time\n- Agent field tracking which agent has the work\n- Excluded from `bd ready` for other agents\n\nDisplay (from ui/styles.go):\n- Icon: (use same as in_progress or custom)\n- Color: Cyan (#59c2ff) - actively worked by agent\n- Style: `StatusHookedStyle.Render()`\n\nImplementation files:\n- `src/core/workflow.rs` - Add StatusHooked variant\n- `src/core/lww.rs` - Add hook_bead field as Lww<Option<String>>\n- `src/cli/hook.rs` - Hook command (optional, may not be needed for non-agent use)\n- `src/cli/unhook.rs` - Unhook command\n- `src/daemon/ops.rs` - Hook/unhook operations\n- `src/cli/list.rs` - Display hooked status with color\n\n**Design Notes**\n\nThis is primarily a Gas Town feature but lives in core beads. beads-rs should:\n1. Support the status and field for compatibility\n2. Implement basic hook/unhook commands\n3. Not implement full agent swarm logic (that's in Gas Town)\n\nThe hook_bead field creates a bidirectional link:\n- Agent bead → hook_bead: \"current work\"\n- Work bead → status: StatusHooked\n\nStatusHooked is distinct from StatusPinned:\n- Hooked: Temporary, active execution state\n- Pinned: Permanent, context marker\n\nConsider whether hook/unhook commands are needed in beads-rs or if this is just for migration/compatibility. May defer command implementation to later.\n\n**Acceptance**\n\n- [ ] Status enum has StatusHooked variant\n- [ ] Bead struct has hook_bead field (Lww<Option<String>>)\n- [ ] StatusHooked displays with appropriate icon/color\n- [ ] Migration handles StatusHooked from Go beads export\n- [ ] Tests for hooked status serialization\n- [ ] (Optional) `bd hook` and `bd unhook` commands\n\n**Files:**\n- src/core/workflow.rs\n- src/core/lww.rs\n- src/cli/list.rs (display)\n- src/migrate/go_export.rs (migration)","priority":3,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"fd18a198-0db8-df1b-3776-eb192099fe05","counter":2618760728762356244}]},"cc":{"max":{}}},"status":"open","_at":[1768622459363,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.24","created_at":[1768622460298,0],"created_by":"darin@darinsmcstudio2.lan","title":"Implement agent audit trail - .beads/interactions.jsonl for LLM call logging","description":"","design":"Port the audit trail feature from Go beads to beads-rs, with redesign for Rust architecture.\n\n## Problem\n\nNeed to log agent interactions (LLM calls, tool invocations) for:\n1. Auditing: \"Why did the agent do that?\"\n2. Dataset generation: SFT/RL fine-tuning\n3. Debugging agent behavior\n\n## Go beads approach\n\nAppend-only JSONL file at `.beads/interactions.jsonl` with:\n- `bd audit record`: Append an interaction entry\n- `bd audit label`: Append a label referencing a parent entry\n\nEntry types:\n- `llm_call`: Model, prompt, response, error\n- `tool_call`: Tool name, exit code, error\n- `label`: Parent entry ID, label value (good/bad), reason\n\n## Redesign needed for beads-rs\n\n**Key question**: Should this be daemon-managed or file-based?\n\n**Option A: Daemon-managed (recommended)**\n- Audit entries go through daemon like other operations\n- Ensures consistency with db state\n- Allows querying audit log via RPC\n- Syncs via git with rest of state\n\n**Option B: Pure file-based**\n- CLI directly appends to JSONL\n- No daemon dependency\n- Simple but less integrated\n\n## Implementation approach (Option A)\n\n**Core types** (`src/core/audit.rs`):\n```rust\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AuditEntry {\n    pub id: String,           // int-xxxxxxxx\n    pub kind: AuditKind,\n    pub created_at: DateTime<Utc>,\n    pub actor: Option<String>,\n    pub issue_id: Option<String>,\n    // Kind-specific fields\n    pub model: Option<String>,\n    pub prompt: Option<String>,\n    pub response: Option<String>,\n    pub error: Option<String>,\n    pub tool_name: Option<String>,\n    pub exit_code: Option<i32>,\n    pub parent_id: Option<String>,  // for labels\n    pub label: Option<String>,\n    pub reason: Option<String>,\n    pub extra: Option<serde_json::Value>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum AuditKind {\n    LlmCall,\n    ToolCall,\n    Label,\n}\n```\n\n**Storage** (`src/daemon/audit.rs`):\n- Write to `.beads/interactions.jsonl` \n- Append-only operations\n- Thread-safe file writes\n- Auto-create file if missing\n\n**CLI commands**:\n```bash\nbd audit record --kind llm_call --model claude-opus-4 --prompt \"...\" --response \"...\"\nbd audit record --stdin < entry.json\nbd audit label <entry-id> --label good --reason \"correct analysis\"\n```\n\n**Daemon operations**:\n- `OpAuditRecord`: Append audit entry\n- `OpAuditLabel`: Append label entry\n- Returns entry ID\n\n## Files to reference\n\nGo implementation:\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/audit.go`\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/audit/audit.go`\n\n## Design notes\n\n**CRITICAL REDESIGN QUESTION**: Should audit log:\n1. Live in `.beads/` and sync via git store ref?\n2. Have its own sync mechanism?\n3. Be optional/opt-in feature?\n\n**Sync considerations**:\n- Audit log can grow large quickly\n- May want separate retention/cleanup policy\n- Should it be in beads/store branch or separate?\n\n**ID format**: `int-xxxxxxxx` (8 hex chars, same as Go)\n\n**File permissions**: 0644 (intended to be shared via git)\n\n**Timestamp**: Always UTC\n\n## Questions for human\n\n1. **Where should interactions.jsonl live?** Same git ref as beads data, or separate?\n2. **Sync strategy?** Include in normal sync or separate mechanism?\n3. **Size limits?** Should we auto-rotate or prune old entries?\n4. **Privacy?** Any PII concerns with logging prompts/responses?\n5. **Schema version?** Add schema_version field for future evolution?","acceptance_criteria":"- [ ] Human has decided on sync strategy for interactions.jsonl\n- [ ] AuditEntry type defined in src/core\n- [ ] Append-only writes to .beads/interactions.jsonl\n- [ ] bd audit record command works\n- [ ] bd audit label command works\n- [ ] JSON stdin input supported\n- [ ] Entry IDs generated with int- prefix\n- [ ] Thread-safe concurrent writes\n- [ ] Auto-creates file if missing","priority":3,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"fc00a13d-4e3b-5c88-24ff-700f43dc8547","counter":13245693131981583272}]},"cc":{"max":{}}},"status":"open","_at":[1768622460298,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.25","created_at":[1768622461123,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add Agent issue type support","description":"**Problem**\nbeads-rs lacks the Agent issue type - agent identity beads that represent autonomous workers in the swarm. Agents self-report state (idle/working/stuck/dead), maintain last_activity for timeout detection, and have slots for current work (hook_bead) and role definition (role_bead).\n\n**What Agent Beads Do (from Go beads)**\nAgent beads are first-class entities in the issue tracker. Each agent (polecat, witness, mayor, etc.) has a bead that:\n- Tracks agent lifecycle state (spawning → running → working → done/stuck/dead)\n- Records last_activity timestamp for heartbeat monitoring\n- Links to role definition (role_bead) and current work (hook_bead)\n- Enables Witness to detect dead agents via timeout\n- Provides audit trail of agent behavior\n\nAgent states (internal/types/types.go lines 579-591):\n- idle: Waiting for work\n- spawning: Starting up\n- running: Executing (general)\n- working: Actively working on a task\n- stuck: Blocked, needs help\n- done: Completed current work\n- stopped: Clean shutdown\n- dead: Died without clean shutdown (set by Witness)\n\n**Go Implementation**\nType definition (internal/types/types.go):\n- IssueType = TypeAgent (line 490)\n- Fields (lines 106-113):\n  - HookBead string: Current work on agent's hook (0..1 cardinality)\n  - RoleBead string: Role definition bead (required)\n  - AgentState AgentState: Current state enum\n  - LastActivity *time.Time: Updated on each action\n  - RoleType string: Role name (polecat|crew|witness|refinery|mayor|deacon)\n  - Rig string: Rig name (empty for town-level agents)\n\nCLI (cmd/bd/agent.go):\n- bd agent state <agent> <state> - Set state and update last_activity\n- bd agent heartbeat <agent> - Update last_activity only\n- bd agent show <agent> - Display agent details\n- bd agent backfill-labels - Migrate old agent beads\n\nSlot management (cmd/bd/slot.go):\n- bd slot set <agent> hook <bead> - Attach work to agent's hook\n- bd slot clear <agent> hook - Detach work from hook\n- bd slot set <agent> role <bead> - Set role definition\n- bd slot show <agent> - Show all slot values\n\nAuto-creation: If agent doesn't exist, bd agent state auto-creates it with gt:agent label.\n\nAgent ID patterns (parseAgentIDFields in agent.go lines 787-842):\n- Town-level: gt-mayor, gt-deacon (no rig)\n- Rig-level singleton: gt-gastown-witness (rig=\"gastown\", role=\"witness\")\n- Rig-level named: gt-gastown-polecat-nux (rig=\"gastown\", role=\"polecat\")\n\n**Design for Rust**\nData model (src/core/):\n```rust\npub enum AgentState {\n    Idle, Spawning, Running, Working, Stuck, Done, Stopped, Dead,\n}\n\npub struct AgentData {\n    state: AgentState,\n    last_activity: Option<SystemTime>,\n    hook_bead: Option<String>,  // 0..1 cardinality\n    role_bead: Option<String>,  // required\n    role_type: Option<String>,  // polecat, witness, etc.\n    rig: Option<String>,        // rig name or empty for town-level\n}\n```\n\nAdd AgentData to Bead or use optional fields.\n\nCLI surface (src/cli/):\n- bd agent state <agent> <state>\n- bd agent heartbeat <agent>\n- bd agent show <agent>\n- bd slot set <agent> <slot> <bead>\n- bd slot clear <agent> <slot>\n- bd slot show <agent>\n\nCardinality enforcement:\n- hook slot: 0..1 (error if already occupied)\n- role slot: required for agents\n\nAuto-creation:\n- Parse agent ID to extract role_type and rig\n- Create with appropriate labels\n\n**Design Notes**\n- Agent beads are infrastructure, not user work items\n- last_activity is critical for Witness timeout detection\n- Slots enforce cardinality at write time (unlike labels)\n- Cross-rig agent references need multi-repo support\n- Auto-creation reduces friction for new agents\n- Consider: Should agents have their own namespace to avoid ID collisions?\n\n**Acceptance**\n- [ ] AgentState enum defined in src/core/\n- [ ] AgentData struct with all fields\n- [ ] Bead can hold agent-specific fields\n- [ ] bd agent state sets state and last_activity\n- [ ] bd agent heartbeat updates only last_activity\n- [ ] bd agent show displays agent fields\n- [ ] bd slot set/clear/show commands work\n- [ ] Hook slot enforces 0..1 cardinality\n- [ ] Agent auto-creation works for non-existent IDs\n- [ ] Agent ID parsing extracts role_type and rig\n- [ ] Tests for agent state transitions\n- [ ] Tests for slot cardinality enforcement\n- [ ] Migration from Go beads preserves agent fields\n\n**Files to study in Go beads:**\n- tmp/beads/internal/types/types.go (lines 106-113: agent fields, 579-600: AgentState)\n- tmp/beads/cmd/bd/agent.go (entire file: CLI implementation)\n- tmp/beads/cmd/bd/slot.go (entire file: slot management)\n- tmp/beads/cmd/bd/agent_test.go","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"c683eaf3-0a41-e8b4-8330-6cdb69dab6f6","counter":9274434705844063688}]},"cc":{"max":{}}},"status":"open","_at":[1768622461123,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.26","created_at":[1768622465359,0],"created_by":"darin@darinsmcstudio2.lan","title":"bd list --pretty with colorized output","description":"**Problem**\n`bd list` output is plain text. Need colorized, formatted output using Ayu theme colors for better scannability.\n\n**Design**\nAdd `--pretty` flag that enables:\n- Status icons with semantic colors (○ open, ◐ in_progress, ● blocked, ✓ closed, ❄ deferred, 📌 pinned)\n- Priority colors: P0 red, P1 orange, P2 gold, P3/P4 neutral\n- Type colors: bug red, epic purple, others neutral\n- Closed issues: entire line dimmed\n- Tree structure for parent-child relationships\n\nFormat per issue:\n```\nSTATUS_ICON ID PRIORITY [Type] Title\n```\n\nReference: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/list.go` formatPrettyIssue()\nStyles: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/ui/styles.go`\n\nAyu colors (from styles.go):\n- P0: #f07171 (red) bold\n- P1: #ff8f40 (orange)\n- P2: #e6b450 (gold)\n- In progress: #ffb454 (yellow)\n- Blocked: #f26d78 (red)\n- Closed: #8090a0 (muted)\n- Bug: #f26d78 (red)\n- Epic: #d2a6ff (purple)\n\n**Design Notes**\n- Use `owo-colors` or `yansi` crate for ANSI coloring\n- Detect NO_COLOR env var and TTY (disable colors if piped)\n- Small Unicode symbols (○●◐), NOT emoji blobs\n- Icons before ID for quick scanning\n- Default to --pretty when stdout is TTY\n\n**Acceptance**\n- [ ] --pretty flag enables colorized output\n- [ ] Status icons with semantic colors\n- [ ] Priority colors (P0/P1 colored, P2-P4 neutral)\n- [ ] Type colors (bug/epic colored, others neutral)\n- [ ] Closed issues dimmed (entire line)\n- [ ] Respects NO_COLOR and non-TTY\n- [ ] Tree structure for parent-child\n\n**Files:**\n- `src/cli/list.rs`\n- `src/cli/ui.rs` (color palette and rendering helpers)\n- `Cargo.toml` (add color crate)","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622465359,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.27","created_at":[1768622466497,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add bd mol distill command to beads-rs","description":"**Problem**\nNeed bd mol distill to extract ad-hoc epics into reusable proto templates. Distill is the reverse of pour - it captures successful workflows for reuse.\n\n**What is Distill?**\nDistill extracts an epic with children → proto template:\n- Input: Existing epic + children (ad-hoc work)\n- Output: Proto with 'template' label (reusable pattern)\n- Process: Extracts structure, preserves deps, adds {{var}} placeholders\n\n**Use Cases**\n- Captured a good workflow? Distill it for reuse\n- Created epic manually? Make it a template\n- Want to replicate a pattern? Extract the proto\n\n**How it Works (Go beads)**\n1. Load epic subgraph (epic + all children + deps)\n2. Identify variable candidates (titles, descriptions)\n3. Replace literals with {{var}} placeholders\n4. Create new proto issue with 'template' label\n5. Clone children with placeholders\n6. Preserve dependency topology\n\n**Command Syntax**\nbd mol distill <epic-id> [--as proto-name] [--dry-run]\n\n**Examples**\n- bd mol distill bd-abc123 --as mol-my-workflow\n- bd mol distill bd-feature-123 --dry-run  # preview extraction\n\n**Design Considerations**\n- Heuristics for variable detection\n- Title/description placeholder insertion\n- Dependency preservation\n- Label handling (strip instance-specific labels?)\n- Human review before saving (--dry-run default?)\n\n**Files to Study (Go beads)**\n- cmd/bd/mol_distill.go (if exists - grep found it)\n- cmd/bd/template.go - loadTemplateSubgraph (reverse operation)\n- docs/MOLECULES.md - distill mention (line 56)\n\n**Acceptance**\n- [ ] bd mol distill command implemented\n- [ ] Epic subgraph extraction\n- [ ] Variable placeholder insertion\n- [ ] Dependency topology preserved\n- [ ] Creates proto with 'template' label\n- [ ] --dry-run preview mode\n- [ ] --as flag for custom proto name\n- [ ] Tests for distill workflow\n","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"a9066714-feee-969b-7d79-d304cc0ea93a","counter":1257918874056156675}]},"cc":{"max":{}}},"status":"open","_at":[1768622466497,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.28","created_at":[1768622470110,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add child-to-parent dependency deadlock detection","description":"**Problem**\nGo beads prevents a specific anti-pattern: children explicitly depending on their parent via blocks/waits-for. This creates a deadlock because:\n- Child can't start (parent is open)\n- Parent can't close (children not done)\n\nThis is an LLM temporal reasoning trap. beads-rs needs this validation.\n\n**How it works in Go beads**\n- Detection in cmd/bd/dep.go lines 152-154 and 343-345\n- Uses `isChildOf()` helper (lines 31-44)\n- Checks hierarchical ID structure: \"bd-abc.1\" is child of \"bd-abc\"\n- Blocks creation with clear error message\n- Error: \"Adding an explicit dependency would create a deadlock\"\n- Pure validation logic - no fix, just reject\n\n**Detection algorithm**\n```go\nfunc isChildOf(childID, parentID string) bool {\n    _, actualParentID, depth := types.ParseHierarchicalID(childID)\n    if depth == 0 {\n        return false // Not hierarchical\n    }\n    if actualParentID == parentID {\n        return true // Immediate parent\n    }\n    return strings.HasPrefix(childID, parentID + \".\")\n}\n```\n\n**Design for Rust**\n1. Add hierarchical ID parsing to BeadId in src/core/identity.rs\n   - Parse \"bd-abc.1.2\" into (base, depth, parent)\n   - Depth 0 = not hierarchical\n2. Add is_child_of() method to BeadId\n3. Add validation in dep add operation (daemon/ops/)\n   - Check if from.is_child_of(to) for blocks/waits-for deps\n   - Return clear error if detected\n4. Add test cases for edge cases:\n   - Immediate child: bd-abc.1 depends on bd-abc\n   - Nested child: bd-abc.1.2 depends on bd-abc\n   - Non-hierarchical: bd-abc depends on bd-xyz (ok)\n\n**Design considerations**\n- Which dep types need this check?\n  * Blocks: yes (creates deadlock)\n  * WaitsFor: yes (creates deadlock)\n  * Parent: no (that's the hierarchy itself)\n  * Others: no (informational)\n- Should we check reverse (parent depending on child)? \n  * That's actually fine - parent blocks until child done\n- Error message clarity for LLMs\n\n**Design questions for human review**\n- Should we detect transitive child relationships?\n  * \"bd-abc.1.2\" is grandchild of \"bd-abc\"\n  * Current Go code handles this via prefix check\n- Should this be a warning or hard error?\n  * Go: hard error (prevents creation)\n  * Seems right - this is always wrong\n\n**Files to study**\n- tmp/beads/cmd/bd/dep.go - isChildOf helper, validation sites\n- tmp/beads/internal/types/types.go - ParseHierarchicalID function\n- src/core/identity.rs - BeadId structure\n\n**Acceptance**\n- [ ] BeadId supports hierarchical parsing\n- [ ] is_child_of() method implemented and tested\n- [ ] Dep add validates child-to-parent for blocks/waits-for\n- [ ] Clear error message returned on violation\n- [ ] Test coverage for immediate and nested children\n- [ ] Cargo fmt, clippy, test pass","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"ae55787a-141c-0d47-2a60-cc9b56483175","counter":17864181886599255929}]},"cc":{"max":{}}},"status":"open","_at":[1768622470110,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.29","created_at":[1768622475281,0],"created_by":"darin@darinsmcstudio2.lan","title":"Init contributor mode - OSS fork workflow support","description":"**Problem**\nOSS contributors face a recursion problem: when using beads to track work on the beads project itself, their personal planning issues leak into PRs. The `.beads/` directory is git-tracked (it's the canonical issue database), but contributors' local issues pollute the diff.\n\n**What the Feature Does**\n`bd init --contributor` wizard that sets up stealth mode for OSS contributors:\n1. Detects fork/contributor status (HTTPS remote vs SSH)\n2. Creates personal planning repo (e.g., `~/.beads-planning/`)\n3. Configures auto-routing:\n   - `routing.mode = auto`\n   - `routing.contributor = ~/.beads-planning`\n   - `routing.maintainer = .`\n4. New issues auto-route to planning repo\n5. Planning issues never appear in upstream PRs\n\n**Example Workflow**\n```bash\n# One-time setup\ncd my-fork-of-beads\nbd init --contributor\n\n# All personal issues route to planning repo\nbd create \"TODO: Test edge case before lunch\" -p 2\nbd create \"Investigate Redis alternative\" -p 3\n# → Created in ~/.beads-planning, NOT in ./beads/\n\n# View all work (upstream + planning)\nbd ready\nbd list\n\n# Git commit/push - no .beads/ pollution in PR ✅\ngit commit -am \"fix: Handle null case\"\ngit push origin my-branch\n```\n\n**Why It Needs Design Work**\n\n1. **Role Detection**:\n   - How to reliably detect maintainer vs contributor?\n   - Git remote URL inspection (SSH = maintainer, HTTPS = contributor)\n   - Explicit override: `git config beads.role contributor`\n   - What about CI environments? Multi-machine setups?\n   - Edge cases: Work machine (SSH) vs personal machine (HTTPS)\n\n2. **Routing vs BEADS_DIR**:\n   - Go beads has BOTH routing config AND BEADS_DIR env var\n   - Which takes precedence?\n   - Backward compatibility with existing BEADS_DIR users?\n   - Should --contributor use routing or BEADS_DIR?\n\n3. **Database Aggregation**:\n   - Contributors need unified view: upstream issues + personal issues\n   - How to merge/hydrate multiple databases for queries?\n   - `bd ready` should show work from both repos\n   - `bd list` should aggregate\n   - But mutations route correctly based on source\n\n4. **Discovered Issue Inheritance**:\n   - If working on upstream issue bd-123, discover bug\n   - Should discovered issue go to planning or upstream?\n   - Go approach: `discovered-from` inherits parent's `source_repo`\n   - Rationale: Discovered work related to parent task\n\n**Key Decisions to Make**\n\n1. **Planning Repo Location**:\n   - Default: `~/.beads-planning/`\n   - User-configurable?\n   - Per-project planning repos? (e.g., `~/.beads-planning-beads/`)\n   - Naming convention?\n\n2. **Auto-Routing Algorithm**:\n   ```\n   When creating issue:\n   1. Check explicit --repo flag (highest priority)\n   2. Check BEADS_DIR env var\n   3. Check routing.mode config\n      - If \"auto\": Detect role → route based on role\n      - If \"explicit\": Use routing.default\n   4. Fallback: Current repo (.)\n   ```\n\n3. **Wizard Flow**:\n   - Detect fork automatically (check git remote)\n   - Prompt for planning repo location\n   - Ask about multi-repo hydration?\n   - Configure sync behavior for planning repo?\n   - Set up gitignore in planning repo?\n\n4. **Integration with Existing Config**:\n   - Go beads has `sync.remote`, `sync.branch` config\n   - Does planning repo have separate sync config?\n   - Or inherit from project repo?\n\n**Trade-offs to Consider**\n\n1. **Automatic vs Manual**:\n   - Pro Auto: Zero-friction, prevents pollution\n   - Con Auto: Magic behavior can confuse\n   - Solution: Clear output showing where issue was created\n\n2. **Single DB vs Dual DB**:\n   - Single: Simpler, easier to query\n   - Dual: Complete isolation, no pollution possible\n   - Dual wins for safety\n\n3. **Discovered Issue Routing**:\n   - Option A: Always go to upstream (they're real bugs)\n   - Option B: Go to planning (keep isolation)\n   - Option C: Inherit parent (Go's approach) ✅\n   - Rationale for C: Discovered work is part of parent task\n\n4. **Privacy**:\n   - Planning repo in home directory = private\n   - But if accidentally committed?\n   - Add .gitignore safety nets?\n\n**Reference Files in Go Beads**\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/docs/CONTRIBUTOR_NAMESPACE_ISOLATION.md` - Full design doc\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/routing/routing.go` - Role detection\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/docs/ROUTING.md` - Auto-routing mechanics\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/docs/MULTI_REPO_AGENTS.md` - Contributor workflows\n\n**Go Implementation Notes**\n- `DetectUserRole(repoPath)` - SSH vs HTTPS detection\n- `DetermineTargetRepo(config, role, path)` - Routing decision\n- `init --contributor` creates `~/.beads-planning/`\n- Explicit `git config beads.role contributor` override\n- `source_repo` field tracks issue provenance\n\n**Open Design Questions**\n\n1. Should first `bd create` without setup show warning?\n   - Pro: Prevents accidental pollution\n   - Con: Friction for new users who might be maintainers\n\n2. Auto-create planning repo on first use?\n   - Pro: True zero-friction\n   - Con: Creates files user didn't ask for\n\n3. How to handle \"graduation\" of issues?\n   - Contributor discovers real bug, wants to file upstream\n   - Need `bd migrate` or `bd promote` command?\n   - Or just manually create in upstream?\n\n**Acceptance**\n- [ ] Design document for contributor mode architecture\n- [ ] Role detection algorithm spec (SSH/HTTPS, overrides, edge cases)\n- [ ] Routing precedence rules (--repo, BEADS_DIR, config)\n- [ ] Planning repo initialization spec\n- [ ] Database aggregation/hydration design\n- [ ] Discovered issue inheritance rules\n- [ ] Wizard UX flow\n- [ ] Migration path for existing BEADS_DIR users\n- [ ] Privacy/safety considerations\n- [ ] Integration with sync config","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"091c4987-c9c2-c5f5-5230-fb145ebc5f7f","counter":16402908577586216834}]},"cc":{"max":{}}},"status":"open","_at":[1768622475281,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.3","created_at":[1768622397302,0],"created_by":"darin@darinsmcstudio2.lan","title":"Mail system - Inter-agent messaging","description":"**Problem**\nAgents need to communicate asynchronously across rigs/workspaces. The Go beads `bd mail` feature enables inter-agent messaging but currently beads-rs just delegates to external providers (like gt mail). We need native mail functionality.\n\n**What the Feature Does**\nFull inter-agent messaging system with commands:\n- `bd mail send <recipient> --subject <subject> [--body <body>]` - Send a message\n- `bd mail inbox [--unread]` - List received messages\n- `bd mail read <msg-id>` - Read a message\n- `bd mail ack <msg-id>` - Acknowledge/mark as read\n- `bd mail reply <msg-id> --body <body>` - Reply to message (threading)\n\nMessages have:\n- ID (msg-xxx format)\n- From/To (BEADS_IDENTITY or config.identity)\n- Subject/Body\n- replies_to field for threading\n- read/acknowledged status\n- timestamp\n\n**Why It Needs Design Work**\n\n1. **Storage Model**: Should messages be:\n   - Separate JSONL file (`.beads/messages.jsonl`)?\n   - In main database with separate table?\n   - Both (db for queries, JSONL for sync)?\n   - How to handle large message volumes?\n\n2. **Identity System**: \n   - How do agents identify themselves? (BEADS_IDENTITY env var? config?)\n   - How do we validate sender identity?\n   - What about privacy/anonymization?\n   - Cross-rig identity mapping?\n\n3. **Routing & Addressing**:\n   - How do you address recipients? (rig name? prefix? both?)\n   - Does routing use routes.jsonl for delivery?\n   - What about broadcast/group messages?\n   - How to handle offline recipients?\n\n4. **Threading Model**:\n   - replies_to field creates threads\n   - How to display conversation trees?\n   - Do threads need special query support?\n   - What about quoting/context in replies?\n\n5. **Sync Behavior**:\n   - Messages sync via git like issues\n   - But privacy implications - do you want all messages in git history?\n   - Option for local-only messages?\n   - Encryption for sensitive comms?\n\n**Key Decisions to Make**\n\n1. **Schema Design**:\n   - Message data structure (see Go implementation in beads for reference)\n   - Index strategy (by recipient, by thread, by read status)\n   - JSONL format vs database-only\n\n2. **Delivery Semantics**:\n   - Push (via git sync) vs Pull (recipient checks)?\n   - Notification mechanism?\n   - Delivery confirmation?\n\n3. **Delegation Model**:\n   - Go beads delegates to external providers (gt mail)\n   - Should beads-rs also support delegation?\n   - Or always use built-in implementation?\n   - Configuration: `mail.delegate` for backward compat?\n\n4. **Message Types**:\n   - Plain text only or structured (JSON)?\n   - Attachments (issue references, diffs)?\n   - Special message types (notifications, alerts)?\n\n**Trade-offs to Consider**\n\n1. **Git History Pollution**:\n   - Pro: Messages sync automatically\n   - Con: Clutters git log, privacy concerns\n   - Option: Separate branch for messages?\n\n2. **Complexity**:\n   - Full mail system is complex\n   - Could start minimal (send/inbox only)\n   - Add threading/ack later\n\n3. **Delegation vs Native**:\n   - Delegation (Go approach): Simpler, reuses existing infra\n   - Native: Better integration, no external deps\n   - Hybrid: Support both?\n\n**Reference Files in Go Beads**\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/mail.go` - Delegation approach\n- Look for mail implementation in orchestrator (gt) for full example\n- AGENTS.md mentions mail but no detailed spec found\n\n**Acceptance**\n- [ ] Design document describing storage model, schema, and sync behavior\n- [ ] Identity system design (how agents identify themselves)\n- [ ] Routing and addressing spec\n- [ ] API design for mail commands\n- [ ] Decision on delegation vs native implementation\n- [ ] Privacy/security considerations documented","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"8fb37d17-5720-a0fd-02b5-11ada42e2ded","counter":7287367238972670084}]},"cc":{"max":{}}},"status":"open","_at":[1768622397302,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.30","created_at":[1768622478293,0],"created_by":"darin@darinsmcstudio2.lan","title":"bd list --watch for live-updating view","description":"**Problem**\nUsers need to monitor issue changes in real-time. Go beads lacks this feature but it's a natural UX enhancement.\n\n**Design**\nAdd `--watch` flag to `bd list` that:\n- Clears screen and re-renders list every N seconds (default 2s)\n- Uses `--interval` flag to customize refresh rate\n- Shows timestamp of last update at top\n- Exits on Ctrl+C (SIGINT)\n- Uses fsnotify/file watching for efficient change detection (optional optimization)\n\nExample usage:\n```bash\nbd list --status open --watch\nbd list --priority 0,1 --watch --interval 5s\n```\n\nDisplay format:\n```\nbd list (last updated: 2025-01-16 14:30:45)\n\n● bd-abc123 P0 [bug] Fix auth timeout\n○ bd-def456 P1 [feature] Add OAuth\n...\n\nPress Ctrl+C to exit\n```\n\n**Design Notes**\n- Use crossterm for terminal clearing and cursor control\n- Watch database file mtime for changes (avoid constant re-queries)\n- Combine with --pretty for best UX\n- --json mode incompatible with --watch (error)\n- Use tokio::time::interval for async refresh loop\n\n**Acceptance**\n- [ ] --watch flag refreshes list automatically\n- [ ] --interval controls refresh rate (default 2s)\n- [ ] Shows last update timestamp\n- [ ] Clears screen between refreshes\n- [ ] Exits cleanly on Ctrl+C\n- [ ] Errors if combined with --json\n- [ ] Works with all existing list filters\n\n**Files:**\n- `src/cli/list.rs`\n- `Cargo.toml` (add crossterm, notify crates)","priority":3,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622478293,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.31","created_at":[1768622479545,0],"created_by":"darin@darinsmcstudio2.lan","title":"Custom statuses configuration system","description":"**Problem**\n\nGo beads allows project-specific custom statuses via configuration. This enables teams to define workflow states beyond the built-in statuses (open, in_progress, blocked, deferred, closed, pinned, hooked).\n\nMissing from beads-rs:\n- Config option for custom statuses\n- Validation that accepts custom statuses\n- Display for custom statuses\n- Similar to custom types system\n\nExample from Go beads:\n```bash\nbd config set status.custom \"awaiting_review,testing,staging\"\n```\n\nThis allows:\n```bash\nbd update bd-abc --status=awaiting_review\n```\n\n**Design**\n\nAdd status.custom config option and validation support.\n\nConfig schema (in .beads.toml):\n```toml\n[status]\ncustom = [\"awaiting_review\", \"testing\", \"staging\"]\n```\n\nOr via CLI:\n```bash\nbd config set status.custom \"awaiting_review,testing,staging\"\n```\n\nValidation:\n- ValidateWithCustomStatuses(customStatuses []string) in Go (types.go line 319)\n- Rust equivalent: Status::is_valid_with_custom(&[String])\n\nBuilt-in statuses are always valid. Custom statuses are validated against config.\n\nDisplay:\n- Custom statuses use default text color (no special styling)\n- Icon: Use \"○\" (hollow circle) as default for unknown/custom statuses\n- Projects can define their own display rules via config (future enhancement)\n\nImplementation files:\n- `src/core/config.rs` - Add status.custom config field\n- `src/core/workflow.rs` - Add is_valid_with_custom() method to Status\n- `src/core/state.rs` - Load custom statuses from config, validate with them\n- `src/daemon/ops.rs` - Use custom status validation when updating beads\n- `src/cli/update.rs` - Accept custom statuses in --status flag\n- `src/cli/list.rs` - Display custom statuses\n\n**Design Notes**\n\nSimilar pattern to custom types (if they exist in beads-rs). Custom statuses:\n- Are defined per-repository (in .beads.toml)\n- Are validated at bead creation/update time\n- Are trusted during import (federation trust model)\n\nCustom status validation should:\n1. Check against built-in statuses first (open, in_progress, etc.)\n2. Then check against custom status list from config\n3. Reject if neither match\n\nStatus validation errors should be helpful:\n```\nError: Invalid status \"review\". Valid statuses: open, in_progress, blocked, deferred, closed, pinned, hooked\nCustom statuses (if configured): awaiting_review, testing, staging\n```\n\nEdge cases:\n- Empty custom status list is valid (no custom statuses)\n- Custom status names must be valid identifiers (lowercase, underscores)\n- Custom statuses can't override built-in statuses\n- Migration from Go beads should preserve custom statuses\n\n**Acceptance**\n\n- [ ] Config has status.custom field (Vec<String>)\n- [ ] `bd config set status.custom \"status1,status2\"` stores custom statuses\n- [ ] Status::is_valid_with_custom() validates against both built-in and custom\n- [ ] `bd update [id] --status=<custom>` accepts custom statuses\n- [ ] Custom statuses display with default styling\n- [ ] Validation errors list both built-in and custom statuses\n- [ ] Tests for custom status validation\n- [ ] Migration preserves custom statuses from Go beads\n\n**Files:**\n- src/core/config.rs\n- src/core/workflow.rs\n- src/core/state.rs\n- src/daemon/ops.rs\n- src/cli/update.rs\n- src/cli/config.rs","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"bfc8464a-15fb-2392-9a9f-e1cb0e1d2235","counter":15371289346030766909}]},"cc":{"max":{}}},"status":"open","_at":[1768622479545,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.32","created_at":[1768622484942,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add bd swarm commands to beads-rs","description":"**Problem**\nNeed swarm coordination commands for multi-agent parallel work on epics. Swarms are DIFFERENT from molecules - they're descriptive (compute ready fronts) vs prescriptive (define workflow).\n\n**What are Swarms?**\nSwarms are multi-agent coordination for parallel epic execution:\n- Analyze: Compute ready fronts (waves of parallel work)\n- Validate: Check epic structure (cycles, inversions, disconnected subgraphs)\n- Status: Show current progress (completed/active/ready/blocked)\n- Create: Link swarm molecule to epic (mol_type=swarm)\n\n**Key Insight**\nSwarms compute ready work from epic dependency graphs. They DON'T prescribe workflow - they discover parallelism opportunities.\n\n**Commands**\n- bd swarm validate <epic-id> - analyze structure, show waves\n- bd swarm status <epic-id> - current execution state\n- bd swarm create <epic-id> - create swarm molecule\n- bd swarm list - list active swarms\n\n**How it Works (Go beads)**\n1. Load epic + all children\n2. Build dependency graph (only within epic)\n3. Topological sort to find ready fronts (Kahn's algorithm)\n4. Detect structural issues (cycles, inversions, disconnected)\n5. Compute max parallelism and estimated sessions\n6. Create swarm molecule (mol_type=swarm, links via relates-to)\n\n**Swarm Analysis Output**\n- Ready fronts: Wave 1 (issues ready now), Wave 2 (after Wave 1), etc.\n- Max parallelism: Largest wave size\n- Estimated sessions: Total issue count\n- Warnings: Potential dependency inversions, disconnected subgraphs\n- Errors: Cycles (makes epic non-swarmable)\n\n**Molecule vs Swarm**\n- Molecule (prescriptive): Template defines workflow (proto → pour → execute)\n- Swarm (descriptive): Analyze existing epic, compute ready work\n\n**Design Considerations**\n- Dependency graph traversal\n- Topological sort with level tracking\n- Cycle detection\n- Heuristic warnings (\"foundation\" issues with no dependents)\n- SwarmAnalysis struct with ready fronts\n- MolType enum (swarm/patrol/work)\n\n**Files to Study (Go beads)**\n- cmd/bd/swarm.go - all swarm commands\n- internal/types/types.go - MolType field (line ~114)\n- docs/MOLECULES.md - swarm explanation (line 21-26)\n\n**Acceptance**\n- [ ] MolType field added to Issue\n- [ ] bd swarm validate command\n- [ ] bd swarm status command  \n- [ ] bd swarm create command\n- [ ] bd swarm list command\n- [ ] Ready front computation (Kahn's algorithm)\n- [ ] Cycle detection\n- [ ] Structural issue warnings\n- [ ] Tests for swarm analysis\n","priority":2,"type":"epic","labels":{"entries":{"human-needed":[{"replica":"5f3785ea-5661-6d1e-7adc-7479efe8c166","counter":16418486850439135454}]},"cc":{"max":{}}},"status":"open","_at":[1768622484942,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.33","created_at":[1768622485660,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add replies-to dependency type for conversation threading","description":"**Problem**\nGo beads supports replies-to dependencies for threading messages/comments. This creates reply chains for inter-agent communication. beads-rs needs this for future messaging features.\n\n**How it works in Go beads**\n- Dependency type: `DepRepliesTo` (in internal/types/types.go)\n- Creates conversation threads\n- ThreadID field groups conversation edges for efficient queries\n- Typically paired with message/comment issue types\n- Non-blocking (doesn't affect ready work)\n\n**Design for Rust**\n1. Add `RepliesTo` variant to `DepKind` enum in src/core/domain.rs\n2. Mark it as non-DAG-enforcing (informational link)\n3. Add optional thread_id field to DepEdge metadata\n   - Groups conversation edges\n   - Enables \"get all replies in thread\" queries\n4. Consider future: reply chain rendering, thread navigation\n\n**Design considerations**\n- ThreadID generation: root message ID? UUID?\n- Should we validate reply targets exist?\n- Threading semantics: linear chain vs tree?\n  * Go: supports both (multiple replies to same message)\n- Display strategy: nest replies in bd show?\n\n**Design questions for human review**\n- Do we need this now or defer until messaging is built?\n  * Pro defer: no users yet, avoid speculative design\n  * Pro now: complete dep type parity with Go\n- Should replies-to enforce message/comment types?\n  * Or allow replying to any bead?\n- Thread query API: part of this bead or separate?\n\n**Files to study**\n- tmp/beads/internal/types/types.go - DepRepliesTo, ThreadID field\n- tmp/beads/cmd/bd/dep.go - how it's used (if at all)\n- Go beads messaging features (if implemented)\n\n**Acceptance**\n- [ ] RepliesTo added to DepKind enum\n- [ ] Optional thread_id metadata field defined\n- [ ] Non-blocking (doesn't affect ready work)\n- [ ] Serde support for thread_id\n- [ ] Cargo fmt, clippy, test pass","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"2e66163b-8b72-8892-a8a1-77839b5f1552","counter":6851366315712993401}]},"cc":{"max":{}}},"status":"open","_at":[1768622485660,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.34","created_at":[1768622488769,0],"created_by":"darin@darinsmcstudio2.lan","title":"Implement stale database handling - AllowStale mode for read-only commands","description":"","design":"Port the stale database handling feature from Go beads to beads-rs.\n\n## Problem\n\nWhen database is stale (git store ref has updates not yet imported), normal commands fail. This breaks read-only workflows where you just want to query current state.\n\n## Go beads solution\n\n`AllowStale` flag that:\n1. Allows read-only commands to proceed with current db state\n2. Auto-imports on stale db for read commands\n3. Fails fast for write commands\n\nStale detection: Compare db last_sync timestamp with git store ref commit time.\n\n## Implementation approach\n\n**Core stale detection** (`src/daemon/staleness.rs`):\n```rust\npub struct StalenessChecker {\n    store_ref: String,  // refs/heads/beads/store\n}\n\nimpl StalenessChecker {\n    /// Check if database is stale compared to git store\n    pub fn is_stale(&self, db: &CanonicalState, repo: &Repository) -> Result<bool> {\n        let store_commit = repo.find_reference(&self.store_ref)?\n            .peel_to_commit()?;\n        let store_time = store_commit.time().seconds();\n        \n        let db_sync_time = db.last_sync_time();\n        \n        Ok(store_time > db_sync_time)\n    }\n    \n    /// Get staleness info for display\n    pub fn staleness_info(&self, db: &CanonicalState, repo: &Repository) -> Result<StalenessInfo> {\n        // commits ahead, time delta, etc.\n    }\n}\n```\n\n**Command context** (`src/daemon/state.rs`):\n```rust\npub struct CommandContext {\n    pub allow_stale: bool,\n    pub readonly: bool,\n}\n\nimpl DaemonState {\n    pub fn check_staleness(&self, ctx: &CommandContext) -> Result<()> {\n        if self.is_stale()? {\n            if ctx.readonly && ctx.allow_stale {\n                // Auto-import for read commands\n                self.import_from_store()?;\n                Ok(())\n            } else if ctx.readonly {\n                warn!(\"Database is stale, proceeding with current state\");\n                Ok(())\n            } else {\n                Err(Error::StaleDatabase)\n            }\n        } else {\n            Ok(())\n        }\n    }\n}\n```\n\n**CLI integration**:\n```rust\n// Global flag\n#[arg(long, global = true)]\nallow_stale: bool,\n\n// Read-only commands automatically use AllowStale\npub const READ_ONLY_COMMANDS: &[&str] = &[\n    \"list\", \"show\", \"ready\", \"blocked\", \"stats\", \n    \"dep-tree\", \"comment-list\"\n];\n```\n\n**Error types** (`src/core/error.rs`):\n```rust\n#[derive(Debug, thiserror::Error)]\npub enum Error {\n    #[error(\"Database is stale. Run 'bd sync' to update, or use --allow-stale\")]\n    StaleDatabase,\n    \n    #[error(\"Cannot perform write operation on stale database\")]\n    WriteOnStale,\n}\n```\n\n## Files to reference\n\nGo implementation:\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/context.go` (AllowStale field)\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/rpc/protocol.go` (read-only ops)\n\nKey logic:\n```go\n// From context.go\nAllowStale   bool\n\n// Auto-import on stale for read commands\nif cmdCtx.AllowStale && isReadOnly {\n    store.ImportFromGit()\n}\n```\n\n## Design notes\n\n**Staleness detection**:\n- Compare git store ref HEAD time with db metadata\n- Store last sync timestamp in db metadata table\n- Cache staleness check result per command\n\n**Auto-import behavior**:\n- Only for read-only commands\n- Transparent to user (maybe log at debug level)\n- Falls back to current state if import fails\n\n**Write command protection**:\n- NEVER allow writes on stale db\n- Clear error message pointing to `bd sync`\n- Prevents merge conflicts from concurrent edits\n\n**Performance**:\n- Staleness check should be fast (cache git ref lookup)\n- Auto-import only when actually stale\n- Don't block reads unnecessarily\n\n## Questions\n\n1. Should auto-import be opt-in or opt-out for read commands?\n2. How stale is too stale? (warn threshold)\n3. Should `bd sync` be run automatically on stale, or require explicit flag?\n4. Cache staleness check for how long?","acceptance_criteria":"- [ ] StalenessChecker detects when db is behind git store\n- [ ] AllowStale flag available globally\n- [ ] Read-only commands auto-import on stale db\n- [ ] Write commands fail fast on stale db\n- [ ] Clear error messages guide user to sync\n- [ ] Staleness info shows commits ahead and time delta\n- [ ] Auto-import is transparent (debug logging only)\n- [ ] No performance regression on staleness check","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"7dec3cad-0b77-499d-5813-2737e4f195dd","counter":8543539697362074134}]},"cc":{"max":{}}},"status":"open","_at":[1768622488769,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.35","created_at":[1768622489084,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add Role issue type support","description":"**Problem**\nbeads-rs lacks the Role issue type - role definition beads that specify agent behavior, responsibilities, and capabilities. Roles are referenced by agent beads via the role_bead field, enabling separation of agent identity (who) from agent behavior (what/how).\n\n**What Role Beads Do (from Go beads)**\nRole beads define:\n- Agent responsibilities and scope\n- Behavioral patterns and workflows\n- Coordination protocols with other roles\n- Skills and capabilities\n\nEach agent bead references a role bead (via role_bead field). This enables:\n- Multiple agents with same role (e.g., multiple polecats)\n- Role updates without touching agent beads\n- Role composition and inheritance\n- Clear separation of identity vs behavior\n\nKnown roles (from internal/types/types.go and agent.go):\n- polecat: Individual contributor, claims and completes work\n- crew: Team-based work, multiple crew members collaborate\n- witness: Monitoring and health checks, timeout detection\n- refinery: Code review and quality gates, merge approval\n- mayor: Town-level orchestration and policy\n- deacon: Operational support, cleanup, maintenance\n\n**Go Implementation**\nType definition (internal/types/types.go):\n- IssueType = TypeRole (line 491)\n- Uses standard Issue fields (no custom fields)\n- Description/Design fields hold role specification\n- Title: Role name (e.g., \"Polecat Role\", \"Witness Role\")\n\nAgent linkage:\n- Agent.RoleBead string field points to role bead ID\n- Agent.RoleType string field holds role name for filtering\n- Labels: role_type:<name> for queries\n\nCLI usage:\n- bd create --type role \"Polecat Role\" - Create role definition\n- bd slot set <agent> role <role-id> - Link agent to role\n- bd list --type role - List all role definitions\n\nRole bead content structure (convention):\n```markdown\n# Polecat Role\n\n## Responsibilities\n- Claim ready work from bd ready\n- Execute tasks independently\n- Report progress via state updates\n- Signal completion or stuck state\n\n## Workflows\n1. Spawn: gt-<rig>-polecat-<name> bead created\n2. Idle: Wait for work\n3. Claim: bd claim <bead-id>\n4. Work: Execute and update state\n5. Complete: bd close <bead-id>\n6. Repeat or Done\n\n## Coordination\n- Reports to: Witness (heartbeat)\n- Escalates to: Mayor (when stuck)\n- Interacts with: Refinery (for merge approval)\n```\n\n**Design for Rust**\nData model (src/core/):\nNo special fields needed - roles are regular beads with:\n- Type = Role\n- Rich markdown in Description/Design\n- Referenced by agent beads via role_bead field\n\nCLI (src/cli/):\n- bd create --type role \"Role name\"\n- bd show <role-id> (render markdown description)\n- bd list --type role\n- bd slot set <agent> role <role-id>\n\nRole discovery:\n- bd list --type role shows available roles\n- Agents parse role_bead to understand behavior\n\n**Design Notes**\n- Roles are configuration/specification, not runtime state\n- Role beads should be pinned (persistent, not work items)\n- Consider: Role versioning for behavior evolution\n- Consider: Role inheritance/composition (roles referencing other roles)\n- Consider: Machine-readable role spec (YAML/JSON in description?)\n- Town-level roles (mayor, deacon) vs rig-level (witness, polecat, crew, refinery)\n\n**Acceptance**\n- [ ] Role type constant defined\n- [ ] bd create --type role works\n- [ ] bd list --type role shows role beads\n- [ ] bd show <role-id> displays role description\n- [ ] bd slot set links agent to role\n- [ ] Agent.role_bead field populated\n- [ ] Role beads can be pinned (persistent context)\n- [ ] Tests for role creation and linking\n- [ ] Migration from Go beads preserves role type\n\n**Files to study in Go beads:**\n- tmp/beads/internal/types/types.go (line 491: TypeRole)\n- tmp/beads/cmd/bd/agent.go (parseAgentIDFields: role classification)\n- tmp/beads/cmd/bd/slot.go (role slot management)","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"6e2239f0-8c35-bba1-235f-0b56baa46874","counter":18246825264147717891}]},"cc":{"max":{}}},"status":"open","_at":[1768622489084,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.36","created_at":[1768622490745,0],"created_by":"darin@darinsmcstudio2.lan","title":"Sorting flags --sort and --reverse for bd list/search","description":"**Problem**\n`bd list` and `bd search` lack flexible sorting. Go beads doesn't have explicit --sort flags but Rust implementation should add this UX improvement.\n\n**Design**\nAdd sorting flags to `bd list` and `bd search`:\n\n`--sort <field>` options:\n- `priority` (default): P0 → P4\n- `created`: oldest → newest\n- `updated`: least recently updated → most recent\n- `status`: open → in_progress → blocked → closed\n- `id`: lexicographic\n- `title`: alphabetic\n\n`--reverse` flag: reverses sort order\n\nExamples:\n```bash\nbd list --sort updated               # least recent first\nbd list --sort priority --reverse    # P4 → P0\nbd list --sort created --reverse     # newest first\nbd search \"auth\" --sort status\n```\n\n**Design Notes**\n- Default sort: priority ASC (P0 first), then created DESC (newest first)\n- Implement in Rust using `sort_by_key` with custom comparators\n- Status sort order: open < in_progress < blocked < deferred < closed\n- Sorting happens in-memory after database query (simple, flexible)\n- Works with all filters (--status, --priority, --label, etc.)\n\n**Acceptance**\n- [ ] --sort flag with options: priority, created, updated, status, id, title\n- [ ] --reverse flag reverses sort order\n- [ ] Default: priority ASC, created DESC\n- [ ] Status sort uses semantic ordering\n- [ ] Works on bd list and bd search\n- [ ] Combines with existing filters\n- [ ] --help documents sort field options\n\n**Files:**\n- `src/cli/list.rs`\n- `src/cli/search.rs`\n- `src/cli/sorting.rs` (new - shared sort logic)","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622490745,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.37","created_at":[1768622499928,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add tracks dependency type for convoy cross-project tracking","description":"**Problem**\nGo beads supports tracks dependencies for convoy issues. Convoys track completion of multiple items across projects with reactive completion semantics. This is non-blocking cross-project reference tracking. beads-rs needs this.\n\n**How it works in Go beads**\n- Dependency type: `DepTracks` (in internal/types/types.go)\n- Convoy issue type tracks multiple issues\n- Non-blocking: doesn't prevent work from starting\n- Reactive: convoy can auto-close when all tracked items close\n- Used for cross-project coordination without blocking\n\n**Design for Rust**\n1. Add `Tracks` variant to `DepKind` enum in src/core/domain.rs\n2. Mark it as non-DAG-enforcing (non-blocking)\n3. Add convoy issue type (separate bead, see parent epic)\n4. Consider: convoy auto-closure logic\n   - When all tracked items close, close convoy?\n   - Or require manual closure?\n\n**Design considerations**\n- Directionality: convoy -> tracked-issue (Go's choice)\n- Query needs: \"list all items tracked by convoy X\"\n- Should tracks support tracking external refs?\n  * Enables cross-repo convoy tracking\n- Convoy completion predicate: all closed? any closed? custom?\n\n**Design questions for human review**\n- Should tracks trigger notifications when items close?\n- Should we support weighted tracking (some items more important)?\n- Should convoy type be required for tracks deps?\n  * Or allow any bead to track others?\n- Auto-closure timing: immediate on last item? batched?\n\n**Files to study**\n- tmp/beads/internal/types/types.go - DepTracks, TypeConvoy\n- tmp/beads/cmd/bd/dep.go - tracks usage in dep list\n- Go beads convoy implementation (if exists)\n\n**Acceptance**\n- [ ] Tracks added to DepKind enum\n- [ ] Non-blocking (doesn't affect ready work)\n- [ ] Can query \"what does convoy X track\"\n- [ ] Supports convoy -> issue directionality\n- [ ] Cargo fmt, clippy, test pass\n\n**Note**\nThis is foundational for convoy support. Full convoy features (auto-closure, reactive completion) likely need separate beads.","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"3f0a6a8e-085d-d2ad-37fa-1e7a9f8b9185","counter":16803162945187070083}]},"cc":{"max":{}}},"status":"open","_at":[1768622499928,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.38","created_at":[1768622510913,0],"created_by":"darin@darinsmcstudio2.lan","title":"Status icons and Ayu theme styling system","description":"**Problem**\nConsistent visual styling across all commands requires a shared UI module with status icons, Ayu color palette, and rendering helpers.\n\n**Design**\nCreate `src/cli/ui.rs` module with:\n\n**Status Icons** (small Unicode, NOT emoji blobs):\n- `○` open (neutral, hollow circle)\n- `◐` in_progress (yellow, half-filled)\n- `●` blocked (red, filled circle)\n- `✓` closed (muted, checkmark)\n- `❄` deferred (muted, snowflake)\n- `📌` pinned (purple, pushpin)\n\n**Ayu Theme Colors** (adaptive light/dark):\n```rust\n// Priority colors\nP0: #f07171 (red, bold)\nP1: #ff8f40 (orange)\nP2: #e6b450 (gold)\nP3/P4: neutral (no color)\n\n// Status colors\nin_progress: #ffb454 (yellow)\nblocked: #f26d78 (red)\nclosed: #8090a0 (muted)\npinned: #d2a6ff (purple)\n\n// Type colors\nbug: #f26d78 (red)\nepic: #d2a6ff (purple)\nothers: neutral\n```\n\n**Rendering Helpers**:\n- `render_status_icon(status)` → colored icon\n- `render_priority(pri)` → colored \"● P0\"\n- `render_type(type)` → colored type badge\n- `render_issue_compact(issue)` → one-line format\n- `render_muted(text)` → gray text\n\n**Design Principle**: Only actionable states get color. Open/closed use neutral colors; in_progress/blocked demand attention.\n\nReference: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/ui/styles.go`\n\n**Design Notes**\n- Use `owo-colors` or `yansi` for ANSI colors with RGB support\n- Detect terminal capabilities (TrueColor vs 256 vs basic)\n- Respect NO_COLOR env var and non-TTY output\n- MutedStyle for inactive/closed items\n- BoldStyle for emphasis (P0 priority)\n- Tree characters: `⎿ ` (child), `└─ ` (last), `  ` (indent)\n\n**Acceptance**\n- [ ] Status icons defined (○ ◐ ● ✓ ❄ 📌)\n- [ ] Ayu color palette (adaptive light/dark)\n- [ ] Priority colors (P0 bold red, P1 orange, P2 gold)\n- [ ] Status colors (in_progress yellow, blocked red, closed muted)\n- [ ] Type colors (bug red, epic purple)\n- [ ] Rendering helper functions\n- [ ] Respects NO_COLOR and terminal capabilities\n- [ ] MutedStyle for closed issues (entire line)\n\n**Files:**\n- `src/cli/ui.rs` (new - core styling module)\n- `Cargo.toml` (add owo-colors or yansi)","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622510913,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.39","created_at":[1768622514230,0],"created_by":"darin@darinsmcstudio2.lan","title":"Gate evaluation commands (bd gate check, list, resolve)","description":"**Problem**\n\nGo beads has async coordination gates that block workflow steps until conditions are met. Gate evaluation commands check gate conditions and auto-close resolved gates.\n\nMissing from beads-rs:\n- `bd gate list` - List open gates\n- `bd gate check` - Evaluate gates and close resolved ones\n- `bd gate resolve` - Manually close a gate\n- `bd gate show` - Show gate details\n- Gate type filtering (--type=gh:run, gh:pr, timer, bead)\n- Auto-discovery of GitHub run IDs by workflow name\n\nGate types (from gate.go):\n- human: Requires manual bd close\n- timer: Expires after timeout\n- gh:run: Waits for GitHub Actions workflow\n- gh:pr: Waits for PR merge\n- bead: Waits for cross-rig bead to close\n\n**Design**\n\nImplement gate evaluation commands using the gate bead infrastructure.\n\nCommands:\n\n1. `bd gate list` - List gates\n   - `--all` - Include closed gates\n   - `--limit=N` - Limit results\n   - Filter: type=gate, exclude status=closed (unless --all)\n\n2. `bd gate check` - Evaluate and auto-close gates\n   - `--type=<type>` - Filter by gate type (gh, gh:run, gh:pr, timer, bead, all)\n   - `--dry-run` - Show what would happen without changes\n   - `--escalate` - Escalate failed/expired gates\n   - `--limit=N` - Limit gates to check\n\n3. `bd gate resolve <id>` - Manually close a gate\n   - `--reason=<text>` - Provide close reason\n   - Equivalent to `bd close <id>` but gate-specific\n\n4. `bd gate show <id>` - Show gate details\n   - Display: await_type, await_id, timeout, waiters, status\n   - Validates issue is type=gate\n\nGate evaluation logic (from gate.go checkGHRun, checkGHPR, checkTimer, checkBeadGate):\n\n**gh:run gates:**\n- Query: `gh run view <run-id> --json status,conclusion`\n- Resolved: status=completed AND conclusion=success\n- Escalated: status=completed AND conclusion in (failure, canceled)\n- Auto-discovery: If await_id is workflow name (non-numeric), query most recent run\n\n**gh:pr gates:**\n- Query: `gh pr view <pr-id> --json state,merged`\n- Resolved: state=MERGED\n- Escalated: state=CLOSED AND merged=false\n\n**timer gates:**\n- Resolved: now > created_at + timeout\n- Never escalated (just expire)\n\n**bead gates:**\n- Format: await_id = \"<rig>:<bead-id>\" (e.g., \"gastown:gt-abc123\")\n- Resolved: target bead status=closed\n- Query cross-rig database (routing.ResolveBeadsDirForRig)\n\nAuto-discovery for gh:run (from discoverRunIDByWorkflowName):\n```rust\n// If await_id is workflow name hint (non-numeric):\n// 1. Query: gh run list --workflow=<name> --json=databaseId,status --limit=5\n// 2. Take most recent run (first in list)\n// 3. Update gate's await_id with discovered run ID\n```\n\nImplementation files:\n- `src/cli/gate/list.rs` - List gates command\n- `src/cli/gate/check.rs` - Gate evaluation command\n- `src/cli/gate/resolve.rs` - Manual gate resolution\n- `src/cli/gate/show.rs` - Show gate details\n- `src/daemon/ops.rs` - Gate evaluation operations\n- `src/daemon/gate_eval.rs` - Gate type-specific evaluation logic\n- `src/daemon/github.rs` - GitHub CLI integration (gh run view, gh pr view)\n\n**Design Notes**\n\nGate evaluation requires external tools:\n- `gh` CLI for GitHub gates (gh:run, gh:pr)\n- Cross-rig database access for bead gates\n- Local time for timer gates\n\nError handling:\n- gh CLI not found → skip GitHub gates, warn user\n- gh CLI auth issues → report error but don't crash\n- Cross-rig database not found → warn but continue\n\nDry-run mode (--dry-run):\n- Show what would happen without making changes\n- Format: \"✓ bd-abc: would resolve - workflow 'CI' succeeded\"\n\nEscalation (--escalate):\n- Failed/expired gates can be escalated to create alerts\n- Call `gt escalate` if available (Gas Town integration)\n- Optional feature, not required for core functionality\n\n**Acceptance**\n\n- [ ] `bd gate list` shows open gates with type, await_id, timeout\n- [ ] `bd gate list --all` includes closed gates\n- [ ] `bd gate check` evaluates all open gates\n- [ ] `bd gate check --type=gh:run` filters to GitHub run gates\n- [ ] `bd gate check --dry-run` shows evaluation results without changes\n- [ ] gh:run evaluation queries GitHub Actions and closes on success\n- [ ] gh:pr evaluation queries PRs and closes on merge\n- [ ] timer evaluation checks created_at + timeout\n- [ ] bead evaluation checks cross-rig bead status\n- [ ] Auto-discovery for gh:run with workflow name hint\n- [ ] `bd gate resolve <id>` manually closes a gate\n- [ ] `bd gate show <id>` displays gate details\n- [ ] Tests for gate evaluation logic (mock gh CLI responses)\n- [ ] Integration test for full gate workflow\n\n**Files:**\n- src/cli/gate/list.rs\n- src/cli/gate/check.rs\n- src/cli/gate/resolve.rs\n- src/cli/gate/show.rs\n- src/daemon/ops.rs\n- src/daemon/gate_eval.rs\n- src/daemon/github.rs","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"f3ab63b8-25f6-ce1c-02fc-da24d85b383d","counter":15418253163362231119}]},"cc":{"max":{}}},"status":"open","_at":[1768622514230,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.4","created_at":[1768622398748,0],"created_by":"darin@darinsmcstudio2.lan","title":"Dynamic shell completions for issue IDs","description":"**Problem**\nShell completion for issue IDs requires typing the full ID manually. Go beads implements dynamic completion that queries the database for matching IDs as you type.\n\n**Design**\nImplement `issueIDCompletion` function that:\n- Uses prefix filtering at the database level (`IDPrefix` filter in SearchIssues)\n- Returns completions in format: `ID\\tTitle` (tab-separated for display)\n- Opens read-only database connection for completion queries\n- Handles database errors gracefully (returns empty on failure)\n- Uses 30s timeout for database locks by default\n\nReference implementation: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/completions.go`\n\n**Design Notes**\n- Clap supports dynamic completions via `ValueHint::Other`\n- Need to add completion script generation (bash/zsh/fish)\n- Optimize for performance - prefix filtering in SQL prevents full table scans\n- Must work without daemon running (uses direct read-only connection)\n\n**Acceptance**\n- [ ] Tab completion for issue IDs in bash/zsh/fish\n- [ ] Completions show ID + title during typing\n- [ ] Prefix filtering optimized at database level\n- [ ] Works without daemon (read-only connection)\n- [ ] Graceful error handling (returns empty on DB errors)\n\n**Files:**\n- `src/cli/completions.rs` (new)\n- `src/cli/mod.rs` (wire completion)\n- `src/bin/main.rs` (clap shell completion subcommand)","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622398748,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.40","created_at":[1768622517020,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add Rig issue type support","description":"**Problem**\nbeads-rs lacks the Rig issue type - multi-repo workspace identity beads that represent a collection of Git repositories working together. Rigs enable cross-repo coordination, routing, and scoped agent operation.\n\n**What Rig Beads Do (from Go beads)**\nA rig is a logical workspace spanning multiple repos. Rig beads:\n- Define rig identity and membership (which repos belong)\n- Enable cross-repo bead references (gastown:bd-abc → rig:bd-xyz)\n- Scope agent operation (agents tied to specific rigs)\n- Coordinate multi-repo workflows (formulas spanning repos)\n\nRig structure:\n- HQ repo: Central coordination repo (e.g., beads-hq)\n- Member repos: Application/project repos (e.g., beads-rs, myapp)\n- Rig name: Identifier (e.g., \"gastown\", \"myproject\")\n\nEach member repo has .beads/config.toml pointing to HQ:\n```toml\n[rig]\nname = \"gastown\"\nhq = \"../beads-hq\"  # Relative path to HQ repo\n```\n\n**Go Implementation**\nType definition (internal/types/types.go):\n- IssueType = TypeRig (line 492)\n- Uses standard Issue fields\n- Rig.Rig field (line 113): Rig name\n- Description holds rig membership and configuration\n\nRig resolution (internal/routing/):\n- ResolveBeadsDirForRig(rigName, currentDir) → (beadsDir, repoDir, error)\n- Traverses filesystem to find HQ repo\n- Validates rig membership\n- Returns HQ .beads dir for cross-repo access\n\nCross-repo routing:\n- Bead IDs: <rig>:<bead-id> (e.g., gastown:bd-abc123)\n- Resolution: Parse rig prefix, resolve to HQ, query database\n- Used in: gate bead gates, agent cross-rig references, convoy tracking\n\nAgent-rig binding:\n- Agent.Rig field specifies rig membership\n- Town-level agents (mayor, deacon) have empty Rig\n- Rig-level agents (witness, polecat) have Rig = \"gastown\"\n\n**Design for Rust**\nData model (src/core/):\n```rust\npub struct RigData {\n    name: String,              // Rig identifier\n    hq_path: Option<String>,   // Path to HQ repo\n    members: Vec<String>,      // Member repo paths\n}\n```\n\nAdd to Bead or use optional fields.\n\nRig resolution (src/git/ or new src/routing/):\n```rust\npub fn resolve_rig_hq(rig_name: &str, current_dir: &Path) \n    -> Result<PathBuf, Error>;\n    \npub fn resolve_cross_repo_bead(rig_bead_id: &str, current_dir: &Path) \n    -> Result<(PathBuf, String), Error>;\n```\n\nCross-repo access:\n- Parse <rig>:<bead-id> references\n- Resolve rig to HQ .beads directory\n- Open HQ database read-only\n- Query for bead\n\nCLI (src/cli/):\n- bd create --type rig \"Rig name\"\n- bd show <rig-id> (display membership)\n- bd list --type rig\n\nConfig integration:\n- Read .beads/config.toml for rig.name and rig.hq\n- Validate rig membership on operations\n\n**Design Notes**\n- Rigs enable multi-repo coordination without monorepo\n- HQ repo is source of truth for rig-level state\n- Cross-repo references must be read-only (no writes to other repos)\n- Rig resolution needs filesystem traversal (security consideration)\n- Consider: Rig discovery (scan workspace for .beads dirs)\n- Consider: Rig validation (ensure member repos agree on HQ)\n- Town-level (no rig) vs rig-level separation\n\n**Acceptance**\n- [ ] Rig type constant defined\n- [ ] RigData struct with name, hq_path, members\n- [ ] bd create --type rig works\n- [ ] bd list --type rig shows rig beads\n- [ ] Config parser reads rig.name and rig.hq\n- [ ] resolve_rig_hq finds HQ repo from rig name\n- [ ] Cross-repo bead ID parsing (<rig>:<id>)\n- [ ] Cross-repo bead resolution via HQ database\n- [ ] Tests for rig resolution\n- [ ] Tests for cross-repo bead access\n- [ ] Migration from Go beads preserves rig type\n\n**Files to study in Go beads:**\n- tmp/beads/internal/types/types.go (line 492: TypeRig, line 113: Rig field)\n- tmp/beads/internal/routing/routing.go (rig resolution logic)\n- tmp/beads/cmd/bd/gate.go (checkBeadGate: cross-rig bead lookup example)\n- tmp/beads/internal/configfile/config.go (rig configuration)","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"43c7e7f3-fbed-23ea-af55-4204f3b6beec","counter":2491772196697158159}]},"cc":{"max":{}}},"status":"open","_at":[1768622517020,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.41","created_at":[1768622517435,0],"created_by":"darin@darinsmcstudio2.lan","title":"Multi-repo dependencies - External reference system","description":"**Problem**\nIssues in one repository often depend on work in another repository. Current dependency system only supports local references. Need to represent cross-repo dependencies using `external:<repo>:<id>` syntax.\n\n**What the Feature Does**\nDependencies can reference issues in other repositories:\n\n```bash\n# Issue in beads-rs blocks on beads-go capability\nbd dep add bd-123 external:beads-go:mol-run-assignee --type blocks\n\n# Shipping a capability (in beads-go)\nbd label add bd-456 export:mol-run-assignee\nbd ship mol-run-assignee\n# → Adds provides:mol-run-assignee label\n\n# Check if external dependency is satisfied\nbd show bd-123\n# Shows: Blocked by external:beads-go:mol-run-assignee (resolved: yes)\n\n# Move issue to another repo\nbd ship bd-123 --to ~/other-repo\n# → Moves issue, preserves dependencies\n```\n\nExternal refs resolve via:\n1. Prefix-based routing (routes.jsonl)\n2. Explicit repo configuration (config.yaml)\n3. Capability labels (provides:xxx)\n\n**Why It Needs Design Work**\n\n1. **Resolution Strategy**:\n   - How to look up external issues?\n   - Option A: Always route via routes.jsonl (prefix-based)\n   - Option B: Explicit repo registry (config: `repos.beads-go = ~/path`)\n   - Option C: Both (try routes, fall back to registry)\n   - What if target repo not found?\n\n2. **Dependency Validation**:\n   - Can we validate external deps exist?\n   - Or treat as opaque references?\n   - Lazy resolution (only when needed)?\n   - Cache resolution results?\n\n3. **Sync Behavior**:\n   - External deps stored as strings in JSONL\n   - How to represent in SQLite? (separate table? JSON column?)\n   - Need foreign key constraints? (probably not - external!)\n   - How to detect broken external refs?\n\n4. **Ready Queue Calculation**:\n   - Issue blocked by external:foo:bar\n   - Is it ready? Need to check external repo\n   - Performance implications (opening multiple dbs)\n   - Caching strategy?\n\n**Key Decisions to Make**\n\n1. **Storage Schema**:\n   ```rust\n   // Option A: Extend Dependency type\n   enum DependencyTarget {\n       Local(IssueId),\n       External { repo: String, id: String },\n   }\n   \n   // Option B: Separate external_deps table\n   struct ExternalDep {\n       issue_id: String,\n       dep_type: DepType,\n       target_repo: String,\n       target_id: String,\n       resolved: Option<bool>, // cache\n   }\n   ```\n\n2. **Repo Registry**:\n   ```toml\n   # .beads/config.toml\n   [repos]\n   beads-go = \"~/projects/beads-go\"\n   beads-rs = \".\"\n   olympus = \"../olympus\"\n   ```\n   \n   Or use routes.jsonl for everything?\n\n3. **Capability System**:\n   - Labels: `export:xxx` (planned capability), `provides:xxx` (shipped)\n   - Command: `bd ship <capability>` adds provides label\n   - Resolution: Look for closed issue with `provides:xxx` in target repo\n   - Alternative: Dedicated capabilities table?\n\n4. **Migration Command**:\n   ```bash\n   bd ship bd-123 --to <repo>\n   # What does this do?\n   # 1. Export issue as JSONL\n   # 2. Import to target repo\n   # 3. Update dependencies?\n   # 4. Leave tombstone in source?\n   ```\n\n**Trade-offs to Consider**\n\n1. **Validation vs Flexibility**:\n   - Strict: Validate external refs exist (slow, fragile)\n   - Loose: Treat as opaque strings (fast, might break)\n   - Middle: Lazy validation, cache results\n\n2. **Performance vs Accuracy**:\n   - Accurate ready queue = check all external deps (slow)\n   - Fast ready queue = assume external deps met (might be wrong)\n   - Solution: Async background resolution?\n\n3. **Coupling**:\n   - Tight: Routes.jsonl + capability labels + repo config\n   - Loose: Just store strings, resolve at display time\n   - Tight enables better UX but more complex\n\n4. **Naming**:\n   - `external:<repo>:<id>` (current Go syntax)\n   - `<repo>::<id>` (Rust-style)\n   - `@<repo>/<id>` (GitHub-style)\n   - Stick with Go for compatibility?\n\n**Reference Files in Go Beads**\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/ship.go` - Ship command\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/routing/routes.go` - ResolveToExternalRef\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/storage/sqlite/external_deps.go` - Storage\n- Search for \"external:\" in codebase for usage examples\n\n**Go Implementation Details**\n- External deps stored as `external:<project>:<id>` strings\n- `ResolveToExternalRef(id, beadsDir)` - Converts local ID to external ref\n- Capability labels: `export:xxx` (planning), `provides:xxx` (shipped)\n- Resolution: Check if target has closed issue with `provides:` label\n- No automatic validation (treat as opaque until needed)\n\n**Use Cases to Support**\n\n1. **Cross-Project Blocking**:\n   - beads-rs feature blocked on beads-go API\n   - Show dependency in `bd show`, `bd ready`\n\n2. **Capability Shipping**:\n   - Team A provides feature for Team B\n   - Team B depends on `external:teamA:feature-x`\n   - Team A ships when ready\n\n3. **Issue Migration**:\n   - Move issue between repos (fork → upstream)\n   - Preserve dependency graph\n\n4. **Multi-Repo Planning**:\n   - Epic spans multiple repos\n   - Child issues in different repos\n   - Still show unified dependency tree\n\n**Open Design Questions**\n\n1. Should external deps be bidirectional?\n   - If A depends on external:B:foo, does B know?\n   - Need reverse index?\n\n2. How to handle repo renames?\n   - External refs by name can break\n   - Use repo URL instead?\n   - Migration tool?\n\n3. Offline behavior?\n   - External repo not available\n   - Show as unresolved? Error?\n   - Grace degradation?\n\n4. Security/trust?\n   - Can malicious external refs DoS by forcing db opens?\n   - Rate limiting? Allowlist?\n\n**Acceptance**\n- [ ] Design document for external reference system\n- [ ] Storage schema (how to represent in SQLite + JSONL)\n- [ ] Resolution algorithm (routes vs config vs both)\n- [ ] Capability label system design\n- [ ] Ship command spec\n- [ ] Ready queue calculation with external deps\n- [ ] Performance considerations (caching, lazy loading)\n- [ ] Error handling (missing repos, missing issues)\n- [ ] Migration/promotion workflow\n- [ ] Repo registry format and management","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"24b5f755-5d7c-853c-3999-8d03ee61cd6d","counter":15662987394879421415}]},"cc":{"max":{}}},"status":"open","_at":[1768622517435,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.42","created_at":[1768622522322,0],"created_by":"darin@darinsmcstudio2.lan","title":"Handle long socket paths - Unix socket 103-108 byte limit via /tmp/beads-<hash>/","description":"","design":"Port the long socket path handling from Go beads to beads-rs.\n\n## Problem\n\nUnix domain sockets have strict path length limits:\n- macOS: 104 bytes (including null terminator)\n- Linux: 108 bytes\n\nWhen workspace path is deep, `.beads/bd.sock` exceeds this limit and daemon fails to start.\n\n## Go beads solution\n\nUse hash-based short paths in /tmp for deep directories:\n1. Compute SHA256 hash of canonicalized workspace path\n2. Create socket at `/tmp/beads-{hash}/bd.sock`\n3. Use natural path `.beads/bd.sock` when short enough\n\nThis ensures:\n- Different workspaces get different socket dirs\n- Same workspace always gets same hash (deterministic)\n- Symlinks and case differences resolve to same hash\n\n## Implementation approach\n\n**Core utilities** (`src/daemon/socket_path.rs`):\n```rust\n/// Maximum Unix socket path length (macOS: 103, Linux: 107)\nconst MAX_SOCKET_PATH: usize = 103;\n\n/// Returns appropriate socket path for workspace\npub fn socket_path(workspace: &Path) -> PathBuf {\n    // Canonicalize for consistent hashing\n    let canonical = normalize_path_for_comparison(workspace);\n    \n    let natural_path = workspace.join(\".beads/bd.sock\");\n    \n    if natural_path.as_os_str().len() <= MAX_SOCKET_PATH {\n        natural_path\n    } else {\n        short_socket_path(&canonical)\n    }\n}\n\nfn short_socket_path(canonical_path: &Path) -> PathBuf {\n    use sha2::{Sha256, Digest};\n    \n    let mut hasher = Sha256::new();\n    hasher.update(canonical_path.as_os_str().as_bytes());\n    let hash = hasher.finalize();\n    \n    // Use first 8 hex chars (4 bytes)\n    let hash_str = hex::encode(&hash[..4]);\n    \n    Path::new(\"/tmp\")\n        .join(format!(\"beads-{}\", hash_str))\n        .join(\"bd.sock\")\n}\n\n/// Create socket directory if needed\npub fn ensure_socket_dir(socket_path: &Path) -> Result<()> {\n    let dir = socket_path.parent().unwrap();\n    \n    // Only create for /tmp/beads-* directories\n    // Don't create .beads directories (should exist)\n    if dir.starts_with(\"/tmp/beads-\") {\n        fs::create_dir_all(dir)?;\n        // Set permissions 0700 for security\n        #[cfg(unix)]\n        {\n            use std::os::unix::fs::PermissionsExt;\n            fs::set_permissions(dir, fs::Permissions::from_mode(0o700))?;\n        }\n    }\n    \n    Ok(())\n}\n\n/// Cleanup socket directory on shutdown\npub fn cleanup_socket_dir(socket_path: &Path) -> Result<()> {\n    let dir = socket_path.parent().unwrap();\n    \n    // Only remove /tmp/beads-* directories we created\n    if dir.starts_with(\"/tmp/beads-\") {\n        let _ = fs::remove_file(socket_path);\n        let _ = fs::remove_dir(dir); // Fails if not empty, that's fine\n    } else {\n        // For .beads/ directories, just remove socket\n        let _ = fs::remove_file(socket_path);\n    }\n    \n    Ok(())\n}\n```\n\n**Path canonicalization** (`src/daemon/path.rs`):\n```rust\n/// Normalize path for comparison (handles symlinks, case-insensitive FS)\npub fn normalize_path_for_comparison(path: &Path) -> PathBuf {\n    // 1. Resolve to absolute\n    let abs = path.canonicalize().unwrap_or_else(|_| path.to_path_buf());\n    \n    // 2. Resolve symlinks\n    let canonical = abs.canonicalize().unwrap_or(abs);\n    \n    // 3. On macOS, resolve to true filesystem case\n    #[cfg(target_os = \"macos\")]\n    {\n        if let Ok(resolved) = resolve_canonical_case(&canonical) {\n            return resolved;\n        }\n    }\n    \n    canonical\n}\n\n#[cfg(target_os = \"macos\")]\nfn resolve_canonical_case(path: &Path) -> Result<PathBuf> {\n    use std::process::Command;\n    \n    let output = Command::new(\"realpath\")\n        .arg(path)\n        .output()?;\n    \n    if output.status.success() {\n        let resolved = String::from_utf8_lossy(&output.stdout)\n            .trim()\n            .to_string();\n        Ok(PathBuf::from(resolved))\n    } else {\n        Err(Error::PathCanonicalization)\n    }\n}\n```\n\n## Files to reference\n\nGo implementation:\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/rpc/socket_path.go`\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/utils/path.go`\n\n## Design notes\n\n**Why /tmp and not $TMPDIR**:\n- On macOS, $TMPDIR is very long: `/var/folders/xx/xxxxxxxxxxxx/T/`\n- /tmp is short and standard across Unix systems\n- Defeats the purpose if temp dir is also too long\n\n**Case-insensitive filesystems** (macOS, Windows):\n- Must use `realpath` to get true filesystem case\n- Ensures `/Users/foo/Desktop` and `/users/foo/desktop` hash the same\n- Critical for daemon socket discovery\n\n**Socket directory cleanup**:\n- Remove on daemon shutdown\n- Only if directory is in /tmp/beads-*\n- Don't remove .beads directories (user data)\n\n**Backwards compatibility**:\n- If natural path is short enough, use it\n- Existing workspaces with short paths unaffected\n- Only deep paths trigger hash-based fallback\n\n## Questions\n\n1. Should we warn user when using hash-based path?\n2. Should hash use full SHA256 or truncated?\n3. Should we document the hash mapping somewhere?\n4. Handle Windows path limits differently?","acceptance_criteria":"- [ ] socket_path() returns natural path when short enough\n- [ ] socket_path() returns /tmp/beads-<hash> for long paths\n- [ ] Hash is deterministic for same workspace\n- [ ] Symlinks resolve to same hash\n- [ ] macOS case-insensitive paths handled via realpath\n- [ ] Socket directory created with 0700 permissions\n- [ ] Socket directory cleaned up on daemon shutdown\n- [ ] Works on both macOS and Linux\n- [ ] No regression for short paths","priority":2,"type":"bug","labels":{"entries":{"human-needed":[{"replica":"0713bf96-b9f2-5698-c808-388c14318112","counter":7218166669106337976}]},"cc":{"max":{}}},"status":"open","_at":[1768622522322,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.43","created_at":[1768622525969,0],"created_by":"darin@darinsmcstudio2.lan","title":"Estimate field for time tracking","description":"**Problem**\nIssues need time estimates for planning. Go beads has `EstimatedMinutes` field but beads-rs doesn't expose it in CLI.\n\n**Design**\nAdd `--estimate` / `-e` flag to `bd create` and `bd update`:\n- Value: integer in minutes (e.g., 60 for 1 hour)\n- Validation: must be non-negative\n- Storage: `estimated_minutes` INTEGER column (already exists in schema from Go beads migration)\n- Display: show in `bd show` and `bd list --pretty` as human-readable duration (e.g., \"1h 30m\")\n\nExamples:\n```bash\nbd create \"Fix auth bug\" --estimate 90           # 1.5 hours\nbd update bd-abc123 --estimate 120               # 2 hours\nbd show bd-abc123  # shows \"Estimate: 2h\"\n```\n\n**Database Schema**:\nAlready exists in types from Go beads:\n```rust\npub struct Bead {\n    // ...\n    pub estimated_minutes: Option<i32>,\n}\n```\n\n**Display Format**:\n- < 60 min: \"30m\"\n- >= 60 min: \"1h 30m\"\n- bd list --pretty: show estimate in muted color after title\n\nReference: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/types/types.go` line 34\n\n**Design Notes**\n- Use chrono::Duration for time calculations\n- Helper function: `format_duration(minutes: i32) -> String`\n- Optional field - not required for issue creation\n- Show in show/list output only if set (not all issues need estimates)\n\n**Acceptance**\n- [ ] --estimate/-e flag on bd create\n- [ ] --estimate/-e flag on bd update\n- [ ] Validation: non-negative integers only\n- [ ] Storage in estimated_minutes column\n- [ ] Display in bd show (human-readable: \"1h 30m\")\n- [ ] Display in bd list --pretty (muted, after title)\n- [ ] Helper: format_duration(minutes) → \"Xh Ym\"\n\n**Files:**\n- `src/cli/create.rs`\n- `src/cli/update.rs`\n- `src/cli/show.rs`\n- `src/cli/list.rs`\n- `src/cli/time_format.rs` (new - duration formatting)","priority":3,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622525969,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.44","created_at":[1768622536153,0],"created_by":"darin@darinsmcstudio2.lan","title":"Gate add-waiter command for notification registration","description":"**Problem**\n\nGo beads supports registering waiters on gate beads. When a gate closes, waiters receive wake notifications via `gt gate wake`. This enables async coordination across agents.\n\nMissing from beads-rs:\n- `bd gate add-waiter <gate-id> <waiter>` command\n- Waiters field on gate beads (array of strings)\n- Wake notification when gate closes\n\nWaiters field (from types.go line 97):\n```go\nWaiters []string `json:\"waiters,omitempty\"` // Mail addresses to notify when gate clears\n```\n\nTypical waiter format: \"gastown/polecats/Toast\" (agent address)\n\n**Design**\n\nAdd waiters field to gate beads and implement add-waiter command.\n\nCommand:\n```bash\nbd gate add-waiter <gate-id> <waiter>\n```\n\nBehavior:\n- Appends waiter to gate's waiters array\n- Checks for duplicates (don't add same waiter twice)\n- Validates issue is type=gate\n- When gate closes, waiters should be notified (future: gt gate wake integration)\n\nWaiters field:\n- Type: Vec<String>\n- Stored in bead as Lww<Vec<String>> (list CRDT)\n- Each waiter is an address (string identifier)\n\nImplementation files:\n- `src/core/lww.rs` - Add waiters field to Bead (if not already present)\n- `src/cli/gate/add_waiter.rs` - Add-waiter command\n- `src/daemon/ops.rs` - Add-waiter operation\n- `src/cli/gate/show.rs` - Display waiters in gate details\n\nCommand validation:\n1. Resolve gate-id to full ID\n2. Load gate bead\n3. Verify type=gate\n4. Check if waiter already registered\n5. Append to waiters array\n6. Update bead\n\n**Design Notes**\n\nWake notification (gt gate wake) is a Gas Town feature, not core beads-rs. For now:\n1. Store waiters field for compatibility\n2. Implement add-waiter command\n3. Don't implement wake notifications (leave for Gas Town)\n\nWaiter format is free-form string. No validation beyond non-empty.\n\nDeduplication is important:\n```rust\nif gate.waiters.contains(&waiter) {\n    println!(\"Waiter already registered on gate {}\", gate_id);\n    return Ok(());\n}\n```\n\nFuture enhancement: When closing a gate, log waiters to stdout so external tools can trigger notifications.\n\n**Acceptance**\n\n- [ ] Gate beads have waiters field (Vec<String>)\n- [ ] `bd gate add-waiter <gate-id> <waiter>` appends to waiters\n- [ ] Duplicate waiters are rejected with message\n- [ ] Non-gate issues are rejected with error\n- [ ] `bd gate show <id>` displays waiters list\n- [ ] Tests for add-waiter operation\n- [ ] Migration preserves waiters from Go beads\n\n**Files:**\n- src/core/lww.rs\n- src/cli/gate/add_waiter.rs\n- src/daemon/ops.rs\n- src/cli/gate/show.rs\n- src/migrate/go_export.rs","priority":3,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"b4224b2d-cef1-309d-c12b-dd139c245596","counter":13812956721719678539}]},"cc":{"max":{}}},"status":"open","_at":[1768622536153,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.45","created_at":[1768622544109,0],"created_by":"darin@darinsmcstudio2.lan","title":"bd activity command for real-time mutation stream","description":"**Problem**\nUsers need visibility into issue and workflow changes as they happen. Go beads has `bd activity` for real-time mutation event streaming.\n\n**Design**\nImplement `bd activity` command that shows mutation events:\n\n**Event Types**:\n- create: new issue created\n- update: issue modified\n- delete: issue removed\n- comment: comment added\n- status_change: workflow state transition\n\n**Flags**:\n- `--follow` / `-f`: stream events in real-time (like tail -f)\n- `--since <duration>`: show events from last N time (e.g., \"5m\", \"1h\", \"30s\")\n- `--type <type>`: filter by event type (create, update, delete, comment)\n- `--limit <n>`: max events to show (default 100)\n- `--interval <duration>`: polling interval for --follow mode (default 500ms)\n\n**Output Format** (human):\n```\n2025-01-16 14:30:45  +  bd-abc123  Created: Fix auth timeout\n2025-01-16 14:31:20  →  bd-abc123  Status: open → in_progress\n2025-01-16 14:35:00  ✓  bd-abc123  Closed: fixed\n```\n\n**Event Symbols**:\n- `+` created\n- `→` status change / update\n- `✓` closed/completed\n- `⊘` deleted\n- `💬` comment added\n\n**JSON Output**:\n```json\n{\n  \"timestamp\": \"2025-01-16T14:30:45Z\",\n  \"type\": \"create\",\n  \"issue_id\": \"bd-abc123\",\n  \"message\": \"Created: Fix auth timeout\",\n  \"actor\": \"user@example.com\"\n}\n```\n\nReference: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/activity.go`\n\n**Design Notes**\n- Store events in `events` table with timestamp, type, issue_id, actor, payload\n- Query events with timestamp ordering (DESC for recent first)\n- --follow mode: poll database every N ms, show new events since last poll\n- Use chrono for duration parsing (--since)\n- Respect --json for machine-readable output\n\n**Implementation**:\n1. Add events table to schema (if not exists)\n2. Emit events on create/update/delete operations\n3. CLI command to query and display events\n4. Streaming mode with polling loop\n\n**Acceptance**\n- [ ] bd activity shows last 100 events by default\n- [ ] --follow streams events in real-time\n- [ ] --since filters by time duration\n- [ ] --type filters by event type\n- [ ] Event symbols (+ → ✓ ⊘ 💬)\n- [ ] JSON output with --json\n- [ ] Timestamp + actor in each event\n- [ ] Efficient polling in follow mode (500ms default)\n\n**Files:**\n- `src/cli/activity.rs` (new)\n- `src/core/events.rs` (new - event emission and storage)\n- `src/git/sync.rs` (emit events on mutations)\n- `migrations/XXX_add_events_table.sql` (if needed)","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622544109,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.46","created_at":[1768622544325,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add Message issue type support","description":"**Problem**\nbeads-rs lacks the Message issue type - ephemeral inter-agent communication beads that enable agents to send messages, coordinate work, and thread conversations. Messages are NOT exported to JSONL (Ephemeral=true) and auto-cleanup.\n\n**What Message Beads Do (from Go beads)**\nMessage beads enable asynchronous communication between agents:\n- Send work requests, status updates, questions\n- Thread conversations via replies_to (now DependencyType)\n- Ephemeral by default (not persisted to JSONL)\n- Auto-cleanup when no longer needed\n\nMessage structure:\n- Sender: Who sent the message (agent bead ID or entity URI)\n- Assignee: Who receives the message\n- RepliesTo: Parent message ID (creates thread via dependency)\n- Ephemeral: true (skip JSONL export)\n- Status: open → closed when acknowledged\n\n**Go Implementation**\nType definition (internal/types/types.go):\n- IssueType = TypeMessage (line 486)\n- Fields:\n  - Sender string (line 75): Who sent this\n  - Ephemeral bool (line 76): If true, not exported to JSONL\n  - Assignee string: Recipient\n  - Uses dependencies table for replies-to threading\n\nEphemeral flag (types.go and nodb.go):\n- Ephemeral=true skips JSONL export in storage layer\n- Messages live in main database but not in issues.jsonl\n- Enables short-lived coordination without polluting history\n\nThreading (Decision 004: Edge Schema Consolidation):\n- Old: RepliesTo field on Issue\n- New: DepRepliesTo dependency type\n- ThreadID field on dependency for efficient queries\n- Enables conversation tree traversal\n\nCleanup:\n- bd cleanup --ephemeral deletes old ephemeral issues\n- Configurable TTL for message retention\n\n**Design for Rust**\nData model (src/core/):\n```rust\npub struct MessageData {\n    sender: String,           // Agent/entity who sent\n    assignee: Option<String>, // Recipient (optional)\n    ephemeral: bool,          // Skip JSONL export\n}\n```\n\nAdd to Bead or use optional fields.\n\nThreading via dependencies:\n- Use DepRepliesTo relation type\n- thread_id for efficient conversation queries\n- src/core/dependencies.rs handles replies-to edges\n\nJSONL export filter:\n- Check Ephemeral flag in export path\n- Skip ephemeral beads in JSONL serialization\n- Ephemeral beads live only in database\n\nCLI (src/cli/):\n- bd create --type message --sender <agent> --assignee <agent> \"Message text\"\n- bd list --type message [--label ephemeral]\n- bd reply <message-id> \"Reply text\" (creates replies-to dependency)\n- bd cleanup --ephemeral (delete old messages)\n\n**Design Notes**\n- Messages blur the line between data and metadata\n- Ephemeral flag is critical - don't pollute git history\n- Threading via dependencies is more flexible than parent field\n- Consider: Message priority/urgency\n- Consider: Broadcast messages (no assignee, multiple recipients)\n- Consider: Message expiry/TTL\n- Consider: Rich message content (attachments, structured data)\n\n**Acceptance**\n- [ ] Message type constant defined\n- [ ] MessageData struct with sender, assignee, ephemeral\n- [ ] Ephemeral flag implemented on Bead\n- [ ] JSONL export skips ephemeral beads\n- [ ] bd create --type message works\n- [ ] Sender and assignee fields populate\n- [ ] bd reply creates replies-to dependency\n- [ ] Conversation threading via DependencyType\n- [ ] bd list --ephemeral filters ephemeral beads\n- [ ] bd cleanup --ephemeral deletes old messages\n- [ ] Tests for message creation and threading\n- [ ] Tests for ephemeral JSONL exclusion\n- [ ] Migration from Go beads preserves message fields\n\n**Files to study in Go beads:**\n- tmp/beads/internal/types/types.go (lines 74-77: message fields, line 486: TypeMessage)\n- tmp/beads/cmd/bd/wisp.go (ephemeral bead handling)\n- tmp/beads/cmd/bd/nodb.go (line 225: ephemeral JSONL filter)\n- tmp/beads/internal/storage/sqlite/schema.go (lines 33-35: sender, ephemeral columns)","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"758d0240-f982-0c35-8c2e-c0d0898792fa","counter":10538132418215412551}]},"cc":{"max":{}}},"status":"open","_at":[1768622544325,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.47","created_at":[1768622554816,0],"created_by":"darin@darinsmcstudio2.lan","title":"Implement macOS case-insensitive path canonicalization using realpath","description":"","design":"Port the macOS path canonicalization from Go beads to beads-rs.\n\n## Problem\n\nmacOS (and Windows) have case-insensitive but case-preserving filesystems. This causes issues with:\n1. **Daemon socket discovery**: `/Users/foo/Desktop` vs `/users/foo/desktop` treated as different workspaces\n2. **Remote URL matching**: Git worktrees with different case don't match\n3. **Path comparisons**: String comparison fails for semantically identical paths\n\n## Go beads solution\n\nUse `realpath(1)` on macOS to resolve paths to their true filesystem case:\n```go\nfunc resolveCanonicalCase(path string) string {\n    if runtime.GOOS == \"darwin\" {\n        cmd := exec.Command(\"realpath\", path)\n        output, err := cmd.Output()\n        if err == nil {\n            return strings.TrimSpace(string(output))\n        }\n    }\n    return \"\"\n}\n```\n\nThis ensures `/Users/foo/Desktop` always resolves to the true case, regardless of how user typed it.\n\n## Implementation approach\n\n**Core path utilities** (`src/core/path.rs`):\n```rust\nuse std::path::{Path, PathBuf};\n\n/// Canonicalize path, resolving symlinks and true case on case-insensitive FS\npub fn canonicalize_path(path: &Path) -> Result<PathBuf> {\n    // 1. Convert to absolute\n    let abs = path.canonicalize()\n        .or_else(|_| std::env::current_dir().map(|cwd| cwd.join(path)))?;\n    \n    // 2. Resolve symlinks\n    let canonical = abs.canonicalize().unwrap_or(abs);\n    \n    // 3. On case-insensitive FS, resolve to true case\n    #[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\n    {\n        if let Ok(resolved) = resolve_true_case(&canonical) {\n            return Ok(resolved);\n        }\n    }\n    \n    Ok(canonical)\n}\n\n#[cfg(target_os = \"macos\")]\nfn resolve_true_case(path: &Path) -> Result<PathBuf> {\n    use std::process::Command;\n    \n    let output = Command::new(\"realpath\")\n        .arg(path)\n        .output()\n        .map_err(|e| Error::PathCanonicalization(e.to_string()))?;\n    \n    if !output.status.success() {\n        return Err(Error::PathCanonicalization(\n            String::from_utf8_lossy(&output.stderr).to_string()\n        ));\n    }\n    \n    let resolved = String::from_utf8_lossy(&output.stdout)\n        .trim()\n        .to_string();\n    \n    Ok(PathBuf::from(resolved))\n}\n\n#[cfg(target_os = \"windows\")]\nfn resolve_true_case(path: &Path) -> Result<PathBuf> {\n    // On Windows, fs::canonicalize already handles case\n    // Just return the input\n    Ok(path.to_path_buf())\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn resolve_true_case(path: &Path) -> Result<PathBuf> {\n    Ok(path.to_path_buf())\n}\n\n/// Normalize path for comparison (lowercase on case-insensitive FS)\npub fn normalize_path_for_comparison(path: &Path) -> Result<PathBuf> {\n    let canonical = canonicalize_path(path)?;\n    \n    #[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\n    {\n        // Lowercase for comparison\n        let lowered = canonical.to_str()\n            .ok_or(Error::InvalidUtf8Path)?\n            .to_lowercase();\n        return Ok(PathBuf::from(lowered));\n    }\n    \n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        Ok(canonical)\n    }\n}\n\n/// Compare two paths for equality (handles case-insensitive FS)\npub fn paths_equal(a: &Path, b: &Path) -> Result<bool> {\n    let a_norm = normalize_path_for_comparison(a)?;\n    let b_norm = normalize_path_for_comparison(b)?;\n    Ok(a_norm == b_norm)\n}\n```\n\n**Usage in daemon**:\n```rust\n// Socket discovery\nlet workspace = canonicalize_path(&env::current_dir()?)?;\nlet socket_path = socket_path(&workspace);\n\n// Remote URL matching\nlet canonical_workspace = canonicalize_path(workspace)?;\nif paths_equal(&canonical_workspace, &stored_workspace)? {\n    // Same workspace\n}\n```\n\n**Error type**:\n```rust\n#[derive(Debug, thiserror::Error)]\npub enum Error {\n    #[error(\"Path canonicalization failed: {0}\")]\n    PathCanonicalization(String),\n    \n    #[error(\"Path contains invalid UTF-8\")]\n    InvalidUtf8Path,\n}\n```\n\n## Files to reference\n\nGo implementation:\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/utils/path.go`\n  - `CanonicalizePath()`: Lines 106-130\n  - `resolveCanonicalCase()`: Lines 135-148\n  - `NormalizePathForComparison()`: Lines 158-182\n\nKey insight from GH#880: Git operations string-compare paths exactly, so we must use the true filesystem case.\n\n## Design notes\n\n**Why realpath, not Rust canonicalize**:\n- `std::fs::canonicalize` resolves symlinks but NOT case on macOS\n- `realpath(1)` gives true filesystem case\n- This is essential for daemon socket matching\n\n**Fallback strategy**:\n1. Try realpath (may not exist on all systems)\n2. If realpath fails, use canonicalized path as-is\n3. Never fail just because realpath unavailable\n\n**Comparison vs display**:\n- `canonicalize_path`: For display, preserve true case\n- `normalize_path_for_comparison`: For comparison, lowercase\n- Don't mix them up!\n\n**Performance**:\n- Cache canonicalized paths (spawning realpath is expensive)\n- Only canonicalize once per daemon lifetime\n- Consider memoization for hot paths\n\n**Testing**:\n- Test on macOS with mixed-case paths\n- Test symlink resolution\n- Test on Linux (should be no-op)\n- Test Windows (use built-in canonicalize)\n\n## Questions\n\n1. Should we cache realpath results in daemon?\n2. What if realpath is not installed? (rare but possible)\n3. Should we warn if case differs from input?\n4. Handle network paths / UNC paths on Windows?","acceptance_criteria":"- [ ] canonicalize_path resolves symlinks\n- [ ] canonicalize_path calls realpath on macOS\n- [ ] normalize_path_for_comparison lowercases on macOS/Windows\n- [ ] paths_equal handles case-insensitive FS correctly\n- [ ] Fallback works if realpath unavailable\n- [ ] Works on macOS with mixed-case input\n- [ ] Works on Linux (no-op)\n- [ ] Works on Windows (uses std::fs::canonicalize)\n- [ ] Error messages are helpful\n- [ ] Tests cover symlinks and case variations","priority":2,"type":"bug","labels":{"entries":{"human-needed":[{"replica":"dea337f8-bcb5-4843-7bc8-d8a47f19ea9a","counter":6972034271141002286}]},"cc":{"max":{}}},"status":"open","_at":[1768622554816,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.48","created_at":[1768622561219,0],"created_by":"darin@darinsmcstudio2.lan","title":"Hooks system - Event-driven extensibility","description":"**Problem**\nUsers need to extend beads with custom automation: notifications, integrations, analytics, etc. A hooks system allows executable scripts to run after beads events, enabling extensibility without modifying core code.\n\n**What the Feature Does**\nHooks are executable scripts in `.beads/hooks/` that run after events:\n\n**Supported Events**:\n- `on_create` - After issue created\n- `on_update` - After issue updated (status, priority, etc.)\n- `on_close` - After issue closed\n\n**Hook Interface**:\n```bash\n#!/bin/bash\n# .beads/hooks/on_create\n# Receives issue JSON on stdin\n# Exit 0 = success, non-zero = logged as warning\n\nissue=$(cat)\nid=$(echo \"$issue\" | jq -r '.id')\ntitle=$(echo \"$issue\" | jq -r '.title')\n\n# Send Slack notification\ncurl -X POST \"$SLACK_WEBHOOK\" \\\n  -d \"{\\\"text\\\": \\\"New issue: $id - $title\\\"}\"\n```\n\n**Example Hooks**:\n```bash\n# .beads/hooks/on_create\n- Send Slack/Discord notification\n- Create GitHub issue mirror\n- Update analytics dashboard\n- Trigger CI pipeline\n\n# .beads/hooks/on_update  \n- Notify assignee of status change\n- Log to audit system\n- Update external tracker\n\n# .beads/hooks/on_close\n- Archive to long-term storage\n- Update burndown chart\n- Send completion notification\n```\n\n**Why It Needs Design Work**\n\n1. **Execution Model**:\n   - Synchronous (block command) vs Asynchronous (fire-and-forget)?\n   - Go implementation: Async by default, RunSync for testing\n   - Timeout handling? (Go: 10s default)\n   - Retry logic?\n   - Error handling - fail command or just log?\n\n2. **Hook Data Format**:\n   - What JSON structure to pass on stdin?\n   - Full Issue object? Minimal info?\n   - Include event type? Actor? Timestamp?\n   - Before/after diff for updates?\n\n3. **Security**:\n   - Hooks are arbitrary code execution\n   - How to prevent malicious hooks in shared repos?\n   - Allowlist/denylist?\n   - Sandboxing?\n   - Warn on first run?\n\n4. **Daemon Interaction**:\n   - Daemon vs direct mode - both should support hooks\n   - Who runs the hook - CLI or daemon?\n   - If daemon: How to pass output back to CLI?\n   - Environment variables inheritance?\n\n**Key Decisions to Make**\n\n1. **Hook Execution Context**:\n   ```rust\n   struct HookContext {\n       event: Event,           // create, update, close\n       issue: Issue,           // full issue object\n       actor: String,          // who triggered\n       changes: Vec<Change>,   // what changed (for updates)\n       timestamp: DateTime,\n   }\n   ```\n\n2. **Hook Discovery**:\n   - Check `.beads/hooks/<event_name>` exists and is executable\n   - Support subdirectories? (`.beads/hooks/on_create/01-slack.sh`)\n   - Hook ordering if multiple per event?\n   - Platform-specific: Unix permissions vs Windows?\n\n3. **Error Handling**:\n   ```\n   Hook fails:\n   - Option A: Ignore, log warning\n   - Option B: Rollback operation, fail command\n   - Option C: Configurable per hook\n   \n   Go approach: Async fire-and-forget, errors ignored\n   ```\n\n4. **Additional Events** (Future):\n   - `on_message` - For mail system\n   - `on_sync` - Before/after git sync\n   - `on_assign` - When assignee changes\n   - `on_label` - When labels change\n   - Keep minimal or allow arbitrary events?\n\n**Trade-offs to Consider**\n\n1. **Sync vs Async**:\n   - Sync: Hooks can modify operation (validation)\n   - Async: No latency, but can't affect outcome\n   - Go choice: Async for speed, RunSync for tests\n   - Rust: Same approach or different?\n\n2. **Richness vs Simplicity**:\n   - Rich: Pass full context, before/after, all metadata\n   - Simple: Just issue ID, user looks up details\n   - Middle: Issue JSON + event type\n\n3. **Security vs Convenience**:\n   - Strict: Require hook approval, sandboxing\n   - Loose: Just run them (Git hook model)\n   - Middle: Warning on first run\n\n4. **Extensibility vs Maintenance**:\n   - Many event types = flexible but complex\n   - Few event types = simple but limiting\n   - Start minimal, add as needed\n\n**Reference Files in Go Beads**\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/hooks/hooks.go` - Core hook system\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/hooks/hooks_unix.go` - Unix implementation  \n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/hooks/hooks_windows.go` - Windows implementation\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/templates/hooks/` - Example hooks\n\n**Go Implementation Details**\n- `Runner` struct with `hooksDir` and `timeout`\n- `Run(event, issue)` - Async execution\n- `RunSync(event, issue)` - Sync execution (for tests)\n- `HookExists(event)` - Check if hook present\n- Hook receives issue as JSON on stdin\n- 10s timeout default\n- Executable permission check (Unix)\n- Fire-and-forget error handling\n\n**Hook Input Format** (Go):\n```json\n{\n  \"id\": \"bd-abc123\",\n  \"title\": \"Issue title\",\n  \"status\": \"open\",\n  \"priority\": 1,\n  \"type\": \"bug\",\n  \"created\": \"2025-01-16T12:00:00Z\",\n  \"updated\": \"2025-01-16T12:00:00Z\",\n  \"created_by\": \"agent-alice\",\n  \"description\": \"Full description...\",\n  \"labels\": [\"bug\", \"urgent\"],\n  \"assignee\": \"agent-bob\"\n}\n```\n\n**Platform Considerations**\n- Unix: Check executable bit (`mode & 0111`)\n- Windows: Check file extension (.bat, .ps1, .exe)\n- Cross-platform hook template examples\n- Environment variable handling\n\n**Use Cases to Support**\n\n1. **Notifications**:\n   - Slack/Discord on issue create\n   - Email on high-priority bugs\n   - Mobile push on assignment\n\n2. **Integration**:\n   - Mirror to Jira/Linear\n   - Create GitHub issues\n   - Update project management tools\n\n3. **Analytics**:\n   - Track cycle time\n   - Generate metrics\n   - Update dashboards\n\n4. **Automation**:\n   - Auto-assign based on labels\n   - Trigger CI jobs\n   - Update documentation\n\n5. **Compliance**:\n   - Audit logging\n   - Security scanning\n   - Policy enforcement\n\n**Open Design Questions**\n\n1. Should hooks be able to modify the issue?\n   - Pro: Enables validation, auto-correction\n   - Con: Complexity, need before/after, rollback\n   - Go approach: No (read-only)\n\n2. Template hooks included in init?\n   - Provide examples in `.beads/hooks.example/`?\n   - Auto-install on `bd init --hooks`?\n\n3. Hook for message events?\n   - `on_message` for mail system\n   - Separate design or include now?\n\n4. Disable mechanism?\n   - `--no-hooks` flag?\n   - Config setting?\n   - Just remove executable bit?\n\n**Acceptance**\n- [ ] Design document for hooks system architecture\n- [ ] Hook execution model (sync vs async, timeouts)\n- [ ] Hook data format (JSON schema for stdin)\n- [ ] Event types and lifecycle\n- [ ] Security considerations (sandboxing, warnings)\n- [ ] Error handling strategy\n- [ ] Platform-specific implementation (Unix vs Windows)\n- [ ] Integration with daemon mode\n- [ ] Example hook templates\n- [ ] Testing strategy for hooks","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"2ab046a9-4f9d-8973-dea1-b3f2b6358b88","counter":9355462451292902946}]},"cc":{"max":{}}},"status":"open","_at":[1768622561219,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.49","created_at":[1768622571168,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add Event issue type support","description":"**Problem**\nbeads-rs lacks the Event issue type - immutable operational state change records that provide an audit trail of swarm activity. Events capture who did what when, enabling debugging, monitoring, and compliance.\n\n**What Event Beads Do (from Go beads)**\nEvent beads are append-only records of state changes:\n- Operational events (agent started, gate resolved, patrol completed)\n- System events (sync failed, timeout detected)\n- Audit trail (who approved what, who escalated)\n- Never modified after creation (immutable)\n\nEvent structure:\n- EventKind: Namespaced event type (e.g., \"patrol.muted\", \"agent.started\")\n- Actor: Entity URI or bead ID who caused the event\n- Target: Entity URI or bead ID affected by the event\n- Payload: Event-specific JSON data\n- Timestamp: When event occurred (CreatedAt)\n\nEvent kinds (namespaced):\n- patrol.*: Patrol lifecycle (started, completed, muted, unmuted)\n- agent.*: Agent lifecycle (started, stuck, stopped, dead)\n- gate.*: Gate events (resolved, escalated, expired)\n- merge.*: Merge events (approved, rejected, merged)\n\n**Go Implementation**\nType definition (internal/types/types.go):\n- IssueType = TypeEvent (line 494)\n- Fields (lines 120-124):\n  - EventKind string: Namespaced event type\n  - Actor string: Entity URI who caused this\n  - Target string: Entity URI or bead ID affected\n  - Payload string: Event-specific JSON data\n\nEvent creation pattern:\n```go\nevent := &types.Issue{\n    IssueType:  types.TypeEvent,\n    Title:      fmt.Sprintf(\"%s: %s\", eventKind, summary),\n    EventKind:  eventKind,\n    Actor:      actorURI,\n    Target:     targetBeadID,\n    Payload:    payloadJSON,\n}\nstore.CreateIssue(ctx, event, actor)\n```\n\nEvent querying:\n- bd list --type event --filter event_kind=patrol.started\n- Filter by actor, target, time range\n- Reconstruct event timelines\n\nImmutability:\n- Events should never be updated after creation\n- Enforce via code convention (no UpdateEvent calls)\n- Consider: Hard validation that prevents event updates\n\n**Design for Rust**\nData model (src/core/):\n```rust\npub struct EventData {\n    event_kind: String,      // Namespaced type (patrol.started)\n    actor: String,           // Entity URI or bead ID\n    target: Option<String>,  // Entity URI or bead ID\n    payload: Option<String>, // JSON blob\n}\n```\n\nAdd to Bead or use optional fields.\n\nEvent creation (src/daemon/ or src/api/):\n```rust\npub fn create_event(\n    event_kind: &str,\n    actor: &str,\n    target: Option<&str>,\n    payload: Option<serde_json::Value>,\n) -> Result<Bead, Error>;\n```\n\nImmutability enforcement:\n- Mark event beads as immutable in type system\n- Return error if update attempted on event type\n- Consider: Separate EventBead enum variant with no update methods\n\nCLI (src/cli/):\n- bd create --type event --event-kind <kind> --actor <uri> --target <id> [--payload <json>]\n- bd list --type event [--filter event_kind=<kind>]\n- bd show <event-id> (display structured event data)\n\n**Design Notes**\n- Events are write-once, read-many (WORM)\n- Event payload should be structured (JSON) for querying\n- Namespaced event kinds enable categorization and filtering\n- Consider: Event aggregation for metrics (count events by kind)\n- Consider: Event streaming/notification (pubsub for new events)\n- Consider: Event retention policy (old events can be archived)\n- Consider: Event schema validation (enforce payload structure per kind)\n\n**Acceptance**\n- [ ] Event type constant defined\n- [ ] EventData struct with event_kind, actor, target, payload\n- [ ] create_event helper function\n- [ ] bd create --type event works\n- [ ] Event fields populate correctly\n- [ ] bd list --type event shows events\n- [ ] bd show <event-id> displays structured event\n- [ ] Immutability enforced (update returns error for events)\n- [ ] Tests for event creation\n- [ ] Tests for event immutability\n- [ ] Migration from Go beads preserves event type and fields\n\n**Files to study in Go beads:**\n- tmp/beads/internal/types/types.go (lines 120-124: event fields, line 494: TypeEvent)\n- tmp/beads/cmd/bd/create.go (event creation examples, if any)\n- tmp/beads/internal/storage/sqlite/schema.go (lines 50-54: event columns)","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"808c9050-11e9-66b2-8da2-e9214f3d4cfd","counter":2052653861025408883}]},"cc":{"max":{}}},"status":"open","_at":[1768622571168,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.5","created_at":[1768622401969,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add Gate issue type support","description":"**Problem**\nbeads-rs lacks the Gate issue type - an async coordination primitive that blocks workflow steps until conditions are met. This is a major swarm coordination feature used for GitHub CI, PR merges, timers, human approvals, and cross-rig bead dependencies.\n\n**What Gates Do (from Go beads)**\nGates are async wait conditions created automatically by formula steps. They block dependent steps until resolved. Gate types:\n- human: Manual resolution via bd close\n- timer: Auto-expires after timeout\n- gh:run: Waits for GitHub Actions workflow\n- gh:pr: Waits for PR merge  \n- bead: Waits for cross-rig bead completion (await_id format: <rig>:<bead-id>)\n\n**Go Implementation**\nType definition in internal/types/types.go:\n- IssueType = TypeGate\n- Fields: AwaitType (string), AwaitID (string), Timeout (Duration), Waiters ([]string)\n- Waiters are notified when gate clears\n\nCLI in cmd/bd/gate.go:\n- bd gate list [--all] - List open/closed gates\n- bd gate show <id> - Show gate details\n- bd gate resolve <id> [--reason] - Manually close gate\n- bd gate check [--type] [--dry-run] [--escalate] - Evaluate gates, auto-close resolved\n- bd gate add-waiter <id> <waiter> - Register for wake notification\n\nGate checking (bd gate check):\n- gh:run: Uses gh CLI to check workflow status/conclusion\n- gh:pr: Uses gh CLI to check PR state/merged\n- timer: Compares current time to created_at + timeout\n- bead: Cross-rig database lookup for target bead status\n\nSchema (internal/storage/sqlite/schema.go):\nMigration 027_gate_columns.go adds await_type, await_id, timeout, waiters columns.\n\n**Design for Rust**\nData model (src/core/):\n```rust\npub enum GateType {\n    Human,\n    Timer,\n    GhRun,\n    GhPr,\n    Bead,\n}\n\npub struct GateData {\n    await_type: GateType,\n    await_id: Option<String>,\n    timeout: Option<Duration>,\n    waiters: Vec<String>,\n}\n```\n\nAdd GateData to Bead enum variants or use optional fields in Bead struct.\n\nCLI surface (src/cli/):\n- bd gate list [--all]\n- bd gate show <id>\n- bd gate resolve <id> [--reason]\n- bd gate check [--type] [--dry-run]\n- bd gate add-waiter <id> <waiter>\n\nGate checking logic:\n- Integrate with gh CLI (Command::new(\"gh\"))\n- Cross-rig bead lookup via git2 (open remote db read-only)\n- Timer expiration via SystemTime\n\n**Design Notes**\n- Gate type is structural (specific fields) not just an enum\n- Waiters enable push notifications (reactive vs polling)\n- Cross-rig bead gates need multi-repo access\n- gh CLI integration is external dependency\n- Escalation (failed/expired gates) needs notification system\n\n**Acceptance**\n- [ ] GateType enum and GateData struct defined in src/core/\n- [ ] Bead can hold gate-specific fields\n- [ ] bd gate list/show/resolve commands work\n- [ ] bd gate check evaluates timer gates\n- [ ] bd gate check evaluates gh:run gates (if gh CLI available)\n- [ ] bd gate check evaluates gh:pr gates (if gh CLI available)\n- [ ] bd gate check evaluates bead gates (cross-rig lookup)\n- [ ] Waiters list can be modified via add-waiter\n- [ ] Tests for gate CRDT merge behavior\n- [ ] Migration from Go beads preserves gate fields\n\n**Files to study in Go beads:**\n- tmp/beads/internal/types/types.go (lines 93-97: Gate fields)\n- tmp/beads/cmd/bd/gate.go (entire file: CLI implementation)\n- tmp/beads/internal/storage/sqlite/migrations/027_gate_columns.go\n- tmp/beads/cmd/bd/gate_test.go","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"de612653-07b8-2d48-206c-20b859969691","counter":12771606559369402638}]},"cc":{"max":{}}},"status":"open","_at":[1768622401969,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.50","created_at":[1768622590654,0],"created_by":"darin@darinsmcstudio2.lan","title":"Implement inline tombstones - Deleted issues as status=deleted with TTL-based expiration","description":"","design":"Port the inline tombstone system from Go beads to beads-rs.\n\n## Problem\n\nWhen issues are deleted, we need to:\n1. Preserve delete markers for sync (CRDT tombstones)\n2. Support 3-way merge of deletions\n3. Eventually garbage collect old tombstones\n4. Keep dependency graph intact during TTL period\n\n## Go beads approach\n\nDeleted issues become tombstones with:\n- `deleted_at`: Timestamp of deletion\n- `deleted_by`: Actor who deleted\n- `delete_reason`: Why deleted\n- `original_type`: Issue type before deletion\n\nTombstones are:\n- Inline in issues table (not separate deletions.jsonl)\n- Exported to JSONL like normal issues\n- Pruned after TTL (default 30 days)\n- Kept if open issues still depend on them\n\n## Implementation approach\n\n**Schema changes** (`src/storage/schema.sql`):\n```sql\nALTER TABLE issues ADD COLUMN deleted_at DATETIME;\nALTER TABLE issues ADD COLUMN deleted_by TEXT DEFAULT '';\nALTER TABLE issues ADD COLUMN delete_reason TEXT DEFAULT '';\nALTER TABLE issues ADD COLUMN original_type TEXT DEFAULT '';\n\n-- Partial index for efficient TTL queries\nCREATE INDEX idx_issues_deleted_at \n    ON issues(deleted_at) \n    WHERE deleted_at IS NOT NULL;\n```\n\n**Core types** (`src/core/types.rs`):\n```rust\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Issue {\n    pub id: String,\n    pub title: String,\n    pub status: Status,\n    // ... other fields ...\n    \n    // Tombstone fields\n    pub deleted_at: Option<DateTime<Utc>>,\n    pub deleted_by: Option<String>,\n    pub delete_reason: Option<String>,\n    pub original_type: Option<IssueType>,\n}\n\nimpl Issue {\n    /// Check if issue is a tombstone\n    pub fn is_tombstone(&self) -> bool {\n        self.deleted_at.is_some()\n    }\n    \n    /// Check if tombstone is expired (past TTL)\n    pub fn is_expired(&self, ttl: Duration) -> bool {\n        if let Some(deleted_at) = self.deleted_at {\n            Utc::now() - deleted_at > ttl\n        } else {\n            false\n        }\n    }\n}\n\n/// Default tombstone TTL\npub const DEFAULT_TOMBSTONE_TTL: Duration = Duration::days(30);\n\n/// Minimum tombstone TTL for safety\npub const MIN_TOMBSTONE_TTL: Duration = Duration::days(7);\n```\n\n**Delete operation** (`src/daemon/operations.rs`):\n```rust\npub fn delete_issue(\n    state: &mut CanonicalState,\n    issue_id: &str,\n    actor: &str,\n    reason: Option<&str>,\n) -> Result<()> {\n    let mut issue = state.get_issue_mut(issue_id)?;\n    \n    // Convert to tombstone\n    issue.deleted_at = Some(Utc::now());\n    issue.deleted_by = Some(actor.to_string());\n    issue.delete_reason = reason.map(|s| s.to_string());\n    issue.original_type = Some(issue.issue_type.clone());\n    \n    // Mark dirty for export\n    state.mark_dirty(issue_id);\n    \n    Ok(())\n}\n```\n\n**Tombstone pruning** (`src/daemon/compact.rs`):\n```rust\n/// Prune expired tombstones that have no open dependencies\npub fn prune_tombstones(\n    state: &mut CanonicalState,\n    ttl: Duration,\n) -> Result<PruneResult> {\n    let mut result = PruneResult::default();\n    \n    // Find expired tombstones\n    let expired: Vec<_> = state.issues()\n        .filter(|i| i.is_expired(ttl))\n        .map(|i| i.id.clone())\n        .collect();\n    \n    // Build dependency map: tombstone_id -> [dependent_issue_ids]\n    let deps_map = build_reverse_deps(state);\n    \n    // Only prune tombstones with no open dependents\n    for tombstone_id in expired {\n        if let Some(dependents) = deps_map.get(&tombstone_id) {\n            let has_open_deps = dependents.iter()\n                .any(|dep_id| {\n                    state.get_issue(dep_id)\n                        .map(|i| i.status == Status::Open)\n                        .unwrap_or(false)\n                });\n            \n            if has_open_deps {\n                result.kept.push(tombstone_id.clone());\n                continue;\n            }\n        }\n        \n        // Safe to delete\n        state.remove_issue(&tombstone_id)?;\n        result.deleted.push(tombstone_id);\n    }\n    \n    Ok(result)\n}\n\n#[derive(Debug, Default)]\npub struct PruneResult {\n    pub deleted: Vec<String>,\n    pub kept: Vec<String>,\n}\n```\n\n**CLI commands**:\n```bash\nbd delete <issue-id> --reason \"duplicate of bd-abc\"\nbd compact --prune  # Age-based pruning (default 30d)\nbd compact --purge  # Dependency-aware purging\nbd compact --older-than 60  # Custom TTL\n```\n\n## Files to reference\n\nGo implementation:\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/compact_tombstone.go`\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/storage/sqlite/migrations/018_tombstone_columns.go`\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/storage/sqlite/migrations/028_tombstone_closed_at.go`\n\n## Design notes\n\n**Why inline tombstones**:\n- Simpler than separate deletions.jsonl\n- Better 3-way merge support\n- Tombstones visible in normal queries\n- Export/import just works\n\n**TTL-based expiration**:\n- Default 30 days gives time for sync\n- Minimum 7 days safety check\n- Dependency-aware: keep if open deps exist\n- Manual override via --older-than\n\n**Sync behavior**:\n- Tombstones exported to JSONL normally\n- Import detects deleted_at and preserves tombstone\n- 3-way merge uses deleted_at for conflict resolution\n- Pruned tombstones just disappear from JSONL\n\n**Migration from deletions.jsonl**:\n- Need migration command to import old deletions\n- Convert deleted_id -> issue with deleted_at\n- Preserve delete metadata\n\n## Questions\n\n1. Should tombstones show in `bd list` by default?\n2. Filter flag: `bd list --include-deleted`?\n3. Should `bd show` work on tombstones?\n4. Warn when deleting issue with open dependents?\n5. Auto-prune on sync or explicit command only?","acceptance_criteria":"- [ ] Schema has deleted_at, deleted_by, delete_reason, original_type\n- [ ] is_tombstone() and is_expired() methods work\n- [ ] bd delete creates tombstones instead of removing\n- [ ] Tombstones exported to JSONL\n- [ ] Tombstones imported from JSONL\n- [ ] Prune removes expired tombstones with no open deps\n- [ ] Kept tombstones if open issues depend on them\n- [ ] Default TTL is 30 days\n- [ ] bd compact --prune works\n- [ ] bd compact --purge works","priority":3,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"4cb4eb26-817e-53fc-2b41-d767695cf95f","counter":13108053629378298605}]},"cc":{"max":{}}},"status":"open","_at":[1768622590654,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.51","created_at":[1768622598117,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add Slot issue type support","description":"**Problem**\nbeads-rs lacks the Slot issue type - exclusive access primitives that coordinate shared resources with a holder and waiters queue. Slots enforce mutual exclusion for resources like merge queues, deployment slots, or critical sections.\n\n**What Slot Beads Do (from Go beads)**\nSlot beads manage exclusive access:\n- One holder at a time (mutual exclusion)\n- Waiters queue for access\n- Automatic slot release when holder closes/releases\n- Used for: merge queues, deployment slots, exclusive workflows\n\nSlot lifecycle:\n1. Create slot (empty, no holder)\n2. Agent claims slot (becomes holder)\n3. Agent uses resource\n4. Agent releases slot (holder becomes empty)\n5. Next waiter (if any) is notified\n\nMerge-slot gate pattern:\n- Refinery uses merge-slot to serialize merges\n- Only one PR can merge at a time\n- Other PRs wait in queue\n\n**Go Implementation**\nType definition (internal/types/types.go):\n- IssueType = TypeSlot (line 495)\n- Fields (lines 99-100):\n  - Holder string: Who currently holds the slot (empty = available)\n  - Waiters []string: Queue of waiting agents\n\nSlot operations (cmd/bd/slot.go for agent slots, cmd/bd/merge_slot.go for merge slots):\n- Claim slot: Set holder if empty, else add to waiters\n- Release slot: Clear holder, notify first waiter\n- Check slot: Query holder and waiters\n\nAgent slots (cmd/bd/slot.go):\nDifferent concept - slots ON agent beads (hook, role)\nThese are fields, not separate slot issue types.\n\nMerge-slot example (cmd/bd/merge_slot.go):\n- Create merge-slot bead for rig\n- Refinery claims slot before merge\n- Other refineries wait\n- Release on merge complete\n\n**Design for Rust**\nData model (src/core/):\n```rust\npub struct SlotData {\n    holder: Option<String>,  // Current holder (empty = available)\n    waiters: Vec<String>,    // Queue of waiting agents\n}\n```\n\nAdd to Bead or use optional fields.\n\nSlot operations (src/daemon/ or src/api/):\n```rust\npub fn claim_slot(slot_id: &str, claimant: &str) -> Result<ClaimResult, Error>;\npub fn release_slot(slot_id: &str, holder: &str) -> Result<(), Error>;\npub fn slot_status(slot_id: &str) -> Result<SlotStatus, Error>;\n\npub enum ClaimResult {\n    Claimed,       // You are now the holder\n    Queued,        // Added to waiters\n    AlreadyHolder, // You already hold it\n}\n\npub struct SlotStatus {\n    holder: Option<String>,\n    waiters: Vec<String>,\n    position: Option<usize>, // Your position if in waiters\n}\n```\n\nCLI (src/cli/):\n- bd slot-claim <slot-id> [<agent>] - Claim or join queue\n- bd slot-release <slot-id> [<agent>] - Release and notify next\n- bd slot-status <slot-id> - Show holder and queue\n- bd create --type slot \"Merge queue\"\n\nNotification:\n- When slot released, notify first waiter\n- Integration with message system or external notification\n\n**Design Notes**\n- Slots vs agent slots: Different concepts!\n  - Slot issue type: Exclusive resource coordination\n  - Agent slot fields: Work/role references on agents\n- Fairness: FIFO queue for waiters\n- Consider: Slot timeout (auto-release if holder doesn't heartbeat)\n- Consider: Slot priority (high-priority claims jump queue)\n- Consider: Multi-slot (lease N slots from pool)\n- Consider: Deadlock detection (slot dependency cycles)\n\n**Acceptance**\n- [ ] Slot type constant defined\n- [ ] SlotData struct with holder, waiters\n- [ ] claim_slot operation implemented\n- [ ] release_slot operation implemented\n- [ ] slot_status query implemented\n- [ ] bd slot-claim works\n- [ ] bd slot-release works\n- [ ] bd slot-status shows holder and queue\n- [ ] bd create --type slot works\n- [ ] Claim enforces mutual exclusion\n- [ ] Release notifies next waiter\n- [ ] Tests for slot claim/release\n- [ ] Tests for waiter queue ordering\n- [ ] Migration from Go beads preserves slot type and fields\n\n**Files to study in Go beads:**\n- tmp/beads/internal/types/types.go (lines 99-100: holder field, line 495: TypeSlot)\n- tmp/beads/cmd/bd/merge_slot.go (merge-slot coordination example)\n- tmp/beads/cmd/bd/slot.go (agent slot management - different concept)","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"09b410db-654b-c21f-f566-460deaca92e2","counter":7715948808307674258}]},"cc":{"max":{}}},"status":"open","_at":[1768622598117,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.52","created_at":[1768622610999,0],"created_by":"darin@darinsmcstudio2.lan","title":"llms.txt standard - AI agent discoverability","description":"**Problem**\nAI agents need a standard way to discover project-specific instructions, APIs, and tools. The llms.txt standard (https://llmstxt.org/) provides a well-known endpoint for agent discoverability. Beads should generate this automatically based on project state.\n\n**What the Feature Does**\nAutomatically generate `/llms.txt` (or `.beads/llms.txt`) containing:\n- Project overview from README\n- Available beads commands (bd create, bd ready, etc.)\n- Current issues and status\n- Project-specific workflows\n- Agent instructions from AGENTS.md\n- Integration points (git hooks, sync, etc.)\n\n**Example Output**:\n```\n# My Project (bd)\n\n> Git-backed issue tracker for AI workflows.\n\n## Essential Commands\n\nbd create \"Title\" -p 1 --json      # Create issue\nbd ready --json                     # Show ready work\nbd sync                             # Sync to git\n\n## Current Work (Auto-generated)\n\nOpen Issues: 12\n- bd-abc (P0): Critical bug in sync\n- bd-xyz (P1): Implement feature X\n\nReady to Work: 5 issues\nBlocked: 3 issues\n\n## Agent Workflows\n\nSee AGENTS.md for complete guide.\nAlways use --json for programmatic access.\nRun `bd sync` at end of session.\n\n## Documentation\n\n- Full docs: ./docs/\n- API: Run `bd help --json`\n```\n\n**Why It Needs Design Work**\n\n1. **Content Strategy**:\n   - What to include? Too much = noise, too little = not useful\n   - Static content (commands, docs) vs dynamic (current issues)\n   - Freshness - regenerate when? After every operation?\n   - Caching strategy?\n\n2. **Generation Model**:\n   - Option A: Generate on-demand (`bd llms-txt`)\n   - Option B: Auto-generate after mutations (create, update, close)\n   - Option C: Web server endpoint (daemon serves it)\n   - Option D: Static file committed to repo\n   - Which fits beads workflow best?\n\n3. **Content Depth**:\n   - Minimal: Just commands and project name\n   - Medium: Commands + current work summary  \n   - Full: Entire state dump (issues, deps, labels)\n   - How to balance discoverability vs overwhelming?\n\n4. **Multi-Repo Handling**:\n   - Single repo: Easy, one llms.txt\n   - Multi-repo/orchestrator: Which issues to show?\n   - Aggregate all rigs?\n   - Per-rig llms.txt?\n\n**Key Decisions to Make**\n\n1. **File Location**:\n   - Standard: `/llms.txt` in repo root (web-accessible)\n   - Beads-specific: `.beads/llms.txt`\n   - Both?\n   - User-configurable via config?\n\n2. **Generation Trigger**:\n   ```\n   Option A: Manual\n   - bd llms-txt > /llms.txt\n   - User commits to repo\n   \n   Option B: Auto-update\n   - After bd create/update/close\n   - Daemon background task\n   \n   Option C: Dynamic\n   - Daemon serves endpoint\n   - Not a file, just API\n   \n   Option D: Hybrid\n   - bd sync generates static file\n   - Always fresh after sync\n   ```\n\n3. **Content Template**:\n   ```markdown\n   # {project_name}\n   \n   > {description from README or config}\n   \n   ## Quick Start\n   {from README or QUICKSTART.md}\n   \n   ## Essential Commands\n   {list of bd commands with examples}\n   \n   ## Current State (as of {timestamp})\n   - Open: {count}\n   - Ready: {count}\n   - Blocked: {count}\n   \n   Top Priority:\n   {top 5 ready issues}\n   \n   ## Workflows\n   {from AGENTS.md if exists}\n   \n   ## Documentation\n   {links to docs, README, etc}\n   ```\n\n4. **Dynamic Content Freshness**:\n   - Include timestamp?\n   - Show staleness warning if old?\n   - Auto-regenerate on `bd sync`?\n   - Manual refresh command?\n\n**Trade-offs to Consider**\n\n1. **Static vs Dynamic**:\n   - Static: Works with any web server, git-tracked\n   - Dynamic: Always fresh, but requires daemon\n   - Hybrid: Best of both?\n\n2. **Detail Level**:\n   - Detailed: More useful for agents\n   - Minimal: Cleaner, less maintenance\n   - Solution: Configurable verbosity?\n\n3. **Performance**:\n   - Full state dump = expensive\n   - Summary = fast but less useful\n   - Cache + incremental updates?\n\n4. **Git Pollution**:\n   - Auto-generated files in commits = noisy\n   - Gitignore llms.txt and serve dynamically?\n   - Or embrace it (it's useful)?\n\n**Reference Files in Go Beads**\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/website/static/llms.txt` - Example output\n- Search for \"llms\" in codebase\n\n**Go Implementation** (if exists):\nCurrently Go beads has a static `website/static/llms.txt` manually maintained.\nNo auto-generation found in codebase - opportunity to pioneer!\n\n**llms.txt Standard**\nFrom https://llmstxt.org/:\n- Markdown format\n- Well-known location: `/llms.txt`\n- Designed for language models to read\n- Should be concise but comprehensive\n- Include project context, APIs, current state\n- Links to fuller documentation\n\n**Use Cases to Support**\n\n1. **Agent Onboarding**:\n   - New AI agent joins project\n   - Reads llms.txt to understand project\n   - Gets current work, commands, workflows\n\n2. **Context Refresh**:\n   - Long-running session\n   - Agent re-reads llms.txt for latest state\n   - Discovers new issues, blockers\n\n3. **Cross-Project Discovery**:\n   - Agent working on multiple projects\n   - Quickly switch context via llms.txt\n   - Consistent format across projects\n\n4. **Documentation Portal**:\n   - Web-accessible project overview\n   - Human-readable too\n   - Living documentation\n\n**Content Sections to Consider**\n\n1. **Project Metadata**:\n   - Name, description\n   - Repository URL\n   - License\n   - Key maintainers\n\n2. **Quick Start**:\n   - Installation\n   - Basic commands\n   - First steps\n\n3. **Current State**:\n   - Issue counts by status\n   - Top priority work\n   - Recent activity\n\n4. **Commands**:\n   - Essential bd commands\n   - JSON output examples\n   - Common patterns\n\n5. **Workflows**:\n   - Agent-specific instructions\n   - Session protocol\n   - Best practices\n\n6. **Documentation Links**:\n   - README\n   - AGENTS.md\n   - API docs\n   - Specs\n\n**Open Design Questions**\n\n1. Should llms.txt be versioned?\n   - Include API version, schema version?\n   - Help agents understand format changes?\n\n2. Multiple formats?\n   - llms.txt (markdown)\n   - llms.json (structured data)\n   - llms.html (pretty view)\n\n3. Privacy/security?\n   - Filter sensitive issues?\n   - Public vs private sections?\n   - Authentication for full details?\n\n4. Customization?\n   - Template system?\n   - User-provided sections?\n   - Plugin hooks to add content?\n\n5. Standard vs beads-specific?\n   - Follow llms.txt spec strictly?\n   - Or extend with beads-specific sections?\n   - Namespace extensions?\n\n**Integration Points**\n\n- `bd info --json` - Current state data\n- `bd ready --json` - Top priority work\n- `bd list --json` - All issues\n- `bd help` - Command reference\n- README.md - Project description\n- AGENTS.md - Agent workflows\n- CLAUDE.md - Agent instructions\n\n**Acceptance**\n- [ ] Design document for llms.txt generation\n- [ ] Content template and structure\n- [ ] Generation trigger strategy (manual, auto, dynamic)\n- [ ] File location(s) decision\n- [ ] Dynamic content freshness approach\n- [ ] Multi-repo handling\n- [ ] Privacy/filtering rules\n- [ ] Performance considerations\n- [ ] Integration with bd sync workflow\n- [ ] Template customization mechanism\n- [ ] Example output for beads-rs itself","priority":3,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"788724f1-c261-6a6d-2987-01e3e1882f58","counter":17140439526438552188}]},"cc":{"max":{}}},"status":"open","_at":[1768622610999,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.53","created_at":[1768622624996,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add custom types system support","description":"**Problem**\nbeads-rs has hardcoded issue types (bug, feature, task, epic, chore). Users cannot define project-specific types (experiment, spike, incident, etc.). This limits expressiveness and forces users to shoehorn domain concepts into generic types.\n\n**What Custom Types Enable (from Go beads)**\nCustom types allow projects to define their own vocabulary:\n- Research projects: experiment, hypothesis, analysis\n- SRE: incident, postmortem, oncall\n- Design: mockup, prototype, usability-test\n- Any domain-specific concept\n\nConfiguration:\n```toml\n[types]\ncustom = [\"experiment\", \"spike\", \"incident\", \"postmortem\"]\n```\n\nValidation:\n- Built-in types: Always valid (catch typos)\n- Custom types: Valid per project (trust local config)\n- Federation: Trust child repo's custom types (don't re-validate)\n\n**Go Implementation**\nType validation (internal/types/types.go):\n```go\n// IsValid checks built-in types only\nfunc (t IssueType) IsValid() bool {\n    switch t { case TypeBug, TypeFeature, ... }\n}\n\n// IsValidWithCustom checks built-in + custom\nfunc (t IssueType) IsValidWithCustom(customTypes []string) bool {\n    if t.IsValid() { return true }\n    for _, custom := range customTypes {\n        if string(t) == custom { return true }\n    }\n    return false\n}\n```\n\nConfig integration (internal/configfile/config.go):\n```go\ntype Config struct {\n    Types struct {\n        Custom []string `toml:\"custom\"`\n    } `toml:\"types\"`\n}\n```\n\nCLI usage:\n- bd config set types.custom \"exp,spike,incident\"\n- bd create --type experiment \"Test hypothesis\"\n- bd list --type experiment\n\nFederation trust model (lines 367-391):\nWhen importing from child repo:\n- Built-in types: Validate (catch typos like \"tsak\")\n- Custom types: Trust (child already validated)\nThis implements \"trust the chain below you\" from HOP.\n\n**Design for Rust**\nData model (src/core/):\n```rust\npub enum IssueTypeVariant {\n    Bug, Feature, Task, Epic, Chore,\n    Gate, Agent, Role, Rig, Convoy, Event, Slot,\n    Message, MergeRequest, Molecule,\n    Custom(String),  // Project-specific types\n}\n\nimpl IssueTypeVariant {\n    pub fn is_builtin(&self) -> bool;\n    pub fn validate(&self, custom_types: &[String]) -> bool;\n}\n```\n\nConfig (src/config/):\n```toml\n[types]\ncustom = [\"experiment\", \"spike\"]\n```\n\nParse in Config struct:\n```rust\npub struct Config {\n    pub types: TypesConfig,\n}\n\npub struct TypesConfig {\n    pub custom: Vec<String>,\n}\n```\n\nValidation:\n```rust\nimpl Bead {\n    pub fn validate(&self, config: &Config) -> Result<(), Error> {\n        self.issue_type.validate(&config.types.custom)?;\n        // ...\n    }\n}\n```\n\nCLI (src/cli/):\n- bd config set types.custom \"exp,spike\"\n- bd config get types.custom\n- bd create --type <custom-type>\n- bd list --type <custom-type>\n\n**Design Notes**\n- Custom types are strings, not validated at compile time\n- Type aliases (feat → feature) still useful for custom types\n- Federation: Import trusts source repo's custom types\n- Consider: Type hierarchy/inheritance (spike extends experiment)\n- Consider: Type-specific field requirements (validate by type)\n- Consider: Type namespacing (rig:experiment vs hq:experiment)\n- Consider: Type discovery (bd types list --all shows built-in + custom)\n\n**Acceptance**\n- [ ] IssueTypeVariant enum with Custom(String) variant\n- [ ] Config.types.custom field\n- [ ] bd config set/get types.custom works\n- [ ] Validation allows built-in + custom types\n- [ ] Validation rejects unknown types\n- [ ] bd create --type <custom> works\n- [ ] bd list --type <custom> filters correctly\n- [ ] bd types command shows built-in + custom\n- [ ] Federation import trusts custom types from source\n- [ ] Tests for custom type validation\n- [ ] Tests for config persistence\n- [ ] Migration from Go beads preserves custom types in config\n\n**Files to study in Go beads:**\n- tmp/beads/internal/types/types.go (lines 518-529: IsValidWithCustom)\n- tmp/beads/internal/types/types.go (lines 367-391: federation trust model)\n- tmp/beads/internal/configfile/config.go (custom types config)\n- tmp/beads/cmd/bd/create.go (type validation with custom)","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"c6072481-5e92-c56a-c3b8-14693550c64e","counter":2750684509595509687}]},"cc":{"max":{}}},"status":"open","_at":[1768622624996,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.54","created_at":[1768622628528,0],"created_by":"darin@darinsmcstudio2.lan","title":"Implement bd resolve-conflicts - JSONL merge conflict resolution with timestamp rules","description":"","design":"Port the conflict resolution feature from Go beads to beads-rs.\n\n## Problem\n\nWhen git merge fails on issues.jsonl, files end up with conflict markers:\n```\n<<<<<<< HEAD\n{\"id\":\"bd-abc\",\"title\":\"Old title\",...}\n=======\n{\"id\":\"bd-abc\",\"title\":\"New title\",...}\n>>>>>>> branch-name\n```\n\nNormal git mergetools don't understand beads merge semantics (LWW by updated_at).\n\n## Go beads solution\n\n`bd resolve-conflicts` command that:\n1. Parses conflict markers in JSONL\n2. Applies beads merge semantics (updated_at wins, arrays merge, etc.)\n3. Writes resolved JSONL atomically\n4. Supports dry-run and JSON output\n\n## Implementation approach\n\n**Core conflict parsing** (`src/merge/conflict_parser.rs`):\n```rust\n#[derive(Debug)]\npub struct ConflictRegion {\n    pub start_line: usize,\n    pub end_line: usize,\n    pub left_side: Vec<String>,   // Between <<<<<<< and =======\n    pub right_side: Vec<String>,  // Between ======= and >>>>>>>\n    pub left_label: String,        // e.g., \"HEAD\"\n    pub right_label: String,       // e.g., \"branch-name\"\n}\n\npub fn parse_conflicts(content: &str) -> Result<(Vec<ConflictRegion>, Vec<String>)> {\n    let mut conflicts = Vec::new();\n    let mut clean_lines = Vec::new();\n    let mut in_conflict = false;\n    let mut current_region: Option<ConflictRegion> = None;\n    \n    for (line_num, line) in content.lines().enumerate() {\n        if line.starts_with(\"<<<<<<<\") {\n            // Start of conflict\n            in_conflict = true;\n            current_region = Some(ConflictRegion {\n                start_line: line_num,\n                left_label: line[7..].trim().to_string(),\n                ..Default::default()\n            });\n        } else if line.starts_with(\"=======\") && in_conflict {\n            // Switch to right side\n            // ...\n        } else if line.starts_with(\">>>>>>>\") && in_conflict {\n            // End of conflict\n            current_region.right_label = line[7..].trim().to_string();\n            conflicts.push(current_region.take().unwrap());\n            in_conflict = false;\n        } else if !in_conflict {\n            clean_lines.push(line.to_string());\n        } else {\n            // Inside conflict, accumulate\n            // ...\n        }\n    }\n    \n    Ok((conflicts, clean_lines))\n}\n```\n\n**Conflict resolution** (`src/merge/conflict_resolver.rs`):\n```rust\npub enum ResolutionMode {\n    Mechanical,     // Use LWW rules automatically\n    Interactive,    // Prompt user (future)\n}\n\npub struct ConflictResolver {\n    mode: ResolutionMode,\n}\n\nimpl ConflictResolver {\n    pub fn resolve(&self, region: &ConflictRegion) -> Result<Vec<String>> {\n        match self.mode {\n            ResolutionMode::Mechanical => self.resolve_mechanical(region),\n            ResolutionMode::Interactive => unimplemented!(\"Interactive mode\"),\n        }\n    }\n    \n    fn resolve_mechanical(&self, region: &ConflictRegion) -> Result<Vec<String>> {\n        // Parse JSONL from both sides\n        let left_issues = self.parse_jsonl(&region.left_side)?;\n        let right_issues = self.parse_jsonl(&region.right_side)?;\n        \n        // Build issue map by ID\n        let mut merged = HashMap::new();\n        \n        for issue in left_issues {\n            merged.insert(issue.id.clone(), issue);\n        }\n        \n        for issue in right_issues {\n            if let Some(existing) = merged.get(&issue.id) {\n                // Same ID - merge using LWW rules\n                let resolved = merge_issues(existing, &issue)?;\n                merged.insert(issue.id.clone(), resolved);\n            } else {\n                // New issue from right\n                merged.insert(issue.id.clone(), issue);\n            }\n        }\n        \n        // Serialize back to JSONL\n        let mut lines = Vec::new();\n        for issue in merged.values() {\n            lines.push(serde_json::to_string(issue)?);\n        }\n        \n        Ok(lines)\n    }\n    \n    fn parse_jsonl(&self, lines: &[String]) -> Result<Vec<Issue>> {\n        lines.iter()\n            .filter(|line| !line.is_empty())\n            .map(|line| serde_json::from_str(line))\n            .collect()\n    }\n}\n```\n\n**CLI command**:\n```rust\n#[derive(Parser)]\npub struct ResolveConflictsArgs {\n    /// File to resolve (defaults to .beads/issues.jsonl)\n    file: Option<PathBuf>,\n    \n    #[arg(long, default_value = \"mechanical\")]\n    mode: ResolutionMode,\n    \n    #[arg(long)]\n    dry_run: bool,\n    \n    #[arg(long)]\n    json: bool,\n    \n    #[arg(long)]\n    path: Option<PathBuf>,\n}\n\npub fn resolve_conflicts(args: ResolveConflictsArgs) -> Result<()> {\n    let file_path = args.file.unwrap_or_else(|| {\n        args.path.unwrap_or_else(|| PathBuf::from(\".\"))\n            .join(\".beads/issues.jsonl\")\n    });\n    \n    // Read file\n    let content = fs::read_to_string(&file_path)?;\n    \n    // Parse conflicts\n    let (conflicts, clean_lines) = parse_conflicts(&content)?;\n    \n    if conflicts.is_empty() {\n        println!(\"No conflict markers found\");\n        return Ok(());\n    }\n    \n    // Resolve each conflict\n    let resolver = ConflictResolver::new(args.mode);\n    let mut resolved_lines = clean_lines;\n    \n    for conflict in &conflicts {\n        let resolved = resolver.resolve(conflict)?;\n        resolved_lines.extend(resolved);\n    }\n    \n    if args.dry_run {\n        println!(\"Would resolve {} conflicts\", conflicts.len());\n        return Ok(());\n    }\n    \n    // Create backup\n    let backup_path = file_path.with_extension(\"jsonl.pre-resolve\");\n    fs::copy(&file_path, &backup_path)?;\n    \n    // Write resolved file atomically\n    let temp_path = file_path.with_extension(\"jsonl.tmp\");\n    fs::write(&temp_path, resolved_lines.join(\"\\n\"))?;\n    fs::rename(&temp_path, &file_path)?;\n    \n    println!(\"Resolved {} conflicts\", conflicts.len());\n    println!(\"Backup: {}\", backup_path.display());\n    \n    Ok(())\n}\n```\n\n## Files to reference\n\nGo implementation:\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/resolve_conflicts.go`\n- `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/internal/merge/merge.go`\n\n## Design notes\n\n**Mechanical resolution rules**:\n1. If issue IDs match: Use LWW merge (latest updated_at wins)\n2. If different IDs: Include both\n3. Merge arrays (labels, deps) by union\n4. Lww fields use timestamp comparison\n\n**Backup strategy**:\n- Always create backup before writing\n- Backup path: `{file}.pre-resolve`\n- Preserve backup even on success\n- Atomic write via temp file + rename\n\n**Error handling**:\n- Invalid JSON in conflict region: report line number\n- Malformed conflict markers: detailed error\n- I/O errors: preserve original file\n\n**Future: Interactive mode**:\n- Show both versions side-by-side\n- Prompt: [L]eft, [R]ight, [M]erge, [E]dit\n- Store choices for replay\n\n## Questions\n\n1. Should this be a CLI-only command or daemon operation?\n2. Auto-resolve on `bd sync` if conflicts detected?\n3. Support for molecules.jsonl and other JSONL files?\n4. Should we mark git conflict as resolved after fixing?","acceptance_criteria":"- [ ] parse_conflicts extracts all conflict regions\n- [ ] Mechanical mode uses LWW merge semantics\n- [ ] Same-ID issues merged correctly\n- [ ] Different-ID issues both included\n- [ ] Backup created before writing\n- [ ] Atomic write via temp file\n- [ ] Dry-run shows what would be resolved\n- [ ] JSON output includes conflict details\n- [ ] Works on issues.jsonl by default\n- [ ] Handles malformed conflicts gracefully","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"e3bc4d60-0ed0-b5d5-36e8-05cfb9e043df","counter":9298302758019665171}]},"cc":{"max":{}}},"status":"open","_at":[1768622628528,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.6","created_at":[1768622403326,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add formula system to beads-rs","description":"**Problem**\nbeads-rs needs the formula system - declarative workflow templates that compile to protos. Formulas are the source layer above protos, enabling composition, inheritance, and complex workflow patterns.\n\n**What are Formulas?**\nFormulas are .formula.json/.formula.toml files that define workflows declaratively:\n- Variable definitions with defaults, validation, enums\n- Steps with dependencies (depends_on, needs, waits_for)\n- Composition via extends, aspects, bond points\n- Control flow: loops, branches, gates\n\n**How it Works (Go beads)**\n1. Parser loads formula from search paths (.beads/formulas/, ~/.beads/formulas/)\n2. Resolve inheritance (extends field)\n3. Apply transformations: control flow, aspects, inline expansion\n4. Cook to proto (ephemeral subgraph in memory) OR persist to DB\n5. Pour/wisp instantiates the proto with variable substitution\n\n**Search Paths**\n1. .beads/formulas/ (project)\n2. ~/.beads/formulas/ (user)  \n3. $GT_ROOT/.beads/formulas/ (orchestrator)\n\n**Commands**\n- bd formula list - list available formulas\n- bd formula show <name> - show formula details\n- bd cook <formula> - compile formula to proto (ephemeral by default)\n- bd cook <formula> --persist - save proto to DB\n- bd pour <formula> --var k=v - inline cook + instantiate persistent\n- bd mol wisp <formula> --var k=v - inline cook + instantiate ephemeral\n\n**Design Considerations**\n- Parser in Rust using serde for JSON/TOML\n- Formula struct mirrors Go internal/formula/formula.go\n- Variable substitution using {{var}} syntax\n- Inheritance resolver (extends field)\n- Aspect system (AOP-style advice: before, after, around)\n- Control flow operators (loops, branches, gates)\n\n**Files to Study (Go beads)**\n- cmd/bd/cook.go - formula cooking logic\n- cmd/bd/formula.go - formula commands (list, show)\n- internal/formula/ - parser, resolver, transformations\n- .beads/formulas/beads-release.formula.toml - complex example\n\n**Acceptance**\n- [ ] Formula parser for JSON/TOML\n- [ ] Variable substitution engine\n- [ ] Inheritance resolver (extends)\n- [ ] bd formula list/show commands\n- [ ] bd cook compiles formula to proto\n- [ ] Integration with pour/wisp\n- [ ] Tests for formula compilation\n","priority":1,"type":"epic","labels":{"entries":{"human-needed":[{"replica":"3c64a699-353d-d72d-f04e-9f4f1b86d92b","counter":17962138994002442544}]},"cc":{"max":{}}},"status":"open","_at":[1768622403326,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.7","created_at":[1768622404673,0],"created_by":"darin@darinsmcstudio2.lan","title":"Implement bd orphans command - Find issues referenced in commits but never closed","description":"","design":"Port the orphan detection feature from Go beads to beads-rs.\n\n## What it does\n\nScans git commit history for issue IDs (bd-xxx pattern) and identifies issues that:\n1. Are referenced in commit messages\n2. Remain in open or in_progress status in the database\n3. Should have been closed but weren't\n\nThis helps find work that's been implemented but not formally closed.\n\n## Implementation approach\n\n**Location**: `src/cli/orphans.rs` (new file), exposed via `src/cli/mod.rs`\n\n**Command structure**:\n```rust\npub struct OrphansArgs {\n    #[arg(long)]\n    json: bool,\n    #[arg(long)]\n    details: bool,\n    #[arg(long, short)]\n    fix: bool,  // Close orphaned issues with confirmation\n}\n```\n\n**Core logic**:\n1. Use git2-rs to walk commit history\n2. Scan commit messages for bd-xxx patterns using regex\n3. Query daemon for status of each referenced issue\n4. Filter for issues still open/in_progress\n5. Build orphan list with metadata (latest commit hash, message)\n\n**Output**:\n- Human mode: Pretty table with issue ID, title, status, latest commit\n- JSON mode: Machine-readable array of orphan objects\n- Details mode: Include full commit info\n\n**Fix mode**:\n- Confirm with user (Y/n prompt)\n- Call daemon to close each orphaned issue with reason \"Implemented\"\n- Report success/failure for each\n\n## Files to reference\n\nGo implementation: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/orphans.go`\nUses shared doctor package: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/doctor/`\n\n## Design notes\n\n- **Shared utility**: The orphan detection logic should be in `src/core/` or `src/git/` as a reusable function, not just in CLI.\n- **Pattern matching**: Use same regex pattern as Go beads for consistency: `bd-[a-z0-9]{5,6}`\n- **Performance**: For large repos, consider limiting commit scan depth or adding --since flag\n- **Edge cases**: \n  - External references (external:xxx) should be ignored\n  - Closed issues should be filtered out\n  - Tombstones (deleted issues) should be handled\n\n## Questions to resolve\n\n1. Should orphan detection be part of `bd doctor` or standalone command?\n2. Do we want to scan all branches or just current branch?\n3. Should we cache commit scan results?","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"5de5f19c-7f1b-43e2-dbe7-6244ded70993","counter":15600066176865691988}]},"cc":{"max":{}}},"status":"open","_at":[1768622404673,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.8","created_at":[1768622410584,0],"created_by":"darin@darinsmcstudio2.lan","title":"Add duplicate command for deduplication links","description":"**Problem**\nGo beads supports `bd duplicate <id> --of <canonical>` to mark an issue as a duplicate and automatically close it. This is essential for large databases with many similar reports. beads-rs needs this.\n\n**How it works in Go beads**\n- Command: `bd duplicate <id> --of <canonical>` (in cmd/bd/duplicate.go)\n- Uses `DepDuplicates` dependency type\n- Automatically closes the duplicate issue\n- Close reason references the canonical issue\n- Stored in dependencies table (per Decision 004: Edge Schema Consolidation)\n\n**Design for Rust**\n1. Add `Duplicates` variant to `DepKind` enum in src/core/domain.rs\n2. Mark it as non-DAG-enforcing (informational link)\n3. Add CLI command: src/cli/commands/duplicate.rs\n   - `bd duplicate <id> --of <canonical>`\n   - Validates canonical issue exists\n   - Rejects self-duplication (id == canonical)\n   - Creates duplicates edge\n   - Closes duplicate issue atomically\n4. Wire through daemon IPC for atomic operation (add dep + close)\n5. Add to CLI command tree\n\n**Design considerations**\n- Atomicity: dependency + closure must be atomic\n- Should we allow closing already-closed duplicates? (Go allows it)\n- Close reason should reference canonical ID\n- Prevent duplicate-of-duplicate chains? (Go doesn't enforce this)\n- What if canonical is itself a duplicate? (follow chain to root?)\n\n**Design questions for human review**\n- Should duplicate edges be unidirectional or bidirectional?\n  * Go: unidirectional (duplicate -> canonical)\n  * Benefit: canonical can list \"all duplicates of me\"\n- Should we auto-cascade when canonical is closed?\n  * Or keep duplicates independent?\n- Display strategy: show \"duplicate of X\" in bd show/list?\n\n**Files to study**\n- tmp/beads/cmd/bd/duplicate.go - Go implementation\n- tmp/beads/internal/types/types.go - DepDuplicates type\n- src/core/bead.rs - bead workflow and closure semantics\n\n**Acceptance**\n- [ ] Duplicates added to DepKind enum\n- [ ] bd duplicate command creates edge and closes issue\n- [ ] Self-duplication rejected\n- [ ] Canonical issue validated to exist\n- [ ] JSON output format matches Go beads\n- [ ] Cargo fmt, clippy, test pass","priority":2,"type":"feature","labels":{"entries":{"human-needed":[{"replica":"bce7a2d2-0dbc-975f-a698-a0887f96ea33","counter":12022866925484701339}]},"cc":{"max":{}}},"status":"open","_at":[1768622410584,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-ze0x.9","created_at":[1768622413176,0],"created_by":"darin@darinsmcstudio2.lan","title":"Tip system with contextual hints","description":"**Problem**\nUsers need contextual guidance after commands. Go beads has a tip system that shows hints based on conditions, with frequency throttling and probability rolls.\n\n**Design**\nImplement tip system with:\n- `Tip` struct: ID, condition function, message, frequency (min gap), priority, probability (0.0-1.0)\n- `maybeShowTip()`: selects and displays tip respecting --json and --quiet flags\n- `selectNextTip()`: filters eligible tips by condition + frequency, sorts by priority, applies probability roll\n- `BEADS_TIP_SEED` env var for deterministic testing\n- Metadata storage: `tip_{id}_last_shown` timestamp in database\n\nSelection algorithm:\n1. Filter to eligible tips (condition true AND frequency elapsed)\n2. Sort by priority (descending)\n3. Apply probability roll in priority order (higher priority tips get first chance)\n\nBuilt-in tips:\n- Claude setup: priority 100, 24h gap, 60% probability when Claude detected but not configured\n- Sync conflict: priority 200, no frequency limit, 100% probability (always show when sync broken)\n\nReference: `/Users/darin/Projects/beads-rs-macstudio/tmp/beads/cmd/bd/tips.go`\n\n**Design Notes**\n- Tips are informational, not errors (use stdout, not stderr)\n- Skip in JSON mode or quiet mode\n- Thread-safe tip registry with RwLock\n- InjectTip/RemoveTip for dynamic tips at runtime\n- Use chrono for time parsing/formatting (RFC3339)\n\n**Acceptance**\n- [ ] Tip struct with condition, message, frequency, priority, probability\n- [ ] maybeShowTip respects --json and --quiet\n- [ ] selectNextTip filters by condition and frequency\n- [ ] Priority-ordered probability rolls (higher priority first)\n- [ ] BEADS_TIP_SEED for deterministic testing\n- [ ] Built-in Claude setup and sync conflict tips\n- [ ] Metadata tracking (last shown timestamp)\n\n**Files:**\n- `src/cli/tips.rs` (new)\n- `src/cli/mod.rs` (integrate into post-command hook)","priority":2,"type":"feature","labels":{"entries":{},"cc":{"max":{}}},"status":"open","_at":[1768622413176,0],"_by":"darin@darinsmcstudio2.lan"}
{"id":"bd-zkjt","created_at":[1768824441845,0],"created_by":"darin@darinsmcstudio2.lan","title":"Replace unlock_store bool with enum in test fixture","description":"tests/integration/fixtures/store_lock.rs returns Result<bool> from unlock_store. Replace with an UnlockOutcome enum to encode whether the lock was removed or missing, and update call sites as needed.","acceptance_criteria":"- unlock_store returns UnlockOutcome enum\\n- call sites updated\\n- cargo check, cargo clippy -D warnings, cargo test pass","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768824646736,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768824646736,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768824646736,0]}
{"id":"bd-zl2m","created_at":[1768778065267,0],"created_by":"darin@darinsmcstudio2.lan","title":"Daemon admin tests use bd CLI; move to IPC for speed","description":"tests/integration/daemon/admin.rs currently shells out to  for init/create/admin status/metrics/etc. These are daemon-level tests and can use IpcClient + Request::* directly. Keep CLI JSON shape tests in tests/integration/cli instead. Should reduce process spawn overhead and runtime.","priority":2,"type":"chore","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768801183268,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768801183268,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768801183268,0]}
{"id":"bd-zl6d","created_at":[1768512765641,0],"created_by":"darin@darinsmcstudio2.lan","title":"Integration test failure: admin_status_monotonic_under_load timeout","description":"**Problem**\nadmin_status_monotonic_under_load fails with \"load generator did not finish within 3s\" at tests/integration/daemon/admin_status.rs:126. This failed in both runs: default integration suite and slow-tests suite. That suggests either a real performance regression or a too-tight timeout for current runtime behavior.\n\n**Repro**\n- cargo test --test integration (failed on 2026-01-15)\n- cargo test --test integration --features slow-tests (failed on 2026-01-15)\n\n**Files**\n- tests/integration/daemon/admin_status.rs\n- tests/integration/fixtures/load_gen.rs\n- src/daemon/* (mutation/apply/IPC throughput under load)","design":"Determine whether the load generator is actually slow (throughput regression) or the test’s 3s deadline is unrealistic. Add timing/logging to record generator throughput, daemon startup time, and status sampling timing. If behavior is correct but slower, adjust the test to wait on completion (with a higher cap based on configured workload), or reduce workload size. If there is a regression, profile the mutation path and fix the bottleneck.","acceptance_criteria":"- [ ] admin_status_monotonic_under_load completes within a realistic bound on typical dev machines and CI.\n- [ ] The test either uses a deadline proportional to workload or documents a tight SLA and enforces it intentionally.\n- [ ] cargo test --test integration --features slow-tests passes reliably.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768525466399,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768525466399,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768525466399,0]}
{"id":"bd-znle","created_at":[1769565897011,0],"created_by":"darin@darinsmcstudio2.lan","title":"mutation: required fields must be non-empty on update","description":"Problem\n- ParsedBeadPatch::parse only blocks Patch::Clear for title/description but allows Patch::Set(\"\") or whitespace.\n- Creates invalid state: required fields present but empty.\n- Create path enforces non-empty; update does not.\n\nImpact\n- Invariant drift between create/update; data quality issues and UI regressions.\n- Not encoded in types (string vs non-empty string).\n","design":"Design\n- Introduce NonEmptyString (or reuse existing type) for required fields at the parse boundary.\n- Normalize (trim) and reject empty values during ParsedBeadPatch::parse.\n- Make CanonicalBeadPatch carry validated non-empty strings for title/description patches, so downstream code never sees invalid values.\n\nScatter fit\n- Single validation point in parse; no downstream checks.\n\nFiles\n- crates/beads-rs/src/daemon/mutation_engine.rs\n- crates/beads-surface/src/ops.rs (if adding NonEmptyString)\n- crates/beads-core/src/event.rs (if validating patch types)","acceptance_criteria":"Acceptance\n- Update requests with title/description set to empty/whitespace are rejected with OpError::ValidationFailed.\n- Types prevent constructing a patch with empty required fields after parsing.\n- Tests cover update rejection and valid trimmed updates.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","notes":[{"id":"go-comment-bd-znle-1","content":"Rendering should stay in the command files themselves (no central render move).","author":"darin@darins-Mac-Studio-2.local","at":[1769597741143,0]},{"id":"legacy-notes","content":"Rendering should stay in the command files themselves (no central render move).","author":"darin@darinsmcstudio2.lan","at":[1769597866832,0]}],"_at":[1769597866832,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769597866832,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769597866832,0]}
{"id":"bd-zp59","created_at":[1769495915565,0],"created_by":"darin@darinsmcstudio2.lan","title":"Encode watermark snapshot invariants in repl protocol types","description":"**Problem**\nReplication watermarks are encoded as *two separate maps*: `WatermarkMap` (seqs) and `WatermarkHeads` (heads). This lets illegal states exist after parsing:\n- seq > 0 with missing head\n- seq = 0 with head present\n- heads map missing namespace/origin entries that exist in seq map\n\nWe then reconstruct `Watermark<K>` at runtime via `watermark_state_from_snapshot` and assume this “can’t be wrong” in downstream logic (`unreachable!` on unknown head). The compiler cannot enforce the invariant, and a malformed peer snapshot or refactor can surface as internal errors or panics.\n\nKey refs:\n- `crates/beads-rs/src/daemon/repl/proto.rs:22` — separate map types.\n- `crates/beads-rs/src/daemon/repl/session.rs:946` — runtime validation.\n- `crates/beads-rs/src/daemon/repl/gap_buffer.rs:293` — `unreachable!` on unknown head.\n\n**Impact**\nRepl correctness + robustness risk at protocol boundary. Invalid snapshots can crash or poison state.","design":"**Design (opinionated)**\nRepresent watermark invariants *in the type* at the protocol boundary.\n\n1) Replace split maps with a per‑origin entry type:\n- `struct WireWatermark { seq: Seq0, head: Option<Sha256> }`\n- `TryFrom<WireWatermark> for Watermark<K>` enforces:\n  - `seq == 0` => `head == None`\n  - `seq > 0` => `head == Some`\n\n2) Use a single snapshot map:\n- `type WatermarkSnapshotWire = BTreeMap<NamespaceId, BTreeMap<ReplicaId, WireWatermark>>`\n- Update `Hello`/`Welcome`/`Ack` to use `WatermarkSnapshotWire` (for durable/applied).\n\n3) Wire compatibility:\n- If backward compatibility is required, keep the same on‑wire shape but *decode into* `WireWatermark` and validate immediately. Encoding should never produce invalid pairs.\n\n4) Remove `watermark_state_from_snapshot` from callers.\n- Session/gap buffer should operate on `Watermark<K>` directly.\n- Eliminate `HeadStatus::Unknown` from the repl/session path or keep it strictly internal.\n\nThis makes snapshot invariants unrepresentable and catches mistakes at compile time.","acceptance_criteria":"**Acceptance**\n- [ ] There is no public API that can create a seq/head snapshot with invalid combinations.\n- [ ] `Hello`/`Welcome`/`Ack` decoding fails fast on invalid seq/head pairs.\n- [ ] Session/gap buffer code consumes typed `Watermark<K>` directly (no runtime `watermark_state_from_snapshot`).\n- [ ] No `unreachable!` remains in repl paths for `HeadStatus::Unknown`.\n- [ ] Tests cover invalid snapshots (missing head for seq>0, head present for seq=0) and round‑trip encoding.","priority":1,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@darins-Mac-Studio-2.local","_at":[1769521639117,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1769521639117,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1769521639117,0]}
{"id":"bd-zvn","created_at":[1765744929887,0],"created_by":"darin@darinsmcstudio2.lan","title":"Fix collision resolution: winner can be deleted by resolution tombstone","description":"**Problem**\nIn `src/git/collision.rs`, collision resolution remaps the loser and writes a tombstone for the old ID using a \"resolution stamp\". But the merge rule in `core/state.rs` is: tombstone wins unless the beads `updated_stamp()` is strictly newer.\n\nIf the tombstone stamp is newer than the winner beads updated stamp (likely, since resolution stamp is generated \"now\"), **the winner gets deleted during join**. This violates spec §4.1.1 (\"winner retains original id\") and is catastrophic.\n\n**Design Options**\n\n*Option A (cleanest):* Lineage-scoped tombstones\nTombstone includes the losing beads `created` stamp (or content-hash) so it only kills that lineage, not the winner occupying the ID.\n\n*Option B (minimal change):* Emit two stamps on collision resolution\n- `t_del` for the loser-id tombstone  \n- `t_win` for a no-op \"bump\" on the winner bead so `t_win > t_del`\nThis makes the winner survive the delete rule while preventing loser resurrection.\n\n**Acceptance**\n- [ ] Deterministic test: collision where winner is older, loser is newer, resolution happens later\n- [ ] Winner survives resolution in all timestamp orderings\n- [ ] Loser cannot resurrect after resolution\n- [ ] Spec compliance verified\n\n**Files:** src/git/collision.rs, src/core/state.rs","priority":0,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@dusk","_at":[1765773848939,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1765773848939,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1765773848939,0]}
{"id":"bd-zwn","created_at":[1768387630958,0],"created_by":"darin@darinsmcstudio2.lan","title":"critical_path test_update_bead flaky in parallel runs","description":"Full cargo test failed: test_update_bead saw type task after update. Running the test alone and critical_path with --test-threads=1 passes. Likely shared runtime dir/daemon across parallel tests.","priority":2,"type":"bug","labels":{"entries":{},"cc":{"max":{}}},"status":"closed","assignee":"darin@book","_at":[1768428574356,0],"_by":"darin@darinsmcstudio2.lan","closed_at":[1768428574356,0],"closed_by":"darin@darinsmcstudio2.lan","assignee_at":[1768428574356,0]}
