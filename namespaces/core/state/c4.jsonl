{"_at":[1769553104744,0],"_by":"darin@darinsmcstudio2.lan","assignee":"darin@darins-Mac-Studio-2.local","created_at":[1768689822716,0],"created_by":"darin@darinsmcstudio2.lan","description":"In repl_core_machine ordered-link mode, ActorWrapper uses StateWrapper with private wrapped_state, so we can't apply node-level invariants. Consider adding a local adapter or upstream accessor to expose the inner state (or expand history-based checks) so ordered-link runs the full property suite.","id":"bd-1nxv","labels":{"cc":{"max":{}},"entries":{}},"priority":2,"status":"closed","title":"Ordered-link repl model can't inspect wrapped state","type":"chore"}
{"_at":[1765785752083,0],"_by":"darin@darinsmcstudio2.lan","assignee":"darin@dusk","closed_reason":"Made imported comment NoteIds globally unique by including issue ID in the format: go-comment-{issue_id}-{comment_id}. Added tests to verify uniqueness across issues.","created_at":[1765690392995,0],"created_by":"darin@darinsmcstudio2.lan","description":"## What's Wrong\nGo comment notes are imported with `NoteId::new(c.id.to_string())`. If comment IDs are not globally unique across issues in beads-go exports, notes can collide and overwrite/merge unexpectedly.\n\n## Where\n- src/migrate/go_export.rs:288 (NoteId::new(c.id.to_string()))\n\n## Why It Matters\nData loss / silent merging during migration: two different comments could end up with the same note ID.\n\n## Suggested Fix\n- Make note IDs include the issue ID (and/or created_at) e.g. `go-comment-<issue-id>-<comment-id>`.\n- Add a migration test fixture with repeated comment IDs across different issues to verify uniqueness.\n\n## Acceptance\n- Import never drops/merges distinct comments due to note ID collisions.","id":"bd-3h8","labels":{"cc":{"max":{}},"entries":{}},"priority":2,"status":"closed","title":"Migration: make imported comment NoteIds globally unique","type":"bug"}
{"_at":[1768639205241,0],"_by":"darin@darinsmcstudio2.lan","acceptance_criteria":"- [ ] New proxy profile covers blackhole + reset behaviors.\n- [ ] New slow e2e uses ReplRig with the profile and passes locally.\n- [ ] Replication converges after faults; no hang.\n- [ ] Cleanup leaves no orphaned processes/sockets.\n- [ ] Tests write only under ./tmp.","assignee":"darin@book","created_at":[1768636568110,0],"created_by":"darin@darinsmcstudio2.lan","description":"**Problem**\nTailnet proxy + rig only cover loopback TCP; we do not exercise half-open resets, blackholes, or NAT-ish failures. This leaves a critical gap in confidence for real deployments where connections stall or reset mid-stream.","design":"**Design**\n- Extend `tailnet_proxy` to support a new profile that can: (a) accept and then blackhole reads/writes, (b) inject hard resets after N frames/bytes, and (c) simulate one-way loss.\n- Add a rig option to select this profile per link.\n- Add a slow e2e in `tests/integration/daemon/repl_e2e.rs` that runs under the new profile and asserts reconnection + convergence.","id":"bd-4p8l","labels":{"cc":{"max":{}},"entries":{}},"priority":0,"status":"closed","title":"Replication e2e under real network pathologies","type":"bug"}
{"_at":[1766124427691,0],"_by":"darin@darinsmcstudio2.lan","assignee":"darin@dusk","created_at":[1766122283056,0],"created_by":"darin@darinsmcstudio2.lan","description":"**Problem**\\nSync/load/refresh pathways have overlapping but different logic. Edge cases (diverged refs, remote missing ref, local ahead, dirty during refresh, rewritten history) are not fully covered by tests. This risks subtle data loss or confusing behavior.\\n\\n**Design**\\nAdd a focused sync-state test harness that builds local/remote repos and exercises: missing refs, local-ahead, remote-ahead, diverged, force-push rewrite, fetch failures, dirty during refresh. Assert invariants: no local data loss, backups created, errors surfaced. Consider consolidating merge logic into a single path to reduce divergence.\\n\\n**Acceptance**\\n- [ ] Tests cover diverged/local-ahead/force-push scenarios.\\n- [ ] Failures are explicit; no silent state drops.\\n- [ ] Backups created when local history would be overwritten.\\n- [ ] Tests pass.\\n\\n**Files:** src/git/sync.rs, src/daemon/core.rs, src/daemon/git_worker.rs, tests/critical_path.rs","id":"bd-8gt","labels":{"cc":{"max":{}},"entries":{}},"priority":1,"status":"closed","title":"Harden git sync state machine edge cases","type":"task"}
{"_at":[1768641572663,0],"_by":"darin@darinsmcstudio2.lan","acceptance_criteria":"- [ ] Stress test triggers WAL rotation and still converges.\n- [ ] Backpressure does not deadlock replication.\n- [ ] Tests write only under ./tmp.","assignee":"darin@book","created_at":[1768636593980,0],"created_by":"darin@darinsmcstudio2.lan","description":"**Problem**\nNo long-running/high-volume replication test exists, so WAL rotation/backpressure under load is unproven.","design":"**Design**\n- Add a slow e2e that lowers wal_segment_max_bytes in config, floods mutations across nodes, and asserts WAL segment rotation and replication catch-up.\n- Verify watermarks/head convergence and no permanent backpressure stalls.","id":"bd-bhj0","labels":{"cc":{"max":{}},"entries":{}},"priority":0,"status":"closed","title":"Replication stress + WAL rotation e2e","type":"bug"}
{"_at":[1767993540504,0],"_by":"darin@darinsmcstudio2.lan","acceptance_criteria":"- [ ] New model file exists (e.g., beads_stateright_models/examples/read_gating_machine.rs) and compiles\n- [ ] Properties cover correct gating and timeout semantics per REALTIME_PLAN.md §16.1\n- [ ] Example runs via cargo run --example read_gating_machine (or equivalent)","assignee":"darin@darinsmacstudio.lan","created_at":[1767985377496,0],"created_by":"darin@darinsmcstudio2.lan","description":"**Problem**\nRead gating semantics (require_min_seen + wait_timeout_ms) are specified in REALTIME_PLAN.md §16.1 but not modeled. Without a model, it is easy to return stale reads or mis-handle retryable timeouts.\n\n**Design Notes**\nModel reads against applied watermarks and a bounded wait timer.","design":"**Design**\nCreate a Stateright model for read gating that uses applied watermarks as the truth (Plan §16.1). Include read requests with require_min_seen and wait_timeout_ms, and allow nondeterministic apply progress. Model should return: success if applied >= required, wait up to timeout, else return retryable error with current applied watermark.\n\nProperties: no read is returned with applied < require_min_seen; timeout responses are retryable and include the current watermark snapshot.","id":"bd-hjm.11","labels":{"cc":{"max":{}},"entries":{"modeling":[{"counter":17600893606934670700,"replica":"a40c0e1d-c70d-328c-120f-51afd29ab862"}],"realtime":[{"counter":13204635967680667723,"replica":"2c5f9be0-c59b-931b-013f-8edfceac9a7c"}],"stateright":[{"counter":17427102999151873277,"replica":"6eba5db3-2465-48dc-b6a8-96e8d377bcc2"}]}},"priority":3,"status":"closed","title":"Stateright: require_min_seen read gating + timeouts","type":"feature"}
{"_at":[1769371351736,0],"_by":"darin@darinsmcstudio2.lan","assignee":"darin@book","created_at":[1769223994111,0],"created_by":"darin@darinsmcstudio2.lan","description":"**Problem**\n\n`bd` fails with `code=NotFound (-3)` when run from a jj-only workspace.\n\n**Root Cause**\n\nRepository discovery in `src/repo.rs` only looks for `.git` directories:\n\n1. `fast_repo_root()` walks up directories checking `dir.join(\".git\").exists()`\n2. Fallback `git2::Repository::discover()` also only finds `.git`\n\njj workspaces don't have `.git` - they have `.jj/repo/store/git_target` pointing to the backing git repo.\n\n**How jj Workspaces Work**\n\n```\n/main-repo/              # colocated repo (has both .git and .jj)\n├── .git/\n├── .jj/repo/store/\n│   ├── type           # contains \"git\"\n│   └── git_target     # contains \"../../../.git\" (relative)\n\n/workspace/              # jj-only workspace (no .git)\n├── .jj/repo/store/\n│   ├── type           # contains \"git\"  \n│   └── git_target     # e.g. \"../../../main-repo/.git\" (relative)\n```\n\nThe `git_target` file contains a relative path from `.jj/repo/store/` to the `.git` directory.\n\n**Design**\n\nExtend `fast_repo_root()` to also detect jj workspaces and resolve their backing git repo.\n\nAdd helper function `jj_git_repo_root()`:\n\n```rust\n/// Resolve jj workspace's backing git repo root, if this is a jj workspace.\nfn jj_git_repo_root(jj_dir: &Path) -> Option<PathBuf> {\n    let store_dir = jj_dir.join(\"repo/store\");\n\n    // Verify this is a git-backed jj repo\n    let type_file = store_dir.join(\"type\");\n    let backend_type = std::fs::read_to_string(&type_file).ok()?;\n    if backend_type.trim() != \"git\" {\n        return None;\n    }\n\n    // Read git_target (relative path to .git)\n    let git_target = store_dir.join(\"git_target\");\n    let target = std::fs::read_to_string(&git_target).ok()?;\n    let target = target.trim();\n\n    // Resolve relative path from store_dir\n    let git_path = store_dir.join(target);\n    let git_path = git_path.canonicalize().ok()?;\n\n    // git_target points to .git dir; return parent (repo root)\n    git_path.parent().map(|p| p.to_path_buf())\n}\n```\n\nModify `fast_repo_root()` to check for jj after checking for .git:\n\n```rust\nfn fast_repo_root(start: &Path) -> Option<PathBuf> {\n    let start = if start.is_absolute() {\n        start.to_path_buf()\n    } else {\n        std::env::current_dir().ok()?.join(start)\n    };\n\n    let mut current = Some(start.as_path());\n    while let Some(dir) = current {\n        // Check for .git first (standard git repo)\n        if std::fs::symlink_metadata(dir.join(\".git\")).is_ok() {\n            return Some(dir.to_path_buf());\n        }\n        // Check for .jj (jujutsu workspace)\n        let jj_dir = dir.join(\".jj\");\n        if std::fs::symlink_metadata(&jj_dir).is_ok() {\n            if let Some(git_root) = jj_git_repo_root(&jj_dir) {\n                return Some(git_root);\n            }\n        }\n        current = dir.parent();\n    }\n    None\n}\n```\n\n**Edge Cases**\n\n- Non-git jj backends (type != \"git\"): returns None, falls through to git2 discover which fails with appropriate error\n- Invalid/missing git_target: returns None\n- Colocated repos (.git and .jj both present): .git found first, works unchanged\n- Symlinked .jj directories: uses symlink_metadata, works correctly\n\n**Acceptance**\n\n- [ ] `bd list` works from jj-only workspace\n- [ ] `bd create` works from jj-only workspace\n- [ ] Colocated repos (with both .git and .jj) still work\n- [ ] Non-jj repos still work unchanged\n- [ ] Tests pass\n- [ ] clippy clean\n\n**Files:** `src/repo.rs`\n\n**Test workspace:** Created at `/Users/darin/Projects/beads-jj-fix` (jj-only, no .git)","id":"bd-ljbq","labels":{"cc":{"max":{}},"entries":{}},"priority":2,"status":"closed","title":"Support jj workspaces in repository discovery","type":"feature"}
{"_at":[1769593916887,0],"_by":"darin@darinsmcstudio2.lan","acceptance_criteria":"Acceptance\n- There is no mutation path that can add a DAG edge without a DepAddKey/NoCycleProof.\n- Compiler forces add paths to handle Acyclic vs Free keys explicitly.\n- Tests cover: cycle detection for Blocks/Parent; Related/DiscoveredFrom bypass DAG checks but still validated.\n- Existing behavior preserved for valid inputs.","assignee":"darin@darins-Mac-Studio-2.local","created_at":[1769565869849,0],"created_by":"darin@darinsmcstudio2.lan","description":"Problem\n- plan_add_dep builds raw DepKey + ad-hoc check_no_cycle, then emits WireDepAddV1.\n- The NoCycleProof/DepAddKey types exist but aren't used here, so the compiler can't enforce that DAG checks happened.\n- A future refactor can bypass the cycle check without the type system noticing.\n\nImpact\n- Cycle invariants for Blocks/Parent depend on discipline instead of types.\n- Violates parse-don't-validate and \"types should tell the truth\".\n","design":"Design\n- Make MutationEngine add deps through DepAddKey only:\n  - Use state.check_dep_add_key(key) to return DepAddKey (Acyclic|Free).\n  - Change WireDepAddV1 (or an internal wrapper) to carry DepAddKey, or make the add path require a DepAddKey parameter.\n- Option A: introduce a ValidatedDepAdd type in core (mirrors ValidatedBeadPatch) that only constructs from DepAddKey; mutation_engine must build that.\n- Option B: split add ops in mutation engine: add_dep_acyclic requires NoCycleProof, add_dep_free does not; prohibit raw DepKey in the API.\n- Ensure all dependency adds (including create's dependency list and SetParent path) go through the same typed gate.\n\nScatter fit\n- One entry point (check_dep_add_key) owns DAG validity; call sites no longer repeat or forget checks.\n\nFiles\n- crates/beads-rs/src/daemon/mutation_engine.rs\n- crates/beads-core/src/dep.rs\n- crates/beads-core/src/state.rs\n- crates/beads-core/src/event.rs (if adding ValidatedDepAdd)","id":"bd-uakj","labels":{"cc":{"max":{}},"entries":{}},"priority":1,"status":"closed","title":"mutation: dep adds must carry DAG proof types","type":"bug"}
